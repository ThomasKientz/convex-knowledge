# Convex Knowledge Base

This document contains comprehensive Convex knowledge including development patterns, official documentation, and helper utilities.

---

# Development Patterns

# AI Agents with Built-in Memory 

Are you trying to build an Agent? An Agentic Workflow? An AI ChatBot?
One of the challenges of building multi-step flows is managing the persistent state (e.g. chat messages) through a web of steps with different agents, and intelligently retrieve them for prompt context in the future. The new Agent component allows you to rapidly define and build agents, and incorporate them into complex workflows.

Some of the things [Agent component](https://www.convex.dev/components/agent) makes easy for you:

- Automatically store messages in user-specific threads that be handed off between agents.
- Search messages via hybrid text and vector search and inject them as context (opt-in and configurable).
- Define and use tool calling that support real-time, reactive queries so clients can see progress of asynchronously-executing workflows.

## What’s an agentic workflow

There’s been a lot of interest recently in making asynchronous agentic workflows with memory.

Here’s what I mean by those terms:

- **Asynchronous:** Long-lived operations that either happen from a user-initiated action, like asking a question in a support chat, or a trigger: a web hook, cron, or previously scheduled function.
- **Agentic:** Conceptual units of responsibility that are “responsible” for something specific and have a set of actions (tools) available to them. Most often these look like calling an LLM.
- **Workflow**: A set of functions that get called, passing context from one to another. The simplest version of this is a single function that calls agents (functions) and eventually returns a result. A fancy version of this looks like the [Workflow component](https://www.convex.dev/components/workflow) with Inngest-inspired syntax that runs durably (more on that below).
- **Memory:** Contextual data that is saved and retrieved, for the use of informing future chats. This could be previous chat messages, use-case-specific data, or in the case of [AI Town](https://www.convex.dev/ai-town), reflections on conversations and previous memories.

#### Is this a new concept?

If you’re familiar with RAG, tool-calling, mixture of experts, dynamic dispatch, and durable functions, this should all be familiar. If not, don’t sweat it; fancy words are often simple concepts. The “tricks” involved are:

- Break down a given task into pieces accomplished by specific LLMs models with domain-specific prompting.
- Provide context to the LLM by using some combination of vector, text, and recency searches.
- Allow the LLM to decide to “call out” to a “tool” when it needs more information or wants to take action. A good example of this is reading/writing code in a GitHub repo.
- Run the workflow “durably” - allowing each unreliable step to have some retry behavior, and allow the overall function to recover after server crashes, always running to completion. [Read more about why I’m excited about that here](https://stack.convex.dev/durable-workflows-and-strong-guarantees).

## What does it look like

To get concrete, let’s look at defining an agent using my new [Agent component](https://www.convex.dev/components/agent)

### Defining an agent

```tsx
import { Agent } from "@convex-dev/agent";
import { components, internal } from "./_generated/api";
import { openai } from "@ai-sdk/openai";

const supportAgent = new Agent(components.agent, {
  chat: openai.chat("gpt-4o-mini"),
  textEmbedding: openai.embedding("text-embedding-3-small"),
  instructions: "You are a helpful assistant.",
9});

```

### Starting a conversation

```tsx
export const createThread = action({
  args: { prompt: v.string() },
  handler: async (ctx, { prompt }) => {
4+   const { threadId, thread } = await supportAgent.createThread(ctx, {});
5+   const result = await thread.generateText({ prompt });
    return { threadId, text: result.text };
  },
8});

```

### Continuing a conversation

```tsx
export const continueThread = action({
  args: { prompt: v.string(), threadId: v.string() },
  handler: async (ctx, { prompt, threadId }) => {
    // This includes previous message history from the thread automatically.
5+   const { thread } = await supportAgent.continueThread(ctx, { threadId });
6+   const result = await thread.generateText({ prompt });
    return result.text;
  },
9});

```

### Using tools

Tools are functions that the LLM can call. We use the [AI SDK Tool](https://sdk.vercel.ai/docs/ai-sdk-core/tools-and-tool-calling) syntax

Configuring tools:

```tsx
const supportAgent = new Agent(components.agent, {
  chat: openai.chat("gpt-4o-mini"),
  textEmbedding: openai.embedding("text-embedding-3-small"),
  instructions: "You are a helpful assistant.",
5+ tools: { accountLookup, fileTicket, sendEmail },
6});
//...
  // or per-invocation in an action
  await thread.generateText({
    prompt,
11+   tools: { accountLookup, fileTicket, sendEmail },
  });

```

Defining Convex tools that have access to the function’s context, including `userId`, `threadId`, `messageId`, and the action `ctx` object which you can use to call queries, mutations, or actions:

```tsx
export const ideaSearch = createTool({
  description: "Search for ideas by space-delimited keywords",
  args: v.object({ search: v.string() }),
4+ handler: async (ctx, { search }): Promise<Doc<"ideas">[]> =>
5+    ctx.runQuery(api.ideas.searchIdeas, { search }),
6});

```

### Incorporating into a durable workflow

```tsx
import { components, internal } from "./_generated/api";
import { WorkflowManager } from "@convex-dev/workflow";

const workflow = new WorkflowManager(components.workflow);
// The `internal.example.foo` syntax is a Convex function reference
const supportAgent = ;

export const supportAgentWorkflow = workflow.define({
  args: { prompt: v.string(), userId: v.string() },
  handler: async (step, { prompt, userId }) => {
11+   const { threadId } = await step.runAction(
12+	    internal.example.supportAgentStep,
13+	    { createThread: { userId },
    );
15+   const result = await step.runAction(
16+	    internal.example.supportAgentStep,
17+     supportAgentStep, { threadId, generateText: { prompt } }
    );
    console.log(result);
    // Call other agents here
  },
22});

```

### Subscribing to asynchronously-generated messages

This will fetch the thread’s messages, and re-run whenever new messages are created (within the query range). React clients can subscribe to the results with `useQuery`.

```tsx
export const getThreadMessages = query({
  args: { threadId: v.string() },
  handler: async (ctx, { threadId }) => {
4+   return await ctx.runQuery(
5+     components.agent.messages.getThreadMessages,
6+     { threadId, limit: 100 });
  },
8});

```

### Using a user’s previous conversations as context manually

If you don’t want the automatic behavior, you can fetch messages yourself

```tsx
const messages = await supportAgent.fetchContextMessages(ctx, {
  userId,
  messages,
  recentMessages: 10,
  includeToolCalls: false,
  searchOtherThreads: true,
  searchOptions: {
    limit: 10,
    textSearch: true,
    vectorSearch: true,
    messageRange: { before: 2, after: 1 },
  },
13});
// do customization and add a final prompt message
const result = await thread.generateText({
  messages,
  saveAllInputMessages: false,
  saveAllOutputMessages: false,
  recentMessages: 0,
  searchOptions: { limit: 0 },
21});

```

### Retrying pesky LLMs who mean well but frequently goof up

Per-agent call retries (immediate, accounting for LLM blips):

```tsx
const supportAgent = new Agent(components.agent, {
  chat: openai.chat("gpt-4o-mini"),
  textEmbedding: openai.embedding("text-embedding-3-small"),
  instructions: "You are a helpful assistant.",
  maxRetries: 3,
6});

```

Retrying the whole action if the server restarts or the API provider is having issues by using the Workpool or Workflow components. This will use backoff and jitter to avoid thundering herds.

Workpool:

```tsx
const workpool = new Workpool(components.workpool, {
  maxParallelism: 10,
  retryActionsByDefault: true,
  defaultRetryBehavior: {
    maxAttempts: 5,
    initialBackoffMs: 1000,
    base: 2,
  },
9});

```

Workflow:

```tsx
const workflow = new WorkflowManager(components.workflow, {
  workpoolOptions: {
    maxParallelism: 10,
    retryActionsByDefault: true,
    defaultRetryBehavior: {
      maxAttempts: 5,
      initialBackoffMs: 1000,
      base: 2,
    },
  },
11});

```

## How does it work

Under the hood, it stores threads, messages, and steps separate. Steps are more verbose outputs of each tool call and generated message, with enough metadata to inspect usage, replay exact requests, etc.

When you make a call from the thread-specific functions, it saves the input prompt (or the last message if you pass in an array of message[1](https://stack.convex.dev/ai-agents#user-content-fn-1)), and as it executes, it saves intermediate steps as it goes. It marks it all as pending until it’s done. If it fails and you call it again, it’s useful to not include the previous partial results, so if it sees pending steps when starting, it will mark them as failed.

The messages and steps are query-able by thread, status, and whether they’re tool calls or not, so you can subscribe to only what you need, avoiding excessive database bandwidth and function calls.

If you provide a text embedder, it will asynchronously generate embeddings for each message, once it completes successfully (no embeddings of results that end up failing). These will be available to vector search per-thread and per-user, if the thread is user-specific.

If you don’t provide a user when initializing the thread, it will only search messages from that thread. If you do provide a `userId` to `createThread` and `continueThread`, you can opt-in to searching that users’s messages in any thread by passing `searchOtherThreads: true`.

## Should I do it myself or use a framework?

Yes! By that I mean, it depends. **tldr:** use a framework until you have a specific need, and pick a framework that makes the off-ramp easy.

#### Use a framework

With any framework or abstraction, it provides value by being opinionated. C is more restricted and opinionated than assembly. React is more restricted and opinionated than raw html.

By using a framework:

1. You get started faster versus reinventing abstractions. It’s fun to implement RAG the first time, less so the tenth.
2. You leverage work that improves over time, with a simple `npm upgrade`.
3. There are cohesive possibilities, for instance combining message history with usage tracking or rate limiting.

#### Don’t use a framework

However, sometimes those opinions can get in the way. From what I hear, most “real” apps abandon LangChain once they want more control over the prompting and internals. Michal [wrote up a good piece about this](https://stack.convex.dev/are-vector-databases-dead#langchain) a year ago after implementing RAG three ways.

The specific pitfalls of these libraries:

1. It isn’t clear what it will and won’t do, or how it works. Ideally it uses existing language, concepts, and syntax, unless there’s an important reason to invent a new concept. For instance, while there are arguably better APIs for LLMs than OpenAI’s `{ role: "user", content: prompt }`, it’s become a de-facto standard and a reasonable enough API.
2. They don’t expose enough knobs and dials so users can tune the prompt to their use-case. In my case, exposing custom system prompts and parameters to determine how many messages to fetch, whether to use text and/or vector search, and how much context around those messages to fetch.
3. They are monolithic. They don’t allow using composable pieces, for instance being able to use it for message querying and storage but calling the LLM with custom context.
4. They use Domain-Specific Languages instead of allowing writing “just code.” While they can aim to be infinitely flexible, code ends up being more readable and composable in my opinion. DSLs are great for many use-cases, but when you want more control, it’s nice to have an escape hatch.

I tried my best to avoid these with my Agent component. If you have thoughts or opinions, please open [a GitHub issue](https://github.com/get-convex/agent/issues)! 🙏

#### Do both

As an example (and because I just released it and am proud of it), here’s how you could use pieces of my component, without buying into the whole system:

- You can call them synchronously from clients, or asynchronously produce results that users can subscribe to via [queries](https://docs.convex.dev/tutorial/).
- You can call the agents directly from Convex HTTP endpoints or serverless functions. You don’t have to use the fancy Workflow component.
- You can pass in custom context (messages) and not have it do any automatic context injection. This is useful if you’re pulling data from your own database tables or third-party resources.
- You can do message search without calling an LLM, if you want to leverage its memory and modify it before making the call to generate anything.
- You can save messages explicitly, instead of having it save them by default.
- You can use any third-party tool that works with the AI SDK and can run in a serverless function (think: AWS lambda Node environment, with some limits on bundle and memory size).
- You can create, paginate, modify, and delete the underlying embeddings. This is useful if you want to re-embed everything with a new model. By default, embeddings are isolated by model and embedding size, so you’ll never get results from a different model’s vector.
- You can wrap tools with your own code, to add custom logic, validation, guardrails or transformations.

## A platform that grows with you

If you aren't excited yet, here's some features that the component can support in the future, by using this foundation:

- Per-user usage tracking for tokens.
- Rate limiting configurations per-user to prevent abuse from individual users or global limits to avoid hitting external API limits.
- Dashboard playground UI to:
  - Visualize tool calling graphs.
  - Inspect and replay past conversations while tuning prompts.
  - Interactively debug failed generations.
  - Search messages while tuning search parameters for your usecase.
  - Replaying failed steps and exporting evals to prevent regressions once you get it working.
- Nested agents as tools in other agents, to allow automatic dispatching from agents to each other automatically. One decision here is whether to fail the whole graph if one agent fails, and whether to roll the whole graph back if failure is detected later on.
- File-search and other memory: upload data per-user or globally to use for vector search for RAG. You can already do this in Convex by chunking, embedding and searching yourself, but Agent can make it easy and automatic.
- A “virtual file system” tool so agents can take actions on files with file version control: especially helpful for apps doing code generation.
- Embedding-based agent router for faster RAG by using [Guardrails, or Semantic Vector Spaces](https://www.pinecone.io/learn/fast-retrieval-augmented-generation/#RAG-with-Guardrails) to decide what to do, instead of asking an LLM.
- A “working memory” context feature that the LLM can periodically update on a per-thread basis.

Whether and when I build these will depend on your feedback , so let me know in [GitHub issues](https://github.com/get-convex/agent/issues) what sounds useful to you.

## Summary

With agents you can organize and orchestrate complex workflows. With the new Agent component, you can store and retrieve message history automatically.

As always, let me know what you think [in Discord](https://convex.dev/community), on [🦋](https://bsky.app/profile/ianmacartney.bsky.social)  or on [𝕏](https://x.com/ianmacartney)

### Footnotes

1. If you pass `saveAllInputMessages: true` it will save all of the messages automatically. The default is `false` since it’s common to pass in a lot of custom context that should not be saved, then a final question. [↩](https://stack.convex.dev/ai-agents#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# AI Chat with HTTP Streaming

[This article](https://stack.convex.dev/gpt-streaming-with-persistent-reactivity) describes how to build a chat app with ChatGPT by streaming text from OpenAI to the Convex database and ultimately to clients with the app loaded. This provides a super responsive experience for everyone using the app, but it can require a lot of database bandwidth since we’re rewriting the document with the message on every streamed update we get from OpenAI.

In this article, we’ll go through an extension to this approach — using [HTTP actions](https://docs.convex.dev/functions/http-actions) with streaming. The end result will be that we can get the responsive, nearly character by character streaming for the user ChatGPT is responding to, while every other client sees updates in larger chunks (and we save on bandwidth).

The full code for this is available [here](https://github.com/sshader/streaming-chat-gpt) but we’ll walk through the most interesting parts below.

![GIF showing two users using the chat app](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fe507ec7431eabc97ee0d8ee3a86b62b66de0738e-640x422.gif&w=3840&q=75)GIF showing two users using the chat app

![Diagram showing data flow for this app](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F6faefc0031e5820043df2eec5af795358b4996b7-1017x621.png&w=3840&q=75)Diagram showing data flow for this app

Above is a diagram showing how data flows in this app. Users are able to send messages using a mutation ( `send`) and read message using a query ( `list`).

When a user sends a message that needs a response from ChatGPT, the `send` mutation returns a result that the client uses to call an HTTP endpoint `/chat`. This endpoint talks to OpenAI, streaming a response from ChatGPT.

Here’s what the client portion of this looks like:

```typescript
// src/App.tsx
// https://github.com/sshader/streaming-chat-gpt/blob/main/src/App.tsx#L84
async function handleGptResponse(
  onUpdate: (update: string) => void,
  requestBody: { messageId: Id<"messages">; messages: Doc<"messages">[] }
6) {
  const convexSiteUrl = import.meta.env.VITE_CONVEX_URL.replace(
    /\.cloud$/,
    ".site"
  );
  const response = await fetch(`${convexSiteUrl}/chat`, {
    method: "POST",
    body: JSON.stringify(requestBody),
    headers: { "Content-Type": "application/json" },
  });
  // Taken from https://developer.mozilla.org/en-US/docs/Web/API/Streams_API/Using_readable_streams
  const responseBody = response.body;
  const reader = response.body.getReader();
  while (true) {
    const { done, value } = await reader.read();
    if (done) {
      onUpdate(new TextDecoder().decode(value));
      return;
    }
    onUpdate(new TextDecoder().decode(value));
  }
27}

```

and when a user sends a message:

```tsx
// src/App.tsx
// https://github.com/sshader/streaming-chat-gpt/blob/main/src/App.tsx#L53
3<form
	onSubmit={async (e) => {
		e.preventDefault();
		const result = await sendMessage({
			body: newMessageText,
			author: NAME,
		});
		setNewMessageText("");
		// Kick off ChatGPT response + stream the result
		if (result !== null) {
			await handleGptResponse((text) => {
				// TODO: make the streamed message appear to the user
				console.log(text);
			}, result);
		}
	}}
	>
	{ /* ... */ }
21</form>

```

We stream every chunk of this response to the client in the `Response` of our HTTP endpoint, and periodically update the database with everything we’ve streamed so far. This is adapted from [this example](https://developers.cloudflare.com/workers/examples/openai-sdk-streaming/) using Cloudflare workers.

```typescript
// convex/http.ts
// https://github.com/sshader/streaming-chat-gpt/blob/main/convex/http.ts#L20
http.route({
	path: "/chat",
	method: "POST",
	handler: httpAction(async (ctx, request) => {
		// Create a TransformStream to handle streaming data
		let { readable, writable } = new TransformStream();
		let writer = writable.getWriter();
		const textEncoder = new TextEncoder();

		const streamData = async () => {
			let content = "";
			const openai = new OpenAI();
			const stream = await openai.chat.completions.create({
				model: "gpt-3.5-turbo",
				messages: [/* ... */],
				stream: true,
			});

			for await (const part of stream) {
				const text = part.choices[0]?.delta?.content || "";
				content += text;

				// write to this handler's response stream on every update
				await writer.write(textEncoder.encode(text));
				// write to the database periodically, like at the end of sentences
				if (hasDelimeter(text)) {
					await ctx.runMutation(internal.messages.update, {
						messageId,
						body: content,
						isComplete: false,
					});
				}
			}

			// flush any last updates
			await ctx.runMutation(internal.messages.update, {
				messageId,
				body: content,
				isComplete: true,
			});
			await writer.close();
		};

		// kick off the request to OpenAI, but don't `await` it, so we can start sending
		// the response. Convex will wait until `writer.close`.
		void streamData();

		// Send the readable back to the browser
		return new Response(readable);
	}),
53});

```

Note: we additionally have to set up CORS to allow our browser to request our HTTP action. There’s an example of this in the [repo](https://github.com/sshader/streaming-chat-gpt/blob/cb1528a345cca6d85dc8d629a80db4fe948c8c29/convex/http.ts#L106), and [Will it CORS?](https://httptoolkit.com/will-it-cors/) is a great resource for setting up CORS correctly.

To show the streamed response immediately on the client, we’ll essentially be building an optimistic update. We’ll store the ID and text of the message we’re receiving from ChatGPT via our HTTP endpoint, and show this text instead of the text returned by `useQuery`. Once the message returned by `useQuery` is complete, we’ll “drop” our optimistic update and start showing the text returned by `useQuery` (which should be exactly the same, provided there were no errors).

Here’s what this looks like in code:

```tsx
export default function App() {
	// Hold state for a message we're streaming from ChatGPT via an HTTP endpoint,
	// which we'll apply on top
	const [streamedMessage, setStreamedMessage] = useState("");
	const [streamedMessageId, setStreamedMessageId] = useState<Id<"messages"> | null>(null);

	useEffect(() => {
		const message = messages.find((m) => m._id === streamedMessageId);
		if (message !== undefined && message.isComplete) {
			// Clear what we streamed in favor of the complete message
			setStreamedMessageId(null);
			setStreamedMessage("");
		}
	}, [messages, setStreamedMessage, setStreamedMessageId]);

	return <main>
		{/* .... */}
		{messages.map((message) => {
		const messageText = streamedMessageId === message._id
			? streamedMessage
			: message.body;
		return (
			<article
			key={message._id}
			className={message.author === NAME ? "message-mine" : ""}>
				<div>{message.author}</div>
				<p>{messageText}</p>
			</article>
			);
		})}
		{/* ... */ }
  </main>
33}


```

```tsx
// src/App.tsx
// https://github.com/sshader/streaming-chat-gpt/blob/main/src/App.tsx#L53
3<form
	onSubmit={async (e) => {
		e.preventDefault();
		const result = await sendMessage({
			body: newMessageText,
			author: NAME,
		});
		setNewMessageText("")
		// Kick off ChatGPT response + stream the result
		if (result !== null) {
			setStreamedMessageId(result.messageId)
			await handleGptResponse((text) => {
				setStreamedMessageText((t) => t + text)
			}, result);
		}
	}}
19>
20{/* ... */}
21</form>

```

### Summary

By leveraging HTTP actions with streaming, this chat app balances real-time responsiveness with efficient bandwidth usage. Users receive character-by-character updates to their own responses directly from ChatGPT, while other users see periodic updates, minimizing database bandwidth.

The full code for this app can be found below:

[sshader/ **streaming-chat-gpt**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/sshader/streaming-chat-gpt)

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Anonymous Users via Sessions

When building a new app, it can be challenging to build much behavior without the notion of a user. However, getting users to sign up for a new service before seeing any benefits is challenging. Signing up is cumbersome, and many people don’t want to share their personal information with a company until they want a long-standing relationship. In this post, we’ll discuss how to model ephemeral users, leveraging the session helpers duscussed in [this post](https://stack.convex.dev/track-sessions-without-cookies). We’ll also discuss the challenges with anonymous auth.

As a real example, while building a [multiplayer Dall-E-based game](https://stack.convex.dev/building-a-multiplayer-game), one goal is to be able to play with the game without having to log in first. However, we also want users to be able to log in eventually, use their profile picture, access old games, or log back into games on a different device or browser tab.

Instead of passing session IDs around for the game, we create a user when the session is created and use that user ID. This way, we can pass around user IDs (which, in general, shouldn’t be treated as secrets) and still have a persistent shared identifier between the client and the server.

## Storing anonymous users in the “users” table

To illustrate the session middleware, I made a [demo app](https://github.com/get-convex/convex-demos/tree/main/sessions) in our [convex-demos repo](https://github.com/get-convex/convex-demos).

The app is a clone of our [tutorial demo](https://github.com/get-convex/convex-demos/tree/main/tutorial), which is a basic chat app. The tutorial generates a random user name on the client when the page loads and sends that string whenever it sends a message. The basic demo has these two downsides that sessions fixes:

- Refreshing the page changes your user name.
- An updated name isn’t reflected in past messages.

Note: Below we'll discuss where `ctx.user` and `ctx.sessionId` come from.

**Persisting user name:**

We can keep your name constant using sessions by storing it a users table, which has a sessionId field we can look it up by. Instead of initializing the random user name in the client, we write it to the users table along with the associated sessionsId when [updating the name](https://github.com/get-convex/convex-demos/blob/main/sessions/convex/name.ts#L18):

```ts
export const set = mutationWithSession({
  args: { name: v.string() },
  handler: async (ctx, { name }) => {
    if (ctx.user) {
      await ctx.db.patch(ctx.user._id, { name });
    } else {
      await ctx.db.insert("users", { name, sessionId: ctx.sessionId });
    }
  },
10});

```

This way, when the user reloads the page, it will read the existing session ID from the browser (in localStorage or sessionStorage, whichever you configured) and use the existing session name.

**Using anonymous users relationally:**

In the [users-and-auth demo](https://github.com/get-convex/convex-demos/tree/main/users-and-auth), we solve updating names by associating each message with a `userId` instead of the user name string. When listing the messages, it would look up the user name on the fly, so the messages always reflected the latest name. The [session demo](https://github.com/get-convex/convex-demos/tree/main/sessions)'s approach is similar, in that it associates a `userId` with a message. It finds or creates the `userId` based on the current `sessionId`. This means updates to the user name will be reflected in old messages:

![Chat app in the sessions demo](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F9e4b93acdb6951017419169dbea1e1df373cdd75-960x510.gif%3Fw%3D450&w=3840&q=75)Chat app in the sessions demo

To send a message, we can get or create a user as follows:

```ts
// in convex/messages.ts
export const send = mutationWithSession({
  args: { body: v.string() },
  handler: async (ctx, { body }) => {
    let userId = ctx.user?._id;
    if (!userId) {
      const { sessionId } = ctx;
      userId = await ctx.db.insert("users", { name: "Anonymous", sessionId });
    }
    await ctx.db.insert("messages", { body, author: userId });
  },
12});

```

### Using custom functions for `ctx.user` and `ctx.sessionId`

You might have noticed a nice `ctx.user` and `ctx.sessionId` magically appearing for these `mutationWithSession` and `queryWithSession` functions. Those are defined in [convex/lib/sessions.ts](https://github.com/get-convex/convex-demos/blob/main/sessions/convex/lib/sessions.ts#L33) using the [custom functions introduced in this post](https://stack.convex.dev/custom-functions).

They let you do things like:

```ts
async function getUser(ctx: QueryCtx, sessionId: SessionId) {
  const user = await ctx.db
    .query("users")
    .withIndex("by_sessionId", (q) => q.eq("sessionId", sessionId))
    .unique();
  return user;
7}

export const mutationWithSession = customMutation(mutation, {
  args: SessionIdArg,
  input: async (ctx, { sessionId }) => {
    const user = await getUser(ctx, sessionId);
    return { ctx: { ...ctx, user, sessionId }, args: {} };
  },
15});

```

Then anyone defining a `mutationWithSession` will have the ctx also include the `user` and `sessionId`. The `useSessionMutation` react hook will automatically pass up the `sessionId`. See [this post](https://stack.convex.dev/track-sessions-without-cookies) for more details on how that works.

### Tips & Gotchas

If you want a very lightweight solution, it doesn’t get much simpler than this. However, with its simplicity comes a limitation of what it can represent.

**If your app will have logged-in users who will interact with anonymous users**, it is awkward to have to look in two different places for users and store two different kinds of IDs depending on which type they are. You might consider having a single "users" table and an `isAnonymous` boolean field.

**If your app can have multiple sessions per user** you'll want to have a separate table that keeps track of `sessionId` s and `userId` s as a [many-to-many table](https://stack.convex.dev/relationship-structures-let-s-talk-about-schemas#many-to-many), instead of storing it in the users table directly.

**If you want to keep session IDs private** you should avoid passing around session IDs as user identifiers. The session ID is essentially the user's credential. So if anyone else has their ID, their requests can impersonate the user. Check out [built-in auth](https://docs.convex.dev/auth/functions-auth). Generally don't return the sessionId associated with other users.

## Summary

In this post, we looked at a couple of strategies for managing user information without requiring a login. Follow along with the multiplayer game using OpenAI [here](https://stack.convex.dev/building-a-multiplayer-game).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Argument Validation without Repetition

When developing Convex apps with TypeScript, you’ll achieve the fastest iteration cycle and best developer experience once you’ve streamlined how schema enforcement, argument validation, and end-to-end type hinting all work together in your app.

In the first post in this series, the [Types and Validators cookbook](https://stack.convex.dev/types-cookbook), we shared several basic patterns & best practices for organizing your codebase to share types & validators from your schema, which becomes the central source of truth for your data model.

In this post, we’ll take it one step further and introduce a few more advanced techniques & helpers to accelerate the development workflow in your Convex projects.

### Review: reuse schema field declarations

As mentioned in the [previous post](https://stack.convex.dev/types-cookbook), you can define validators describing your data model in your schema file, then export them for use across your codebase like so:

```tsx
// in convex/schema.ts
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export const recipeFields = {
  name: v.string(),
  course: v.union(
    v.literal("appetizer"),
    v.literal("main"),
    v.literal("dessert")
  ),
  ingredients: v.array(v.string()),
  steps: v.array(v.string()),
14};

export default defineSchema({
  recipes: defineTable(recipeFields).index("by_course", ["course"]),
18});

```

The exported object can then be used wherever you need data of the same shape, for example to validate arguments of an `addRecipe` mutation that inserts a new document:

```tsx
// in convex/recipes.ts
import { mutation } from "./_generated/server";
import { recipeFields } from "./schema";

export const addRecipe = mutation({
  args: recipeFields,
  handler: async (ctx, args) => {
    return await ctx.db.insert("recipes", args);
  },
10});

```

And to ensure your frontend is also typed accordingly, the generated `Doc<table>` generic type, along with handy utilities like `WithoutSystemFields<document>`, ensures your client-side code matches the data model defined by your schema:

```tsx
// in src/NewRecipePage.tsx

import { api } from "../convex/_generated/api";
import type { Doc } from "../convex/_generated/dataModel";
import type { WithoutSystemFields } from "convex/server";

export function SaveRecipeButton({
  recipeData,
9}: {
  recipeData: WithoutSystemFields<Doc<"recipes">>,
11}) {
  const createRecipe = useMutation(api.recipes.create);
  const onClick = () => createRecipe(recipeData);
  return <button onClick={onClick}>Save recipe</button>;
15}

```

### Put TS utility types to work

Sometimes you only want to work with a specific subset of the fields for a given table. On the client side, you can use TypeScript’s builtin [`Pick`](https://www.typescriptlang.org/docs/handbook/utility-types.html#picktype-keys) and [`Omit`](https://www.typescriptlang.org/docs/handbook/utility-types.html#omittype-keys) utility types to specify exactly which fields are needed:

```tsx
// in src/Cookbook.tsx
type RecipeSummary = Pick<Doc<"recipes">, "name" | "course">;
type UncategorizedRecipe = Omit<Doc<"recipes">, "course">;

function RecipeHeader({ recipe }: { recipe: RecipeSummary }) {
  return (
    <h1>
      {recipe.name} ({recipe.course})
    </h1>
  );
11}

function RecipeDetails({ recipe }: { recipe: UncategorizedRecipe }) {
  return (
    <p>
      {recipe.name}: {recipe.steps.length} steps
    </p>
  );
19}

```

Similarly, you can use TypeScript’s builtin [`Partial`](https://www.typescriptlang.org/docs/handbook/utility-types.html#partialtype) to make an all-fields-optional type for those cases where you’re not sure which subset of a document might be needed. This comes in handy when patching documents, for example:

```tsx
// in src/Cookbook.tsx
import { useMutation } from "convex/react";
import { api } from "../convex/_generated/api";
import type { Id, Doc } from "../convex/_generated/dataModel";

function RecipeEditor({ recipeId: Id<'recipes'> }) {
	const updateRecipe = useMutation(api.recipes.update);

	// in response to some user input...
  const newData: Partial<Doc<'recipes'>> = {
		name:  'Sweeter recipe name',
		course: 'dessert'
  });
	updateRecipe(recipeId, newData);
15}


```

### Choose validator subsets with object destructuring

Similar to `Pick` in TypeScript, object de-structuring helps you derive subsets of the validators exported from your schema, and use these to validate function arguments:

```tsx
// in convex/recipes.ts
import { query} from "./_generated/server";
import { recipeFields } from "./schema";

const { course } = recipeFields;

export const findRecipesByCourse = query({
  args: { course },
  handler: async (ctx, args) => {
    return await ctx.db
      .query("recipes")
      .withIndex("by_course", (q) => q.eq("course", args.course))
      .collect();
  },
15});

```

And analogous to TypeScript’s `Omit`, combining de-structuring with the rest operator ( `...`) lets you ignore certain field validators and work with just those that remain:

```tsx
// in convex/recipes.ts
import { mutation } from "./_generated/server";
import { recipeFields } from "./schema";

const { course, ...recipeWithoutCourse } = recipeFields

export const addDessert = mutation({
  args: recipeWithoutCourse,
  handler: async (ctx, args) => {
    return await ctx.db.insert("recipes", { ...args, course: "dessert" });
  },
12});

```

### `Table` helper for schema definition & validation

[get-convex/ **convex-helpers**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/get-convex/convex-helpers)

The [`convex-helpers`](https://github.com/get-convex/convex-helpers) library provides a convenient [`Table` helper](https://github.com/get-convex/convex-helpers/blob/main/packages/convex-helpers/server/index.ts) to codify the pattern of splitting validator fields out of table definitions.

`Table` accepts a `fields` argument defining your field validators (just like you’d pass to `defineTable`):

```tsx
// convex/schema.ts
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";
import { Table } from "convex-helpers/server"; // npm i convex-helpers

export const Recipes = Table("recipes", {
  name: v.string(),
  course: v.union(
    v.literal("appetizer"),
    v.literal("main"),
    v.literal("dessert")
  ),
  ingredients: v.array(v.string()),
  steps: v.array(v.string()),
15});

export default defineSchema({
  recipes: Recipes.table.index("by_course", ["course"]),
19});

```

The object returned by `Table` provides easy access to not only the table itself, which can then be passed to `defineSchema()`, but also the corresponding validators you’ve defined, with or without the system fields `_id` and `_creationTime` which are automatically added to the table’s documents:

```tsx
Recipes.table; // object returned by defineTable(), passed to defineSchema()
Recipes.withoutSystemFields; // the user-defined field validators
Recipes.withSystemFields; // those validators plus _id and _creationTime
Recipes.doc; // v.object() validator for the table's docs (incl. system fields)

```

These can be used as needed in your Convex functions. For example, for a `addRecipe` mutation that inserts a new document into the table, you can use `.withoutSystemFields` to validate the incoming table data:

```tsx
// convex/recipes.ts
import { mutation, action } from "./_generated/server";
import { Recipes } from "./schema";

export const addRecipe = mutation({
  args: Recipes.withoutSystemFields,
  handler: async (ctx, args) => {
    return await ctx.db.insert("recipes", args);
  },
10});

```

When you need to pass a whole document in as a function argument, after getting it from the database, `.doc` provides the corresponding object validator. For example, say you have a `generateThumbnail` action to [generate an AI image](https://stack.convex.dev/using-dall-e-from-convex) based on a recipe document:

```tsx
// in convex/recipes.ts
import { action } from "./_generated/server";
import { internal } from "./_generated/api";

export const generateThumbnail = action({
  args: {
    recipe: Recipes.doc,
  },
  handler: async (ctx, args) => {
    const imgStorageId = await generateDallE(
      `A recipe named ${args.recipe.name} made with ` +
      args.recipe.ingredients.join(", ")
    );
    await ctx.runMutation(internal.recipes.addImage, {
      recipeId: args.recipe._id,
      imgStorageId,
    });
  },
19});

```

#### `.doc` vs. `.withSystemFields`: A quick note on `v.object()`

While `.withSystemFields` is a regular old object (which just happens to have field names as keys and `Validator` s as values), `.doc` provides the `ObjectValidator` corresponding to the `.withSystemFields` object.

In other words, `Recipes.doc` is equivalent to `v.object(Recipes.withSystemFields)`.

```tsx
// To accept a whole document as an argument:
args: {
    recipe: Recipes.doc, // <- you can't pass Recipes.withSystemFields here, as each arg expects a validator, not an object
4}

// To accept each of the fields as separate arguments:
args: Recipes.withSystemFields // <- you can't pass Recipes.doc here, as args expects an object, not a validator


```

You can use the `.doc` validator when passing entire documents as function arguments, and `.withSystemFields` when you need a JS object, for instance to destructure or spread arguments as described earlier. It’s currently not possible to “unwrap” a `v.object()` to get the individual field validators, though that might be supported in the future.

### Recap: DRY validators & types

With a few TS & JS builtins and `convex-helpers` utilities, you can streamline your argument validator definitions, minimizing repetition across your Convex codebase.

- Expose your tables’ field validators defined in `convex/schema.ts` for use in functions
- Use Convex generic types like `Doc` , and TS utility types like `Pick` & `Omit`, to get the (sub)sets of fields you need in TypeScript
- Use object destructuring & the rest operator ( `...`) to get the (sub)sets of fields you need for argument validation in Convex functions
- Use the `Table` helper from `convex-helpers` for easy access to the defined table and the corresponding validators for its documents, with or without system fields

If you found these tips useful, or have any of your own you’d like to share with other developers in the Convex community, please jump on [Discord](https://www.convex.dev/community) and let us know!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Going local-first with Automerge and Convex

I’ve spent some time recently figuring out how to use Convex and [Automerge](https://automerge.org/) together to enable local-first text editing UX:

- Collaborate with other people, without clobbering their changes.
- Continue editing offline when the network is slow, intermittent, or drops entirely.
- Local edits survive the browser closing or computer restarting and sync the next time you open the document with an internet connection.

I’ll walk you through how it works, how to think about adding local-first features to your app, and tips for specifically working with Automerge and Convex.

## Why local first?

Having to wait for a server to load & acknowledge every change in your app makes for a bad experience, and inhibits offline workflows. Local-first, among other things, is a commitment to the user’s experience of interacting with your app. Check out [this localfirst.fm podcast](https://www.localfirst.fm/1) for a good overview.

Storing and editing data locally provides a snappy, consistent experience. Syncing those changes to other clients enables multiplayer collaboration and works well with our multi-device world. For instance, to allow multiple users to make edits and not clobber each others’ changes, CRDTs (Conflict-free Replicated Data Type) can be used to merging distributed changes. One use case CRDTs excel at is merging text edits in a way that will usually result in a reasonable output string. [Automerge](https://automerge.org/) and [Yjs](https://docs.yjs.dev/) both have strong CRDT implementations and we’ll talk about Automerge specifically in this post.

It’s worth noting, however, that CRDTs are not the only way to achieve local-first UX. This article does a great job laying out the landscape of how server architecture works in the context of techniques like OT / CRDT: [https://mattweidner.com/2024/06/04/server-architectures.html](https://mattweidner.com/2024/06/04/server-architectures.html) and check out [An Object Sync Engine for Local-first Apps](https://stack.convex.dev/object-sync-engine) for a glimpse of how Sujay is thinking about local sync with Convex.

### A word of caution

I’d like to call out early that reasoning through distributed systems problems is not for the faint of heart, and going local-first can turn your problems into distributed state problems. While the UX can be magical, it can also incur a high cognitive cost, so it’s worth thinking through what tools you incorporate, and how that integrates with the rest of your app.

As we’ll discuss [below](https://stack.convex.dev/automerge-and-convex#crdt-considerations), you may decide to keep the server in the loop for parts of your app when consistency, correctness, or convenience are important. Thankfully, none of this needs to be either-or. We can use Automerge to manage CRDTs alongside Convex for the rest of the app’s data and backend needs.

## What is Automerge?

> **Automerge is a library of data structures for building collaborative applications.**

Automerge is a CRDT implementation, with a ton of libraries and optimizations to make it easy to build local-first collaborative apps. Specifically, they provide:

- Abstractions for capturing changes to JSON documents (not just strings!) and encoding them in a compact binary format that can be applied on other clients.
- Adapters to store those changes, such as the `IndexedDBStorageAdapter` which allows you to store the document contents and history in the browser, so it can be read & written offline, and persists across browser or computer restarts.
- Implements the CRDT merge logic to combine edits made by multiple clients in isolation into a single document version, and have every client agree what that version looks like, regardless of the order they received the updates.
- Opinionated conflict resolution logic with reasonable defaults and [“just picking one”](https://automerge.org/docs/documents/conflicts/) when necessary, which is reasonable for certain use-cases.[1](https://stack.convex.dev/automerge-and-convex#user-content-fn-1)
- Change idempotency: internally the encoded change has a history of each change and can de-duplicate changes, so they safely no-op when re-applied multiple times.
- Adapters to sync changes peer-to-peer. Even if you don’t plan to make a fully distributed app, you can use their `MessageChannel` or `BroadcastChannel` adapter to sync changes to other browser tabs, so they can stay in sync when offline editing.

Some code to help make it concrete:

```tsx
// Get a type-safe reference to an Automerge document
const [doc, changeDoc] = useDocument<TaskList>(docUrl);
3...
// Handling edits of an <input> element
5<input
  onChange={(e) =>
	  changeDoc((d) => {
	    updateText(d.tasks[index], ["title"], e.target.value);
    })
  }
  value={doc.tasks[index].title}

```

```ts
// Save a snapshot (includes the full edit history)
const snapshot = A.save(doc);
this.lastSync = A.getHeads(doc);
4...
// Sync changes since the last sync point
const previousDoc = A.view(doc, this.lastSync);
const changes = A.getChanges(previousDoc, doc);
const current = A.getHeads(doc);
await syncTheChanges(documentId, changes);
this.lastSync = current;

```

```ts
// Apply new changes
const docWithChanges = A.loadIncremental<TaskList>(doc, incrementalChanges);

```

### Under the hood

Automerge has some very cool structures and optimizations to efficiently store and manipulate the full history of changes to a document. Understanding these is not necessary for using it, but if you’re curious (or working with it at a low level) then read on. Otherwise you can skip to the [Tips section below](https://stack.convex.dev/automerge-and-convex#tips-for-structuring-your-data).

#### git-like

Similar to `git`, each change has an associated hash, one or more parents, and they use `heads` terminology in a similar way. Changes are represented as a directed graph of hashes, and can be queried to find all changes between two points. One difference is that they work with `Heads`, an array of hashes, rather than a single hash (by comparison a git commit has a single hash to identify it). You call `getHeads(doc)` to get a reference to the point in history of the document. Note: in practice I’ve found this is just one hash unless the document was created multiple times with the same ID and later merged.

#### Snapshots and incremental changes

The underlying storage interface differentiates between snapshots and incremental changes. However, thanks to the encoding of change dependencies, it is ok to have a change represented in multiple places. Each snapshot includes a full history, so one version of “sync” would be each client continuously uploading a snapshot, and “applying” each others’ snapshots. When applying, it internally skips all the previously-applied changes, and only applies the previously unseen changes. For efficiency, incremental changes can be saved either individually (from [`getLastLocalChange`](https://automerge.org/automerge/api-docs/js/functions/getLastLocalChange.html)), or as a series of changes (from [`getChanges`](https://automerge.org/automerge/api-docs/js/functions/getChanges.html)), and applied with [`applyChanges`](https://automerge.org/automerge/api-docs/js/functions/applyChanges.html) as a list of changes or with [`loadIncremental`](https://automerge.org/automerge/api-docs/js/functions/loadIncremental.html) as a single binary blob with all of the changes appended together.

The IndexedDB storage uses a single binary buffer of changes so it can store multiple changes at once, and save both as a single binary blob, and load all of them together. The main difference with a snapshot, then, is merely the expectation that it goes back to the beginning of the document’s history (allowing it to fully hydrate a document), though both are a series of changes under the hood.

#### Actors

Each change is attributed to an “actor” - which can be thought of as a browser tab. This means it doesn’t perfectly correspond to a user. A single user can show up as multiple actors if they have multiple tabs open, and their actor identity shouldn’t be trusted to be stable. However, a given actor enables the system to provide a sense of causal changes. Modeling each change done by an actor as a sequence allows their merge algorithms to implement a version of “last writer wins” that is consistent across clients.

### Tips for structuring your data

Here’s some tips for working with CRDT data structures.

#### Generate IDs for objects

When generating an array of objects, generate a random ID for each one to track which is which, versus using an indirect reference like the index. When using something like React, you’ll want a `key` that is stable even while creating new elements are being created by other users. This also allows you to consistently identify the data you just created, so you can focus it. See [here](https://github.com/ianmacartney/automerge-convex-quickstart/blob/hosted/src/App.tsx#L24) for an example using `crypto.randomUUID()`.

#### Be mindful of schema migrations and versioning

You are responsible for the data format and migrations within the CRDT. The binary encoding is not validated by the database layer (Convex or otherwise). If you want to change data formats, you need to modify new documents, documents currently stored in the database, and documents that are on clients that haven’t synced yet. When in doubt, follow general best practice for graceful migrations: type new fields as optional, don’t change the type to required unless you have ensured a backfill migration has been run on it, and mark deprecated fields as optional and keep the declaration around in code even after you stop using them, unless you know for sure the value has been cleared, to avoid future surprises. See the [automerge docs](https://automerge.org/docs/cookbook/modeling-data/#versioning) for more tips on handling versioning and migrations.

#### Clearing history

If you want to clear out older history, you can create a new document with the value of the old snapshot. However, changes made to the old document can’t be applied to the new document, so ensure clients have synced their changes before making the change.

#### Using the Automerge ID as a foreign key

Use the Automerge document ID as a foreign key in your other data.

In the demo we store it in the URL hash, which means the client doesn’t need to look up any server data to know what data to look for locally. However, this means migrating the data to a new document will break the link, and we also can’t generate a new link to the same document, if it gets publicly leaked.

You can also store the ID in another automerge document, but be aware that Automege doesn’t provide consistency guarantees between documents. You might get an update with a reference to a document you don’t have synced yet, or sync a document before seeing it show up as a reference in the related document.

By storing it in a normal database document, you can have an index on it, allowing you to look up related documents, enforce uniqueness, and other standard relational database features. For instance, you might have a “blogs” table that has a reference to the blog content’s automerge document ID. When the automerge content changes, we can find the associated blog post record in the table, authorize that the change is being made by an approved author, push changes to a CDN for the given URL, etc.

We’ll see more examples of what you get when you pair CRDT structures with a backend system in the next section.

## Syncing CRDTs with Convex

Now that we’ve looked at what CRDTs like Automerge can provide, let’s bring the server into the mix. With a centralized server, you can:

- Sync changes between users, even if no two users are online at the same time.
- Authenticate users, and authorize operations to prevent users from seeing or modifying data.
- Add structured relationships between automerge documents and other app data.
- Enables server-driven workflows, like scheduling the daily creation of a new shared document, or updating a document when receiving a web hook from a third party.
- Load data for Server-Side Rendering, so your client can see data on the first page load before their client loads IndexedDB or syncs the latest changes.

### Automerge Convex Quickstart

I’ve hooked up Automerge and Convex in [this open-source repo](https://github.com/ianmacartney/automerge-convex-quickstart) forked from [Automerge’s quickstart](https://github.com/automerge/automerge-repo-quickstart). There is a hosted version of it [here](https://labs.convex.dev/automerge). The basic setup is there is a Convex backend that coordinates with an [Automerge Repository](https://automerge.org/docs/concepts/#repositories) so local changes get synced to the server, and remote changes get synced down and applied. The setup:

```tsx
// src/main.tsx
const automerge = new Repo({
  network: [],
  storage: new IndexedDBStorageAdapter(),
5});

const convex = new ConvexReactClient(convexUrl);

sync(automerge, convex);

```

The `sync` function talks to endpoints defined in `convex/sync.ts` that stores the data in a Convex table:

```ts
// convex/schema.ts
export default defineSchema({
  automerge: defineTable({
    documentId: v.string() as VString<DocumentId>,
    type: v.union(v.literal("incremental"), v.literal("snapshot")),
    hash: v.string(),
    data: v.bytes(),
  })
    .index("doc_type_hash", ["documentId", "type", "hash"])
    .index("documentId", ["documentId"]),
11});

```

This is intended as a demo to show how Convex can be used as a sync engine, and should be treated as an alpha release. I’m working on encapsulating this in a [Convex Component](https://www.convex.dev/components) to make it easy to drop into new or existing projects, without adding anything to your own schema. Stay tuned for updates (join [our Discord](https://convex.dev/community), follow me on ~~Twitter~~ ~~X~~ [Twitter](https://twitter.com/ianmacartney), or ).

### Sync logic

The sync employed here roughly matches what is outlined in the [Map of Sync](https://stack.convex.dev/a-map-of-sync) post under Automerge. The rough flow of the logic is:

1. When the Automerge repo starts tracking a new document, read the data from IndexedDB and new changes from the server. If we haven’t pulled from the server before, download all changes from the server. If we have data and haven’t submitted anything to the server before, submit a snapshot of the local data.
2. Subscribe via paginated queries to server changes, fetching new pages whenever new data is available (using Convex’s built-in realtime query subscriptions). Apply all changes we haven’t seen before, identified by `_id`. The new data comes from a subscription on `_creationTime`, which is when the change was saved on the server (not when it was created by a client, potentially offline). When we get new changes, we update the latest `_creationTime` we’ve seen,[2](https://stack.convex.dev/automerge-and-convex#user-content-fn-2) so future loads can start subscribing from there.[3](https://stack.convex.dev/automerge-and-convex#user-content-fn-3)
3. When a document changes locally (by subscribing to the Automerge document’s change handler), we calculate the changes between the last synced server state and our current state(”heads”). We submit those changes as an incremental change via a mutation.
   - The Convex client provides a lot of guarantees around mutations that help us out here. When Convex is offline, a mutation will be queued up to be sent when the connection reconnects. Mutations also support idempotent delivery, so even if there is a network or server failure, when the client reconnects it will ensure the mutation is run exactly once.
   - This function has some logic to ensure it is [single-flighted](https://stack.convex.dev/throttling-requests-by-single-flighting). Any changes made while one request is in flight will be picked up by the next request.
   - If multiple clients in different browser tabs observe the same change by the same actor, we de-duplicate changes server-side with a hash of the contents. And even if changes get stored in duplicate, they internally de-duplicate when being applied.
   - Since submitting changes and snapshots can safely be inserted in parallel with other clients, many users can all be making changes at once without causing any database conflicts.
4. Occasionally, we can compact changes into a snapshot, so new clients can sync a single document instead of thousands of small changes. This has been implemented in a way to avoid conflicts with concurrent submissions of changes or snapshots.

**Note**: there are many ways of structuring this sort of sync. I considered a series of approaches before landing on this one, and all have their merits in different usecases.

### Using Automerge in a serverless environment

Traditionally, Automerge is used in a long-lived server environment, such as in a browser or node server. In the serverless world powered by lightweight runtimes, there are some practical considerations when using Automerge, since it relies on wasm.

When using it in Convex, I’d recommend using the automerge library server-side from a node action that can load the wasm as part of the installation process. To do this, put your automerge in actions in a file with `“use node”;` at the top, and add a `convex.json` file at the root of your project with contents: `{ "node": { "externalPackages": ["@automerge/automerge"] } }`. Then you can use imports like `import * as A from "@automerge/automerge/next";` and everything will just work.

If you need to use Automerge in a query or mutation, those run in the Convex v8 runtime (similar to deno and other runtimes). In those cases, use the [escape hatch documented here](https://automerge.org/docs/library_initialization/#the-escape-hatch). It might look like:

```ts
import * as Automerge from "@automerge/automerge/slim/next";
// @ts-expect-error wasm is not a module
import { automergeWasmBase64 } from "@automerge/automerge/automerge.wasm.base64.js";

async function load() {
  return Automerge.initializeBase64Wasm(automergeWasmBase64 as string);
7}

async function automergeLoaded() {
  await Automerge.wasmInitialized();
  // This is unnecessary, but as a pattern I use this return value
  // so all code referencing Automerge has waited for wasm to load.
  return Automerge;
14}

16/** Fetches an Automerge document's contents */
export const doc = query({
  args: { documentId: v.string() },
  handler: async (ctx, args) => {
    // Start loading wasm in parallel with querying data
    void load();
    const result = await ctx.db
      .query("automerge")
      .withIndex("doc_type_hash", (q) => q.eq("documentId", args.documentId))
      .collect();
    // Ensure we wait for wasm to fully load before using it
    const A = await automergeLoaded();
	  return A.loadIncremental(
	    A.init(),
	    mergeArrays(result.map((r) => new Uint8Array(r.data)))
	  );
	},
33}

```

Note: loading wasm from a string can add up to 200ms to each request, so try to avoid it when possible. If your clients are trusted to maintain data validity, it’s simpler to do the Automerge operations client-side, and have the server merely pass around the efficient binary changes. This is what the demo does.

You can still enforce authorization and authentication without loading Automerge server-side, but you lose the ability to audit the content of each change on the server. Let’s look next at some options for validating and capturing data when you want to enforce invariants beyond what CRDTs can guarantee.

### Data touch points

As is, the sync mechanism will sync any Automerge document. To validate the document, you can materialize a version of it at various points, depending on your requirements:

- You should eagerly validate the data client-side, to prevent bad changes at the source.
- You can validate the data when you create a new snapshot server-side. It is already reading all of the data, so it is a convenient time to work with the concrete value. This can also be a point where you save the concrete value elsewhere for indexing, ease of querying, etc. For validation, you could treat incremental changes as merely suggestions until they are compacted and resolved into a snapshot.
- To validate every change server-side at submission time, you can use a node action to load the full document, see the document value with the change applied, validate it, then save or reject the change. However, there is still the chance that two independent changes will be valid in isolation but not when combined. To fix this, we need to serialize the changes.
  - One version of this over-writes a single snapshot every time, so there’s only one version of the document server-side.
  - Another more efficient approach adds an incrementing sequence number to each change. Two parallel requests will attempt to use the same sequence number and conflict, allowing you to try again with the latest data.
  - Thanks to Convex’s transactions, which provide serializable isolation, both of these approaches are safe. You can compare the current state (e.g. last snapshot version or latest sequence number) when inserting to ensure there haven’t been any racing writes. However, if there are frequent concurrent writes to a document, loading the full document and validating the result will cause a lot of data reads and [OCC conflicts](https://docs.convex.dev/error).

If you want to reject a change server-side, you need to structure it in Automerge as yet another additive change, like a `git revert` commit reversing the changes of a previous commit. Automerge intentionally doesn’t make it easy to scrub a change out of history across all clients it may have been synced to. To implement undo, I would check out using [`automerge-patcher`](https://github.com/onsetsoftware/automerge-patcher) along with `A.diff` to craft a change inverse, as undo functionality was cut for version 1.0 ( [feature request here](https://github.com/automerge/automerge/issues/985)).

## CRDT Considerations

Using CRDTs for your data model comes with making some concessions worth considering before committing. As James and Jamie often say in the [Databased Podcast](https://www.convex.dev/podcast), it’s easier to start with stronger guarantees and decide when to weaken them, rather than to start with weaker guarantees and try to build stronger guarantees out of weaker ones.

Here are three C’s to consider for CRDTs: Consistency, Correctness, and Convenience.

### Consistency

- The data that updates via a CRDT doesn’t have any consistency guarantees with other parts of your data by default. If your data is split between CRDT documents, there is nothing built into Automerge guaranteeing that changes will happen in lockstep. If you data is in one CRDT document, merges may choose a resolution in one part of your document that doesn’t match an expected change in another part.
- You may have a combination of local changes and server state that is distinct from every other client and server’s view of the data. It is hard to make strong guarantees about the data relations you have at any given time, when there isn’t a central authority consolidating the mess. It is up to you to reason through all of the intermediate states clients can be in, and to defend against clients who submit changes to the data that don’t match your client’s expectations.
- By comparison, structuring local edits as non-authoritative optimistic updates on top of otherwise-consistent-by-design server data structures the local writes as pending.

### Correctness

- The parts of your data model that you structure via CRDT will not change transactionally with other data by default. This affects consistency, as we just discussed, but can also impact correctness when you use that data to make decisions. If a project is being reassigned to another user, is there a time where the old project owner could be charged, but the new owner gets the email receipt? When you want to express data dependencies and discrete state changes, transactions are the right tool for the job, and it’s often worth waiting until you have an internet connection to validate whether it went through or not, before continuing on.
- There is often a subset of application state that should not allow arbitrary client changes. Is this user an admin? Have they paid their bill? Are published tweets editable? Even if you write good client code, you can’t assume that all connected clients are running your code. I’d urge you to evaluate important state-related decisions in a trusted environment behind auth checks.
- Automerge uses “last writer wins” conflict resolution, which may often result in what you want, but may also lead to invalid and missing data. If you’re working with a CRDT and have the thought “it would be really bad if this gets lost” then I’d capture that data change elsewhere or invest in some lucky charms (why choose?).

### Convenience

This point is interesting since there are a ton of conveniences provided both by CRDTs and server-federated operations. Depending on your architecture, you may move much faster in a local-first codebase, or you might end up reinventing web3 to build a simple Twitter clone.

- If the user can make significant edits solo or offline, it’s much more convenient to work with local data, and have the client “drive” the interaction. If the user’s workflow communicates with other web services anyways, it’s more convenient to drive the flow from the server, which can track a durable workflow and react to webhooks from third party services.
- If multiple users are simultaneously editing data that is highly visible (e.g. a todo item description, or its checkbox status), CRDTs are incredibly convenient. It’s easier for a user to correct bad conflict resolutions as they see them, rather than think through innumerable permutations of user actions and trying to infer intent. However, if the data model is not easily surfaced to the user and therefore bad merges are hard to detect and surface, it’s much more convenient (for you the programmer!) to hold a single “golden” version with carefully federated changes. This can still be a local-first experience, but might look like claiming a write lock on a document before you can submit changes, to enforce a linear history.
- If the ratio of data reads to writes is heavily read-skewed (such as media-driven or e-commerce), sync can be an annoying level of indirection to work with. There are two insights here: first is that often the app has a much clearer idea of the most urgent data to fetch, rather than a sync engine; second is it’s really convenient to have a mutation that I can await, knowing that it went through successfully when the promise resolves. If the writes are infrequent but important, I actually prefer waiting for 🔄 to become ✅.

### Thought exercise: public computers

As an aside to make some of these points concrete, let’s consider a use-case that is less commonly considered in local-first design: supporting users accessing your site from a shared browser, such as a public computer.

- Can you quickly show them data and enable quick actions without loading the full history on every new client?
- Can you prevent the next user from seeing their data? Will you need to track all their locally-persisted documents and delete them in the case they click “Log out”? Will you delete data regardless whenever a user’s auth credentials expire? What if your website is never visited again, and sensitive data is orphaned?
- Will you encrypt the automerge binary contents, or just refuse to persist any data if they indicate it’s a public computer on sign-in?

I’m interested in your takes! Drop me a note in [the Discord comments](https://convex.dev/community).

## Summary

We looked at considerations for building local-first features, syncing Automerge CRDTs with Convex, and tips for using both systems. To see it in action, check out the [hosted demo](https://labs.convex.dev/automerge) and [repo](https://github.com/ianmacartney/automerge-convex-quickstart), and stay tuned for an automerge [component](https://www.convex.dev/components).

[ianmacartney/ **automerge-convex-quickstart**\\
\\
What are you syncing about? Automerge and Convex!\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/ianmacartney/automerge-convex-quickstart)

### Footnotes

1. Note: there is a capability to detect conflicts and one could theoretically provide a UI to a user with both versions of the data, but the current API is underpowered and requires a level of defensiveness that gives me the impression that they don’t expect regular usage. You need to check for conflicts after each change (no support for a range), and check each field individually. [↩](https://stack.convex.dev/automerge-and-convex#user-content-fnref-1)

2. One nuance is that we only persist the latest `_creationTime` we’ve seen once we know the new changes have been flushed to disk. If the user’s browser closes or crashes before in-memory changes have been saved, we want to re-fetch those changes next time. [↩](https://stack.convex.dev/automerge-and-convex#user-content-fnref-2)

3. There is one edge case when paginating by `_creationTime`: multiple mutations running and inserting around the same time might insert slightly out of order: a later mutation might insert a document with a `_creationTime` slightly earlier than the mutation that ended earlier. Thankfully this won’t cause any issues with the regular paginated queries, [since they are reactive and avoid gaps and duplicate entries by journaling their end cursor](https://stack.convex.dev/fully-reactive-pagination). However, the initial query for changes since a specific time might miss changes inserted around the same time. To account for this, the query for our first page also fetches the changes that came just before our last seen `_creationTime`. [↩](https://stack.convex.dev/automerge-and-convex#user-content-fnref-3)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Components for your Backend

With Convex [Components](https://www.convex.dev/components), you can incorporate off-the-shelf features into your app. They enable an ecosystem of powerful building blocks to reduce the amount of code you have to write and maintain yourself. These vary from new database features like providing [geospatial search](https://www.convex.dev/components/geospatial), drop-in features like [LaunchDarkly feature flags](https://www.convex.dev/components/launchdarkly) or [Expo push notifications](https://www.convex.dev/components/push-notifications), or common utilities to [retry](https://www.convex.dev/components/retrier) or [cache actions](https://www.convex.dev/components/action-cache) (Convex’s serverless functions that can have side effects).

In this post we’ll cover:

- What are components and why they’re a powerful abstraction.
- What it looks like to add some components to an existing app.
- Best practices for using components.

## What are Convex Components?

Components can be thought of as a combination of concepts from frontend components, third party APIs, and both monolith and service-oriented architectures.

If you’re already sold and looking to jump right in you can skip this section. If you’re interested in the larger conceptual model they fit into, check out [The Software-Defined Database](https://stack.convex.dev/the-software-defined-database).

Without further ado, here are some of the component capabilities I’m excited about.

### Data

Similar to frontend components, Convex Components encapsulate state and behavior, and allow exposing a clean interface. However, instead of just storing state in memory, these can have internal state machines that can persist between user sessions, span users, and change in response to external inputs, such as webhooks. Components can store data in a few ways:

- Database tables with their own schema validation definitions. Since Convex is realtime by default, data reads are automatically reactive, and writes commit transactionally.
- File storage, independent of the main app’s file storage.
- Durable functions via the built-in function scheduler. Components can reliably schedule functions to run in the future and pass along state.

Typically, libraries require configuring a third party service to add stateful off-the-shelf functionality, which lack the transactional guarantees that come from storing state in the same database.

### Isolation

Similar to regular npm libraries, Convex Components include functions, type safety, and are called from your code. However, they also provide extra guarantees.

- Similar to a third-party API, components can’t read data for which you don’t provide access. This includes database tables, file storage, environment variables, scheduled functions, etc.
- Similar to service-oriented architecture, functions in components are run in an isolated environment, so they can’t read or write global variables or patch system behavior.
- Similar to a monolith architecture, data changes commit transactionally across calls to components, without having to reason about complicated distributed commit protocols or data inconsistencies. You’ll never have a component commit data but have the calling code roll back.
- In addition, each call to a component is a sub-transaction isolated from other calls[1](https://stack.convex.dev/backend-components#user-content-fn-1), allowing you to safely catch errors thrown by components. It also allows component authors to easily reason about state changes without races, and trust that a thrown exception will always roll back the Component’s sub-transaction.

### Encapsulation

Being able to reason about your code is essential to scaling a codebase. Components allow you to reason about API boundaries and abstractions.

- The transactional guarantees discussed above allows authors and users of components to reason locally about data changes.
- Components expose an explicit API, not direct database table access. Data invariants can be enforced in code, within the abstraction boundary. For example, the [aggregate component](https://www.npmjs.com/package/@convex-dev/aggregate) can internally denormalize data, the [rate limiter](https://www.npmjs.com/package/@convex-dev/ratelimiter) component can shard its data, and the [push notification](https://www.npmjs.com/package/@convex-dev/expo-push-notifications) component can internally batch API requests, while maintaining simple interfaces.
- Runtime validation ensures all data that cross a component boundary are validated: both arguments and return values. As with normal Convex functions, the validators also specify the TypeScript types, providing end-to-end typing with runtime guarantees.

## Adding components to your app: walkthrough

To make this concrete, let’s look at what it takes to add some components to an existing app I’m working on. It’s an embeddings-based word game where you submit word guesses that match the meaning of two target words. Let’s add:

- An [aggregate](https://www.convex.dev/components/aggregate) component for a leaderboard to track top scores, calculate ranks, etc.
- An [action cache](https://www.convex.dev/components/action-cache) to only ever calculate an embedding once for a given word.
- A [rate limiter](https://www.convex.dev/components/rate-limiter) for how fast guest users can join, and how fast you can submit guesses.
- A [sharded counter](https://www.convex.dev/components/sharded-counter) to scalably track total guesses.
- A [migration](https://www.convex.dev/components/migrations) manager, to manage our online migrations.

The full diff can be seen in [this pull request](https://github.com/ianmacartney/mid-embeddings/pull/1), with a commit for each step of the way. Note: the rate limiter and migration components are conversions from the `convex-helpers` equivalents. With components, they no longer need to add tables to your main schema.

```bash
npm i convex@latest
npm i @convex-dev/aggregate @convex-dev/action-cache @convex-dev/sharded-counter @convex-dev/ratelimiter @convex-dev/migrations

```

As covered in the docs and each component’s README (as seen in the [components gallery](https://www.convex.dev/components), [npm](https://www.npmjs.com/search?q=convex%20component), or [GitHub](https://github.com/orgs/get-convex/repositories?q=component)), adding a component involves:

1. Adding a new file to your project: `convex.config.ts` where you configure which components your app uses.





```tsx
// convex/convex.config.ts:
import { defineApp } from "convex/server";
import aggregate from "@convex-dev/aggregate/convex.config";
import actionCache from "@convex-dev/action-cache/convex.config";
import shardedCounter from "@convex-dev/sharded-counter/convex.config";
import ratelimiter from "@convex-dev/ratelimiter/convex.config";
import migrations from "@convex-dev/migrations/convex.config";

const app = defineApp();

app.use(aggregate, { name: "leaderboard" });
app.use(actionCache);
app.use(shardedCounter);
app.use(ratelimiter);
app.use(migrations);

export default app;

```

2. Running `npx convex dev` to generate code for associated components, so you have type-safe access to them via `import { components } from "./_generated/api";`





```bash
1$ npx convex dev
2# ...
3✔ Installed component actionCache.
4✔ Installed component aggregate.
5✔ Installed component migrations.
6✔ Installed component ratelimiter.
7✔ Installed component shardedCounter.

```

3. Instantiating the helper Class(es) for the components, which wrap up the underlying component API calls and provide conveniences like generic types. We’ll look at each of them next.


### Adding a leaderboard with the `aggregate` component

To get a leaderboard, we can define an aggregate and connect it to table updates using [Triggers](https://stack.convex.dev/triggers). Here we make an aggregate that’s namespaced by gameId and sorted by score. The configuration ends up looking like:

```tsx
// in convex/functions.ts
import {
  internalMutation as internalMutationRaw,
  mutation as mutationRaw,
5} from "./_generated/server";
import { Triggers } from "convex-helpers/server/triggers";
import { TableAggregate } from "@convex-dev/aggregate";
import { customCtx, customMutation } from "convex-helpers/server/customFunctions";
import { DataModel, Id } from "./_generated/dataModel";
import { components } from "./_generated/api";

const triggers = new Triggers<DataModel>();

export const leaderboard = new TableAggregate<{
  Namespace: Id<"games">;
  Key: number;
  DataModel: DataModel;
  TableName: "guesses";
19}>(components.leaderboard, {
  namespace: (d) => d.gameId,
  sortKey: (d) => d.score,
  sumValue: (d) => d.score,
23});
triggers.register("guesses", leaderboard.trigger());

const mutation = customMutation(mutationRaw, customCtx(triggers.wrapDB));
const internalMutation = customMutation(
  internalMutationRaw,
  customCtx(triggers.wrapDB),
30);

```

**Note**: in order to keep the aggregate up to date, you need to use these versions of `mutation` and `internalMutation` instead of the built-in ones. You can see in [this commit](https://github.com/ianmacartney/mid-embeddings/pull/1/commits/d9daefc622978ba268bed5f00f3242ff54aebc3f) where I make this change along with adding an ESLint rule to prevent anyone from accidentally importing the “raw” versions of them.

To find the high score for a game, I can use `max`:

```ts
leaderboard.max(ctx, { namespace: args.gameId });

```

To find the rank of my best guess amongst all guesses for a game, I can use `indexOf`:

```ts
leaderboard.indexOf(ctx, bestGuess.score, {
	namespace: args.gameId,
	id: bestGuess._id,
	order: "desc",
5});

```

Read [the docs](https://www.convex.dev/components/aggregate) for a full rundown of its capabilities.

### Caching embeddings with `action-cache`

For my game, I use embeddings of every search a user enters. To avoid generating duplicates, I can use the [Action Cache](https://www.convex.dev/components/action-cache) component:

```tsx
const embedCache = new ActionCache(components.actionCache, {
  action: internal.embed.generateEmbedding,
3});

```

Instead of calling the action directly, I can call it through the cache, which will return the cached value (based on the function name and arguments), or generate one on the fly.

```tsx
await embedCache.fetch(ctx, { model: CONFIG.embeddingModel, input: text });

```

**Tip**: by including the model in the arguments, I ensure that it will never return cached embeddings generated by a different model, since the args are part of the cache key.

[Read the docs](https://www.convex.dev/components/action-cache) to learn about setting an expiration policy or manually clearing values.

### Tracking fast-changing stats with `sharded-counter`

With the hopes that my game will become a grand success, I want to count not only the guesses within a daily game, but across all days. I’d also like a global count on the homepage including all games by all authors. As you may have seen with [One Million Checkboxes](https://labs.convex.dev/million), keeping a count fast and correct can be nontrivial. [Sharded Counter](https://www.convex.dev/components/sharded-counter) isn’t as fully-featured as Aggregate, but it excels at high throughput counting.

Configuration:

```tsx
import { ShardedCounter } from "@convex-dev/sharded-counter";

const counter = new ShardedCounter(components.shardedCounter);

```

Adding to counters when adding a guess, but only for active games:

```tsx
//inside the function used to add guesses
if (game.active) {
  await counter.add(ctx, "total"); // overall guesses vanity metric
  await counter.add(ctx, args.gameId); // individual daily game
  await counter.add(ctx, game.namespaceId); // daily games share a namespace
  await counter.add(ctx, args.userId); // how many guesses a user has ever made
7}
return ctx.db.insert("guesses", { ... });

```

I can then add live-updating stats to various parts of the UI showing activity, without worrying about query performance.

```tsx
const totalCount = await counter.count(ctx, "total");

```

**Note**: be careful about calling `count` within mutations, since any two mutations both adding and reading the count will conflict with each other, requiring one to retry. Read more about that [here](https://stack.convex.dev/how-convex-works#read-and-write-sets).

### Using `ratelimiter` to deter abuse

Using application-layer rate limits allows you to control how frequently things can happen. Here I added a simple limit on how fast users can sign in as a guest (to hamper floods of automated signups).

```tsx
const rate = new RateLimiter(components.ratelimiter, {
  anonymousSignIn: {
    kind: "token bucket",
    rate: 100,
    period: MINUTE,
    shards: 10,
  },
8});

```

It is then used as part of the sign up flow:

```tsx
await rate.limit(ctx, "anonymousSignIn", { throws: true });

```

It will throw an exception if the rate is exceeded, rolling back the transaction.

Similar to the counter, it can be configured with the number of shards to enable more parallelism by distributing the load. More shards come with a higher chance of rejecting a request erroneously when running close to the limit, as the capacity is distributed amongst them.

See [the docs](https://www.convex.dev/components/rate-limiter) for more information.

### Configuring stateful `migrations`

[Migrations](https://www.convex.dev/components/migrations) allow us to modify data. The component makes it easy: you define a function that modifies a single row, and it will run it in batches and keep track of the bookkeeping.

Configuration:

```tsx
export const migrations = new Migrations<DataModel>(components.migrations, {
  internalMutation,
3});

```

**Note**: we pass in the `internalMutation` we made when configuring the `aggregate` component. That way if our migrations ever modify the `guesses` table, it will keep the associated aggregate information updated.

While the app doesn’t need to modify any data right now, it does need to update the aggregates and counters for guesses submitted before we added the above counter logic. So we’ll define a “migration” over the guesses table that, instead of modifying each guess, updates the counters and leaderboard. We’ll limit it to only the guesses submitted before we deployed the counter change, so we don’t double-count any guesses.

```tsx
// in convex/game.ts
export const addOldGuesses = migrations.define({
  table: "guesses",
  customRange: (query) =>
    query.withIndex("by_creation_time", (q) =>
      q.lt("_creationTime", Number(new Date("2024-10-22T16:20:00.000Z"))),
    ),
  migrateOne: async (ctx, doc) => {
    await leaderboard.insertIfDoesNotExist(ctx, doc);
    const game = await ctx.db.get(doc.gameId);
    if (!game?.active) {
      return;
    }
    await counter.add(ctx, "total");
    await counter.add(ctx, doc.gameId);
    await counter.add(ctx, game.namespaceId);
    await counter.add(ctx, game.userId);
  },
19});
export const backfill = migrations.runFromCLI(internal.game.addOldGuesses);

```

We could run it from the dashboard or CLI: `npx convex run game:backfill`.

If we had a bug and it failed part way, we could see how many guesses it had processed, resume where it left off, test a dry run, or start over after. By default if we run it again it will no-op:

```tsx
1$ npx convex run game:backfill
2[CONVEX ?(game:backfill)] [DEBUG] 'Migration already done.'
3{
  cursor: '07b6def...',
  isDone: true,
  latestStart: 1729614001337,
  name: 'game:addOldGuesses',
  processed: 8675
9}

```

### Walkthrough done!

Check out [convex.dev/components](https://www.convex.dev/components) to see the full list of components available now, and let us know what you’d like to see.

## Best practices for using components

### Avoid modifying data directly from the dashboard

You can see your component’s data and its internal functions on the dashboard by selecting it from the components dropdown (you won’t see this dropdown until you have your first component, by the way). However, directly modifying the data or running internal functions might violate some invariant the component depends on. Limit interacting with it through the Class it provides, through functions in your own application.

### Using multiple component instances

Some components make sense to only have a single instance of, for instance you probably only need one [crons](https://www.convex.dev/components/crons) component for dynamically periodic function calls. For others, you’ll need to have multiple components for different use cases. It’s important to know when to make multiple component instances.

One thing that can be confusing is that when I say “multiple components” I mean multiple calls to `app.use(somecomponent, { name: "uniqueName" })`. Conceptually, every call to `.use` makes a new component that has its own isolated database tables. Merely instantiating the component’s Class multiple times via `new SomeComponent(components.somecomponent)` will have multiple references to the **same component**. For some components this is fine. For instance, for [rate limiting](https://www.convex.dev/components/rate-limiter) each limit has its own name, and different Class instances can point to the same component instance:

```tsx
const userLimits = new RateLimiter(components.ratelimiter, {
   freeTrialSignUp: { kind: "fixed window", rate: 100, period: HOUR },
   //...
4};
// OK
const messageLimits = new RateLimiter(components.ratelimiter, {
  sendMessage: { kind: "token bucket", rate: 10, period: MINUTE, capacity: 3 },
8});

```

As long as the names don’t conflict, they can happily use the same component. However, for the [aggregates](https://www.convex.dev/components/aggregate) component, you need to make sure each table you’re aggregating over has its own data:

```tsx
// convex/convex.config.ts
app.use(aggregate, { name: "aggregateScores" });
app.use(aggregate, { name: "aggregateByGame" });

// convex/foo.ts
const byScores = new TableAggregate(components.aggregateScores, {...});
const byGame = new TableAggregate(components.aggregateByGame, {...});

```

### Am I locked in?

Similar to using a third party service as part of your app, using components means that some of your app’s data is stored in isolated tables. When you decide to change third-party providers, you need to think about how your data will transfer. Similarly with components, you will need to get your data out of the component.

- Rest assured that the data is still in your Convex database. You can see the data from the Convex dashboard, and it is included in snapshot imports and exports, allowing your components to restore from a backup at the same snapshot as the rest of your data.
- If you want to modify the behavior of a component, you are free to fork or vendor in the implementation. Components need not be installed by npm. You can add functions, modify the schema, etc.
- For now, component data is tied to the component’s name. Each component has a default name (for instance the [action cache](https://www.convex.dev/components/action-cache) is named `actionCache` by default), but can be overridden when installing like `app.use(ratelimiter, { name: "customName" })`. This means you can replace a component and maintain its data by re-using the same name, provided it has a compatible schema to the existing data.

## Summary

Components are a big step forward in the composability of backend functionality, bringing the enforced isolation and local-reasoning benefits of service-oriented architecture together with the transactional simplicity of monolith architecture. It allows encapsulating logic and data to build powerful features that can ship in a tidy package with a clean abstraction layer. As always, let us know what you think [in Discord](https://convex.dev/community).

### Footnotes

1. Components function calls provide serializable isolation, the strongest level, mirroring Convex mutations. This means two calls can each read from the database, modify it, and write it back without worrying about race conditions. [↩](https://stack.convex.dev/backend-components#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Background Job Management

What do you do when the work you want to perform should happen after a request?

How can you see incremental progress on workflows that may take a while? Or cancel a job scheduled for the future?

In this post, we’ll look at a pattern for managing asynchronous work that allows you to:

1. Start a long-running job and respond quickly to a client.

2. Track incremental progress on multi-stage tasks.

3. Subscribe to the status and result of a background task from multiple clients.

4. Cancel a request transactionally (i.e., without race conditions).

5. Monitor job timeouts.

6. Implement custom retry logic in the case of transient failures.

As an example of this pattern, I’ll be referencing [a multiplayer game using Dall-E](https://stack.convex.dev/building-a-multiplayer-game). While building it, I found that OpenAI’s image endpoint could sometimes take over 30 seconds, timing out and giving a bad user experience. Rather than have the client wait on a single request, I schedule the work to be run asynchronously using Convex’s [function scheduling](https://docs.convex.dev/using/scheduling). You can see the code [here](https://github.com/get-convex/multiplayer-game-with-dall-e).


## Tracking status in a table

The high-level approach uses a table to keep track of a long-running task’s state. For my example, I made a “submissions” table to track generating an image using OpenAI based on a prompt:

```tsx
// in convex/schema.ts
submissions: defineTable({
    prompt: v.string(),
    authorId: v.id("users"),
    result: v.union(
      v.object({
        status: v.literal("generating"),
        details: v.string(),
      }),
      v.object({
        status: v.literal("failed"),
        reason: v.string(),
        elapsedMs: v.number(),
      }),
      v.object({
        status: v.literal("saved"),
        imageStorageId: v.string(),
        elapsedMs: v.number(),
      })
    ),
  }),

```

Depending on the status of the work, we capture different information.

### 1\. Starting a job without waiting for it

To start the process, the client calls a [mutation](https://docs.convex.dev/understanding/convex-fundamentals/functions#mutation-functions), which creates the submission document, schedules the work to start immediately, and returns the ID:

```tsx
// in convex/submissions.tx "start" mutation
const submissionId = await db.insert("submissions", {
  prompt,
  authorId: session.userId,
  result: {
    status: "generating",
    details: "Starting...",
  },
9});
// Kick off createImage in the background
// so we don't block this request.
scheduler.runAfter(0, internal.actions.createImage, { prompt, submissionId });
return submissionId;

```

Mutations are transactional, so we could have also checked if there was an ongoing submission for the user or a duplicate request. Importantly, we pass the submission ID to the client and the action that will update the submission.

### 2\. Tracking incremental progress

Once the client receives the submission ID, it can update its UI reactively based on the submission status:

```tsx
const Submission = ({ submissionId }) => {
  const result = useSessionQuery(api.submissions.get, { submissionId: props.submissionId });
  switch (result?.status) {
    case "generating":
      return (
        <figure>
          <article aria-busy="true"></article>
          {result.details}
        </figure>
      );
    case "failed":
      return <p>{result.reason}</p>;
    case "saved":
      return (
        <figure>
          <img src={result.url} />
          Generated in {result.elapsedMs / 1000} seconds.
        </figure>
      );
  }
  return null;
22};

```

As a reminder, Convex [queries are re-run automatically](https://docs.convex.dev/understanding/convex-fundamentals/functions#query-functions) whenever the underlying data changes. So as the submission is altered, this React component will re-render with the latest results.

On the server, it can update the status from the action by running the `submissions:update` mutation:

```tsx
// in actions/createImage.ts
runMutation(internal.submissions.update, {
  submissionId,
  result: {
    status: "generating",
    details: "Generating image...",
  }
8});

```

Which can be as simple as:

```tsx
// in convex/submissions.ts
export const update = internalMutation(async (ctx, {submissionId, result}) => {
  await ctx.db.patch(submissionId, { result });
4});

```

When the request is done, it’s up to you whether you write to the job table with the results or commit them elsewhere. In my case, I let the user decide whether they like the image before submitting it to the game, so the action is only responsible for generating it.

### 3\. Subscribing from multiple clients

One nice side-effect of storing the data in a table and reactively querying it is that you can subscribe to the result from multiple clients. Anyone with the submissionId can wait for results. On a higher level, you can also see real-time statistics about the health of the jobs. Because Dall-E can be so slow, I decided to surface its status in the UI, to manage user expectations.

Here I query the latest five submissions and calculate their average time and average success rate:

```tsx
// in submissions.ts
export const health = query(async (ctx) => {
  const latestSubmissions = await ctx.db
    .query("submissions")
    .order("desc")
    .filter((q) => q.neq(q.field("result.status"), "generating"))
    .take(5);
  let totalTime = 0;
  let successes = 0;
  for (const submission of latestSubmissions) {
    totalTime += submission.result.elapsedMs;
    if (submission.result.status === "saved") successes += 1;
  }
  const n = latestSubmissions.length;
  return [totalTime / n, successes / n];
16});

```

### 4\. Cancelling a request safely

When you schedule a job, it returns an ID of type `Id<"_scheduled_functions">`, which can be used to query the status and cancel it through the scheduler's [`ctx.scheduler.cancel`](https://docs.convex.dev/scheduling/scheduled-functions#canceling-scheduled-functions) function.
You can alternatively do this in your own table: you can check if it’s already started and, if it hasn't, update its status to “canceled” in the table otherwise. When the job runs, it can query the table and either return early or mark the task as “started.” With either approach, because mutations are transactional with serializable isolation, you are guaranteed that either the mutation to cancel the job will see that it has already “started” or the job will see “canceled” - you’ll never think that you canceled a task but find out it ran anyways.

For example, say you want to make a last-minute change to which email a user will get. It is important to send only one email. You can cancel the current pending email, and if you succeeded in canceling it, send an updated one instead.

### 5\. Monitoring timeouts

To mark a job as timed out, you can schedule a follow-up mutation when you’re scheduling the job.

```tsx
// in submissions.ts "start" mutation:
scheduler.runAfter(30, internal.submissions.timeout, { submissionId });

```

The timeout could do something like:

```tsx
export const timeout = internalMutation(async (ctx., { submissionId }) => {
  const submission = await ctx.db.get(submissionId);
  if (submission.result.status === "generating") {
    await ctx.db.patch(submissionId, {
      result: { status: "failed", reason: "Timed out", elapsedMs: 30000 },
    });
  }
8});

```

Depending on your application, you might want your background job to not save results if it ends up finishing anyways, so it could check that the status isn’t already “failed" and commit in the same mutation - similar to canceling a request above.

### 6\. Implementing retries

Convex functions give you [different guarantees around failure and retries](https://docs.convex.dev/understanding/convex-fundamentals/functions). To summarize, Convex automatically retries your queries and mutations, but cannot automatically retry actions since they may contain side effects that may not be safe.

Sometimes, however, it does make sense to retry an action. Such as fetching resources from an external service that has transient failures.

See [this article](https://stack.convex.dev/retry-actions) about implementing retries.

Whenever implementing retries, ensure you incorporate [backoff and jitter](https://aws.amazon.com/builders-library/timeouts-retries-and-backoff-with-jitter/) to ensure you don’t exacerbate issues for the service you’re hitting.

## Summary

In this post, we looked at some patterns for using a table to track scheduled functions to achieve a number of common behaviors for background tasks. As always, let us know what you think in [our Discord](https://convex.dev/community)!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Using TypeScript to Write Complex Query Filters

## TL;DR

There’s a new Convex helper to perform generic TypeScript filters, with the same performance as built-in Convex filters, and unlimited potential.

```typescript
import { filter } from "convex-helpers/server/filter";
// Change this
ctx.db.query("posts")
	.filter((q) => ...limited functionality...)
	.paginate(opts);
// Into this
filter(ctx.db.query("posts"),
	(post) => ...unlimited functionality...
9).paginate(opts);

```

## The filtering problem

To read data from the Convex database, you write queries to fetch data and display it in your app, and each query filters to return only the data it wants.

You can make your queries fast with indexes, discussed [below](https://stack.convex.dev/complex-filters-in-convex#Optimize-with-indexes). But to get started, or if your filter is complicated enough, you won’t be using indexes. You’ll be using plain query filters, like this:

```typescript
export const messages = query({
  args: { channel: v.string() },
  handler: async (ctx, args) => {
    return await ctx.db
      .query("posts")
      .filter((q) => q.eq(q.field("channel"), args.channel)
      .collect();
  },
9});

```

This is equivalent to the following query in SQL, assuming the table has no indexes:

```sql
SELECT * FROM messages WHERE channel = "$channel"

```

At first glance, Convex’s filter syntax is limited. There’s `q.eq`, `q.lt`, `q.or`, and a few more, but nothing advanced. You can’t manipulate strings or loop over arrays. Newcomers to Convex may think these complex patterns are impossible. But in fact the patterns are still possible, and more powerful patterns are available than you might expect from SQL or another query language. That’s because your Convex app can leverage a TypeScript runtime to run arbitrary code _within_ the database.

## Filter too complex? Do it in TypeScript

> Disclaimer
>
> Do this while prototyping or if you know the query doesn’t have to scale. If you need to scale, use indexes as described [below](https://stack.convex.dev/complex-filters-in-convex#optimize-with-indexes).

Let’s work with an example. We’ll have a table of posts, like you might display in a Twitter-like feed, where each post has a short array of tags.

```typescript
export default defineSchema({
  posts: defineTable({
    body: v.string(),
    tags: v.array(v.string()),
  }),
6});

```

That’s our data model, and we want to build a query that looks up all posts with a given tag. We’re building a simple search box where you can type in “happy” and posts tagged as “happy” show up.

My first instinct would be to use `.filter`, like the following. However, this doesn’t work because database query `.filter` doesn’t support array containment.

```typescript
// This query is what we want.
export const postsWithTag = query({
  args: { tag: v.string() },
  handler: async (ctx, args) => {
    return await ctx.db
      .query("posts")
      // Doesn't work because q.arrayIncludes doesn't exist.
      .filter((q) => q.arrayIncludes(q.field("tags"), args.tag)
      .collect();
  },
11});

```

So what can we do?

Well, remember that Convex’s runtime can run arbitrary TypeScript and JavaScript. So we can fix the example by replacing the database query `.filter` with a TypeScript array `.filter`.

```typescript
export const postsWithTag = query({
  args: { tag: v.string() },
  handler: async (ctx, args) => {
    const allPosts = await ctx.db.query("posts").collect();
    return allPosts.filter((post) => post.tags.includes(args.tag));
  },
7});

```

And that’s it! The `await ctx.db.query("posts").collect()` returns an array of all posts, which we then filter to only the posts which include `args.tag` in their array of tags. Syntactically, we swapped the order so `.collect()` comes before `.filter()`.

#### Collecting only some of the results

Swapping the order of `.collect()` and `.filter()` works and even has the same performance (more on that below), but what if you don’t need all the results? When using `.first()`, `.unique()`, `.take()`, or `.paginate()`, you don’t need to collect all documents before filtering; you want to apply the filter as you go. Even in this case, we can use TypeScript for filtering; it’s just not a simple `Array.filter()` method call.

I implemented a function in the [“convex-helpers” npm package](https://www.npmjs.com/package/convex-helpers) that does the right thing under the hood: the `filter` helper.

```typescript
import { filter } from "convex-helpers/server/filter";

export const firstPostWithTag = query({
  args: { tag: v.string() },
  handler: (ctx, args) => {
    return filter(
      ctx.db.query("posts"),
      (post) => post.tags.includes(args.tag),
    ).first();
  },
11});

```

The `filter` function in “convex-helpers” allows you to attach a custom filter to any query:

- It can use `.first()`, `.unique()`, `.take(n)`, `.paginate(opts)`, `.collect()`, or `.next()` to get results.
- It can use indexes to efficiently scope down and order the data being filtered: `.withIndex(...)` or `.withSearchIndex(...)`.
- It works with `order("desc")` to reverse the order.
- It can accept and execute an `async` predicate function

Since it works for any query, you can give your Convex filters superpowers by replacing `X.filter((q) => ...).Y` with `filter(X, (doc) => ...).Y`.

Note the `filter` helper looks at documents one at a time. So doing `filter(db.query("posts"), predicate).first()` stops when it finds a single post for which `predicate(post)` is true. This is equivalent to `db.query("posts").filter(predicate).first()` and better than `db.query("posts").collect().filter(predicate)[0]` which would look at every post.

#### Performance of TypeScript filters is the same as SQL unindexed `WHERE` clauses

It may look like the TypeScript filter is slower than the database query filter. After all, surely telling `db.query` you only want _some_ posts must be faster than asking `db.query` for _every_ post and then removing the ones you don’t want.

However, that would be incorrect. Both the `db.query` filter and the TypeScript filter are running in the Convex runtime, which you can think of as running “in the database.” The difference is almost entirely syntactic.[1](https://stack.convex.dev/complex-filters-in-convex#user-content-fn-1) Trying to fit a complex filter in a `db.query` filter isn’t worth it, when you can just use TypeScript.

Let’s compare to using a SQL server, say Postgres, directly.

```sql
SELECT * FROM posts WHERE 'happy'=ANY(tags);

```

In Postgres, this would scan all `posts`, filter them by tags in the Postgres server, and return the matching posts to the client. Convex with the TypeScript filter does the same: it scans all `posts`, filters them by tags in the Convex server, and returns the matching posts to the client. Postgres isn’t magical; it has to look at all `posts` to do the query, and so does Convex.

Let me reiterate: there is no reason to use `db.query(...).filter(...).collect()` over `filter(db.query(...), predicate).collect()`.

- Both of them scan the same documents
- They both execute the filter within the Convex runtime
- They both rerender `useQuery` hooks at the same rate — whenever anything in the table changes
- In mutations, they would cause mutations to retry at the same rate — because Convex mutations use optimistic concurrency control
- Both of them are equivalent in performance to an unindexed SQL `WHERE` clause

#### TypeScript filters are powerful and easy to write

Other databases have entire libraries of custom filter syntax, and they’re all different. Here’s array containment:

- Postgres uses `'happy'=ANY(tags)`
- MySQL uses `FIND_IN_SET('happy', tags) > 0`
- MongoDB uses `tags: { "$in" : ["happy"]}}`

In Convex you can use TypeScript or JavaScript, which means not only can you use the `Array.includes` [function](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/includes) you’re already familiar with (i.e. `post.tags.includes("happy")`), but you have the full power of recursive syntax and npm libraries at your disposal.

Want to search for tags that would be too large to print? In Convex you could do this

```typescript
function tagsOverflow(post: Doc<'posts'>) {
  const tagString = post.tags.map((tag) => '#' + tag).join(', ');
  return tagString.length > 100;
4}
const allPosts = await ctx.db.query("posts").collect();
const overflowingPosts = allPosts.filter(tagsOverflow);

```

I can write this filter with rudimentary TypeScript knowledge, without searching StackOverflow. I would need help to write this same filter on a different database, if it’s even possible.

And you’re not limited to single-table filters. You can do arbitrary joins against other tables, with no worries about race conditions because Convex queries are transactional. And you can sort by an arbitrary combination of fields, using TypeScript’s `Array.sort`.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

## Optimize with Indexes

Before optimizing, make sure you need to. If you only have a few hundred documents, filtering in TypeScript is fine and should be the default while prototyping.

Check out “ [Queries that scale](https://stack.convex.dev/queries-that-scale)” for tips and tricks on writing scalable queries. That article give widely useful tips, while this section doubles down on the example given above, describing every possible way you could address it.

Let’s walk through the ways to optimize the posts-and-tags query at the expense of data model complexity, mutation performance, and even the performance of other queries.

#### Array `includes` with index and a join

We want to find all posts with a given tag, so let’s add an index on the tags.

What if we add `.index("by_tags", ["tags"])` to the posts table?

An index sorts the documents in a table, allowing queries to binary-search for a range and iterate over it. If we wanted to query for posts with `tags` exactly equal to `["happy"]`, we could use this index. We could even use it to find posts where `tags` starts with `["happy", ...]` since those are all together in the index. But sorting by `tags` doesn’t place `["happy", "joyful"]` next to `["wonderful", "happy"]`; the post with tags `["sad", "corgi"]` would be in between (because “h” < “s” < “w”).

So we need a way to group all posts with common tags together. We can do this by adding a new table:

```typescript
export default defineSchema({
  posts: defineTable({
    body: v.string(),
    tags: v.array(v.string()),
  }),
  tagged_posts: defineTable({
    tag: v.string(),
    post: v.id("posts"),
  }).index("by_tag", ["tag"]),
10});

```

Whenever a post is inserted, modified, or deleted, the “tagged\_posts” table must be updated in sync. This requires changing mutations, but don’t worry about race conditions when updating both tables, because mutations are committed as transactions.[2](https://stack.convex.dev/complex-filters-in-convex#user-content-fn-3)

Once your new table is set up, the query can use the index.

```typescript
export const postsWithTag = query({
  args: { tag: v.string() },
  handler: async (ctx, args) => {
    const taggedPosts = await ctx.db.query("tagged_posts")
      .withIndex((q) => q.eq("tag", args.tag))
      .collect();
    return await Promise.all(
      taggedPosts.map((taggedPost) => ctx.db.get(taggedPost.post))
    );
  },
11});

```

This is _the_ efficient way to look up posts by tag. It looks up exactly the post ids associated with each tag, and joins against the posts table.

#### Advanced indexes

In addition to standard indexes, Convex also offers full text search and vector indexes. If you store data in specific ways, you can leverage these indexes to get you the results you want. If we store tags in a space-separated string instead of an array, we can use full text search.

```typescript
export default defineSchema({
  posts: defineTable({
    body: v.string(),
    // e.g. "happy joyful", "wonderful happy", "sad corgi"
    tags: v.string(),
  }).searchIndex("search_tags", { searchField: "tags" }),
7});
export const postsWithTag = query({
  args: { tag: v.string() },
  handler: async (ctx, args) => {
    return await ctx.db.query("posts")
      .withSearchIndex("search_tags", (q) => q.search("tags", args.tag))
      .collect();
  },
15});

```

The behavior has slightly changed, due to the nature of full text search. If a tag contains a space, it’s equivalent to having two tags. The query can now search for tags with fuzzy search, so misspellings are tolerated. And you can search for multiple tags at once.

Using full text search can work for our tags example, but it’s tricky to generalize to other complex filters.[3](https://stack.convex.dev/complex-filters-in-convex#user-content-fn-4) Similarly, vector indexes can organize your data by distances between vectors, which are often used with AI-computed embeddings but can be any vectors.

#### Escape hatch: pagination

You may have noticed that TypeScript filters can work with pagination. This can return small or empty pages to the client, which can slow down load times and cost database bandwidth as it traverses the entire table across many pages. But it always works! Each query only looks at a small page of data, so they can run within Convex’s query limits.

```typescript
import { filter } from "convex-helpers/server/filter";

export const postsWithTag = query({
  args: { tag: v.string(), paginationOpts: paginationOptsValidator },
  handler: (ctx, args) => {
    return filter(
      ctx.db.query("posts"),
      (post) => post.tags.includes(args.tag),
    ).paginate(args.paginationOpts);
  },
11});

```

#### Combining indexes with TypeScript filters

Often you can use an index to narrow down the results, and attach a TypeScript filter on the results.

```typescript
import { filter } from "convex-helpers/server/filter";

export const postsWithTagAndAuthor = query({
  args: { author: v.id("users"), tag: v.string() },
  handler: (ctx, args) => {
    return filter(
      ctx.db.query("posts")
        .withIndex("by_author", q => q.eq("author", args.author)),
      (post) => post.tags.includes(args.tag),
    ).collect();
  },
12});

```

Maybe there are tons of posts in the database, but each author has only written a small number. Then you can look through the author’s posts with an index, and use a TypeScript filter to identify the posts with a tag.

#### Denormalizing properties

If there’s a specific query you need to make faster, you can consider storing extra fields on your document to improve query performance. Suppose your app’s home page shows posts tagged as “important”, so you want fast lookup for that specific tag.

```typescript
// Add field to schema
export default defineSchema({
  posts: defineTable({
    body: v.string(),
    tags: v.array(v.string()),
    isImportant: v.boolean(),
  }).withIndex("by_important", ["isImportant"]),
8});
// Set field when inserting and updating
await ctx.db.insert("posts", {
  body,
  tags,
  isImportant: tags.includes("important"),
14});
// Now you can query for the denormalized field with an index
// Remember to keep it in sync when there's a db.patch or db.replace.
await ctx.db.query("posts")
  .withIndex("by_important", q => q.eq("important", true))
  .collect();

```

As a general pattern, you can store booleans or other types on your documents to speed up lookup by those properties.

## Recap

Complex filters work differently in Convex compared to other databases. Instead of restricted custom syntax, you can leverage TypeScript to do any filter you want. The built-in `db.query(...).filter(...)` can be replaced with the equally efficient and more powerful `filter` from convex-helpers. If you’re ready to optimize beyond filters, use indexes to speed up your queries. [Read more about that here](https://stack.convex.dev/queries-that-scale). Happy querying!

### Footnotes

1. `db.query` filters run in Rust, while TypeScript/JavaScript filters run in … JavaScript. So a `db.query(tbl).filter(pred)` may be slightly faster than a `filter(db.query(tbl), pred)` because the latter does context-switching between JavaScript and Rust. But they scan the same data under the hood, and performance differences from context switching are overshadowed by any changes that affect the number of documents scanned. [↩](https://stack.convex.dev/complex-filters-in-convex#user-content-fnref-1)

2. If you don’t want to manually manage the extra table, use [https://stack.convex.dev/ents](https://stack.convex.dev/ents) . If you want nicer query syntax, use [https://stack.convex.dev/functional-relationships-helpers](https://stack.convex.dev/functional-relationships-helpers). [↩](https://stack.convex.dev/complex-filters-in-convex#user-content-fnref-3)

3. An enterprising engineer used Convex’s full text search to build a geospatial index, with Uber’s H3 library: [https://github.com/sujayakar/geospatial-convex](https://github.com/sujayakar/geospatial-convex). It wasn’t easy, but the example shows surprising ways you can use indexes to organize data. [↩](https://stack.convex.dev/complex-filters-in-convex#user-content-fnref-4)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Managing Reactivity with useBufferedState

Play

Reactivity has taken a dominant position today within web app development. Our components and app state are all reactive, and the world has adapted–most would argue, for the better.

But has Convex gone too far? 😉

A new generation of serverless backends like Convex is recklessly spreading reactivity across our databases, server-side functions, and protocols, making global reactivity a new phenomenon. Shared global data is becoming reactive by default. Is this good for the world?

In this video, Jamie Turner explores one circumstance where this pervasive reactivity poses a challenge, and he builds one useful abstraction for taming over-reactivity and turning it back into a strength.

Code: [https://github.com/jamwt/convex-buffered-state](https://github.com/jamwt/convex-buffered-state)

Jamie on Twitter: [https://twitter.com/jamwt](https://twitter.com/jamwt)

**Technologies used:**

React: [https://reactjs.org/](https://reactjs.org/)

Next.js: [https://nextjs.org/](https://nextjs.org/)

TailwindCSS: [https://tailwindcss.com/](https://tailwindcss.com/)

Convex: [https://convex.dev](https://convex.dev/)

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# CRUD APIs: Functional, but Inefficient

## Implementing basic CRUD endpoints

The term CRUD, or CRUD API, is often tossed around when interacting with databases or building backend APIs. This article will examine what CRUD is, what it’s suitable for, and its shortcomings. Finally, we’ll explore how to quickly implement a CRUD API using a modern backend like Convex.

## What is CRUD, and why should I care?

CRUD is a common and straightforward way to model API services by addressing data inside database tables as individual objects. Imagine our app has a `posts` table:

| Id | Body | Author |
| --- | --- | --- |
| 1 | I just went to the park today. | Jack |
| 2 | Careful! Don’t fall down the hill! | Jill |

To evolve this table data over time, there are four specific operations we need to perform on individual records.

#### **1\. Create a** new object

When a user adds a post, we’ll insert one into the table:

| Id | Body | Author |
| --- | --- | --- |
| 1 | I just went to the park today. | Jack |
| 2 | Careful! Don’t fall down the hill! | Jill |
| 3 | Hills are overrated | Gus |

#### 2\. Read an existing object

When someone wants to retrieve a post, typically, they’ll provide some unique information like the post ID. In this case, someone wants to see what Jack initially said:

| Id | Body | Author |
| --- | --- | --- |
| 1 | I just went to the park today. | Jack |
| 2 | Careful! Don’t fall down the hill! | Jill |
| 3 | Hills are overrated | Gus |

#### 3\. Update an object

At times, we’ll need to modify an object we already stored. We typically do this by providing a unique ID for a specific object and the new field data for that object. If Gus started to think more favorably of hills, we might see an update like this:

| Id | Body | Author |
| --- | --- | --- |
| 1 | I just went to the park today. | Jack |
| 2 | Careful! Don’t fall down the hill! | Jill |
| 3 | Hills are underrated | Gus |

#### 4\. Delete an object

Finally, sometimes, our app needs to take a post out of the table altogether. Perhaps after all this inane discourse about hills, Jill no longer cares if Jack or Gus falls down one. If so, she can choose to remove message 2:

| Id | Body | Author |
| --- | --- | --- |
| 1 | I just went to the park today. | Jack |
| ~~2~~ | ~~Careful! Don’t fall down the hill!~~ | ~~Jill~~ |
| 3 | Hills are underrated | Gus |

... becomes:

| Id | Body | Author |
| --- | --- | --- |
| 1 | I just went to the park today. | Jack |
| 3 | Hills are underrated | Gus |

This simple object model combined with these four operations ( **C** reate, **R** ead, **U** pdate, **D** elete) constitutes a flexible way to manage all table data. So, the acronym **CRUD** refers to this very approach to API design.

## Is this like REST?

REST is one common way to implement CRUD APIs over HTTP. REST combines the semantics of certain HTTP methods with resource paths to achieve the create, read, update, and delete CRUD operations.

Here’s how our previous scenario would be implemented with REST:

**1\. Creation** with REST involves using the `POST` HTTP method and providing the object contents in the request body. This generates a new object for the collection at the given resource path and returns the associated unique ID (in this case, as a JSON response):

```jsx
Request:
	POST /posts/
	{"body": "Hills are overrated","author":"Gus"}
Response (201 Created):
  {"id":3}

```

The created entity now has an HTTP resource path associated with it. The path convention is the concatenation of the collection path and the unique ID as a child document—in this case, `/posts/3`.

**2\. Reading** an object with REST simply uses the `GET` method at the resource’s path:

```jsx
Request:
	GET /posts/1
Response (200 OK):
  {"id":1,"body": "I just went to the park today.","author":"Jack"}

```

**3\. Updating** an object with a REST API involves the `PUT` (or `PATCH` for partial updates) HTTP method. The body data of the request should contain the new object contents:

```jsx
Request:
	PUT /posts/3
	{"body": "Hills are underrated","author":"Gus"}
Response (200 OK)

```

**4.** Finally, **deleting** an object uses the HTTP `DELETE` method:

```jsx
Request:
  DELETE /posts/2
Response (200 OK)

// Later...
Request:
	GET /posts/2
Response (404 Not found)

```

That’s it! Simple, right? And since CRUD maps so cleanly to the HTTP services we use everywhere, why use anything other than RESTful APIs to manage our backend data?

While that would be nice and simple, CRUD and REST have some significant limitations that require us to be pretty thoughtful about where we can and cannot use it. Let’s dive into them now.

## Common CRUD (and REST) pitfalls

#### Action-ness vs. object-ness

There are times when the thing you want to happen to your backend is—simply put—more of an arbitrary action than an addition or modification of persistent data. So if you find yourself doing strange convolutions to figure out which “object” should be `POST` ed to in order to kick off some side effect—perhaps a login or a call to a third-party API—CRUD just may not be the right fit for that task.

In fact, many teams find that when they try to wedge CRUD into this situation, they end up `POST` ing entries into a table that becomes a de-facto task/job queue. Now, they’ve accidentally created a need for some sort of asynchronous background work—even if a short blocking operation without any persisted records would have been adequate and simpler.

So, if your intuition says a particular backend call might not need to persist anything, avoiding CRUD is probably wise.

#### Grouped changes to objects

Instead of _no_ records needing to be written, at times your server endpoint needs to update (or insert) _two_ or more records atomically in one transaction. In this case, there is, again, no obvious single object to act as the target of your `PUT` or `POST`.

A CRUD/REST die-hard may argue that “restful” paths are abstract, logical objects, and so they don’t need to map 1:1 with a single database record. In practice, though, tracking how these logical objects map to backend data can be complex. It can also be messy to try to maintain cogent and sound implementations of the full set of create, read, update, and delete CRUD operations.

#### Request waterfalls

Request waterfalls occur when a server-provided parent object contains references to additional “child” objects. The application must then fetch each of those children, and possibly even _they_ contain further references that must be fetched. Each one of these iterations requires another request/response cycle between the app and the server API, which often takes hundreds of milliseconds. If your app does enough of these cycles, it can make your app appear sluggish to load and update—a frustrating experience for your users!

To mitigate this, a common optimization developers pursue is implementing a single server endpoint that recursively resolves the object reference hierarchy and then combines the whole tree of descendants into a single composite response. That way, the application gets everything it needs in one “round trip.”

It’s very difficult to use this strategy with simple CRUD. Since each endpoint returns a single object, request waterfalls occur naturally. Again, you can create composite objects that are logical views of combined data, but can you also `PUT` to them and `POST` to them? The CRUD paradigm breaks down.

#### Authorization without sufficient context

Consider that simple CRUD APIs propose changes to an object with little more parameterization than an object ID and the new fields. However, application authorization logic often needs more contextual information about the intent or environment of the requestor. Since CRUD is so specific about what information is necessary to read or change backend data, your backend lacks the flexibility it sometimes needs to authorize the operation securely.

### Our Advice: unless you _know_ simple CRUD is sufficient, prefer functions

Modern systems like [tRPC](https://trpc.io/) and Convex are converging on representing the boundary between the app and the backend modeled precisely the same way as every other interface in your app: with functions.

Functions are powerful enough to:

- Modify single objects
- Modify groups of objects transactionally
- Trigger a secure server action that persists no database state
- Resolve dependent reads into a single composite response
- Utilize rich authorization context for sophisticated permissions schemes

Basically, functions are the most potent building blocks of abstraction we have in programming languages. So don’t get too ideological about CRUD (or REST) for your APIs. When CRUD patterns feel awkward, try a simple functional/RPC-style API for that endpoint instead.

## Get some CRUD in your Convex

Now that we’ve explored the pros and cons of CRUD, here’s what a simple implementation would look like in a Convex backend:

```ts
import { v } from "convex/values";
import { partial } from "convex-helpers/validators";
import schema from "./schema";
import {
  internalMutation,
  internalQuery,
7} from "./_generated/server";

const teamFields = schema.tables.teams.validator.fields;

export const create = internalMutation({
  args: teamFields,
  handler: (ctx, args) => ctx.db.insert("teams", args),
14});

export const read = internalQuery({
  args: { id: v.id("teams") },
  handler: (ctx, args) => ctx.db.get(args.id),
19});

export const update = internalMutation({
  args: {
    id: v.id("teams"),
    patch: v.object(partial(teamFields)),
  },
  handler: (ctx, args) => ctx.db.patch(args.id, args.patch),
27});

export const delete_ = internalMutation({
  args: { id: v.id("teams") },
  handler: (ctx, args) => ctx.db.delete(args.id),
32});

```

You may have noticed this example only utilizes the `internal` variants of Convex’s query and mutation functions. Why? Because exposing this API essentially lets the entire internet arbitrarily change your tables. And they can do it without any record of who and why!

If you’d like to publicly expose some of these CRUD functions for your Convex tables, simply alter the above examples to use the standard `query` and `mutation` functions. But be cautious and think through the security implications! Even better, read on for an example of using row-level security (RLS) along with CRUD to expose a safe public API.

### Low-code CRUD

Sold on CRUD for some of your tables? Well, good news! [convex-helpers](https://github.com/get-convex/convex-helpers/tree/18cb4a193690d546caefaaac12cf29bdb7c3614c/packages/convex-helpers#crud-utilities) has a library to make exposing selected crud API methods dead simple. Here’s an example that wraps an app’s users table to expose a CRUD-style `read` query and `update` mutation:

```ts
// in convex/users.ts
import { crud } from "convex-helpers/server/crud";
import schema from "./schema.js"

export const { create, read, update, destroy } = crud(schema, "users");

```

Then, you can access these functions from actions elsewhere in your code with references like `internal.users.read`:

```ts
// in some file
export const myAction = action({
  args: { userId: v.id("users") },
  handler: async (ctx, args) => {

    const user = await ctx.runQuery(internal.users.read, { id: args.userId });

    // Do something interesting

    await ctx.runMutation(internal.users.update, {
      id: args.userId,
      patch: { status: "approved" },
    });

  }
16});

```

To expose the CRUD API publicly, you can pass two more parameters to `crud`, allowing you to add access checks, as we’ll see next.

### CRUD with Row Level Security

To protect your CRUD API when exposing it publicly, you can use row-level security to check access rules when reading/updating data on a per-document granularity. For CRUD, this means we can define rules for how documents can be accessed and modified and then use those rules to protect the public API we expose. This leverages [“custom functions”](https://stack.convex.dev/custom-functions) in Convex, which let you create builders like `query`, `mutation`, or `action` that modify the `ctx` and `args`, similar to middleware. Here’s what this approach might look like in practice:

```ts
import { crud } from "convex-helpers/server/crud";
import { customCtx, customMutation, customQuery } from "convex-helpers/server/customFunctions";
import { Rules, wrapDatabaseReader, wrapDatabaseWriter } from "convex-helpers/server/rowLevelSecurity";
import { DataModel } from "./_generated/dataModel";
import { mutation, query, QueryCtx } from "./_generated/server";
import schema from "./schema";

async function rlsRules(ctx: QueryCtx) {
  const identity = await ctx.auth.getUserIdentity();
  return {
    users: {
      read: async (_, user) => {
        // Unauthenticated users can only read users over 18
        if (!identity && user.age < 18) return false;
        return true;
      },
      insert: async (_, user) => {
        return true;
      },
      modify: async (_, user) => {
        if (!identity)
          throw new Error("Must be authenticated to modify a user");
        // Users can only modify their own user
        return user.tokenIdentifier === identity.tokenIdentifier;
      },
    },
  } satisfies Rules<QueryCtx, DataModel>;
28}

// makes a version of `query` that applies RLS rules
const queryWithRLS = customQuery(
  query,
  customCtx(async (ctx) => ({
    db: wrapDatabaseReader(ctx, ctx.db, await rlsRules(ctx)),
  })),
36);

// makes a version of `mutation` that applies RLS rules
const mutationWithRLS = customMutation(
  mutation,
  customCtx(async (ctx) => ({
    db: wrapDatabaseWriter(ctx, ctx.db, await rlsRules(ctx)),
  })),
44);

// exposing a CRUD interface for the users table.
export const { create, read, update, destroy } = crud(
  schema,
  "users",
  queryWithRLS,
  mutationWithRLS,
52);

```

You can choose to only de-structure the functions that you need, so you can avoid exposing `destroy` altogether, for example.

Happy CRUDding!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Customizing serverless functions without middleware

Writing code for a backend API often requires doing similar steps: authenticate a user, looking up their roles and feature flags, etc. In most backend frameworks, the platform exposes bespoke ways of interacting with request handlers. It’s often referred to as middleware, sitting between the application code and the system code. In this article I’m going to make the case for keeping as much as possible **out** of middleware[1](https://stack.convex.dev/custom-functions#user-content-fn-1), and how to stay sane in the process.

## Why do we want it?

When you start out, you might have a lot of repeated lines at the beginning of each function like:

```js
const user = await getUser(ctx);
if (!user) throw new Error("Authentication required");
const session = await ctx.db.get(sessionId);
if (!session) throw new Error("Session not found");

```

Note: This syntax is for Convex, but the general idea applies to any backend framework.

You might also want to adjust the behavior of the function, for instance wrapping your database interface with a version that does authorization checks before every operation, based on the logged-in user:

```js
// Pass in a user to use in evaluating rules,
// which validate data access at access / write time.
ctx.db = wrapDatabaseWriter({ user }, ctx.db, rules);

```

As a programmer, it’s natural to want to abstract this away. Modify it once and have it applied everywhere, right? Middleware seems like the right tool for the job. So…

## What’s the problem?

Middleware is often full of magic that can bring a lot of confusion to new members of a codebase, or new users of a platform.

- What is happening to my request?
- Is it validating that the user is logged in?
- Did it start a transaction for me? Will it clean it up?
- Where does this magical session object come from?
- How were these globals initialized?
- Which middleware **aren’t** being applied to my function?

When you’re looking at the endpoint handler, you don’t have a clear idea how requests are being modified before they get to your code. The configuration for middleware is not a simple `Cmd+click` “Jump-to-definition” hop away. You have to know where it’s defined, how it’s configured to apply (or not), and what it’s doing. Which brings me to my first principle of sorts when it comes to customizing functions:

### 1\. Function customization should be obvious and discoverable

You should be able to tell whether a function’s arguments are being modified or not, and find the code modifying the request or doing extra logic, via Cmd+click. Thankfully, using patterns like decorators for middleware in python help with this. If there are multiple modifications happening, that should be clear too, which leads to the next principle:

### 2\. Customization should be explicit and direct

When composing multiple behaviors, it can be confusing to reason about ordering and dependencies when nesting. If your row level security depends on certain data being available, such as the logged in user, that shouldn’t require having to remember to chain behavior in the right order. Another pattern one might consider, which I previously suggested in the “wrappers as middleware” series, results in nested function definitions like this:

```js
// BAD: do I really have to remember to do this in the right order everywhere?
export const myFunction = mutation(
  withUser(
    withSession(
      withRowLevelSecurity(async (ctx, args) => {
        // ...
      })
    )
  )
10);

```

With this approach, it’s easy to forget which order execution happens in, and how types are passed along. It ends up requiring more cognitive overhead than the simple lines it’s replacing! Ideally the custom behavior is relatively short and straightforward (to reduce cognitive overhead). As we’ll see later, writing it as a single imperative function is easier to reason about than layers upon layers of wrapped functions, each only contributing a few lines of code. It also allows you to define a small number of “blessed” function types, rather than deciding what to compose for every callsite.

Aside: the “wrapper” sort of type inference also ends up being hard for TypeScript to infer the type of `ctx` and `args` here. It was often necessary to write functions that combined behavior to get the types working, which leads to the third principle:

### 3\. Type safety should be default and predictable

When middleware defines request-scoped variables, the types for what’s available at the endpoint isn’t always clear. At a former python-heavy company, there was a User provided to every handler, but it wasn’t clearly typed, so you had to know or guess what was defined on it. When working in Go, the `ctx` passed to every function has the same type ( `ctx.Context`) regardless of what has been added to it upstream. In TypeScript we can do better.

However, getting the types right for those higher level functions, or writing generic function wrapping code gets complicated quickly. I previously suggested this as the pattern in my “wrappers as middleware” series, but the types were so annoying that many users either gave up on the approach or gave up on type safety. **You shouldn’t need a math degree to add a parameter to a function.**

The types can speak for themselves when provided to the endpoint handler, and often communicate enough that the user doesn’t need to jump to the custom function definition. The functions that are being modified should have type signatures that make it obvious what’s available and what’s not. And that goes for the customization logic too: adding lookups and behavior should feel type-safe and allow you to hover over intermediate values to inspect types. If you change your logic and introduce a bug, you should get type errors.

## How do we do it?

To achieve these goals for Convex, I’ve implemented functions to customize the Convex [query](https://docs.convex.dev/functions/query-functions), [mutation](https://docs.convex.dev/functions/mutation-functions), and [action](https://docs.convex.dev/functions/actions) builders (and their [internal corollaries](https://docs.convex.dev/functions/internal-functions)). They can be imported from the `convex-helpers` npm package.[2](https://stack.convex.dev/custom-functions#user-content-fn-2)

For those who aren’t familiar with Convex, it’s a hosted backend as a service, including everything from a reactive database and serverless functions to file storage, scheduling, and search. Check out the [docs](https://docs.convex.dev/home) to learn more about the basics.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

From here on, we’ll look at my approach for Convex. The general approach should translate to other frameworks, to varying degrees.

### Modifying the `ctx` argument to a server function for user auth

Here’s an example where we only modify some values in the `ctx` passed to a Convex function. We look up the logged in user, and provide it as `ctx.user` within a function defined with `userQuery`. We also wrap database reads with some row-level security.

```js
import { query } from "./_generated/server";
import { customQuery, customCtx } from "convex-helpers/server/customFunctions";

// Use `userQuery` instead of `query` to add this behavior.
const userQuery = customQuery(
  query, // The base function we're extending
  // Here we're using a `customCtx` helper because our modification
  // only modifies the `ctx` argument to the function.
  customCtx(async (ctx) => {
    // Look up the logged in user
    const user = await getUser(ctx);
    if (!user) throw new Error("Authentication required");
    // Pass in a user to use in evaluating rules,
    // which validate data access at access / write time.
    const db = wrapDatabaseReader({ user }, ctx.db, rules);
    // This new ctx will be applied to the function's.
    // The user is a new field, the db replaces ctx.db
    return { user, db };
  })
20);

// Used elsewhere

// Defines a publicly-accessible mutation endpoint called "myInfo"
// Returns basic info for the authenticated user.
export const myInfo = userQuery({
  args: { includeTeam: v.boolean() },
  handler: async (ctx, args) => {
    // Note: `ctx.user` is defined. It will show up in types too!
    const userInfo = { name: ctx.user.name, profPic: ctx.user.profilePic };
    if (args.includeTeam) {
      // If there are any rules around the teams table,
      // the wrapped `ctx.db` can ensure we don't accidentally
      // fetch a team the user doesn't have access to.
      const team = await ctx.db.get(ctx.user.teamId);
      return { ...userInfo, teamName: team.name, teamId: team._id };
    }
    return userInfo;
  }
40});

```

The `customCtx` function here is a convenience function for when you want to modify `query`, `mutation`, or `action` and don't need to consume or modify arguments.

### Consuming a function argument for basic API key auth

Here’s another example where we add an additional argument to every `apiMutation` function. Any client calling these functions will need to pass an `apiKey` parameter, but the implementation of these functions doesn’t receive or specify argument validation for it.

```js
import { mutation } from "./_generated/server";
import { customMutation } from "convex-helpers/server/customFunctions";

// Use `apiMutation` instead of `mutation` to apply this behavior.
const apiMutation = customMutation(mutation, {
  // This is the expanded customization simplified by `customCtx` above
  // You can specify arguments that the customization logic consumes
  args: { apiKey: v.string() },
  // Similar to the `args` and `handler` for a normal function, the
  // args validated above define the shape of `args` below.
  input: async (ctx, { apiKey }) => {
    // Add a simple check against a single API_KEY.
    if (apiKey !== process.env.API_KEY) throw new Error("Invalid API key");
    // We return what parameters to ADD to the modified function parameters.
    // In this case, we aren't modifying ctx or args
    return { ctx: {}, args: {} };
  },
18});

//... used elsewhere

// Defines a publicly-accessible mutation endpoint called "doSomething"
export const doSomething = apiMutation({
  // Note we don't specify "apiKey" at every callsite
  args: { someArg: v.number() },
  // Note: args here doesn't include "apiKey" since it wasn't returned above.
  handler: async (ctx, args) => {
    const { someArg } = args;
    // ...
  }
31});

```

Note: to do more robust API key validation, I’d make an `api_keys` table and have the key be an ID to a document in that table. In that document you can capture who it was issued to, whether it’s been invalidated, its expiration, etc. The example with env variables above is a tactical convenience for when you have a single other trusted environment.

### Modifying `ctx` and `args` for a session implementation

Another example of a custom function:

```js
import { mutation } from "./_generated/server";
import { customMutation } from "convex-helpers/server/customFunctions";

// Use `sessionMutation` to define public queries
export const sessionMutation = customMutation(mutation, {
  // Argument validation for sessionMutation: two named args here.
  args: { sessionId: v.id("sessions"), someArg: v.string() },
  // The function handler, taking the validated arguments and context.
  input: async (ctx, { sessionId, someArg }) => {
    const user = await getUser(ctx);
    if (!user) throw new Error("Authentication required");
    const session = await ctx.db.get(sessionId);
    if (!session) throw new Error("Session not found");
    // Pass in a user to use in evaluating rules,
    // which validate data access at access / write time.
    const db = wrapDatabaseWriter({ user }, ctx.db, rules);
    // Note: we're passing args through, so they'll be available below
    return { ctx: { db, user, session }, { sessionId, someArg } };
  }
20})

export const checkout = sessionMutation({
  args: {
    // Note: you can specify this as an argument if you want,
    // if you match the type. Or you can omit it. You will get it either way.
    // sessionId: v.id("sessions"),
  },
  // args here includes sessionId and someArg (including in the type)
  handler: async (ctx, args) {
    const { user, session } = ctx;
    const cart = await db.get(session.cartId);
    await purchase(ctx, user, cart, args.sessionId);
  }

```

### Further extension

Instead of making layers of these functions, I recommend you do it all in one place when possible. You can use regular function encapsulation to hide unnecessary details, but by adding incremental changes to the same function, you can see all of the modifications and how they interact in the same place.

If you want variations on the behavior, make separate custom functions and use shared functions to avoid repeating too much code. However, I’d bias towards being explicit when possible, so it’s obvious which arguments are being added / removed.

Note: you can also un-define fields in `ctx` by returning `undefined`. E.g. to remove `db` you can return `ctx: { db: undefined }`.

### Downsides?

Are there any downsides? Of course! There is no perfect design or abstraction. For instance, you still have to remember to use the special function. Here are some ways to mitigate it:

- Add an `eslint` rule that prohibits importing the bare `query` or `mutation` anywhere - you can add exceptions for where you override them.
- Instead of replacing `db` with a “safer” version, you can change its name, and remove the original name, like: `ctx: { safeDB: db, db: undefined }`. Then in any place where you expected to do `ctx.safeDB`, you’ll get a type error if you’re not using your custom function.

## Recap

`customFunction` helpers are:

1. **Discoverable and obvious**: you can tell if your function is modified by whether it uses `mutation` or `apiMutation`. You can command+click `apiMutation` to jump to its definition.
2. **Explicit and direct** function calls make it easy to see what modifications are happening, and in which order. Dependencies look like regular function arguments (such as for `wrapDatabaseWriter`).
3. **Easy and predictable** types are available at each step of the customization. It’s all fully type-safe TypeScript, without having to add any type annotations! Meaning this is valid JavaScript too.

If you want to see the code, you can check it out / fork it / submit a PR here:

[get-convex/ **convex-helpers**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/get-convex/convex-helpers)

### Footnotes

1. I should admit that I likened my previous attempts at generic function customization as “middleware” - and I’m not opposed to the idea of centralizing the customization logic, provided it meets the principles here. For instance, I really like FastAPI’s argument dependency ergonomics. [↩](https://stack.convex.dev/custom-functions#user-content-fnref-1)

2. Install `convex-helpers` with `npm i convex-helpers@latest`. [↩](https://stack.convex.dev/custom-functions#user-content-fnref-2)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Convex Cookbook: Dynamic Query Builders

## TL;DR

You can write a Convex query whose structure -- which index/order/filters to apply, if any -- depends on runtime factors. This article gives a recipe for building queries dynamically.

The file [dynamicQuery.ts](https://github.com/ldanilek/query-cookbook/blob/main/convex/dynamicQuery.ts) has a pattern which you can copy to build Convex queries dynamically.
You can copy it into a `.cursorrules` file to encourage Cursor to use it, or otherwise reference it in your workflow.

### What's a dynamic query?

Convex stores your data so you can query it in many ways. This article will assume the following schema:

```ts
export default defineSchema({
  messages: defineTable({
    author: v.string(),
    conversation: v.string(),
    body: v.string(),
    hidden: v.boolean(),
  }).index("by_author", ["author"])
  .index("by_conversation", ["conversation"])
  .searchIndex("by_body", { searchField: "body" }),
10})

```

Usually you know what you want, so you can write a query to get everything you need, like here's how to get the 10 most recent messages with a given author:

```ts
const results = await ctx.db.query("messages")
  .withIndex("by_author", q=>q.eq("author", args.author))
  .order("desc")
  .take(10);

```

But sometimes you want to build the query dynamically, where parts of the query only apply in certain circumstances. e.g. You want a single query that can find messages by author, or by conversation, or with no filters at all. And once you've added the filters, you sometimes want to order the newest message first, or sometimes the oldest should be first.

Convex queries are plain TypeScript, so you want to build up a `query` variable like so:

```ts
let query = ctx.db.query("messages");
if (args.authorFilter !== undefined) {
  query = query.withIndex("by_author", q=>q.eq("author", args.authorFilter));
4}
if (args.conversationFilter !== undefined) {
  query = query.withIndex("by_conversation", q=>q.eq("conversation", args.conversationId));
7}
if (args.bodyFilter !== undefined) {
  query = query.withSearchIndex("by_body", q=>q.search("body", args.bodyFilter));
10}
if (args.newestFirst) {
  query = query.order("desc");
13}
if (args.excludeHidden) {
  query = query.filter(q => q.eq(q.field("hidden"), false));
16}
const results = await query.take(10);

```

This code works in JavaScript because there are no typechecks, but if you try to
write this code in TypeScript, it won't work! This article describes why and gives a recipe for fixing the problem.

## Why doesn't a single `query` variable work?

Convex queries are constrained by TypeScript to be valid, following simple rules:

- You can't use two indexes to execute a single query, so `query.withIndex(...).withIndex(...)` is invalid.
- A query can only have a single order, so `query.order("desc").order("asc")` is invalid.
- A text search index is both an index and an order (the order is by descending search relevance), so `.withSearchIndex(...)` is incompatible with `.withIndex(...)` and `.order(...)`.

A Convex query keeps all of the necessary information in its type. On the initial table query -- `ctx.db.query("messages")` \-\- you can apply an index. But after you've applied an index, you can no longer apply another, so the query must change type. Similarly, you can't do `.order("desc").order("asc")` so applying an order also changes the query type.

In TypeScript a variable's type can't change, so you can't use a single `query` variable for all stages of building the query.

## Solution: build in stages with multiple variables

The solution is to build the query with a new variable and type for each stage.

1. Pick a table to query.
2. Pick an index and apply an index filter.
3. Pick an order.

After these three stages, we have a complete query. There are two further things we can do, but they don't change the query type:

- Apply a post-filter, if any.
- Get results.

```ts
// Stage 1: Pick the table to query.
const tableQuery: QueryInitializer<DataModel["messages"]> = ctx.db.query("messages");

// Stage 2: Pick the index to use.
let indexedQuery: Query<DataModel["messages"]> = tableQuery;
if (args.authorFilter !== undefined) {
  indexedQuery = tableQuery.withIndex("by_author", q=>q.eq("author", args.authorFilter));
8}
if (args.conversationFilter !== undefined) {
  indexedQuery = tableQuery.withIndex("by_conversation", q=>q.eq("conversation", args.conversationId));
11}

// Stage 3: Apply ordering.
let orderedQuery: OrderedQuery<DataModel["messages"]> = indexedQuery;
if (args.newestFirst) {
  orderedQuery = indexedQuery.order("desc");
17}

// Stage 2 & 3: Apply text search index which includes both index and ordering.
if (args.bodyFilter !== undefined) {
  orderedQuery = tableQuery.withSearchIndex("by_body", q=>q.search("body", args.bodyFilter));
22}

// Post-filter: Filters don't change the query builder's type.
// You can also use the `filter` helper from `convex-helpers`.
if (args.excludeHidden) {
  orderedQuery = orderedQuery.filter(q => q.eq(q.field("hidden"), false));
28}

// Get results using `.first`, `.unique`, `.collect`, `.take`, or `.paginate`.
const results = await orderedQuery.take(10);

```

Now we've separated out the stages of building a dynamic query in Convex,
while appeasing the TypeScript gods to ensure that the query is always valid.

### Revealed structure: multiple filters

Consider what happens if you pass in both `args.authorFilter` and `args.conversationFilter`.

In the untyped code, it looks like both filters are applied:

```ts
if (args.authorFilter !== undefined) {
  query = query.withIndex("by_author", q=>q.eq("author", args.authorFilter));
3}
if (args.conversationFilter !== undefined) {
  query = query.withIndex("by_conversation", q=>q.eq("conversation", args.conversationId));
6}

```

But in fact this code throws an error at runtime, because the query can only have a single index. In the typed code, you can see the variable `indexedQuery` getting overwritten with a new `tableQuery.withIndex(...)`, so the author filter is lost and only the conversation filter applies:

```ts
if (args.authorFilter !== undefined) {
  indexedQuery = tableQuery.withIndex("by_author", q=>q.eq("author", args.authorFilter));
3}
if (args.conversationFilter !== undefined) {
  indexedQuery = tableQuery.withIndex("by_conversation", q=>q.eq("conversation", args.conversationId));
6}

```

If this behavior is intended, the separate variables have made it more obvious. On the other hand, if we want both filters to apply, we have two choices:

1. Apply one of the filters as a post-filter, either with `.filter()` or the [`filter` helper function](https://stack.convex.dev/complex-filters-in-convex).
2. Use a multi-field index such as `.index("by_conversation_and_author", ["conversation", "author"])`.

## Put it all together

The [dynamicQuery.ts](https://github.com/ldanilek/query-cookbook/blob/main/convex/dynamicQuery.ts)
file has the full example, along
with comparisons to untyped JavaScript and an equivalent SQL query builder.

When building a Convex app, you can usually use fixed queries whose structure
doesn't depend on runtime arguments. But sometimes you need to build a query
dynamically, and this article shows how to do so while maintaining typechecks.

Code helpers like Copilot and Cursor might not discover the pattern on their own,
so you can hint it to them by copying `dynamicQuery.ts` into their context.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Convex Ents: Manage your document relationships

> Ents is in maintenance mode. We're open to taking PRs, and will make sure it doesn't break. There will not be active feature development from the Convex team.

Note: This article assumes some familiarity with Convex. If you’re not familiar with it, check out the [Convex tutorial](https://docs.convex.dev/get-started).

[Convex Ents](https://labs.convex.dev/convex-ents) is a library for Convex providing a bunch of useful functionality:

1. Simpler ways to model and query related documents
2. Ability to easily map and filter documents retrieved from the database
3. Enforcing unique document field values
4. Defining default values for easier document shape evolution
5. Propagating deletion to related documents
6. Soft and scheduled document deletion
7. And more

While all of these can be achieved without Convex Ents, the library makes them really easy. If you’re familiar with Prisma or Drizzle ORM, you’ll find yourself at home. Let’s look at each item on the list in more detail.

### Simpler ways to model and query related documents

You can store IDs of other documents in Convex documents, just like in any other relational database. These can represent 1:1 and 1:many relationships between documents, which in the Ents parlance are called “edges”:

In vanilla Convex:

```jsx
// schema.ts
users: defineTable({
  name: v.string(),
4}),
messages: defineTable({
  text: v.string(),
  userId: v.id("users")
8})
  .index("userId", ["userId"])

// myFunctions.ts
// args: userId
const messages = await ctx.db
  .query("messages")
  .withIndex("userId", (q) => q.eq("userId", userId))
  .collect();

```

In this example we have two tables, users and messages, and messages have a required `userId` field. We also defined an index on this field, so that we can efficiently retrieve just the messages related to a given userId. Which is exactly what we did in the example query.

Now let’s look at the equivalent with Convex ents:

```jsx
// schema.ts
users: defineEnt({
  name: v.string(),
4})
  .edges("messages", { ref: true }),
messages: defineEnt({
  text: v.string()
8})
  .edge("user")

// myFunctions.ts
// args: userId
const messages = await ctx.table("users")
  .getX(userId)
  .edge("messages");

```

While there are a bunch of differences in the code between this version and the “vanilla” Convex code, the semantics are exactly the same.

First, we define two “ents” (short for “entity”): users and messages. The message ents are declared to have a unique `edge` to the users table. This translates to the exact same code you saw above: a `userId` field, and an associated index. Additionally, the user ents are declared to have 1:many `edges` to the messages table ( `ref: true` means that the edge is stored as a “reference” in a field - the field name is inferred). This information doesn’t affect the Convex schema, but it allows you to query the relevant messages “from” the user ent.

And that’s exactly what we do in the example query. Instead of `ctx.db.query` we use `ctx.table`. We then ask for the ent with the given `userId` \- but we don’t retrieve it. Instead we immediately ask to traverse the 1:many “messages” edge. This performs the same indexed retrieval as the vanilla code.

#### Many to many relationships

So far we have saved a little bit of code, but Convex Ents shine even more when it comes to modeling many to many relationships. Let’s look at vanilla Convex example first:

```jsx
// schema.ts
roles: defineTable({
  name: v.string(),
4}),
permissions: defineTable({
  name: v.string(),
7})
roles_to_permissions: defineTable({
  rolesId: v.id("roles"),
  permissionsId: v.id("permissions")
11})
  .index("rolesId", ["rolesId", "permissionsId"])
  .index("permissionsId", ["permissionsId"])

// myFunctions.ts
// args: roleId
const rolePermissions = await Promise.all(
  await ctx.db
    .query("roles_to_permissions")
    .withIndex("rolesId", (q) => q.eq("rolesId", roleId))
    .collect(),
  (doc) => ctx.db.get(doc.permissionId),
23);
// args: roleId, permissionId
const hasPermission = (await ctx.db
  .query("roles_to_permissions")
  .withIndex("rolesId", (q) =>
    q.eq("rolesId", roleId).eq("permissionId", permissionId),
  )
  .first()) !== null;

```

To model a many to many relationship in a relational database, you usually define another table to store the relationship, like the `roles_to_permissions` table in this example. You need 2 indexes on it, one for each “foreign key”, so that you can efficiently retrieve related documents from either “side” of the relationship.

Then when you do this retrieval you have to first find the relevant documents representing the relationship, and then you have to map over them to retrieve the document from the other table, this is how we get `rolePermissions`.

In this example we also showcase how to use one of the indexes to answer the common question: “Does this document have given relationship with this other document?”, to get `hasPermission`.

Now let’s look at the equivalent with Convex ents:

```jsx
// schema.ts
roles: defineEnt({
  name: v.string(),
4})
  .edges("permissions"),
permissions: defineEnt({
  name: v.string(),
8})
  .edges("roles")

// myFunctions.ts
// args: roleId
const rolePermissions = await ctx.table("roles")
  .getX(roleId)
  .edge("permissions");
// args: roleId, permissionId
const hasPermission = await ctx.table("roles")
  .getX(roleId)
  .edge("permissions")
  .has(permissionId);

```

As before, this code is semantically equivalent to the vanilla Convex code, but is perhaps more clearly aligned with our intent 💡.

Let’s say that you also need to retrieve the role document itself in the previous example. This is easy with Ents:

```jsx
// myFunctions.ts
const role = await ctx.table("roles").getX(roleId)
const rolePermissions = await role.edge("permissions");

```

All we had to do is split the chained call and `await` the result of the `getX` (get or throw) method call.

This brings us to our second item:

### Ability to easily map and filter documents retrieved from the database

You’ve already seen that Convex Ents use chained method calls, similar to the built-in `ctx.db` API. Ents have one trick up their sleeve though: all methods are `await`-able. This makes the API even more fluent:

```jsx
// myFunctions.ts
const allUsers = await ctx.table("users");
const user = await ctx.table("users").getX(userId);
const messages = await ctx.table("users").getX(userId).edge("messages");

```

This is achieved via “lazy” `Promise` s. Unlike normal JavaScript Promises, which kick off work immediately when they’re created, the `ctx.table` method and methods chained to it return a lazy promise, which doesn’t perform any work until it is `await` ed.

This also allows ents to have extra helper methods which help with retrieving documents, performing “joins” and returning filtered data from Convex functions:

```jsx
return await ctx.table("users")
  .getX(userId)
  .edge("messages")
  .map((message) => {
    const attachments = await message.edges("attachments");
    return {
      _id: message._id,
      text: message.text,
      numAttachments: attachments.length,
    };
  });

```

There are two main things happening in this example, using the `map` method:

1. We query the related `attachments` for given message
2. We only return the fields we want to return to the client

This is totally possible with vanilla Convex, it’s just a bit more code:

```jsx
return await Promise.all(
  (
    await ctx.db
      .query("messages")
      .withIndex("userId", (q) => q.eq("userId", userId))
      .collect()
  ).map((message) => {
    const attachments = await ctx.db
      .query("attachments")
      .withIndex("messageId", (q) => q.eq("messageId", message._id))
      .collect();
    return {
      _id: message._id,
      text: message.text,
      numAttachments: attachments.length,
    };
  }),
18);

```

We’ll pick up the pace and cover the next two points quickly:

### Unique field values

In databases fields there are often “unique” fields which serve as “secondary” keys by which documents can be retrieved. In Convex we can achieve this by:

1. Defining an index on the field
2. Ensuring that a document with a given value doesn’t already exist, anywhere we write given documents

```jsx
// schema.ts
users: defineTable({
  email: v.string(),
4}),
  .index("email", ["email"])

// myFunctions.ts
// Before every insert, patch or replace using the `email` field:
const existing = await ctx.db
  .query("users")
  .withIndex("email", (q) => q.eq("email", email))
  .first();
if (existing !== null) {
  throw new Error(
    `In table "users" cannot create a duplicate document with field "email" of value \`${email}\`, existing document with ID "${
      existing._id as string
    }" already has it.`,
  );
19}

```

Convex Ents have a built-in shortcut for this:

```jsx
// schema.ts
users: defineEnt({}),
  .field("email", { unique: true })

// myFunctions.ts
// The uniqueness check is performed automatically

```

No extra code is required when writing to the `users` table.

### Default field values

When you evolve your schema over time you’ll probably add more fields. But existing documents in the database won’t have any values for these fields yet. The easiest approach is to add an optional field:

```jsx
// schema.ts
posts: defineTable({
  // ... other fields
  contentType: v.optional(v.union(v.literal("text"), v.literal("video")))
5}),

```

In this example we added a `contentType` field, and made it optional. Everywhere we read posts, we can manually include a default value, in vanilla Convex:

```jsx
// myFunctions.ts
return (await ctx.db.query("posts")).map((post) => ({
  ...post,
  contentType: post.contentType ?? "text",
5}));


```

Usually you want to always specify the new field when writing the document. It’s not possible to automatically require this with the built-in schema validation, you have to make sure you write the value yourself.

If the default value is just a simple value like in this example, you can achieve this more easily with Convex Ents:

```jsx
// schema.ts
posts: defineEnt({
  // ... other fields
4})
  .field(
    "contentType",
    v.union(v.literal("text"), v.literal("video")),
    { default: "text" }
  )

// myFunctions.ts
// The "contentType" is not optional, and defaults to "text"
return await ctx.table("posts");

```

Since `contentType` is not an optional field in the document type, TypeScript can ensure that you’re always providing it when writing to the database.

### Cascading deletes, soft deletion and scheduled deletion

In vanilla Convex, when a document is deleted other documents can still include “references” to it by storing the deleted document’s ID. This is a great, simple and scalable model. When querying the ID Convex will return null, and this can be handled (or ignored) by your code.

However, relationships are often required, and it can be easier to reason about your data model without “dangling references” in your documents. For this reason, Convex Ents do not support dangling references in the edges declared via `edge` and `edges`. Convex already makes this easy when writing data to the database, simply by declaring the field which stores the “foreign key” as NOT optional.

This makes deletion in general more challenging though. You can easily have a scenario where a document’s ID is stored in 1000s or even more other documents. Deleting all of these documents in a single mutation, which is within a single transaction, is simply impossible, as it would require a long-lived transaction, grinding the whole database to a halt (something Convex does not allow, instead failing the mutation).

Convex Ents include 3 deletion behaviors:

1. The default one deletes all related documents that require the existence of a given document - cascading deletions, in a single transaction. This is a fine behavior that preserves the “no dangling references” invariant, as long as you don’t expect to have many related documents.
2. The soft deletion behavior doesn’t actually delete the document, but instead sets a `deletionTime` field on it. It’s up to you to make sure that soft delete documents are not shown when they should not be. For example you might want to show the “group posts” of deleted users, because the posts really belong to the “group”, but you don’t show the user’s “profile”.
3. The scheduled deletion behavior combines the two: First it performs only soft deletion, and then, with an optional delay, performs the cascading delete, over possibly many scheduled mutations to make sure that each individual mutation doesn’t read or write too many documents. The deletion is performed depth first, so that no dangling references are created in the process.

Learn more about the different deletion behaviors in [Cascading Deletes documentation](https://labs.convex.dev/convex-ents/schema/deletes).

### Conclusion

We hope you find the library interesting, both for its own merits and as an example of an abstraction that can be built on top of the powerful Convex base. Notably, Ents is built entirely on top of vanilla Convex, and you can contribute to it or fork it to meet your own needs or preferred API ergonomics. The library is still in its early experimental stage, without the stability or quality guarantees built-in Convex provides. If it does seem promising to you, please give it a try and [let us know your feedback on Discord](https://convex.dev/community).

Check out these links to learn more:

- [Convex Ents docs](https://labs.convex.dev/convex-ents)
- [Convex Ents repo](https://github.com/xixixao/convex-ents)
- [Convex Ents issues](https://github.com/xixixao/convex-ents/issues)
- [Prisma vs Convex examples](https://labs.convex.dev/convex-vs-prisma)

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Launching Features Right on Time: Feature Gating

Let’s talk about feature flags.

Have you ever wanted to launch a new feature at an exact time, and not just when some deployment finishes? Or made a mistake on a new feature and had to wait for a “hot fix” deploy to switch back to the old version? Wouldn’t it be great to roll out & roll back a feature with the flick of a switch? Today we’re going to talk about how to flip features on and off remotely using a clever use of the reactive nature of Convex queries. For those who don’t already know, Convex is a backend-as-a-service that allows you to write reactive queries and transactional mutations, all in typescript (or vanilla js if you prefer). Learn more at [docs.convex.dev](https://docs.convex.dev/).

## What is a feature flag?

A “feature flag” or “feature gate” or “kill switch” are all terms I’ve heard for similar functionality: deciding what _feature_ to show a user based on some configurable state, referred to here as a _flag_. Implementations differ slightly, but there will be some API to get the current value for a given flag so you can make decisions in the frontend and/or backend code.

There are companies like LaunchDarkly who have made this their whole business. At Dropbox, we rolled our own version. There is a lot of value in using an off-the-shelf solution, and a lot of advanced functionality that we won’t replicate here today. The goal today is to see how easy it is to provide a basic implementation. The basic feature set we are targeting is:

1. A feature can be enabled / disabled without re-deploying.
2. A client can get updates to the state without reloading the page.

## LaunchDarkly Integration

**Update:** We've released a turn-key integration for adding feature flags to your Convex application with LaunchDarkly. You can follow instructions to install it [here](https://www.convex.dev/components/launchdarkly). This articles still serves as a good reference for implementing your own solution for feature flagging in Convex.

## Safely adding a new feature

I’m going to be adding an interactive chat to the Convex homepage where there is currently just a static image:

![App screenshot](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F8ac3c2708ca4d01cc85a8c0c45aeb5c176fe9086-233x403.png%3Fw%3D300&w=3840&q=75)App screenshot

... into an interactive chat window:

![App screenshot](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F23afdc8526353caeaa106d7a5a3fd261ee9791c3-320x355.gif%3Fw%3D700&w=3840&q=75)App screenshot

This is the fourth panel in a component showing the code necessary to implement chat, so it seems only fair to see the code in action!

Here’s the React component that’s showing the fourth image:

```jsx
1<div className="...">
  <Image
    src="/tabsContent4.png"
    width={210}
    height={388}
    alt="Image of messaging app"
    loading="eager"
  />
9</div>

```

What we want is to have some conditional like this:

```jsx
1<div className="...">
  {showMessages ? (
    <Messages />
  ) : (
    <Image
      src="/tabsContent4.png"
      width={210}
      height={388}
      alt="Image of messaging app"
      loading="eager"
    />
  )}
13</div>

```

But how do we get the value of showMessages?

## Flags table

Let’s keep a table in our backend of what features are on & off, and have the website decide which to show based on that value. Our table in the Convex dashboard after `db.insert("flags", {key: "homepage_chat", value: true})` looks like this:

![Screenshot of the flags table](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Ff308d225e3233d8aafdee27f41c2d84256477ed8-559x266.png%3Fw%3D450&w=3840&q=75)Screenshot of the flags table

## Reading the value

To wire up the value to the frontend, we will use a server-side query to read the flag’s value. In Convex, we can do this by making a file in `convex/flags.ts` in our code repo like this:

```jsx
export const get = query(async ({ db }, { flagName }) => {
  const flag = await db
    .query("flags")
    .filter(q => q.eq(q.field("key"), flagName))
    .first();
  return flag?.value;
7});

```

Once we run `npx convex deploy`, this code will run in Convex’s servers. By using Convex, the return value will automatically be cached based on the function parameters, and the cache automatically invalidates when the flag value changes. Read more about this [here](https://docs.convex.dev/understanding/convex-fundamentals/functions#query-functions). This makes the lookup in the general case wicked fast, and avoids hammering the database. Caching is especially important if it’s a value every client would be fetching, which is the case for config values like this. Traditionally, you’d need to implement your own caching layer with something like Redis, and manually track the cache invalidation. With Convex, it happens by default!

To access it on the client, we just updated our code to:

```tsx
const showMessages = useQuery(api.flags.get, { flagName: "homepage_chat" });

```

This React hook will return the flag’s value, and will trigger a refresh whenever the value changes. Under the hood it’s using a WebSocket that’s shared with any other Convex queries you might be subscribed to, so it’s not clogging the network with polling requests, and the changes are near-instantaneous!

## In action

To prove that it works in production:

![Enabling the feature in production](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fbad730aad2fcacae636e8b7d1f1c87ad44704e6c-960x583.gif%3Fw%3D600&w=3840&q=75)Enabling the feature in production

## Default value

One edge case that off-the-shelf solutions provide, is supplying an initial value until you get the latest version from the server. For this, there’s a few strategies:

1. Show a loading indicator until you know what to show. This is a poor UX, but may be necessary when enabling the wrong feature could be catastrophic.
2. Supply a default in code to use until you get a server response. If you go with this approach for a new feature, the typical flow is to ship the code defaulting to “off”, and then once you’ve released the feature, change the default to “on,” to reduce re-rendering. In our code this looks like `useQuery(api.flags.get, { flagName: "homepage_chat" }) ?? DEFAULT` since Convex returns `undefined` until the first response comes in. This is my favorite, as it also serves as documentation to code readers about what the “canonical” value is at a given point in git history.
3. Supply a default based on a recent, but potentially stale state. For SSG, you might read the flag value when the page is being generated, and use that possibly-stale value as the default. For SSR, you could read the flag value when the page is being rendered, and provide that as the default value.
4. Store the last read default in the browser’s localStorage or similar. I like this one the least, since you still have to handle the initial visit default, and the staleness of the value is hard to reason about. If you return something more complex than a boolean, you might end up with a value that is no longer supported!

## Common pitfalls

While feature flagging is great, I can say from experience that if you don’t maintain some discipline, the code can get hard to reason about. In particular, watch out for these pitfalls:

1. Testing: Make sure your tests check all possible values, not just the default path.
2. Ownership: Every feature flag should have a point of contact who knows why it’s there, and when it can be removed.
3. Documentation: Related to ownership, documenting feature flags can be critical for an oncall rotation to know how to mitigate issues arising from your new feature. What is safe to change? How would I turn it off? I have even linked to feature flags from alerting systems, with instructions about how to turn off features in the case of overload, calling out the expected user impact.
4. Removal: For launching a new feature, you should add removing the feature flag as part of the feature release process. Once it’s been successfully rolled out and you have confidence in it, removing the code helps delete unused code, as well as make the codebase easier to reason about.

## Advanced features

As I mentioned before, there’s good reasons to use off-the-shelf feature flagging solutions. They’ve thought a lot about it, and help you avoid a lot of the above pitfalls, as well as provide rich features that we didn’t even discuss:

- Segmenting the user population. You might want to roll a feature out slowly, only show it to internal users, or A/B test different approaches.
- Metrics. Know how many users have seen a flag in a each state, who they are, and ensuring they’re consistently assigned the same state whenever possible.
- Fancy UIs to manage and audit feature flag changes. In our example we just manually toggled values in the database, which isn’t a very good idea for a production site! These are great places to add documentation and usage graphs.
- Offline caching, which is especially important for mobile clients.

… and the list goes on.

## In summary

![Silhouette of a man against a dark, cloudy sky](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F6f755c51e0130a3bf79ba0bda634fd4922aaee18-1985x1468.png%3Fw%3D450&w=3840&q=75)Silhouette of a man against a dark, cloudy sky

Today we made a slick, minimal feature gate for a new feature, allowing us to roll out on our own schedule, and roll back just as fast. Convex allowed us to achieve all of this without having to worry about caches, invalidation, polling, or triggering UI refreshes ourselves. I hope it’s been helpful! And of course, if you have any questions or need help building anything in Convex, please come visit us in [Discord](https://convex.dev/community).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Database Relationship Helpers

In the [Relationship Structures post](https://stack.convex.dev/relationship-structures-let-s-talk-about-schemas), we looked at how to structure one-to-one, one-to-many and many-to-many relationships using a relational database, and what those queries look like in Convex.

In a SQL-based database, you might be used to the `JOIN` operator, which connects fields from multiple tables into a single flat result. With Convex, we chose to instead expose predictable primitives that you can compose to fetch data, without the sometimes-unpredictable black-box of a query planner. To read more about our thoughts on SQL, [read this post](https://stack.convex.dev/not-sql). To read more about our indexes, [read the docs](https://docs.convex.dev/database/indexes/indexes-and-query-perf).

In this post, we’ll look at some helper functions to help write code to traverse relationships in a readable, predictable, and debuggable way.
The code is in the [convex-helpers npm package](https://www.npmjs.com/package/convex-helpers) if you want to use it in your project.
You can see the source (including fancy typescript types) [here](https://github.com/get-convex/convex-helpers/blob/main/packages/convex-helpers/server/relationships.ts). By the end, we’ll be able to compose functions to execute a complex query involving the SQL equivalent of **select** ing, **join** ing, **group** ing, **sort** ing, and fetching **distinct** documents.

The examples will reference this schema:

```ts
defineSchema({
  users: defineTable({
    name: v.string(),
  }),
  authorProfiles: defineTable({
    userId: v.id('users'), // one to one
    bio: v.string(),
  }).index('userId', ['userId']),
  posts: defineTable({
    title: v.string(),
    authorId: v.id('authorProfiles'), // one to many
    content: v.string(),
  }).index('by_authorId', ['authorId']), // by_ prefix works too
  comments: defineTable({
    postId: v.id('posts'), // one to many
    userId: v.id('users'), // one to many
    text: v.string(),
  }).index('postId', ['postId']),
  postCategories: defineTable({ // many to many relationship table
    postId: v.id('posts'),
    categoryId: v.id('categories'),
  }).index('postId', ['postId']),
  categories: defineTable({ ... }),
24});

```

To use `convex-helpers`, first `npm i convex-helpers` then you can import them:

```js
import {
  getAll,
  getOneFrom,
  getManyFrom,
  getManyVia,
6} from "convex-helpers/server/relationships";

```

## One-to-one

When each document only has one or zero related documents.

### Direct reference: `db.get`

![An arrow points from the left circle to the right circle](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fd5f932d9aec16a2718db3172743b9b80f5db6f7e-3176x1544.png%3Fw%3D800&w=3840&q=75)An arrow points from the left circle to the right circle

If you have an id of a document, you can directly access it with `db.get`. This is the simplest lookup.

```js
const user = await db.get(author.userId);

```

### Back-reference: the `getOneFrom` helper

![An arrow points from the right circle to the left circle](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F44225e22c177e1b2991393180a46a18c9089e402-3176x1544.png%3Fw%3D800&w=3840&q=75)An arrow points from the right circle to the left circle

To fetch a document that has a reference to the document on hand, we use an index on the other table's reference.
For example we can look up an author profile from a user by querying on the index for `userId`:

```js
const author = await db
  .query("authorProfiles")
  .withIndex("userId", q => q.eq("userId", user._id))
  .unique();

```

Using the helper from `convex-helpers`, you can write:

```js
const author = await getOneFrom(db, "authorProfiles", "userId", user._id);

```

**Note**: As is, it will return null if there is no author profile for that user.
If you want to throw an exception instead, use `getOneFromOrThrow`.

## One-to-many

When each document has potentially many related documents.

### Direct references: the `getAll` helper

![A circle on the left points to 3 circles on the right](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F1fdccdb7fdfd240ce605711efbf03eac4f7b6ad4-3176x3176.png%3Fw%3D800&w=3840&q=75)A circle on the left points to 3 circles on the right

To look up a list of IDs all at once, we fetch all of the documents in parallel:

```js
const userPromises = [];
for (const userId of userIds) {
  userPromises.push(db.get(userId));
4}
const users = await Promise.all(userPromises);

```

If you aren't familiar with `Promise.all`, or want to learn about an `asyncMap` helper, read [below](https://stack.convex.dev/functional-relationships-helpers#mapping-over-async-functions).

To make this more readable, we can use the `getAll` helper:

```js
const users = await getAll(db, userIds);

```

**Note**: As is, it will return null in the place of any user that doesn't exist.
If you want to throw an exception instead, use `getAllOrThrow`.

### Back-references: the `getManyFrom` helper

![Three circles on the right point to a circle on the left](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F8b47eb1f3ca96bba00da5eb13063d3e446d9d6d5-3176x3176.png%3Fw%3D800&w=3840&q=75)Three circles on the right point to a circle on the left

We can extend the `getOneFrom` helper for the one-to-many case, differing only by using `collect` instead of `unique`. To get all of the posts for an author, we can do:

```js
const posts = db
  .query("posts")
  .withIndex("by_authorId", q => q.eq("authorId", author._id))
  .collect();

```

Using the helper from `convex-helpers`, you can write:

```js
const posts = await getManyFrom(db, "posts", "by_authorId", author._id);

```

Together with `getAll` we can look up all the users associated with comments on a post:

```js
const comments = await getManyFrom(db, "comments", "postId", post._id);
const userIds = comments.map(comment => comment.userId);
const users = await getAll(db, userIds);

```

These helpers may seem small, but they end up making for much more readable queries. See [below](https://stack.convex.dev/functional-relationships-helpers#come-together-joining-data-with-functions) for a complex example.

### How does the by\_ prefix work?

If you were reading carefully, you might be surprised that I could type just `getManyFrom(db, "posts", "by_authorId", author._id)` above even though the field referenced is just `authorId`. Both the types and the runtime will not require you to pass another argument specifying the field name if your index is just the field name with a "by\_" prefix. The tradeoff here is that it doesn't allow you to use these helpers if your field itself starts with a "by\_" prefix.

If you do want to have your index named something else, you can pass another argument specifying the field name. e.g. if our index was `.index("by_author", ["authorId"])` then the call would need to look like `getManyFrom(db, "posts", "by_author", author._id, "authorId")`.

**This works for all of the relationship helpers that use indexes.**

### What about N+1?

With traditional databases, there is a common issue called the “N+1 problem” where, instead of fetching all data in one request, you end up fetching **one** entity, then the **N** entities associated with it. This is an issue primarily because the code doing the querying is executing far from the database, so you end up waiting on many network requests, and if each query is non-trivial, you may cause excess load to your database.

Wait, isn’t that exactly what the `getAll` helper is doing?

Yes! However, Convex’s architecture changes some key aspects, which enables us to write queries like `getAll`.

1. The functions are being executed very close to the database. This cuts out the largest contributor to the wait time, especially if you’re executing requests serially (i.e. a waterfall of requests).
2. Convex’s concurrency model ( [read about our OCC here](https://docs.convex.dev/database/advanced/occ#when-occ-loses-determinism-wins)) doesn’t ever lock the database for reads, and thanks to its deterministic V8 runtime, queries can be cached efficiently and automatically by Convex, while maintaining stronger default ACID guarantees than other databases.[1](https://stack.convex.dev/functional-relationships-helpers#user-content-fn-1)
3. The `db.get` query is fast. Using “point queries” where you’re just loading one row is not a difficult or expensive task for our database. My heuristic when writing a query is that `db.get` is on the order of 1 millisecond, going from function to database and back with data.

All of this together means that you can write code to fetch the data you want instead of coercing your desires into a SQL command. And by the way, the SQL query planner is doing exactly this - fetching a range of documents via an index, then doing point queries for all the associated documents. It’s just hiding it away from you, making the performance harder to predict and debug.

Don’t worry if this is a bit confusing, the good news is you can write code without having to worry about packing your queries into a single expression.

## Many-to-many

For many-to-many relationships using **direct references** and **back-references** (see the [Relationship Structures](https://stack.convex.dev/relationship-structures-let-s-talk-about-schemas) post for more details), the access pattern is the same as for one-to-many: you can use `getAll` and `getManyFrom`. When you structure a many-to-many relationship by using a relationship (aka join) table, however, we can combine looking up the relationship documents with looking up each referenced document.

### Join table: The `getManyVia` helper

![Three circles on the left and three circles on the right connect both ways via intermediary circles](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F061207caeb5de6f6061f314381a1fe1a78d149e5-3176x3176.png%3Fw%3D800&w=3840&q=75)Three circles on the left and three circles on the right connect both ways via intermediary circles

In our schema, we used the "postCategories" table to store associations between a post and a category.
To fetch all of the categories for a post, without the helper, it could look like:

```js
const links = await getManyFrom(db, "postCategories", "postId", post._id);
const categoryIds = links.map(link => link.categoryId);
const categories = await getAll(db, categoryIds);

```

Using the `convex-helpers` utility:

```js
const categories = await getManyVia(db, "postCategories", "categoryId", "postId", post._id);

```

**Note**: As above, it will return null in the place of any category that doesn't exist.
If you deleted a category but not the entries in "postCategories" pointing to it, for example.
If you want to throw an exception instead, use `getManyViaOrThrow`.

## Mapping over async functions

Let’s take a quick detour to make ourselves a utility function called `asyncMap`. In javascript, there’s an easy way to turn array A into a new array B using `const b = a.map(someFunction)`. It does roughly the equivalent of:

```js
const b = [];
for (const item of a) {
  b.push(someFunction(item));
4}

```

Unfortunately, when you use `map` over an `async` function, you end up with a list of promises instead of the results. So let’s define a function that will act like `map` but await all the promises, like:

```js
const bPromises = [];
for (const item of a) {
  // Start running each async function
  bPromises.push(someFunction(item));
5}
const b = [];
for (const item of bPromises) {
  // Wait for each function to finish
  b.push(await someAsyncFunction(item));
10}

```

### The `asyncMap` helper

A simplified version of it which behaves like the above code, uses `Promise.all`:

```js
async function asyncMap(iterable, asyncTransform) {
  const promises = [];
	for (const item of iterable) {
		promises.push(asyncTransform(item));
	}
  return Promise.all(promises);
7}

```

For example:

```js
const b = await asyncMap(a, someAsyncFunction);

```

This creates all of the promises without waiting on any of them, so they can run in parallel. For those familiar with promises and async-await patterns, you are likely used to this pattern. We could even simplify it to a one-liner:

```js
const asyncMap = (list, asyncTransform) => Promise.all(list.map(asyncTransform));

```

However, I prefer the for-loop version as it supports iterables like `Set`, which don’t have a `.map` function.

To use the version in [convex-helpers](https://www.npmjs.com/package/convex-helpers):

```js
import { asyncMap } from "convex-helpers";

// getAll equivalent
const users = await asyncMap(userIds, doc => db.get(doc));
// or even
const users = await asyncMap(userIds, db.get);

// getManyVia equivalent
const categories = await asyncMap(
  await getManyFrom(db, "postCategories", "postId", post._id),
  (link) => db.get(link.categoryId)
12);

```

### A note on index naming

The helpers so far have leveraged the pattern of naming the index the same as the field you're indexing.
This helps avoid having to type out overly-duplicative information.
However, you may want a different name, especially for an index that has multiple fields.
For example, if you want the postCategories table to be able to check whether a post already has a category, you might change the "postId" index to:

```js
defineSchema({

  postCategories: defineTable({ // many to many relationship table
    postId: v.id('posts'),
    categoryId: v.id('categories'),
  }).index('postId_categories', ['postId', "categories"]),
7})

```

In this case, you can pass an extra argument to the helpers (and their TypeScript type will force you to):

```js
// if there were only one category for a post
const link = await getOneFrom(db, "postCategories", "postId_categories", post._id, "postId");
// get all the postCategory link documents.
const links = await getManyFrom(db, "postCategories", "postId_categories", post._id, "postId");
// many via join table
const categories = await getManyVia(
  db, "postCategories", "categoryId", "postId_categories", post._id, "postId"
8);

```

Thankfully the TypeScript types will prompt you to pick a table name, then an index name, then an argument that matches the type of the index's first field, then the field name if it doesn't match the index.

## Come together: joining data with functions

The beauty of writing the database queries in code is that you can compose functions to get the flexibility you want, while having full control over the order of queries ( `db.query`) and direct lookups ( `db.get`).

As a reminder, here are all the helper functions defined above:

```js
import {
  getAll,
  getOneFrom,
  getManyFrom,
  getManyVia,
6} from "convex-helpers/server/relationships";

// one-to-one via back reference
const author = await getOneFrom(db, "authorProfiles", "userId", user._id);
// one-to-many direct lookup
const users = await getAll(db, userIds);
// one-to-many or many-to-many via back references
const posts = await getManyFrom(db, "posts", "by_authorId", author._id);
// many via join table
const categories = await getManyVia(db, "postCategories", "categoryId", "postId", post._id);

```

With these, we can implement all sorts of lookups and joins, all in javascript!

**Let’s write a query to:**

1. Look up all posts I’ve written (associated with my “author profile”).
2. Include the associated comments in a “comments” field of each post.
3. Add the categories associated with each post via a join table “postCategories” and put them in a “categories” array on each post.
4. Sort the posts by the number of comments.
5. Get the comment users, but only the distinct users, and return them separately since there might be a lot of duplication.

```js
const author = await getOneFrom(db, 'authorProfiles', 'userId', user._id);
const barePosts = await getManyFrom(db, 'posts', 'by_authorId', author._id);
const commenterIds = new Set();
const posts = await asyncMap(barePosts, async (post) => {
  const comments = await getManyFrom(db, 'comments', 'postId', post._id);
  comments.forEach((comment) => commenterIds.add(comment.userId));
  const categories = await getManyVia(
    db, 'postCategories', 'categoryId', 'postId', post._id
  );
  return { ...post, comments, categories };
11});
posts.sort((a, b) => b.comments.length - a.comments.length);
const commentUsers = await getAll(db, commenterIds);
return {posts, commentUsers};

```

No query planning, no SQL, and no table scans. And it’s all just code, so you can write your own helper functions to make it even more readable, and trust that you know what it’s doing under the hood.

## Summary: the beauty of layering

By leveraging some helper functions, we were able to reconstruct various operations to combine data. Unlike SQL, however, we were explicit about the operations, rather than trusting a query planner and guessing at which indexes to define. In Convex, you can solve many problems with function abstractions, rather than pushing that complexity to the database layer. And thanks to the proximity to the database, these queries are very fast, so you don’t have to compromise on speed to have the ergonomics of writing in Javascript.

This applies to many other areas in Convex as well - writing authorization in functions rather than a clunky DSL, writing “middleware” as wrapper functions, and more. By providing powerful primitives and guarantees about execution purity, Convex gives you a solid foundation on which to layer behavior.

As always, let us know what you think in [Discord](https://convex.dev/community), and if you come up with your own patterns for readable, composable querying.

### Footnotes

1. Most databases, including Postgres, default to “read committed” isolation, which is a weaker guarantee than “serializable” isolation, which Convex provides by default. [↩](https://stack.convex.dev/functional-relationships-helpers#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Testing Your App: How to Generate Fake Data

Are you setting up a new development environment and would like to fill it with sample data instead of it being empty? Or perhaps you want to make sure that your UI looks good when you have more than a few rows in your database?

You could create many rows by yourself, but it is tedious if you want good-looking and numerous results. In this article, we’re going to discover a much better way to seed your database with sample data.

## Install Faker

We’re going to use a library called [Faker](https://fakerjs.dev/). It provides helpful functions to generate realistic values in large quantities.

Before we begin, make sure you have a Convex project set up on your machine. If you don't have one already, you can create one using the [Quickstart guide](https://docs.convex.dev/quickstarts).

Then, install Faker using the following command:

```bash
npm install @faker-js/faker

```

## Create an Internal Mutation

I will start by creating a new mutation in my Convex app by writing the following code in a file named `convex/users.ts`:

```typescript
import { internalMutation } from "./_generated/server";

export const createFake = internalMutation(async (ctx) => {
  // …
5});

```

Marking the mutation as internal ensures that users of my app can’t call it. I will still be able to call it myself from the dashboard or [the Convex command-line tool](https://docs.convex.dev/cli#run-convex-function).

## Insert Fake Data

Now, we’re ready to start inserting data. You can consult the [Faker documentation](https://fakerjs.dev/api/) to know which data types it can generate:

![The Faker documentation.](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fd0905e01d05b33fcc1dda0f8350d644ea0691e9d-2626x1978.png%3Fw%3D1400&w=3840&q=75)The Faker documentation.

For my project, I need a list of users that each have a name, a company, and an avatar. I will use the corresponding types to create 200 new users:

```typescript
import { faker } from '@faker-js/faker';
import { internalMutation } from "./_generated/server";

export const createFake = internalMutation(async (ctx) => {
  // Initialize Faker with a random value
  faker.seed();

  for (let i = 0; i < 200; i++) {
    await ctx.db.insert("users", {
      name: faker.person.fullName(),
      company: faker.company.name(),
      avatar: faker.image.avatar(),
    });
  }
15});

```

In the beginning of the function, we call `faker.seed()` so that Faker generates different data each time we call our function. We need it because Faker initializes its random number generator statically. When using Convex, this will happen every time you push new code, not every time you call a function.

Now that we’ve written our function, we can run it using `npx convex run` in the command line. You can also run it [from the Convex dashboard](https://docs.convex.dev/dashboard/deployments/functions#running-functions) instead.

```
npx convex run users:createFake

```

When opening my `users` table [in the Convex dashboard](https://docs.convex.dev/dashboard/deployments/data), I can see that I’ve successfully created 200 new users:

![My fake users in the dashboard.](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F7b481bcc5fdb38b5e2bfd4a5310711081b3e66c7-3246x1744.png%3Fw%3D1400&w=3840&q=75)My fake users in the dashboard.

And when opening my app, I can see that not only do I see all my fake users, but also that they all have avatars!

![The new users in my sample app.](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fc88cf6d5486033191c9be6aba3017901ae951a16-2538x1564.png%3Fw%3D1400&w=3840&q=75)The new users in my sample app.

## Summary

We’ve seen how to create fake data using the Faker library and use it to create rows in the Convex database. To learn more advanced ways to generate fake data, you can read [the Faker documentation](https://fakerjs.dev/api/).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# GPT Streaming With Persistent Reactivity

Building ChatGPT-powered experiences feel snappier when the responses show up incrementally. Instead of waiting for the full response before showing the user anything, streaming the text in allows them to start reading immediately.

OpenAI exposes a streaming API for chat completions. But how do you manage a GPT streaming request when you have a server between the client and OpenAI? You might be tempted to use HTTP streaming end to end - both from the client to the server and the server to OpenAI. However, there’s another way that comes with some big benefits. Spoiler: it’s possible to use a database as a layer of reactivity that separates client request lifecycles from server requests. Don’t worry if that doesn’t make sense yet - we’ll take it one step at a time.

This post will look at working with streams with OpenAI’s Node SDK. Beyond just getting streaming for a single user, we’ll look at an approach that enables:

- **Persisting** the response even if the user closes their browser.
- **Multiplayer chat**, including **streaming multiple ChatGPT messages** at once.
- **Resuming** a stream when a user **refreshes their browser** mid-stream.
- Streaming to **multiple users** at once.
- Implement **custom stream granularity**, such as only updating on full words or sentences, rather than on each token.

To do this, we’ll use Convex to store the messages and make the request to OpenAI. This code is [on GitHub](https://github.com/ianmacartney/streaming-chat-gpt) for you to clone and play with.

![Diagram of browsers talking to Convex, which talks to OpenAI](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F9a7b8865f6cd1cb6748fdb88c986d6ec7bd26bdb-1200x638.png&w=3840&q=75)Diagram of browsers talking to Convex, which talks to OpenAI

## Persisting messages

Let’s say we have a chat app, like the one pictured in the gif above. We want to store the messages from each user, as well as messages populated by responses from OpenAI. First let’s look at how data is stored (2), assuming a client sends a message (1).

When a user sends a message, we immediately commit it to the database, so they’re correctly ordered by creation time. This code is executed on the server:

```tsx
export const send = mutation({
  args: { body: v.string(), author: v.string() },
  handler: async (ctx, { body, author }) => {
    // Save our message to the DB.
    await ctx.db.insert("messages", { body, author });

    if (body.indexOf("@gpt") !== -1) {
      // ...see below
    }
  }
11});

```

This [`mutation`](https://docs.convex.dev/get-started#mutation-functions) saves the message to the database. When the user wants a response from the GPT model (by adding “@gpt” to the message), we will:

1. Store a placeholder message to update later.
2. Make a streaming request to OpenAI in an asynchronous background function.
3. Progressively update the message as the response streams in.

By running the streaming request asynchronously (versus blocking in a user request), we can interact with ChatGPT and save the data to the database **even if the client has closed their browser**. It also allows us to run many requests in **parallel**, from the same or **multiple users**.

We also run it asynchronously because, in Convex, mutations are pure transactions and as such can’t do non-deterministic things like making API requests. In order to talk to third-party services, we can use an `action`. Actions are non-transactional serverless functions that can talk to third-party services. We trigger the background job to call ChatGPT and update the message body by [scheduling](https://docs.convex.dev/scheduling/scheduled-functions) the [action](https://docs.convex.dev/functions/actions) like so:

```tsx
// ...when the user wants to send a message to OpenAI's GPT model
const messages = // fetch recent messages to send as context
// Insert a message with a placeholder body.
const messageId = await ctx.db.insert("messages", {
  author: "ChatGPT",
  body: "...",
7});
// Schedule an action that calls ChatGPT and updates the message.
await ctx.scheduler.runAfter(0, internal.openai.chat, { messages, messageId });

```

We schedule it for zero milliseconds later, similar to doing `setTimeout(fn, 0)` in JavaScript. The message writing and action scheduling happens transactionally in a [mutation](https://docs.convex.dev/functions/mutation-functions), so we will only run the action if the messages are successfully committed to the database.

When the action wants to update the body of a message as the streaming results come in, it can invoke an `update` mutation with the `messageId` from above:

```tsx
export const update = internalMutation({
  args: { messageId: v.id("messages"), body: v.string() },
  handler: async (ctx, { messageId, body }) => {
    await ctx.db.patch(messageId, { body });
  },
6});

```

Note: An `internalMutation` is just a mutation that isn’t exposed as part of the public API. Next we’ll look at the code that calls this `update` function.

Convex has end-to-end reactivity, so when we update the messages in the database, the UI automatically updates. See [below](https://stack.convex.dev/gpt-streaming-with-persistent-reactivity#client-streaming-via-subscriptions) what it looks like to reactively query data.

## Streaming with the OpenAI node SDK

Streaming is currently available in the beta version of OpenAI’s node SDK. To install it:

```bash
npm install openai

```

The `internal.openai.chat` action we referenced above will live in `convex/openai.ts` \- see the full code [here](https://github.com/ianmacartney/streaming-chat-gpt).

```tsx
import { OpenAI } from "openai";
import { internalAction } from "./_generated/server";
//...
type ChatParams = {
  messages: Doc<"messages">[];
  messageId: Id<"messages">;
7};
export const chat = internalAction({
  handler: async (ctx, { messages, messageId }: ChatParams) => {
    //...Create and handle a stream request

```

### Creating a stream request

```tsx
// inside the chat function in convex/openai.ts
const apiKey = process.env.OPENAI_API_KEY!;
const openai = new OpenAI({ apiKey });

const stream = await openai.chat.completions.create({
  model: "gpt-3.5-turbo", // "gpt-4" also works, but is so slow!
  stream: true,
  messages: [\
    {\
      role: "system",\
      content: "You are a terse bot in a group chat responding to q's.",\
    },\
    ...messages.map(({ body, author }) => ({\
      role:\
        author === "ChatGPT" ? ("assistant" as const) : ("user" as const),\
      content: body,\
    })),\
  ],
19});
//...handling the stream

```

Note passing `stream: true`. This changes the return format, which **unfortunately does not currently provide token usage** as the non-streaming version does. I hope this is fixed in a future release, as keeping track of token usage is useful to know how different users or features are affecting your costs.

### Handling the stream

The API exposed by the `openai` SDK makes handling the stream very easy. We use an async iterator to handle each chunk, appending it to the body and updating the message body with everything we’ve received so far:

```tsx
let body = "";
for await (const part of stream) {
  if (part.choices[0].delta?.content) {
    body += part.choices[0].delta.content;
    await ctx.runMutation(internal.messages.update, {
      messageId,
      body,
    });
  }
10}

```

Note that here we’re updating the message every time the body updates, but we could implement **custom granularity** by deciding when to call `runMutation`, such as on word breaks or at the end of full sentences.

This action allows us to stream messages from OpenAI to our server function and into the database. But how does this translate to clients updating in real time? Next, let’s see how the client reactively updates as messages are created and updated.

## Client “streaming” via subscriptions

After the previous sections, you might be surprised how little is required to get the client to show live updating messages. I put streaming in quotes since we aren’t using HTTP streaming here - instead, we’re just using the reactivity provided out-of-the-box by Convex.

On the client, we use the `useQuery` hook, which calls the `api.messages.list` server function in the `messages` module, which we’ll see in a second. This hook will give us an updated list of messages every time a message is added or modified. This is a special property of a Convex [query](https://docs.convex.dev/get-started#query-functions): it tracks the database requests, and when any of the data is changed it:

1. Invalidates the query cache (which is managed transparently by Convex).
2. Recomputes the result.
3. Pushes the new data over a WebSocket to all subscribed clients.

```tsx
export default function App() {
  const messages = useQuery(api.messages.list);
  ...
  return (
    ...
    {messages?.map((message) => (
      <article key={message._id}>
        <div>{message.author}</div>
        <p>{message.body}</p>
      </article>
    ))}

```

Because this query is decoupled from the HTTP streaming response from OpenAI, **multiple browsers** can be subscribed to updates as messages change. And if a user **refreshes or restarts their browser**, it will just pick up the latest results of the query.

On the server, this is the [query](https://docs.convex.dev/database/reading-data#querying-documents) that grabs the most recent 100 messages:

```tsx
export const list = query({
  handler: async (ctx): Promise<Doc<"messages">[]> => {
    // Grab the most recent messages.
    const messages = await ctx.db.query("messages").order("desc").take(100);
    // Reverse the list so that it's in chronological order.
    // Alternatively, return it reversed and flip the order via flex-direction.
    return messages.reverse();
  },
9});

```

Convex is doing some magic under the hood. If any message is inserted or updated into the database that would match this query - for instance if a new message is added or one of the first 100 messages is edited - then it will automatically re-execute this query (if there are any clients subscribed to it via `useQuery`). If the results differ, it will push the new results over a WebSocket to the clients, which will trigger an update to the components using `useQuery` for that query.

To give you a sense of performance, `list` takes ~17ms and `update` takes ~7ms for me on the server, so the total latency between a new token coming from OpenAI and a new set of messages being sent to the client is very fast. The gifs in this article are real recordings, not sped up.

![GPT response streaming in quickly](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F2979c6d28d619bffded99c19bca49f6d229a4cdb-960x960.gif&w=3840&q=75)GPT response streaming in quickly

## Summary

We looked at how to stream ChatGPT responses into Convex, allowing clients to watch the responses, without the flakiness of browser-based HTTP streaming requests. The full code is available [here](https://github.com/ianmacartney/streaming-chat-gpt). Let us know [in Discord](https://convex.dev/community) what you think!

#### Extra Credit 🤓

Beyond what’s covered here, it would be easy to extend this demo to:

- Store whether a message has finished streaming by storing a boolean on the message updated at the end of the stream.
- Add error handling, to mark a message as failed if the stream fails. See [this post](https://stack.convex.dev/full-stack-chatgpt-app#creating-the-action) for an example of updating a message in the case of failure.
- Schedule a function to serve as a watchdog, that marks a message as timed out if it hasn’t finished within a certain timeframe, just in case the action failed. See [this post](https://stack.convex.dev/background-job-management#5-monitoring-timeouts) for more details, as well as other patterns for background jobs.
- Organize the messages by thread or user, using [indexes](https://docs.convex.dev/database/indexes/).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Help, my app is overreacting!

The apps we build don’t exist in a vacuum; they’re used by real users, and we want to give them a really good experience!

Let’s say I’m building a simple task manager app where I want to show the user a list of tasks, each of which has a certain status like “New” or “In Progress”, and possibly an owner assigned to the task:

![Screenshot of a simple web app showing 'Task Manager' heading and 'New Task' button at top left, a user icon and log out button at top right, and in the main section a table of tasks with columns '#' (task number), 'Task' (title), 'Owner' (user icon, if any), 'Status' ('In Progress', 'New' etc.)](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F11ef431d4eb2d0a2dc547e6b2d7a95f4a6f5d6ce-1110x780.png&w=3840&q=75)Screenshot of a simple web app showing 'Task Manager' heading and 'New Task' button at top left, a user icon and log out button at top right, and in the main section a table of tasks with columns '#' (task number), 'Task' (title), 'Owner' (user icon, if any), 'Status' ('In Progress', 'New' etc.)

For the best user experience, I want the app to always show the latest data, even if that data is actively changing while I’m viewing the page. For example, if another user somewhere adds a new task, or changes the title of a task, I want to see the app update immediately without having to manually reload the page, hit a “refresh” button, or the like.

In this post, we’ll explore:

- How a reactive backend like Convex helps build live-updating apps that show users the fresh data they deserve
- The default behavior of reactive data updates from Convex’s `useQuery` and `usePaginatedQuery` hooks, and how that might affect UX in different contexts
- How I can customize the way my app reacts to data updates to more easily deliver the intended user experience

Let’s dig in!

### A visit from the reactive-query fairy

With traditional backends, to achieve the desired behavior I’d have to go out of my way to keep the data updated, for example by polling (actively re-fetching the data every so often). That works to a certain extent, but means:

- more code for me to write/maintain (more work! more bugs!)
- more request-response cycles that might slow down my app
- some lag time in when the user sees the new data if it changes between polling cycles

I also might run the risk of inconsistencies in what the user sees, if I’m making multiple queries of the same data (e.g. one query that fetches the total number of tasks, and other that fetches the detailed task list); with no way to guarantee their polling cycles will stay in sync, one query might pick up new data before the other.

Luckily, we live in the futuristic-sounding year of 2023, and we now have not only reactive frontend frameworks like [React](https://reactjs.org/), but also reactive backends like [Convex](https://www.convex.dev/) that work hand-in-hand with my reactive frontend to automatically keep my app’s data fresh!

For example, [Convex’s `useQuery` hook](https://docs.convex.dev/api/modules/react#usequery) returns a reactive value that gives me the up-to-date result of running a particular database query. Say I have a `listAllTasks` [Convex query function](https://docs.convex.dev/understanding/convex-fundamentals/functions#query-functions) that queries the `tasks` table in my database:

```jsx
// convex/listAllTasks.ts
import { query } from './_generated/server'

export default query(async ({ db }) => {
  // Grab all the rows in `tasks` table and collect into an array
  return await db.query('tasks').collect()
7})

```

I can pull the reactive results of running that query into my frontend with `useQuery` like so:

```jsx
// pages/index.tsx
import React from 'react'
import { useQuery } from '../convex/_generated/react'
import { TaskList } from '../components/tasks'
import { LoginHeader, NewTaskButton } from '../components/util'

export default function App() {
	const tasks = useQuery('listAllTasks')

	return (
		<main>
      <LoginHeader />
			<div id="controls">
	      <NewTaskButton />
      </div>
      <TaskList tasks={tasks} />
    </main>
	)
19}

```

Thanks to the `useQuery` hook, the `tasks` value updates instantly any time the data changes, and the component re-renders. So in the case where another user adds a task while I’m viewing the list, I see it show up instantly:

![Screen capture of two separate users navigating to the Task Manager app in two windows side-by-side. In the left window, one user adds a new task titled “Reactively load data”. In the right window, another user is viewing the task list, and sees the new task appear instantly when the first user saves the new task. ](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F880a5e1f80a9210822be8a0779f7906c5c3923d3-1080x401.gif&w=3840&q=75)Screen capture of two separate users navigating to the Task Manager app in two windows side-by-side. In the left window, one user adds a new task titled “Reactively load data”. In the right window, another user is viewing the task list, and sees the new task appear instantly when the first user saves the new task.

And if I have multiple queries referencing the same data (e.g. say I have another function `countTasks` that also reads from the `tasks` table, which I invoke in another component with `useQuery('countTasks')`), I don’t have to worry about the kind of race condition possible with polling that could lead to the count of tasks being inconsistent with what’s shown in the task list. Convex ensures all of my `useQuery` calls stay in sync, consistently pushing out the exact same data to all of my queries whenever that data changes. One less thing to worry about? Music to my ears!

But what happens _while_ the data is loading? The value returned by `useQuery` is initially `undefined` until the data has loaded, so I can [check for that](https://docs.convex.dev/using/best-practices#loading-states) to display some kind of loading state to my users (here I just show a simple ‘loading’ message, but in a real app I might display e.g. a spinner icon or ghost component):

```jsx
// in App() function
2{tasks === undefined ? <p>Loading tasks...</p> : <TaskList tasks={tasks} />}

```

![Screen capture of the Task Manager app reloading. Before the task list appears, the text “Loading tasks…” is briefly displayed in its place.](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fd5045fe0d7343b1fd1013e85ff0234ba829f9f70-1080x805.gif&w=3840&q=75)Screen capture of the Task Manager app reloading. Before the task list appears, the text “Loading tasks…” is briefly displayed in its place.

Fantastic! My app auto-updates with the latest data without the user having to do anything, and I can show a loading state while initially fetching the data. My users always see the freshest data, the app doesn’t have to constantly poll for data updates, and I didn’t even have to write that much code to make it happen!

In other words, with this kind of pattern for reactive data, it feels like the answer to all my wishes fell right into my lap, er, app!

### Overreacting can be distracting

However, this convenient out-of-the-box reactivity might be _more_ than I need in certain situations. For example, say I want to let users check boxes to specify the particular task status(es) they’re interested in, e.g. only `New` or `In Progress` tasks:

![Screenshot of the same Task Manager app task list page, but now under the user icon and log out button at top right there are also checkbox inputs labeled “New” (checked), “In Progress” (checked), “Done” (unchecked), and “Cancelled” (unchecked).](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F562f07c431660c0db8ee9f6c1fd38aebdbc633c2-1110x780.png%3Fw%3D720&w=3840&q=75)Screenshot of the same Task Manager app task list page, but now under the user icon and log out button at top right there are also checkbox inputs labeled “New” (checked), “In Progress” (checked), “Done” (unchecked), and “Cancelled” (unchecked).

To achieve this, I can make a `listTasksWithStatus` query function that looks similar to `listAllTasks`, but with an additional `taskStatuses` parameter that accepts an array of status values used to filter the query results:

```jsx
// convex/listTasksWithStatus.ts
import { query } from './_generated/server'

export default query(async ({ db }, { statuses }: { statuses: string[] }) => {
  // Grab rows in `tasks` table matching the given filter
  return await db
    .query("counter_table")
    .filter((q) =>
      q.or(
        // Match any of the given status values
        ...statuses.map((status) => q.eq(q.field("name"), status))
      )
    )
    .collect(); // collect all results into an array
15});

```

Then in my frontend I can wire up some checkbox inputs so that whenever the user changes the checked values, their selections are captured as [state](https://beta.reactjs.org/learn/state-a-components-memory) and passed along to `useQuery`:

```jsx
// in pages/index.tsx
import React, { useState, type ChangeEventHandler } from 'react'
import { useQuery } from '../convex/_generated/react'
import { TaskList } from '../components/taskList'
import { LoginHeader, NewTaskButton, Checkboxes } from '../components/util'

const allStatuses = ['New', 'In Progress', 'Done', 'Cancelled']

export default function App() {
  const user = useQuery('getCurrentUser')

  const [checkedValues, setCheckedValues] = useState(['New', 'In Progress'])

  const handleChangeChecked = ((event) => {
    // Process a checkbox change event affecting the status filter
    const target = event.target as HTMLInputElement
    if (target.checked) {
      // A formerly unchecked status filter is now checked; add value to array
      setCheckedValues([...checkedValues, target.value])
    } else {
      // A formerly checked status filter is now unchecked; remove value from array
      setCheckedValues(checkedValues.filter((s) => s !== target.value))
    }
  }) as ChangeEventHandler

  const tasks = useQuery('listTasksWithStatus', { statuses: checkedValues })

  return (
    <main>
      <LoginHeader />
      <div id="controls">
        <NewTaskButton />
				<Checkboxes // simple component creating a checkbox input for each status
          values={allStatuses}
          checkedValues={checkedValues}
          onChange={handleChangeChecked}
        />
      </div>
      {tasks === undefined ?  <p>Loading tasks...</p> : <TaskList tasks={tasks} />}
    </main>
  )
42}

```

This basically works, updating the list reactively based on the user’s input, but unfortunately whenever `checkedValues` updates, something annoying happens - do you see it?

![Screen capture of a user checking and unchecking the checkboxes. Each time one is checked/unchecked, the task list briefly disappears, replaced by “Loading tasks…” text, and then quickly reappears with tasks that match the new checkbox selections. ](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F8a8dc9564b4372290526cee6a1809977d76aa624-720x499.gif&w=3840&q=75)Screen capture of a user checking and unchecking the checkboxes. Each time one is checked/unchecked, the task list briefly disappears, replaced by “Loading tasks…” text, and then quickly reappears with tasks that match the new checkbox selections.

Whenever the user updates their selection, there’s a brief, distracting flash of the loading state. This is because whenever `checkedValues` changes:

1. the component re-renders, making a new call to `useQuery`
2. `useQuery` does its intended job of returning `undefined` while the updated query is initially running
3. the component sees `tasks` is `undefined` and renders the loading state, until
4. the new results come back, `tasks` updates, and the component finally re-renders with the new data

That behavior might be what I want in some contexts, but in this case I don’t want my users to see that distracting flash; instead, during that brief loading period after they’ve checked a box I’d rather keep showing them the old, stale data from the previous selection, and wait to re-render until the new, fresh data has finished loading.

In other words, you might say my app is “overreacting” to updates from `useQuery`, not all of which I want to translate into UI updates! I don’t want to give up the convenient reactivity of `useQuery`, but I want to customize its behavior to smash the flash.

### Impacting how the query’s reacting

Essentially, for this use case what I’d like is a version of `useQuery` that’s a little bit _less_ reactive, skipping those intermediate `undefined` states when the query changes, and instead keeping the data more “stable” by continuing to give me the stale data from the previous query until the fresh data has finished loading.

[Refs](https://beta.reactjs.org/learn/referencing-values-with-refs) to the rescue! To customize the behavior of `useQuery` to fit my use case, I can implement a [custom React hook](https://beta.reactjs.org/learn/reusing-logic-with-custom-hooks) that I’ll call `useStableQuery`, which functions similarly to `useQuery` but keeps track of the resulting data with React’s [builtin `useRef` hook](https://beta.reactjs.org/reference/react/useRef), which gives me a Ref object whose identity remains stable between re-renders, and which does not trigger a re-render when its value (accessed via the object’s `.current` property) changes.

By using a ref to capture the reactive `useQuery` return value, I can decide to only update the value returned from `useStableQuery` once the query result is no longer `undefined`:

```jsx
// hooks/useStableQuery.ts

import { useRef } from 'react'
import { useQuery } from '../convex/_generated/react'

export const useStableQuery = ((name, ...args) => {
  const result = useQuery(name, ...args)

	// useRef() creates an object that does not change between re-renders
  // stored.current will be result (undefined) on the first render
  const stored = useRef(result)

	// After the first render, stored.current only changes if I change it
  // if result is undefined, fresh data is loading and we should do nothing
  if (result !== undefined) {
    // if a freshly loaded result is available, use the ref to store it
    stored.current = result
  }

  // undefined on first load, stale data while reloading, fresh data after loading
  return stored.current
22}) as typeof useQuery // make sure we match the useQuery signature & return type

```

(Note: I could also implement this pattern directly in the component that calls `useQuery`, without writing a custom hook, but putting it in a hook lets me more easily reuse this logic across multiple components/queries.)

In my component, I can now swap the original `useQuery` out for my custom `useStableQuery`, capturing the resulting `tasks` just like before:

```jsx
// in pages/index.tsx
import { useStableQuery } from '../hooks/useStableQuery'

// ...

export default function App() {
  // ...
  const tasks = useStableQuery('listTasks', checkedValues)
  // ...
10}

```

Now, `tasks` is only `undefined` on the very first load, and whenever `checkedValues` updates in reaction to user input and its new value is passed in to `useStableQuery`, `tasks` does not update until the fresh new data is ready, skipping the intermediate `undefined` state that was causing the loading flash before. Success!

![Screen capture of a user checking and unchecking the boxes as before, but now there is no flash of “Loading tasks…” before the new data is shown.](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fb2314d94994a8917153d4f842f4d51b1a1aa34e4-720x499.gif&w=3840&q=75)Screen capture of a user checking and unchecking the boxes as before, but now there is no flash of “Loading tasks…” before the new data is shown.

### What about pagination, is that a complication?

If the app I’m building is for a big organization likely to have a ton of tasks, I probably want to use a [paginated query](https://docs.convex.dev/using/pagination) instead. Initially, I’ll only show users the first page of results, then load additional pages as needed (e.g. when the user clicks a button, or scrolls to the bottom).

I can update my `listTasksWithStatus` function to return paginated results like so, accepting a `paginationOptions` object as the second parameter and replacing `.collect()` with `.paginate(paginationOptions)`:

```jsx
// convex/listTasksWithStatus.ts
import { query } from './_generated/server'

export default query(
  async ({ db }, { paginationOpts, statuses }) => {
    // Grab rows in `tasks` table matching the given filter
    return await db
      .query('tasks')
      .filter((q) =>
        q.or(
          // Match any of the given status values
          ...statuses.map(( }status) => q.eq(q.field('status'), status))
        )
      )
      // paginate the results instead of collecting into an array
      .paginate(paginationOpts)
  }
18)

```

In my component, I can now replace `useQuery` with [Convex’s analogous `usePaginatedQuery` hook](https://docs.convex.dev/api/modules/react#usepaginatedquery), which accepts the additional `paginationOptions` argument that lets me specify the initial number of items I want in the first page. In addition to the `results` data for the loaded page(s), `usePaginatedQuery` also returns a `status` value indicating pagination status (either `'CanLoadMore'`, `'LoadingMore'` or `'Exhausted'`) and a `loadMore` function I can call to load additional pages when the user clicks a button.

I can use this hook in my component like so, checking `status` to know when to display the loading state and adding a simple button to load the next page, if any:

```jsx
// in pages/index.tsx
import { usePaginatedQuery } from 'convex/react'

export default function App() {
	// ...set up checkedValues & handler same as before

  const {results, status, loadMore} = usePaginatedQuery(
    'listTasks',
    { statuses: checkedValues},
    { initialNumItems: 10 }
  )

  return (
    <main>
      {/* ...header & controls same as before */}
      {status === 'LoadingMore'
        ?  <p>Loading tasks...</p>
        : <TaskList tasks={results} />}
      {loadMore && <button onClick={() => loadMore(10)}>Load more</button>}
    </main>
  )
22}

```

But once again, the user sees an empty flash whenever they change their checkbox selections, since the status switches back to `LoadingMore` while the new page is being fetched.

![Screen capture of a slightly different version of the app that now shows only up to 10 tasks, with a “Load more” button appearing at the bottom of the list if there are more tasks available. When the user clicks the checkboxes, there is once again a brief flash of the loading message before the new data is shown.](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F1ea530adfd34d425dd327ba452eb4028929a5a94-720x539.gif&w=3840&q=75)Screen capture of a slightly different version of the app that now shows only up to 10 tasks, with a “Load more” button appearing at the bottom of the list if there are more tasks available. When the user clicks the checkboxes, there is once again a brief flash of the loading message before the new data is shown.

Ugh, there goes my app overreacting again, what a drama queen! How do I rein it in while still using a paginated query?

To get the stable behavior I want and ignore the intermediate loading states as before, I can make a paginated version of my custom query hook called `useStablePaginatedQuery`. It follows the same pattern as `useStableQuery`, but checks for the `LoadingMore` status rather than `undefined` to determine when _not_ to update the results:

```jsx
// in hooks/useStableQuery.ts
import { useRef } from 'react'
import { usePaginatedQuery } from '../convex/_generated/react'

export const useStablePaginatedQuery = ((name, ...args) => {
  const result = usePaginatedQuery(name, ...args)
  const stored = useRef(result)

  // If new data is still loading, wait and do nothing
  // If data has finished loading, use the ref to store it
  if (result.status !== 'LoadingMore') {
    stored.current = result
  }

  return stored.current
16}) as typeof usePaginatedQuery

```

Now, when I replace `usePaginatedQuery` with `useStablePaginatedQuery` in my component, I get the slightly-less-reactive behavior I’m looking for; no flash, no drama!

```jsx
// in pages/index.tsx
import { useStablePaginatedQuery } from '../hooks/useStableQuery'

// ...

export default function App() {
  // ...
  const {results, status, loadMore} = useStablePaginatedQuery(
    'listTasks',
    { statues: checkedValues },
    { initialNumItems: 10 }
  )
  // ...
14}

```

![Screen capture of the same view of the app showing up to 10 tasks and possibly a “Load more” button. Now when the user clicks the checkboxes, there is no flash of the “Loading tasks…” message before the new data is shown. ](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F5f72dc485e5f97b2ebd9d126dfd0fa83e2e559fc-720x539.gif&w=3840&q=75)Screen capture of the same view of the app showing up to 10 tasks and possibly a “Load more” button. Now when the user clicks the checkboxes, there is no flash of the “Loading tasks…” message before the new data is shown.

### Let's recap this (less-)reactive app

To recap, in a use case like this task manager app, where I want to reactively query data based on user input while still giving users a smooth & stable experience:

- Using a reactive backend like [Convex](https://www.convex.dev/) with a reactive frontend framework like [React](http://reactjs.org/) lets me easily build live-updating apps, without having to constantly poll for updates in the background or make users manually refresh the page
- The reactive value returned by the [Convex `useQuery` hook](https://docs.convex.dev/api/modules/react#usequery) (which is `undefined` while data is loading) is exactly what I want in some cases (e.g. `listAllTasks`), as Convex will automatically update it whenever the data changes
- In other cases (like `listTasksWithStatus`), the `undefined` returned by `useQuery` while loading might not be ideal, e.g. causing an undesirable reloading flash if I’m dynamically updating the query arguments based on user input/app state
- If the default behavior of `useQuery` doesn't quite fit my use case, I can customize it by writing my own version, e.g. `useStableQuery`, which ‘skips’ intermediate `undefined` states with the help of [React’s `useRef` hook](https://beta.reactjs.org/learn/referencing-values-with-refs)
- If I want to [paginate](https://docs.convex.dev/using/pagination) the query results, I can write an analogous `useStablePaginatedQuery` which uses the same `useRef` pattern in conjunction with `[usePaginatedQuery](https://docs.convex.dev/generated-api/react#usepaginatedquery)`

If you have a use case similar to mine, feel free to use these hooks in your own apps! You can find the code in the [get-convex/convex-helpers](https://github.com/get-convex/convex-helpers/blob/main/src/hooks/useStableQuery.ts) repo on Github.

And if your use case is slightly different and you want to customize the reactive behavior of `useQuery` some other way, I hope this has provided a useful example of how to implement your own version with exactly the behavior you want! For another example of tweaking an app’s reactive dataflow with a custom React hook, check out [Jamie Turner’s video on Managing Reactivity with useBufferedState](https://stack.convex.dev/coping-with-the-web-s-looming-global-reactivity-crisis).

Have you run into other issues with reactive data updates? Do you have other favorite patterns for managing reactive query results? Feel free to jump into the [Convex community Discord](https://www.convex.dev/community) to share & discuss!

_Cover image: Roy Lichtenstein, “Crying Girl" (1963), via [WikiArt](https://www.wikiart.org/en/roy-lichtenstein/crying-girl-1963) (fair use)_

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Optimize Transaction Throughput: 3 Patterns for Scaling with Convex and ACID Databases

Here are some patterns to run more transactions per second — more concurrency leading to higher throughput.

This post will use Convex for examples, although the patterns are generalizable to any ACID database, especially one that uses optimistic concurrency control.

## What are Conflicts?

Two serializable transactions conflict if one of them reads or writes data that the other writes. If this happens, the transactions can’t run in parallel with each other, which reduces throughput.

There are several common workloads where the most obvious way to write the transactions will cause many conflicts. But the same workload can be changed to have fewer conflicts and higher throughput. Let’s look at some patterns you can apply to achieve your scaling goals.

## Pattern: Queue

For this workload, you’ve got a list of things and you want to process them as a batch. Here’s the standard code:

```ts
export const enqueueEmail = mutation({
  args: { recipient: v.string(), body: v.string() },
  handler: async (ctx, args) => {
    await ctx.db.insert("emails", args);
  }
6});

export const processBatchOfEmails = mutation({
  args: {},
  handler: async (ctx) => {
    const emails = await ctx.db.query("emails").collect();
    await ctx.scheduler.runAfter(0, internal.emails.sendEmails, { emails });
  },
14});

export const sendEmails = internalAction({
  args: {},
  handler: async (ctx) => {
    await ResendClient.sendBatch(emails);
    await ctx.runMutation(internal.emails.deleteBatchOfEmails,
      { emails: emails.map((email) => email._id) });
  },
23});

export const deleteBatchOfEmails = internalMutation({
  args: { emails: v.array(v.id("emails")) }
  handler: async (ctx) => {
    await Promise.all(emails.map((email) => ctx.db.delete(email)));
  },
30});

```

It looks like we’re being very efficient, because we’re debouncing batches of emails to send them all at once. But wait! The `processBatchOfEmails` mutation is reading the whole “emails” table. That means it conflicts with every `enqueue` mutation. In there are too many email requests, `processBatchOfEmails` might never succeed because it’s blocked by continuous `enqueue` s. And if `processBatchOfEmails` doesn’t succeed, the set of emails keeps getting longer, so it’s likely to take longer next time, and even more likely to be blocked by a concurrent `enqueue`.

We can reduce conflicts by separating the reads in `processBatchOfEmails` from the writes of `enqueueEmail`. Notice that `enqueueEmail` writes documents with high `_creationTime`, so we can make `processBatchOfEmails` only look at documents with low `_creationTime`. Suppose it just takes the first 10.

```ts
export const processBatchOfEmails = mutation({
  args: {},
  handler: async (ctx) => {
    const emails = await ctx.db.query("emails").take(10);
    await ctx.scheduler.runAfter(0, internal.emails.sendEmails, { emails });
  },
7});

```

Or maybe it should take only emails that have been in the queue for more than 30 seconds.

```tsx
export const processBatchOfEmails = mutation({
  args: {},
  handler: async (ctx) => {
    const emails = await ctx.db.query("emails")
      .withIndex("by_creation_time",
        (q) => q.lt("_creationTime", Date.now()-30*1000)
      ).collect();
    await ctx.scheduler.runAfter(0, internal.emails.sendEmails, { emails });
  },
10});

```

Despite appearances, this is more efficient than before, because now emails can be enqueued and sent at the same time. You need to call `processBatchOfEmails` repeatedly to make sure everything gets processed, but that was necessary before as well. As an additional benefit, you can avoid unbounded queries which might slow down the mutation or hit query limits.

I call this the “queue” pattern, because the table is acting as a FIFO queue. Insertions are at one end of an index range — in this example we’re using `by_creation_time` but it can be any index — and processing happens at the other end. If there’s enough incoming data that throughput would be obstructed by conflicts, then the ends of the queue are far enough apart to avoid conflicts.

If you want to see this pattern in practice, it’s used extensively in the Convex Workpool component.

## Pattern: Hot and Cold Tables

Splitting tables by temperature is useful if you’ve got large tables, with some fields that change often and some that rarely change. Let’s use a school roster for this example.

```ts
export const sendEmailToAllStudents = mutation({
  args: { body: v.string() },
  handler: async (ctx, args) => {
    for await (const student of ctx.db.query("students")) {
	    await ctx.db.insert("emails", {
        recipient: student.email,
        body: args.body,
      });
    }
  },
11});

export const updateStudentGrade = mutation({
  args: { student: v.id("students"), grade: v.number() },
  handler: async (ctx, args) => {
    await ctx.db.patch(args.student, { grade: args.grade });
  },
18});

```

We’ve got two mutations here: one that sends an email to all students and one that updates a student’s grade. Notice that `updateStudentGrade` modifies the student, so `sendEmailToAllStudents` which reads the student documents will conflict with it.

One way to think about this table is that the “grade” field is updated frequently and only read from certain mutations, while “email” is updated infrequently and read from more mutations. In temperature terms, “grade” is a hot field and “email” is a cold field. So we can split them into separate tables and remove conflicts.

```ts
export const sendEmailToAllStudents = mutation({
  args: { body: v.string() },
  handler: async (ctx, args) => {
    for await (const student of ctx.db.query("students")) {
	    await ctx.db.insert("emails", {
        recipient: student.email,
        body: args.body,
      });
    }
  },
11});

export const updateStudentGrade = mutation({
  args: { student: v.id("students"), grade: v.number() },
  handler: async (ctx, args) => {
    const gradeDoc = await ctx.db.query("studentGrades")
      .withIndex("by_student", (q) => q.eq("student", args.student))
      .unique();
    await ctx.db.patch(gradeDoc!._id, { grade: args.grade });
  },
21});

```

The new “studentGrades” table holds hot fields, which are frequently written. This separates it from the “students” table which holds only holds cold fields, which are infrequently written and frequently read. Our two mutations have the same behavior as before, and

## Pattern: Predicate Locking

For this workload, you’ve got a value that’s changing frequently, and some other mutation checking it for abnormal values. I’ll also note we’re a ways into a post about transactions, and we haven’t mentioned bank accounts yet. Proceed with the standard code:

```ts
async function getBalance(ctx: QueryCtx) {
	const accountId = await getAccountId(ctx.auth);
  return await ctx.db.query("balances")
    .withIndex("by_account", (q) => q.eq("accountId", accountId))
    .unique();
6}

async function throwIfOverdrawn(ctx: QueryCtx) {
  const balanceDoc = await getBalance(ctx);
  if (balanceDoc.balance < 0) {
    throw new ConvexError("you are overdrawn");
  }
13}

export const withdraw = mutation({
  args: { amount: v.string() },
  handler: async (ctx, args) => {
    await throwIfOverdrawn(ctx);
    const balanceDoc = await getBalance(ctx);
    await ctx.db.patch(balanceDoc._id,
      { balance: balanceDoc!.balance - args.amount }
    );
  },
24});

export const issueLoan = mutation({
  args: { amount: v.string() },
  handler: async (ctx, args) => {
    await throwIfOverdrawn(ctx);
    await ctx.db.insert("loans", {
      accountId: await getAccountId(ctx.auth),
		  amount: args.amount,
		});
	},
35});

```

This code looks ideal, because it’s verifying the constraint that we want: you can’t issue a withdrawal or a loan to someone who has an overdrawn account. However, notice that `issueLoan` and `withdraw` conflict with each other, since they both read the “balances” document and `withdraw` writes to that document. If we really need high throughput, we can look for a better way.

How can you allow these mutations to run in parallel without changing their behavior? Use a “predicate lock” to look specifically for balances that are overdrawn.

```ts
// before
balances: defineTable(...).index("by_account", ["accountId"])
// after
balances: defineTable(...).index("by_account", ["accountId", "balance"])

```

This compound index appears useless at first glance, because there’s only once “balances” document for each “accountId”. But it enables the following trick:

```ts
async function throwIfOverdrawn(ctx: QueryCtx) {
  const accountId = await getAccountId(ctx.auth);
  const balanceDoc = await ctx.db.query("balances")
    .withIndex("by_account", (q) =>
      q.eq("accountId", accountId).lt("balance", 0)
    ).unique();
  if (balanceDoc) {
    throw new ConvexError("you are overdrawn");
  }
10}

```

With this, we slightly change `issueLoan` and any mutation that only cares about checking for an overdrawn balance. The visible behavior stays exactly the same, but now it only reads documents where `balanceDoc.balance < 0`. If someone does a `withdraw` but the balance stays positive, you can do an `issueLoan` in parallel and the mutations won’t conflict.

For documents that change frequently between common states, other mutations can choose to only read documents in certain abnormal states. This improves throughput in the steady state, because the mutations usually don’t conflict.

## Recap

If you’re having problems with mutation throughput, it may be because the mutations are reading unnecessary documents. You can sculpt `ctx.db.query` s to only look at the essential documents, using patterns like making your table into a queue, splitting fields into hot and cold tables, and taking predicate locks on a field. As I was writing the Workpool component, I used all three of these patterns and more.

Once your transactions avoid conflicting with each other, your app can scale indefinitely.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Advanced HTTP Endpoints: Convex ❤️ Hono

[Convex](https://convex.dev/) supports [HTTP actions](https://docs.convex.dev/functions/http-actions), meaning your backend can receive requests not only from Convex clients, such as the [ConvexReactClient](https://docs.convex.dev/using/project-setup#configure-the-convex-client), but also from third-party webhooks and other clients that want to communicate with a custom HTTP API.

Currently, these endpoints have a simple router. In this post, we’ll look at how to add more advanced features, such as:

- Dynamic routes or slug routes — e.g. `users/:userId`
- Middleware — e.g. check auth on all routes under `/api/*` or implementing CORS
- Helpers for validating an incoming Request’s query params or body
- Helpers for formatting a JSON response or text response
- Custom 404 (Not Found) responses

While it’s possible to build these yourself on top of Convex primitives, existing JS libraries already do a great job at this. In this post, we’re going to go through how you can leverage [Hono](https://hono.dev/) with Convex [HTTP actions](https://docs.convex.dev/functions/http-actions). To see the implementation, check out [`hono.ts`](https://github.com/get-convex/convex-helpers/blob/main/packages/convex-helpers/server/hono.ts) in the [convex-helpers package](https://www.npmjs.com/package/convex-helpers#hono-for-advanced-http-endpoint-definitions). We’ll also look more generally at how to extend Convex HTTP endpoint behavior.

Note: you don’t need to use TypeScript, but I will use it in my examples because both Hono and Convex offer slick TypeScript support!

## Using Hono with Convex

To use Hono, you’ll need to:

1. `npm install hono convex-helpers` in your project.
2. In `convex/http.ts`, import `Hono`, `HonoWithConvex`, `HttpRouterWithHono`, and `ActionCtx` [1](https://stack.convex.dev/hono-with-convex#user-content-fn-1):

```ts
import { Hono } from "hono";
import { HonoWithConvex, HttpRouterWithHono } from "convex-helpers/server/hono";
import { ActionCtx } from "./_generated/server";

const app: HonoWithConvex<ActionCtx> = new Hono();

// Add your routes to `app`. See below

export default new HttpRouterWithHono(app);

```

The `HonoWithConvex` is just a type that tells Hono to expect the Convex [`ActionCtx`](https://docs.convex.dev/generated-api/server#actionctx) as its [env](https://hono.dev/api/context#env) binding. `HttpRouterWithHono` does the magic to connect Hono routes to Convex HTTP actions.

Let’s look at a few ways to use Hono:

### Slug routing and response formatting

For illustration, we’ll implement an endpoint from the [Convex demo for HTTP action](https://github.com/get-convex/convex-demos/tree/main/http) to use Hono. Here’s an example handler showcasing several of Hono’s features:

```ts
// Routing with slugs
app.get("/listMessages/:userId{[0-9]+}", async (c) => {
  // Extracting a token from the URL!
  const userId = c.req.param("userId");

  // Running a Convex query
  const messages = await c.env.runQuery(api.messages.getByAuthor, { authorNumber: userId });

  // Helpers for pretty JSON!
  c.pretty(true, 2);
  return c.json(messages);
12});

```

…and an example response:

```bash
1$ curl https://happy-animal-123.convex.site/listMessages/123
2[\
  {\
    "_creationTime": 1677798437141.091,\
    "_id": {\
      "$id": "messages|lqMHm5kDS9m6fBsSnx5L2g"\
    },\
    "author": "User 123",\
    "body": "Hello world"\
  },\
11]

```

### Input validation

Here’s another handler with input validation:

```typescript
import { z } from "zod";
import { zValidator } from "@hono/zod-validator";

app.post(
  "/postMessage",
  // Body validation!
  zValidator(
    "json",
    z.object({
      author: z.string().startsWith("User "),
      body: z.string().max(100),
    })
  ),
  async (c) => {
    // With type safety!
    const { body, author } = c.req.valid("json");
    await c.env.runMutation(api.messages.send, { body, author });
    return c.text("Sent message!");
  }
20);

```

…and an example response:

```bash
1$ curl -d '{ "body": "Hello world", "author": "123" }'  https://happy-animal-123.convex.site/postMessage
2{
  "success": false,
  "error": {
    "issues": [\
      {\
        "code": "invalid_string",\
        "validation": {\
          "startsWith": "User "\
        },\
        "message": "Invalid input: must start with \"User \"",\
        "path": [\
          "author"\
        ]\
      }\
    ],
    "name": "ZodError"
  }
19}

```

### Middleware: Adding CORS

Another example, copying from [Hono docs](https://hono.dev/middleware/builtin/cors). This adds CORS support to the `/api/*` and `/api2/*` routes with different configurations.

```typescript
import { cors } from 'hono/cors'
2...
app.use('/api/*', cors())

app.use(
  '/api2/*',
  cors({
    origin: 'http://examplesite.com',
    allowHeaders: ['X-Custom-Header', 'Upgrade-Insecure-Requests'],
    allowMethods: ['POST', 'GET', 'OPTIONS'],
    exposeHeaders: ['Content-Length', 'X-Kuma-Revision'],
    maxAge: 600,
    credentials: true,
  })
15)

```

The `.use` function registers a handler for all `/api/*` requests. As we’ll see below, you can use this for a variety of situations, including logging.

### Custom 404 responses

To set up a custom 404, we can do:

```typescript
// Custom 404
app.notFound(c => {
  return c.text("Oh no! Couldn't find a route for that", 404);
4});

```

See [https://hono.dev/](https://hono.dev/) for more features.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

## Under the hood

Curious about how to extend Convex [HTTP actions](https://docs.convex.dev/functions/http-actions) for your own purposes? Read on!

### Extending routes using the `/` prefix

If the routing options aren’t flexible enough for your use case, you can handle all HTTP requests with a single `httpAction` and do complex routing there. For instance, instead of using `HttpRouterWithHono`, we could define a single route per HTTP method in `convex/http.ts`:

```typescript
import { httpRouter, ROUTABLE_HTTP_METHODS } from "convex/server";
import { httpAction } from "./_generated/server";
import { HonoWithConvex } from "./lib/honoWithConvex";

const app: HonoWithConvex = new Hono();

// Add your routes to `app`.

const http = httpRouter();
for (const routableMethod of ROUTABLE_HTTP_METHODS) {
	http.route({
		pathPrefix: "/",
		method: routableMethod,
		handler: httpAction(async (ctx, request: Request) => {
			return await app.fetch(request, ctx);
		}),
	})
18}
export default http;

```

We could stop here — we can now use Hono and Convex together! But we could make a couple of additional improvements to leverage the [Convex dashboard](https://dashboard.convex.dev/).

### Using middleware to add per-route logging

Here’s what we see in the [Convex dashboard](https://dashboard.convex.dev/) under “Logs” given the approach of registering an `httpAction` per method:

![Logs showing GET /*](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F06c3e0c48a26da60a29a095e5c6f5e184d6ae2b0-1302x310.png%3Fw%3D700&w=3840&q=75)Logs showing GET /\*

All our GET requests will appear as `GET /*` even when we have multiple routes.

We can pretty easily get a little more information using one of Hono’s features — logging middleware:

```typescript
import { logger } from "hono/logger";
import stripAnsi from "strip-ansi";

app.use(
  "*",
  logger((...args) => {
    console.log(...args.map(stripAnsi));
  })
9);

```

Now the [Convex dashboard](https://dashboard.convex.dev/) looks more like this:

![Logs with GET /listMessages/123](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fe1ff98ab9fdcc7e5eee3b741eca5025b98c762e9-1350x524.png%3Fw%3D700&w=3840&q=75)Logs with GET /listMessages/123

Note: these say `0ms` because they’re running in [Convex’s deterministic environment that provides a different `Date.now()`](https://docs.convex.dev/understanding/convex-fundamentals/functions#determinism).

### Subclassing `HttpRouter` (the `HttpRouterWithHono` approach)

If we want the fullest integration with the [Convex dashboard](https://dashboard.convex.dev/), we’d like to see something like this under “Logs”, where we show the routed path:

![Logs showing GET /listMessages/:userId](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F212100c96760c3d1b86ec79a59ce3d5246a60ca3-1526x514.png%3Fw%3D700&w=3840&q=75)Logs showing GET /listMessages/:userId

And then see a corresponding entry with metrics under the “Functions” tab:

![Functions metrics for GET /listMesssages/:userId](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F9527a4a514b8fb6aa98023e27da58b90fbdede3b-970x922.png%3Fw%3D450&w=3840&q=75)Functions metrics for GET /listMesssages/:userId

The code needed for this behavior is in [`honoWithConvex.ts`](https://github.com/get-convex/convex-helpers/blob/main/convex/lib/honoWithConvex.ts).

**How does it work?**

`HttpRouterWithHono` is a subclass of the Convex [`HttpRouter`](https://docs.convex.dev/api/classes/server.HttpRouter) which overrides two special methods:

- `getRoutes` returns a list of `[path, method, handler]`, which we use to populate the Functions page on the dashboard.
- `lookup(path, method)` returns `[handler, path, method]`. Convex will run `handler` when responding to the request and use the `path` and `method` for metrics and logging (so this should match a path + method combo from `getRoutes`)
  - As an example, I wanted `lookup("/listMessages/123", "GET")` to return `"/listMessages/:userId{[0-9]+}"` for the path and `"GET"` for the method.

The implementation I added is not optimal (it loops through all the routes), but it still works! The Convex router is very flexible, so there are many options for configuring how your HTTP actions get routed and show up in the dashboard.

Now, we can use Convex with Hono and take advantage of most of the features provided in the Convex dashboard!

## Summary

In this post, we looked at how to use Hono with Convex, including how to extend Convex’s HTTP actions to add your own functionality. Let us know what you think in [our discord](https://convex.dev/community) and if you end up using Hono and Convex together! ❤️

### Footnotes

1. `HonoWithConvex` and `ActionCtx` are just being used for types. If you're using JavaScript, you can ignore that import and just initialize `app` as `const app = new Hono();` [↩](https://stack.convex.dev/hono-with-convex#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Implementing work stealing with a reactive database

In [“Push vs. pull: patterns for compute-heavy workloads”](https://stack.convex.dev/work-stealing) I discuss a technique for distributed processing called “work stealing” and compare it to traditional “push-based” approach of load balancing HTTP requests. As a reminder, this is the general flow:

![Diagram of a client request going to Convex, being added to the queue of work, then a Worker calling Convex to claim the work, then doing a resource-intensive task, then writing the result back to Convex, which triggers a subscription the client had, sending the result down to the Client as part of a query](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fe2bd61b2149a5ffedebfe962889b0db100bfa00d-962x969.png&w=3840&q=75)Diagram of a client request going to Convex, being added to the queue of work, then a Worker calling Convex to claim the work, then doing a resource-intensive task, then writing the result back to Convex, which triggers a subscription the client had, sending the result down to the Client as part of a query

In this post I’ll dig into the details of how I implemented it for [llama farm](https://github.com/get-convex/llama-farm-chat).

[get-convex/ **llama-farm-chat**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/get-convex/llama-farm-chat)

## Tracking work

I use a table “jobs” representing what needs to be done:

```tsx
    jobs: defineTable({
      work: v.object({
        // details about what needs to be done
      }),
      status: literals(
        "pending",
        "inProgress",
        "success",
        "failed",
        "timedOut"
      ),
      lastUpdate: v.number(),
      workerId: v.optional(v.id("workers")),
      janitorId: v.optional(v.id("_scheduled_functions")),
    }).index("status", ["status", "lastUpdate"]),

```

I’ll explain `lastUpdate`, `workerId`, and `janitorId` below.

When there is a request needing an LLM, a job is inserted into the table.

```tsx
  await ctx.db.insert("jobs", {
    work: {
      // details about what needs to be done
    },
    status: "pending",
    lastUpdate: Date.now(),
  });

```

In my case, the work included the message to update with the result, and the chat context. All clients in the group chat subscribe to the latest messages, so as the worker updates the message with streamed results, they all see updates automatically.

## Workers

Each worker is subscribed to a query `isThereWork` that just returns true or false:

```tsx
export const isThereWork = query({
  args: {},
  handler: async (ctx) => {
    const work = await ctx.db
      .query("jobs")
      .withIndex("status", (q) => q.eq("status", "pending"))
      .first();
    return !!work;
  },
10});

```

A benefit of Convex queries is they automatically have caching and reactivity. All workers subscribed to the query will get the same cached response, and when a pending job is inserted, the cache will automatically be invalidated, the query re-run, and all workers will receive `true`. So long as there is one or more pending jobs, the query will remain `true`.

A more sophisticated algorithm could entail:

- Returning the work to be done, to help workers decide what they want to claim.
- Subscribe each worker to a subset of job queues. This can be used to:
  - Scope workers to certain users or organizations. And extension to llama farm I plan to implement is having user-supplied workers that only process requests for the groups that the user is in.
  - Shard work - where each worker pull the oldest request from the subset of queues it’s responsible for, stealing work from other queues only if it’s totally idle. This can help avoid database contention as traffic scales.

### The work loop

#### Waiting for work

In a loop, the worker waits for work to exist (for the `isThereWork` subscription to return true), tries to claim work, and then processes it, if it claimed any:

```tsx
  while (true) {
    await waitForWork(client);
    const work = await client.mutation(api.workers.giveMeWork, { apiKey });
    // null if another worker claimed it first.
    if (work) {
      await doWork(work, client, apiKey);
    }
  }

```

- The `waitForWork` function uses the `onUpdate` API of the `ConvexClient` to make an await-able promise from `isThereWork`.





```tsx
function waitForWork(client: ConvexClient) {
  return new Promise<void>((resolve, reject) => {
    const unsubscribe = client.onUpdate(
      api.workers.isThereWork, {},
      (thereIsWork) => {
        if (thereIsWork) {
          resolve();
          unsubscribe();
        }
      },
      reject,
    );
  });
14}

```


#### Claiming work

To claim work, it:

- Finds the first pending job, if there is one. It also fetches the latest version of any related data that the request needs, such as previous messages in the group chat.

- Marks it as `"inProgress"` and note the `workerId` of the worker claiming the task. The worker passes an API key to authenticate its request. I use a [custom function](https://stack.convex.dev/custom-functions) to make a `workerMutation` which validates the API key and looks up the associated worker.

- Schedules a “janitor” function to mark the job as `"timedOut"` if we haven’t heard from the worker in a while. The worker will periodically call `imStillWorking` to update the job’s `lastUpdated` field to let the server know it’s still alive. When it does so, it will also cancel the janitor function by its `janitorId` and schedule a new one.





```tsx
  if (job.janitorId) {
    await ctx.scheduler.cancel(job.janitorId);
  }
  job.janitorId = await ctx.scheduler.runAfter(
    WorkerDeadTimeout,
    internal.workers.markAsDead,
    { jobId: job._id }
  );

```


All of these operations leverage Convex’s strong transactional guarantees (in particular, serializable isolation) to not have to worry about race conditions. The scheduled functions will not be scheduled if a transaction rolls back, and conflicts are automatically retried.

### Submitting

When a worker is done, it calls `submitWork` which:

- Updates the message associated with the job.
- Marks it as success or failed.
- Re-submits it to be retried if it hasn’t been retried too many times already. See below for more details.

If the request was a streaming request, it publishes updates periodically, so the user can see the response stream in. It batches updates by only sending them when it sees punctuation like `, . ! ? \n` or if it’s longer than 100 characters.

### Handling retries

A worker can either fail explicitly or disappear:

If the worker’s LLM fails in a way it can detect:

- It will retry a few times with backoff, and report failure if it fails the last attempt.
- If the worker reports failure, the job will be attempted by another worker by inserting a copy of the job as “pending” and checking for previous attempts by the same worker when claiming a job.

If the worker dies unexpectedly:

- The worker stops calling `imStillWorking`, so `lastUpdated` stops being incremented.
- The janitor function `markAsDead` eventually executes, marking the request as `timedOut`.
- The job is not retried, with the reasoning that in a chat app, by the time a request times out, the value of a response is significantly diminished as they may have already sent other messages since then, and they can explicitly request another response if they want.

## Summary

In this post we looked at how to implement a work stealing pattern in Convex, using subscription to connect jobs completed by workers with clients who submitted the jobs.

Check out the repo, and be sure to read [this post](https://stack.convex.dev/work-stealing) on the tradeoffs of work stealing if you haven’t already.

[get-convex/ **llama-farm-chat**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/get-convex/llama-farm-chat)

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Log Streams: Common uses

With Convex, you can see information about each function executed by Convex, such as whether it succeeded and how long it took to execute, as well as any log lines from `console.log` s within your functions. These are useful for understanding what your Convex deployment is doing as well as debugging any unexpected issues. Recent events are visible in the [dashboard](https://dashboard.convex.dev/) and from the CLI with `npx convex logs` or with the `--tail-logs` argument to `npx convex dev`.

However, you can also set up [Log Streams](https://docs.convex.dev/production/integrations/log-streams/) to send these events to [Axiom](https://app.axiom.co/) or [Datadog](https://www.datadoghq.com/).

Log streams give you more control over your logs and errors:

- Retain historical logs as long as you want (vs. Convex only keeps logs for the last 1000 functions)
- Add more powerful filtering + data visualizations base on logs
- Integrate your log streaming platform with other tools (e.g. PagerDuty, Slack)

This article will go over a few common ways to use log streams and how to set them up with either Axiom or Datadog:

- Replicating the Convex dashboard logs page
- Filtering to relevant logs by request ID
- Searching for logs containing a particular string
- Emitting + filtering namespaced logs with structured metadata
- Visualizing Convex usage
- Alerting on approaching Convex limits

## How to set up a log stream

Follow our [docs](https://docs.convex.dev/production/integrations/log-streams) to set up a log stream. You’ll need to set up an account for whichever tool you’re using. I’ve personally liked using Axiom for logs and [Sentry](https://sentry.io/) for [exception reporting](https://docs.convex.dev/production/integrations/exception-reporting).

## Common ways to use log streams

The full schema of the Convex log events is documented [here](https://docs.convex.dev/production/integrations/log-streams#log-event-data-model-beta), and the log stream provider of your choosing will have their own docs on how to filter and visualize data, but in this section, we’ll go through a couple common scenarios.

### Recreating the dashboard logs page

The dashboard logs page shows `console` log lines + function executions sorted by time.

To do this with a log stream, we can filter to logs where `topic` is either `console` or `function_execution`.

Some useful columns to display

- `function.path`, `function.type`, `function.request_id`
- For function executions: `functon.cached`, `status`, `error_message`
- For console events: `log_level`, `message`

Since there are different columns for console logs events vs. function execution log events, you might set up two different views for them. Once you have these set up how you want, save the queries or add them to a dashboard for easy use later on.

Below is an example showing console logs in Axiom and an example of showing function executions in Datadog.

![Console logs in Axiom](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fd31a05f63e05df1accfd685ca8d71ff388e25909-3824x2302.png&w=3840&q=75)Console logs in Axiom

![Function executions in Datadog](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F40700131e03fa549faf658186dff46288e3c68a3-3824x2302.png&w=3840&q=75)Function executions in Datadog

### Filtering to a request ID

In the dashboard, clicking on an entry in the logs page will open up a view filtered to that request using the [Request ID](https://docs.convex.dev/functions/debugging#finding-relevant-logs-by-request-id). You can also do this in Axiom or Datadog by filtering your events further on `function.request_id`. The request ID shows up in error messages and sentry, so this can be useful for investigating an error found in Sentry or reported by a user.

![Request ID filtering in the dashboard](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F3e5b490c5572cf78f90cd56ca0066f526d3a330e-1030x320.png&w=3840&q=75)Request ID filtering in the dashboard![Request ID in Sentry](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fe7f5bad60dd696343f93cbdd3f2f460e8a8eb409-1195x167.png&w=3840&q=75)Request ID in Sentry

**Axiom:**
In the Axiom “Explore” tab with something like this:

```
your_dataset
2| where ['data.function.request_id'] == "your request ID here"

```

**Datadog:**
In the Datadog logs page:

```
1@function.request_id:"your request ID here"

```

### Filtering to `console` events with a particular message

**Axiom:**

```
your_dataset
2| where ['data.topic'] == "console"
3| where ['data.message'] contains "hello"

```

**Datadog:**

```
1@message:hello

```

### Namespaced logs + structured metadata

As an example, if I have an app where users play games against each other, I might want to log information about each game with some specific attached metadata (like the game ID).

In my Convex functions, I’ll do something like this:

```js
console.log(JSON.stringify({
	topic: "GAME",
	metadata: { gameId: "my game ID here" },
	message: "Started"
5}))

```

Then I can parse these logs in Axiom or Datadog and be able to filter to all events with topic `“GAME”` with a particular ID.

To make this a little easier, we can make this a helper function:

```
function logEvent(topic, metadata, message) {
	console.log(JSON.stringify({ topic, metadata, message }))
3}

```

Going further, we could use [`customFunctions`](https://github.com/get-convex/convex-helpers/blob/main/packages/convex-helpers/README.md#custom-functions) to wrap `console.log` and handle logging these structured events. A usage of this might look something like

```js
ctx.logger.log(LOG_TOPICS.Game, { gameId }, "Started")

```

An example implementation of `ctx.logger` and some examples of its usage can be found [here](https://github.com/sshader/proset/pull/6).

**Axiom:**

(optional) Add a [virtual field](https://axiom.co/docs/query-data/virtual-fields) `parsed_message` so we can use this field in filters. This saves us from having to repeat the parsing logic in our query.

```
1['your_dataset']
2| extend parsed_message = iff(
    isnotnull(parse_json(trim("'", tostring(["data.message"])))),
    parse_json(trim("'", tostring(["data.message"]))),
    parse_json('{}')
6)

```

![Adding a virtual field in Axiom](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4828ec45bce1cff19ba3fea9f504bcf834aa9825-3824x2302.png&w=3840&q=75)Adding a virtual field in Axiom

In the “Explore” page:

```
your_dataset
2| where ['data.topic'] == "console"
3| where parsed_message["topic"] == "GAME"
4| where parsed_message["metadata"]["gameId"] == <your id>
5| project ['data.timestamp'], ['data.log_level'], parsed_message["message"]

```

![Filtering to logs for a game in Axiom](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F12f91e73050f0d6429e597be0f66f0e72be75728-3824x2302.png&w=3840&q=75)Filtering to logs for a game in Axiom

**Datadog:**

Add a pipeline with a [Grok parser](https://docs.datadoghq.com/service_management/events/pipelines_and_processors/grok_parser/?tab=matchers) to parse the `message` field as JSON on all events with the `topic` as `console`. I used

```
rule '%{data:structured_message:json}'

```

![Adding a Grok parser in Datadog](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F95f3f200abe6afb9a2c66058198188cb373afa9e-3824x2302.png&w=3840&q=75)Adding a Grok parser in Datadog

Filter logs as follows:

```
1@structured_message.topic:GAME @structured_message.metadata.gameId:<specific ID>

```

![Filtering to logs for a game in Datadog](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F867739891c908ccd7db65183ce79f6e43caff0a3-3824x2302.png&w=3840&q=75)Filtering to logs for a game in Datadog

Note: `message` is formatted using [`object-inspect`](https://www.npmjs.com/package/object-inspect), so printing a string requires removing the outer single quotes.

### Visualizing usage

Function executions contain the `usage` field which can be used to track usage state like database bandwidth and storage per function.

**Axiom:**

```
your_dataset
2| where ['data.topic'] == "function_execution"
3| extend databaseBandwithKb = (todouble(['data.usage.database_read_bytes']) + todouble(['data.usage.database_write_bytes'])) / 1024
4| summarize sum(databaseBandwithKb) by ['data.function.path'], bin_auto(_time)

```

**Datadog:**

You will want to make this a “ [measure](https://docs.datadoghq.com/logs/explorer/facets/#quantitative-facets)” for the usage fields you care about and might want to make a “facet” for `function.path`. Below is an example of making a measure for `database_write_bytes`.

![Defining a measure in Datadog](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F2726cdaa564d9cc386b39bcdb6a40fb4bd4407b1-960x720.png&w=3840&q=75)Defining a measure in Datadog

![Making a pie chart in Datadog](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F50372fb3dca7160d7b48834c422435609b06519b-2516x1214.png&w=3840&q=75)Making a pie chart in Datadog

### Convex system warnings

Convex automatically adds warning messages when a function is nearing limits (e.g. total bytes read, execution time). These have the `system_code` field which is a short string summarizing the limit. Adding an alert for events with `system_code` is a good way of automatically detecting functions that are approaching limits before they exceed the limits and break.

![An alert in Datadog for Convex system warnings](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fa15b69b95ee91501f456b091b7c96727869ad554-610x628.png&w=3840&q=75)An alert in Datadog for Convex system warnings

## Summary

Log streams like Axiom and Datadog can be used to provide powerful querying and alerting on logs and errors from your Convex functions, helping with debugging issues when they come up and providing early insights to detect smaller issues before they become bigger.

This article covers how to do the following common things with either Axiom or Datadog hooked up as a Convex log stream:

- Replicating the Convex dashboard logs page, but with more history
- Filtering to relevant logs by request ID
- Searching for logs containing a particular string
- Emitting + filtering namespaced logs with structured metadata
- Visualizing Convex usage
- Alerting on approaching Convex limits

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# 4 Devs, 1 Idea, 4 Apps in 4 Hours(!!) with Convex

Using Convex, 4 web devs built their own fullstack app based on this prompt:

> Build a way to show real-time updates on the website for a Dungeons and Dragons-themed small business!

See what they built, learn how they did it, and watch their reactions to each other's work in this installment of the "4 Web Devs, 1 App Idea" video series.

Featuring projects by:

[Web Dev Cody](https://www.webdevcody.com/)

- Live app: [the-obsidian-forge.vercel.app](https://the-obsidian-forge.vercel.app/)
- Source code: [github.com/webdevcody/the-obsidian-forge](https://github.com/webdevcody/the-obsidian-forge)
- In-depth explainer: [stack.convex.dev/wdc-coding-challenge-with-jason](https://stack.convex.dev/wdc-coding-challenge-with-jason)

[Anjana Vakil](https://anjana.dev/)

- Live app: [anjana.dev/questferret](https://anjana.dev/questferret/)
- Source code: [github.com/vakila/questferret](https://github.com/vakila/questferret)

[Tom Ballinger](https://ballingt.com/)

- Live app: [partyisfull.com](https://www.partyisfull.com/)
- Source code: [github.com/thomasballinger/your-party-is-full](https://github.com/thomasballinger/your-party-is-full)

[Jason Lengstorf](https://jason.energy/links)

- Live app: [dnd-lamp-store.netlify.app](https://dnd-lamp-store.netlify.app/)
- Source code: [github.com/learnwithjason/dnd-lamp-store](https://github.com/learnwithjason/dnd-lamp-store)

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Can your database do this? Ep. 1: Magic caching

Check out the [`ConvexQueryCacheProvider`](https://www.npmjs.com/package/convex-helpers#query-caching) in the `convex-helpers` npm package.

`npm i convex-helpers`

```tsx
1<ConvexClientProvider>
	<ConvexQueryCacheProvider>
	  {children}
	</ConvexQueryCacheProvider>
5</ConvexClientProvider>

```

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Merging Streams of Convex data

## TL;DR

New convex-helpers are available now for fetching streams of documents, merging them together, filtering them them out, and paginating the results. With these helpers, you can replicate patterns you may know from SQL: [`UNION ALL`](https://stack.convex.dev/merging-streams-of-convex-data#unions), [`JOIN`](https://stack.convex.dev/merging-streams-of-convex-data#streamed-joins-flatmap), [`DISTINCT`](https://stack.convex.dev/merging-streams-of-convex-data#distinct), [`GROUP BY`](https://stack.convex.dev/translate-sql-into-convex-queries/#group-by), and [`WHERE`](https://stack.convex.dev/merging-streams-of-convex-data#filtering) clauses where index fields are skipped.

```ts
import { stream, mergedStream } from "convex-helpers/server/stream";
import schema from "./schema";

export const conversation = query({
  args: { u1: v.id("users"), u2: v.id("users"), paginationOpts: paginationOptsValidator },
  handler: async (ctx, { u1, u2, paginationOpts }) => {

    // Stream of messages from u1 -> u2, oldest to newest
    const messages1 = stream(ctx.db, schema)
      .query("messages")
      .withIndex("from_to", (q) => q.eq("from", u1).eq("to", u2));

    // Stream of messages from u2 -> u1, oldest to newest
    const messages2 = stream(ctx.db, schema)
      .query("messages")
      .withIndex("from_to", (q) => q.eq("from", u2).eq("to", u1));

    // Merged stream of messages between u1 <-> u2, oldest to newest
    const messages = mergedStream([messages1, messages2], ["_creationTime"]);

    // Filter out archived messages, with arbitrary TypeScript predicates
    const activeMessages = messages.filterWith(async (m) => !m.archived);

    // Paginate the result
    return activeMessages.paginate(paginationOpts);
  },
27});

```

Check out the [companion article](https://stack.convex.dev/translate-sql-into-convex-queries) for more examples of patterns with vanilla Convex and query streams.

![Merge the streams](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F8fcc1e68d76cf1b97e9c10aadc53b5a6e2534251-480x201.tif&w=3840&q=75)Merge the streams

## Writing Queries as Code

Convex lets you query your database with plain TypeScript, so you can run many npm libraries _within_ a database call. Your query is automatically reactive, cached, and with no race conditions.

When fetching database records, you might find the interface a bit limited. The core interface is designed to be a [good abstraction over your data](https://www.youtube.com/watch?v=dS9jtih4dI4&t=1802s), but with only the ability to read index ranges, advanced patterns may feel out of your grasp.

If you’re approaching Convex from a SQL background, you’re used to a language with many features to union, aggregate, group, join, filter, and otherwise munge data. How can you do all of these things with index ranges? You have all of TypeScript to work with, and by the power of Turing completeness, you can write code that does anything. But we software engineers don’t like to reinvent the wheel; why write code when someone (or some LLM) can write it for you.

We at Convex have written many helpers for you, so you can read your data with the patterns you’re familiar with.

- Joins, with [Relationship helpers](https://stack.convex.dev/functional-relationships-helpers) or [Ents](https://stack.convex.dev/ents)
- [Filters](https://stack.convex.dev/complex-filters-in-convex)
- [Aggregates](https://www.convex.dev/components/aggregate)

What’s missing?

## Unions

![unions](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F35911efc2cae374074daff01200c6497a8e43c22-250x177.jpg&w=3840&q=75)unions

Well, you might think, unions are easy: just query both ranges and concatenate the results.

Suppose you have messages stored with this schema:

```tsx
messages: defineTable({
  from: v.id("users"),
  to: v.id("users"),
  body: v.string(),
5}).index("from_to", ["from", "to"]),
// Note: in Convex, every index implicitly ends in "_creationTime"

```

#### Union via Raw Convex Queries

To get all of the messages in a two-way conversation, you can write this query:

```tsx
export const conversationMessages = query({
  args: { u1: v.id("users"), u2: v.id("users") },
  handler: async (ctx, args) => {
		const messages1 = await ctx.db.query("messages")
			.withIndex("from_to", q => q.eq("from", args.u1).eq("to", args.u2))
			.collect();
    const messages2 = await ctx.db.query("messages")
			.withIndex("from_to", q => q.eq("from", args.u2).eq("to", args.u1))
			.collect();
		return [...messages1, ...messages2]
			.sort((a, b) => b._creationTime - a._creationTime);
12});

```

There’s our union! However, you may notice a limitation: you need to fetch all of the messages from both parts of the union, so you can combine them and sort.

What if you only want the first 5 messages? What if you want to paginate the conversation, getting one page of messages at a time? If there are too many messages to read them all at once, you shouldn’t have to collect them all just to union them, sort them, and take the first few.

We’re aiming for the equivalent of this SQL query:

```sql
SELECT * FROM messages
  WHERE (`from` = 'u1' AND `to` = 'u2')
  OR (`from` = 'u2' AND `to` = 'u1')
  ORDER BY _creationTime DESC LIMIT 5;

```

And we can achieve it in Convex by streaming documents. Here’s how!

## Stream the documents

The `convex-helpers` library introduces a new concept to Convex queries: streams. A stream is an [async iterable](https://javascript.info/async-iterators-generators) of documents, ordered by indexed fields. If you have a stream of messages ordered by creation time, you can imagine them flowing out of the stream, so you can read them one at a time.

You can create multiple streams, which don’t do anything until you start consuming them. Here’s an example of some streamed messages, where each from/to pair is streamed separately, in order of creation time.

![multiple streams](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F0953fa01edc24dc8649f91e29b9d72d72544507f-2548x692.png&w=3840&q=75)multiple streams

You create streams with a similar syntax to querying data. Instead of `ctx.db.query`, you’ll be using `stream(ctx.db, schema).query` . Streams and queries have the same interface, so you apply index and order in the same way. And after constructing a stream you can get documents like with any query, so `.first()` , `.unique()`, `.take(n)`, `.collect()`, and `.paginate(opts)` all work.

```tsx
import { stream } from "convex-helpers/server/stream";
import schema from "./schema";

const messages = await stream(ctx.db, schema)
  .query("messages")
  .withIndex("from_to", q => q.eq("from", u1).eq("to", u2))
  .order("desc")
  .collect();

```

From that example you can see the syntax is familiar, just requiring wrapping `ctx.db` in a `stream(ctx.db, schema)`. So what can you do with streams?

## Merge the streams

With data streaming in from multiple index ranges, we can merge them to generate new streams, and treat the combined stream in the same way — combine it some more, or get results.

![merged streams](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F5a16ac87e26dc91a443c80b8dea8ea0f9f3dfdda-2498x258.png&w=3840&q=75)merged streams

In code, you can do this with a `mergedStream` . If `messages1` and `messages2` are the two streams, you merge them like so:

```tsx
import { mergedStream } from "convex-helpers/server/stream";

const conversation = mergedStream([messages1, messages2], ["_creationTime"]);
// From the resulting stream you can fetch results as needed.
const startOfConversation = await conversation.take(10);

```

The second argument ( `["_creationTime"]` in the example) determines the order used for merging. Under the hood, mergedStream looks at all of the potential next documents from each stream, and yields the one that comes next in this order. In order to work, _each stream must already be ordered in that way_. So `messages1` and `messages2` must be ordered by `["_creationTime"]`.

So does that mean the second argument _must_ be `["_creationTime"]`? Nope, it still gives you extra flexibility. Imagine that `messages1` is composed of messages from user Egon to user Peter, and `messages2` is messages from Peter to Egon. Since “from” and “to” fields are constant within each stream, each stream is _also_ ordered by `["from", "to", "_creationTime"]`. So what happens if you merge in that order instead? Then all of Egon’s messages will be before Peter’s in the mergedStream.

Concretely, you’re allowed to merge with documents using a prefix of index fields, which are then ordered based on the rest of the index’s fields, similar to using `.withIndex` with `q.eq(field, value)`.

Using a mergedStream, you can take a union of individual streams and interleave the results into exactly the documents you want to return from your query.

## Streamed Joins (flatMap)

![a flat map](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fb92b7643837e29ece467473ec29fe71137db4842-300x138.jpg&w=3840&q=75)a flat map

While joins are already supported by [Relationship helpers](https://stack.convex.dev/functional-relationships-helpers) or [Ents](https://stack.convex.dev/ents), those patterns don’t support pagination easily. They support getting a page of results and fetching a join object for each one, but you can’t get arbitrarily many objects for each one. How can we use the streaming pattern to paginate a more complex join?

Each stream needs to be consumed in order, so it supports a `flatMap` interface, which may be familiar from languages like [JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/flatMap) or [Rust](https://docs.rs/futures-util/latest/futures_util/stream/trait.StreamExt.html#method.flat_map). Each item becomes a stream of items, and all of the streams are concatenated into a single stream.

![flatMap of streams](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fab1771430cfcfcb10d6e40529d31a63a635de4d8-2466x696.png&w=3840&q=75)flatMap of streams

If we start with a stream of friends, and do `flatMap` so each friend expands into a stream of messages, we end up with a stream of messages. These messages are ordered first by the friend, then by the message’s creation time.

In this example, we have a friends table which has all of the friends for a user, and we want to paginate through all messages sent to this user by friends.

```tsx
import { stream } from "convex-helpers/server/stream";
import schema from "./schema";

export const messagesFromFriends = query({
  args: { user: v.id("users"), paginationOpts: paginationOptsValidator },
  handler: async (ctx, { user, paginationOpts }) => {
    // Stream of the friends for args.user
    const friends = stream(ctx.db, schema)
      .query("friends")
      .withIndex("user", q => q.eq("userId", args.user));
    // For each friend, get a stream of the messages they sent to args.user.
    // The flatMap makes this a stream of messages, ordered by [friendId, _creationTime]
    const messagesFromFriends = friends
	    .flatMap((friend) => stream(ctx.db, schema)
			  .query("messages")
	      .withIndex("from_to", q => q.eq("from", friend.friendId).eq("to", args.user)),
				["from", "to"],
	    );
		// Paginate the result
		return messagesFromFriends.paginate(args.paginationOpts);
	},
22});

```

Note the second argument of `flatMap` is the indexed fields of the inner stream. In this example, `flatMap` turns each friend into a stream of messages with the "from\_to" index, so the second argument to `flatMap` is the fields of that index: `["from", "to"]`.

Now we have flat-mapped a stream into a larger stream, but we’ve lost information from the original stream. What if there’s some information on the “friend” document and we want every one of their messages to be tagged with that information. Let’s build some true JOIN-like behavior, with fields from both tables coming together so the result has the fields of both.

Enter: the `map` method.

You can map documents in a stream to any value. You can add fields, remove fields, do a one-to-one join, etc. After a `map`, the stream will have the same index keys and pagination cursors, but the values returned will be modified according to the mapping function. Here’s a simple example:

```tsx
const pageOfMessageBodies = stream(ctx.db, schema)
  .query("messages")
  .map((message) => message.body)
  .paginate(args.paginationOpts);

```

And here’s an example of using it alongside a join, to combine the fields of both tables onto the final documents:

```tsx
const friends = stream(ctx.db, schema)
  .query("friends")
  .withIndex("user", q => q.eq("userId", args.user));
const messagesFromFriends = friends
	.flatMap((friend) => stream(ctx.db, schema)
	  .query("messages")
		.withIndex("from_to", q => q.eq("from", friend.friendId).eq("to", args.user))
		// for each message, include relevant fields from the friend that sent it
		.map((message) => ({
		  fromBestFriend: friend.isBest,
			friendshipStarted: friend._creationTime,
		  ...message
		}),
		["from", "to"],
	);
// Paginate the result
return messagesFromFriends.paginate(args.paginationOpts);

```

## Filtering

Filtering with TypeScript predicates is already possible, either with Array.filter or the [`filter` helper](https://stack.convex.dev/complex-filters-in-convex). However, these filters can cause unwanted behavior with pagination: they can cause small or empty pages if the filter excludes most documents.

The alternative, if you want your pages to be full, would be to keep reading documents until you have enough to fill a page. The built-in function `.filter` does this, but it has restricted operations. It can’t run arbitrary TypeScript, and it certainly can’t do database lookups to filter based on a join-table.

Introducing `.filterWith`, which excludes documents from a stream before applying pagination, and also allows arbitrary async TypeScript.

```tsx
const messagesByActiveUsers = stream(ctx.db, schema)
  .query("messages")
  .withIndex("by_creation_time")
  .order("desc")
  .filterWith(async (message) => {
    const author = await ctx.db.get(message.from);
    return !author.isBanned;
  });
return messagesByActiveUsers.paginate(paginationOpts);

```

The filtered stream is still a stream, and it’s still ordered by the same fields as before. You can construct `mergedStream` s from filtered streams, and vice versa.

The downside of this method, and the reason I still personally prefer the `filter` helper, is you might read too much data and slow down or crash your query. To avoid that, you can pass in `maximumRowsRead` to the `paginationOpts`.

## Distinct

The article [SELECT DISTINCT without SQL](https://stack.convex.dev/select-distinct) describes how you can get the distinct values for a field, in a Convex query. This behavior, using the same algorithm, is available on streams with a nice syntax. You give it a set of indexed fields like `["to"]` and it returns the first streamed item with each distinct set of fields, e.g. the first message for each possible value of `message.to`. The distinct fields must be a prefix of the index fields, after discounting equality checks (similar to `mergedStreams` fields).

```ts
const messageRecipients = stream(ctx.db, stream)
  .query("messages")
	.withIndex("from_to", q => q.eq("from", args.user))
	.distinct(["to"])
	.map(async (message) => (await ctx.db.get(message.to))!);
return messageRecipients.paginate(args.paginationOpts);

```

This example starts with a stream of messages "from" the current user. Then it skips through the list to find the first message sent "to" each recipient. Finally, for each of these messages, it looks up the recipient user's details.

### Index Skip Scan

Databases with query planners occasionally use an [Index Skip Scan](https://oracle-base.com/articles/9i/index-skip-scanning) plan (although you can never rely on a query planner to do something efficient; it can and will choose to scan the whole table when you're not looking).

Convex streams can do that plan too (reliably). The idea of an Index Skip Scan is that for each prefix of an index key, you do a separate query on that subset of the table. Once you phrase it like that, you can see how to achieve the plan with methods we've already introduced: distinct and flatMap.

Suppose each message has a priority which is a number, and you want to find recent messages of high priority. That is, we want to find messages `WHERE priority > 5 AND _creationTime > now-24h`. This isn't a contiguous range of any index, so we need an Index Skip Scan plan:

1. Start with an index on `.index("priority", ["priority"])`
2. Find the distinct priorities greater than 5
3. flatMap each of those priorities into recently created messages.

```ts
const priorities = stream(ctx.db, schema).query("messages")
  .withIndex("priority", q => q.gt("priority", 5))
	.order("desc")
  .distinct(["priority"])
  .map(async (message) => message.priority);

const messages = priorities.flatMap(async (priority) =>
  stream(ctx.db, schema).query("messages").withIndex("priority", q =>
    q.eq("priority", priority).gt("_creationTime", Date.now() - 24*60*60*1000)
  ).order("desc"),
	["priority", "_creationTime"],
12);
const results = await messages.paginate(args.paginationOpts);

```

These results will be in descending order of `["priority", "_creationTime"]`. If you want the order to ignore priority, instead of `flatMap` you would get all priorities up-front and use `mergedStream`.

```ts
const allPriorities = await stream(ctx.db, schema).query("messages")
  .withIndex("priority", q => q.gt("priority", 5))
  .distinct(["priority"])
  .map(async (message) => message.priority)
	.collect();
const messages = mergedStream(allPriorities.map((priority) =>
	stream(ctx.db, schema).query("messages").withIndex("priority", q =>
    q.eq("priority", priority).gt("_creationTime", Date.now() - 24*60*60*1000)
	).order("desc"),
	["_creationTime"]
11);
const results = await messages.paginate(args.paginationOpts);

```

## Composing Patterns

You saw some examples in the [Distinct](https://stack.convex.dev/merging-streams-of-convex-data#distinct) section, but it's worth noting that all of the above patterns compose with each other.

For example, you can get the `.distinct` values for a field, `.filterWith` to remove some of them, `.flatMap` them into an Index Skip Scan of the table, `mergedStreams` them to interleave the results with documents from another table, `.filterWith` again to remove some more results you don't like, and `.map` the result to join with another table and remove some fields.

You're just writing TypeScript code, so you can choose to split each pattern into [TypeScript functions in different files](https://docs.convex.dev/understanding/best-practices#use-helper-functions-to-write-shared-code). You can build queries dynamically, choosing to use a different index based on function arguments: [build the query dynamically](https://stack.convex.dev/dynamic-query-builders) with the types `import { StreamQueryInitializer, StreamQuery, OrderedStreamQuery } from "convex-helpers/server/stream"`.

If you can imagine a way to fetch your data, you can implement it in code. Use streams to help realize that vision.

## Pagination Warnings

Streams are built to work well with `stream(...).<query>.paginate(opts)`, but there are some pitfalls when compared to the vanilla `ctx.db.<query>.paginate(opts)`.

1. Indexed fields, including those from filtered-out documents, are encoded into pagination cursors without encryption. If you use filtering to exclude documents that the client should not know about, their index keys may be leaked to the client. For example,





```tsx
// Pagination cursors come from index keys on documents,
// even if the documents are filtered out.
// So you might be telling the client the
// ["from", "to", "_creationTime"] fields of any message,
// even if `haveAccess` is false.
const messagesCheckAccessControl = await stream(ctx.db, schema)
  .query("messages")
  .withIndex("from_to")
  .filterWith(async (message) => haveAccess(ctx, message))
  .paginate(args.paginationOpts);

```

2. Pagination cursors only work when passed back into the same stream, constructed in the same way. If your query is data-dependent, paginated queries might get confused. For example,





```tsx
const newestUser = await ctx.db.query("users").order("desc").first();
return await stream(ctx.db, schema)
	.query("messages")
	.withIndex("from_to", q => q.eq("from", newestUser._id))
	.paginate(paginationOpts);

```





This query looks at a different index range depending on data in the “users” table. If a new user is created, pages will try to reload using cursors that correspond to the original user.

When using `.paginate` on a native `ctx.db.query`, we detect this case and throw an error which causes the client to discard all pages and start over. But with `stream` pagination, you would have to identify this issue yourself.

3. Reactive pagination allows the native `ctx.db.query().paginate` to keep pages contiguous even as documents are added and removed. See the [Fully Reactive Pagination](https://stack.convex.dev/fully-reactive-pagination) post. But streaming pagination doesn’t have this guarantee automatically. If you’re using reactive pagination, like the React `usePaginatedQuery` hook, holes or overlaps may develop between pages. To avoid such problems, you can pass the `continueCursor` back in as `endCursor` to pagination opts, which will ensure that a page ends at the same place where the next page starts. This requires calling each query twice, since you don't know the continueCursor until after the first execution. If you’re calling your paginated query in a non-reactive context like an action, this won’t be an issue.


To get all the pagination features you know and love from vanilla Convex, make sure to (1) not use `.filterWith` for access control, (2) keep query definitions stable even if data changes, and (3) use non-reactive pagination or pass `endCursor` through.

## Recap

Streams are a new way to fetch data from Convex.

- Start with the abstraction of documents arriving in a stream, generated by `stream(ctx.db, schema)` and otherwise familiar query syntax
- Merge streams in adjustable merge order with `mergedStream`
- Expand each item in a stream into multiple items, potentially streamed from a JOIN table, with `.flatMap`
- Modify the stream’s values with `.map`
- Filter documents out of the stream by calling `.filterWith`
- Get results with the query functions you’re already familiar with: `.first`, `.unique`, `.take`, `.collect`, and crucially `.paginate`.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Stateful Online Migrations using Mutations

Migrations are inevitable. Initial schemas aren't perfect on the first try. As your understanding of the problem evolves, you will inevitably change your mind about the ideal way to store information.
So how do you do it at scale, where you might not be able to change everything in a single transaction?

In this post, we’ll look at strategies for migrating data. In particular, scalable online migrations that don't require downtime or block pushes. We’ll be working specifically with Convex, but the concepts are universal.

To learn about migrations at a high level and some best practices, see [this intro to migrations](https://stack.convex.dev/intro-to-migrations).

To start writing your own migrations, check out the
[Migrations Component](https://www.convex.dev/components/migrations).

## Schema Migrations

One thing to call out explicitly is that with Convex, you **don’t** have to write migration code like “add column” or “add index” explicitly. All you need to do is update your `schema.ts` file and Convex handles it. Convex isn’t rigidly structured like most SQL databases are. If you change your field from `v.string()` to `v.union(v.string(), v.number())`, Convex doesn’t have to reformat the data or table. However, it **will** enforce the schema you define, and will not let you deploy a schema that doesn't match the data at rest. Or you can turn off schema validation and throw unstructured data into Convex and it will also work[1](https://stack.convex.dev/migrating-data-with-mutations#user-content-fn-1).

With schema validation enabled, Convex will help your code and data stay in sync by only letting you push schemas that match the current data. To add a string field to an object, for instance, you can push a schema where that field is `v.optional(v.string())`. Once there is a string on every object, Convex will let you push a schema that is just `v.string()` and future writes will enforce that the field will always be set and be a string.

In this way, Convex gives you the ease of just defining your types declaratively, while also guaranteeing that they match the reality of the data at rest when you deploy your code and schema. It’s also worth mentioning that transitions from one schema definition and code version to the next are atomic, thanks to Convex coordinating both the functions and the database.

The rest of this post is about how you go about changing the underlying data.

## Data Migrations using Mutations

To migrate data in Convex, you can use a [mutation](https://docs.convex.dev/functions/mutation-functions) to transform your data.
In particular, you'd likely use an [`internalMutation`](https://docs.convex.dev/functions/internal-functions) so it isn't exposed on your public API.

To make this easy, I've made a [Migration Component](https://www.convex.dev/components/migrations) to help define, run, and monitor your migrations.
We'll use it in the following examples. See the component page for steps to install and configure it.

### Common use cases

Here's how to achieve common migration patterns:

#### Adding a new field with a default value

```ts
export const setDefaultPlan = migrations.define({
  table: "teams",
  migrateOne: async (ctx, team) => {
    if (!team.plan) {
      await db.patch(team._id, { plan: "basic" });
    }
  },
8});

```

If you’re using a schema and validation, you’d likely update the team’s schema first to define “plan” as:

`plan: v.optional(v.union(v.literal("basic"), v.literal("pro")))`

Then, after all the fields have a value, you’d change it to:

`plan: v.union(v.literal("basic"), v.literal("pro"))`

Convex won’t let you deploy a schema that doesn’t conform to the data unless you turn off schema validation. As a result, you can safely trust that the typescript types inferred from your schema match the actual data.

Note: this doesn’t have to be a static value. You could write the value based on other fields in the document, or whatever custom logic you like.

As a reminder for those who skipped [the primer](https://stack.convex.dev/intro-to-migrations), to do this correctly, you’d also want to update your code to start writing the default field value on new documents before running this mutation to avoid missing any documents.

#### Deleting a field

If you’re sure you want to get rid of data, you would modify the schema in reverse: making the field optional before you can delete the data.

`isPro: v.boolean()` -\> `isPro: v.optional(v.boolean())`

Then you can run the following:

```ts
export const removeBoolean = migrations.define({
  table: "teams",
  migrateOne: async (ctx, team) => {
    if (team.isPro !== undefined) {
      await db.patch(team._id, { isPro: undefined });
    }
  },
8});

```

As mentioned in the migration [primer](https://stack.convex.dev/intro-to-migrations), I advise deprecating fields over deleting them when real user data is involved.

#### Changing the type of a field

You can both add and delete fields in the same migration - we could have done both the setting a default plan and deleting the deprecated `isPro` plan:

```ts
export const updatePlanToEnum = migrations.define({
  table: "teams",
  migrateOne: async (ctx, team) => {
    if (!team.plan) {
      await db.patch(team._id, {
        plan: team.isPro ? "pro" : "basic",
        isPro: undefined,
      });
    }
  },
11});

```

I'd recommend new fields when types change, but if you want to use the same field, you can do it with a union:
`zipCode: v.number()` -\> `field: v.union(v.string(), v.number())`

```ts
export const zipCodeShouldBeAString = migrations.define({
  table: "addresses",
  migrateOne: async (ctx, address) => {
    if (typeof address.zipCode === "number") {
      // Note: as a convenience, it will apply a patch you return.
      return { zipCode: address.zipCode.toString() };
    }
  },
9});

```

#### Inserting documents based on some state

Let's say you're changing user preferences from being an object in the users schema to its own document - you might consider doing this as preferences grows to be a lot of options, or to avoid accidentally returning preference data to clients for queries that return users.
You can walk the users table and insert into another table:

```ts
export const changePreferencesToDocument = migrations.define({
  table: "users",
  migrateOne: async (ctx, user) => {
    const prefs = await ctx.db
      .query("preferences")
      .withIndex("userId", (q) => q.eq("userId", user._id))
      .first();
    if (!prefs) {
      await ctx.db.insert("preferences", user.preferences);
      await ctx.db.patch(user._id, { preferences: undefined });
    }
  },
13});

```

You'd want to also have code that is adding perferences documents by default for new users, so the migration is only responsible for older users. You'd also update your code to first check the user for preferences, and if it's unset, fetch it from the table. Later, once you're confident there are preferences for all users, remove the preferences object from the users schema, and the code can just read preferences from the table.

#### Deleting documents based on some state

If you had a bug where you didn't delete related documents correctely, you might
want to clean up documents based on the existence of another document.
For example, one gotcha with vector databases is forgetting to delete embedding documents linked to chunks of documents that have been deleted.
When you do a vector search, you'd get results that no longer exist.
To delete the related documents you could do:

```ts
export const deleteOrphanedEmbeddings = migrations.define({
  table: "embeddings",
  migrateOne: async (ctx, doc) => {
    const chunk = await ctx.db
      .query("chunks")
      .withIndex("embeddingId", (q) => q.eq("embeddingId", doc._id))
      .first();
    if (!chunk) {
      await ctx.db.delete(doc._id);
    }
  },
12});

```

### Defining your own migrations

How would you do this without the `migration` component? The rest of this post is here if you want to know how to build some of this yourself. If you're happy with the component, you can stop reading here.

If your table is small enough (let’s say a few thousand rows, as a guideline), you could just do it all in one mutation. For example:

```jsx
export const doMigration = internalMutation(async ({ db }) => {
  const teams = await db.query("teams").collect();
  for (const team of teams) {
    // modify the team and write it back to the db here
  }
6});

```

This would define the `doMigration` mutation, which you could run from the dashboard or via [`npx convex run`](https://docs.convex.dev/cli#run-convex-functions).

#### Big tables

For larger tables, reading the whole table becomes impossible. Even with smaller tables, if there are a lot of active writes happening to the table, you might want to break the work into smaller chunks to avoid conflicts. Convex will automatically retry failed mutations up to a limit, and mutations don’t block queries, but it’s still best to avoid scenarios that make them likely.

There are a few ways you could break up the work. For the component, I use [pagination](https://docs.convex.dev/database/pagination).
Each mutation will only operate on a batch of documents and keep track of how far it got, so the next worker can efficiently pick up the next batch. One nice benefit of this is you can keep track of your progress, and if it fails on some batch of data, you can keep track of the cursor it started with and restart the migration at that batch.
Thanks to Convex’s [transactional guarantees](https://docs.convex.dev/database/advanced/occ), either all of the batch or none of the batch’s writes will have committed. A mutation that works with a page of data might look like this:

```jsx
export const myMigrationBatch = internalMutation(
  async ({ db }, { cursor, numItems }) => {
    const data = await db.query("mytable").paginate({ cursor, numItems });
    const { page, isDone, continueCursor } = data;
    for (const doc of page) {
      // modify doc
    }
    return { cursor: continueCursor, isDone };
  },
10);

```

#### Running a batch

To try out your migration, you might try running it on one chunk of data via the CLI or by going to the functions panel on [the dashboard](https://docs.convex.dev/dashboard/deployments/functions#running-functions) and clicking “Run function.” To run from the beginning of the table, you’d pass as an argument:

`{ cursor: null, numItems: 1 }`

On the CLI it would be:

```sh
npx convex run mutations:myMigrationBatch '{ "cursor": null, "numItems": 1 }'

```

It would then run and return the next cursor (and print it to the console so you can look back if you lose track of it). To run the next batch, just update the parameter to the cursor string instead of `null`.

You could keep running it from here, but it might start to feel tedious. Once you have confidence in the code and batch size, you can start running the rest. You can even pass in the cursor you got from testing on the dashboard to skip the documents you’ve already processed ☝️.

#### Looping batches from an action

To iterate through chunks, you can call it from an action in a loop:

```jsx
export const runMigration = internalAction(
  async ({ runMutation }, { name, cursor, batchSize }) => {
    let isDone = false;
    while (!isDone) {
      const args = { cursor, numItems: batchSize };
      ({ isDone, cursor } = await runMutation(name, args));
    }
  },
9);

```

You can then go to the dashboard page for the `runMigration` function and test run the mutation with the arguments `{ name: "myMigrationBatch", cursor: null, batchSize: 1 }`

Here `"myMigrationBatch"` is whatever your mutation’s path is, e.g. if it’s in the file `convex/migrations/someMigration.js`, it would be `"migrations/someMigration:myMigrationBatch"`.

To use the CLI, you could run:

```sh
npx convex run migrations:runMigration '{ "name": "myMigrationBatch", "cursor": null, "batchSize": 1 }'

```

It is also possible to loop from a client, such as [the `ConvexHttpClient`](https://docs.convex.dev/api/classes/browser.ConvexHttpClient), if you make it a public mutation. You could also recursively schedule a mutation to run, as an exercise left to the reader.

#### Batching via recursive scheduling

In the component, we use recursive scheduling for batches. A mutation keeps scheduling itself until the pagination is done.

```ts
export const myMigrationBatch = internalMutation({
  args: { cursor: v.union(v.string(), v.null()), numItems: v.number() },
  handler: async (ctx, args) => {
    const data = await ctx.db.query("mytable").paginate(args);
    const { page, isDone, continueCursor } = data;
    for (const doc of page) {
      // modify doc
    }
    if (!isDone) await ctx.scheduler.runAfter(0, internal.example.myMigrationBatch, {
      cursor: continueCursor,
      numItems: args.numItems,
    });
  }
14);

```

#### An aside on serial vs. parallelizing

You might be wondering whether we should be doing all of this in parallel. I’d urge you to start doing it serially, and only add parallelization gradually if it’s actually too slow. As a general principle with backend systems, avoid sending big bursts of traffic when possible. Even without causing explicit failures, it could affect latencies for user requests if you flood the database with too much traffic at once. This is a different mindset from an analytics database where you’d optimize for throughput. I think you’ll be surprised how fast a serial approach works in most cases.

## Summary

In this post, we looked at a strategy for migrating data in Convex using mutation functions. As with other posts, the magic is in composing functions and leveraging the fact that you get to write javascript or typescript rather than divining the right SQL incantation.
[Docs for the component are here](https://www.convex.dev/components/migrations),
and code for the component is available [on GitHub](https://github.com/get-convex/migrations). If you have any questions don’t hesitate to reach out in [Discord](https://convex.dev/community).

[get-convex/ **migrations**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/get-convex/migrations)

### Footnotes

1. Technically, there are some restrictions on Convex values, such as array lengths and object key names that you can read about [here](https://docs.convex.dev/production/state/limits). [↩](https://stack.convex.dev/migrating-data-with-mutations#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Convex in Multiple Repositories

Have you ever wanted to use your Convex functions in a different repository than where you define them? with type-safety? Well.. look no further.

Convex recently released the ability to generate a TypeScript API specification from your function metadata, which enables this use-case. Some scenarios in which this would useful are collaborating with frontend developers or contractors in a separate repository, having multiple product surfaces (admin vs. main), and having client implementations in separate repositories.

Below, I will dive into an example of what this workflow could look like. To get started, you should install the “Convex Helpers” library using `npm install convex-helpers` and [define validators](https://docs.convex.dev/functions/validation) on all your Convex functions.

## Using Convex within multiple repositories

Previously, it was hard to use Convex functions in a type-safe way outside of the repository where your Convex functions are defined. Now, we provide you a way to generate a file similar to `convex/_generated/api.d.ts` that you can use in separate repositories.

### 1\. Generate an `api.ts` file

You can run:

```bash
npx convex-helpers ts-api-spec

```

to generate a TypeScript API file for your Convex deployment. Below is an example of a Convex function definition and the corresponding API file. Your generated file will look something like the `api.ts` file below.

```tsx
// api.ts (generated API file)
import { FunctionReference, anyApi } from "convex/server";
import { GenericId as Id } from "convex/values";

export const api: PublicApiType = anyApi as unknown as PublicApiType;
export const internal: InternalApiType = anyApi as unknown as InternalApiType;

export type PublicApiType = {
  messages: {
    list: FunctionReference<
      "query",
      "public",
      Record<string, never>,
      Array<{
        _creationTime: number;
        _id: Id<"messages">;
        author: string;
        body: string;
      }>
    >;
    send: FunctionReference<
      "mutation",
      "public",
      { author: string; body: string },
      null
    >;
  };
28};
export type InternalApiType = {};

```

The types in this example come from a `convex/messages.ts` file like:

```tsx
// convex/messages.ts (function definition)
export const list = query({
  args: {},
  returns: v.array(
    v.object({
      body: v.string(),
      author: v.string(),
      _id: v.id("messages"),
      _creationTime: v.number(),
    }),
  ),
  handler: async (ctx) => {
    return await ctx.db.query("messages").collect();
  },
15});

export const send = mutation({
  args: { body: v.string(), author: v.string() },
  returns: v.null(),
  handler: async (ctx, { body, author }) => {
    const message = { body, author };
    await ctx.db.insert("messages", message);
  },
24});


```

### 2\. Install Convex in a separate repository

Once you generate this file, you can use it in any other repository you want to use your Convex functions in. You must also install the Convex package in this other repository using

```bash
npm install convex

```

The most common use-case for this is having your frontend code exist in a separate repository than the code for your Convex deployment.

### 3\. Connect to your backend from the separate repository

We must ensure that your frontend code is connecting to the correct Convex deployment. You can do this by setting your deployment URL as an environment variable when you create your Convex client. The example below is for React (Vite). See the [Quickstarts](https://docs.convex.dev/quickstarts) for details on how to configure clients for other frameworks.

```tsx
import { StrictMode } from "react";
import ReactDOM from "react-dom/client";
import "./index.css";
import App from "./App";
import { ConvexProvider, ConvexReactClient } from "convex/react";

const address = import.meta.env.VITE_CONVEX_URL as string;

const convex = new ConvexReactClient(address);

ReactDOM.createRoot(document.getElementById("root")!).render(
  <StrictMode>
    <ConvexProvider client={convex}>
      <App />
    </ConvexProvider>
  </StrictMode>,
17);

```

### 4\. Use `api.ts` from the separate repository

Once you have this `api.ts` copied into another repository, you can use it with the Convex client to call any of the Convex functions with type safety. Below is an example `App.tsx` file that imports from the copied-over `api.ts` file.

```tsx
// src/App.tsx
import { FormEvent, useState } from "react";
import { useMutation, useQuery } from "convex/react";
// Note: we are importing from `../api` not `../convex/_generated/api`
import { api } from "../api";

export default function App() {
  const messages = useQuery(api.messages.list) || [];

  const [newMessageText, setNewMessageText] = useState("");
  const sendMessage = useMutation(api.messages.send);

  const [name] = useState(() => "User " + Math.floor(Math.random() * 10000));
  async function handleSendMessage(event: FormEvent) {
    event.preventDefault();
    await sendMessage({ body: newMessageText, author: name });
    setNewMessageText("");
  }
  return (
    <main>
      <h1>Convex Chat</h1>
      <p className="badge">
        <span>{name}</span>
      </p>
      <ul>
        {messages.map((message) => (
          <li key={message._id}>
            <span>{message.author}:</span>
            <span>{message.body}</span>
            <span>{new Date(message._creationTime).toLocaleTimeString()}</span>
          </li>
        ))}
      </ul>
      <form onSubmit={handleSendMessage}>
        <input
          value={newMessageText}
          onChange={(event) => setNewMessageText(event.target.value)}
          placeholder="Write a message…"
        />
        <input type="submit" value="Send" disabled={!newMessageText} />
      </form>
    </main>
  );
44}

```

Now your frontend code is talking to your backend in a separate repository!

### Notes

- Argument and return value validators are not required, but the generated specs will only be as good as the validators provided. Convex validators (things like `v.string()`) are how Convex provides both runtime validation and provides typesafe APIs to clients. For this API generation to work the best, you’ll want to define both `args` and `returns` validators to provide the types.
- When you update your Convex backend and want to use the updated functions, you’ll need to re-generate the `api.ts` file. We suggest making this process part of your deployment workflow.

Check out the docs [here](https://docs.convex.dev/production/multiple-repos). I am excited to see what you build with this new functionality!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Supercharge `npm run dev` with package.json scripts

`npm run dev` is the standard for "run my website locally," but how does it work? How can we expand its functionality? In this post we'll look at:

- How to configure what `npm run dev` does.
- How to decompose complex commands into granular units.
- How to run multiple commands in parallel.
- How to run pre-requisites without losing normal `Ctrl-C` behavior.
- How to add seed data (if none exists) when starting up a Convex backend.

As a motivating example, here are some npm run scripts defined in the [convex-helpers](https://github.com/get-convex/convex-helpers) example app. We'll cover what each piece does

```json
  "scripts": {
    "dev": "npm-run-all --parallel dev:backend dev:frontend",
    "build": "tsc && vite build",
    "dev:backend": "convex dev",
    "dev:frontend": "vite",
    "predev": "convex dev --until-success",
    "test": "vitest"
  },

```

## What does `npm run dev` do?

`npm run dev` sets up a [local development server](https://stack.convex.dev/developing-with-the-oss-backend), enabling real-time code changes and instant feedback. This command simplifies the development process by automatically reloading the application whenever you make changes to the code.

### How and where they're defined

`npm run` executes commands that are defined in your `package.json` in your project's workspace. These commands are often pre-configured when you start your repo from a command like `npm create vite@latest` with commands for:

- `dev`: Run a development environment. This often includes auto-reloading the UI when files change. For [Vite](https://vitejs.dev/) this is `vite` and [Next.js](https://nextjs.org/) is `next dev`.
- `build`: Build the website for deployment. This will generally compile and bundle all your html, css, and javascript. For Vite this is `vite build` and Next.js is `next build`.
- `test`: Run tests - if you're using [Jest](https://jestjs.io/), it's just `"test": "jest"` or `vitest` for [Vitest](https://vitest.dev/).

Here's a basic example from Next.js:

```js
// in package.json
2{
// ...
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
//...

```

Here you can run `npm run dev` or `npm run lint` etc.

You can learn more about `npm run` in [the docs](https://docs.npmjs.com/cli/v10/commands/npm-run-script).

## Why use package.json scripts?

It's a fair question why one would put commands that are already so simple into package json scripts. Why not just call `jest` or `vite` or `next build`? There's a few good reasons:

1. You can save the default parameters for `npm run` commands so you don't have to remember or document the "standard" way of starting something. We'll see below how you can configure it to chain commands and run others in parallel.
2. It allows you to easily run commands that are installed by `npm` but not globally accessible from your shell (terminal).[1](https://stack.convex.dev/npm-run-dev-with-package-scripts#user-content-fn-1) When you install things like `npm install -D vitest`, it installs `vitest` into `node_modules/.bin`.[2](https://stack.convex.dev/npm-run-dev-with-package-scripts#user-content-fn-2) You can't run `vitest` directly in your shell,[3](https://stack.convex.dev/npm-run-dev-with-package-scripts#user-content-fn-3) but you can have a config like: `"scripts": { "test": "vitest" }` and `npm run test` will run `vitest`.
3. It always runs with the root of the package folder as the "current directory" even if you're in a subdirectory. So you can define a script like `"foo": "./myscript.sh"` and it will always look for `myscript.sh` in the package root (in the same directory as package.json). Note: you can access the current directory where it was called via the `INIT_CWD` environment variable.
4. You can reference variables in the `package.json` easily when the script is run from `npm run`. For instance, you can access the "version" of your package with the `npm_package_version` environment variable, like `process.env.npm_package_version` in js or `$npm_package_version` in a script.
5. If you have multiple workspaces (many directories with their own package.json configured into a parent package.json with a "workspaces" config), you can run the same command in all workspaces with `npm test --workspaces` or one with `npm run lint --workspace apps/web`.

## Does `npm run dev` work with yarn / pnpm / bun?

Yes! Even if you install your dependencies with another package manager, you can still run your package scripts with npm.

```sh
yarn # similar to `npm install`
npm run dev # still works!

```

You don't have to remember that `npm run dev` maps to `yarn dev` (or `yarn run dev`). The same goes for `npx`: `npx convex dev` works regardless of what package manager you used to install things.

## Running multiple commands in parallel with `npm run all` or `concurrently`

There are a couple packages you can use to execute npm commands concurrently:[4](https://stack.convex.dev/npm-run-dev-with-package-scripts#user-content-fn-4)

1. [`npm-run-all`](https://github.com/mysticatea/npm-run-all)
2. [`concurrently`](http://npmjs.org/package/concurrently)

Here's an example of `npm-run-all`:

```json
  "scripts": {
    "dev": "npm-run-all --parallel dev:backend dev:frontend",
    "dev:backend": "convex dev",
    "dev:frontend": "vite",
  },

```

This defines three npm run scripts.

1. `npm run dev:backend` runs `convex dev`.
2. `npm run dev:frontend` runs `vite`.
3. `npm run dev` runs both `convex dev` and `vite` in parallel via `npm-run-all`.

Both outputs are streamed out, and doing Ctrl-C will interrupt both scripts. With `npm run all`, you can easily run both the [Convex backend](https://stack.convex.dev/building-the-oss-backend) and frontend services with one command.

Here's an example of using concurrently to run the same project:

```json
 "scripts": {
    "dev": "concurrently \"npm run dev:backend\" \"npm run dev:frontend\"",
    "dev:backend": "convex dev",
    "dev:frontend": "vite",
  },

```

This set of package json scripts run multiple npm run commands in parallel similar to `npm run all` but uses the `concurrently` package which provides additional features like better handling of command outputs and more control over execution control.

## Enhancing `npm run dev` with `predev` and `postbuild`

You can specify commands to run before (pre) or after (post) another command (say, X) by naming your command `preX` or `postX`. In the example:

```json
  "scripts": {
    "dev": "npm-run-all --parallel dev:backend dev:frontend",
    "dev:backend": "convex dev",
    "dev:frontend": "vite",
    "predev": "convex dev --until-success",
  },

```

This will run `convex dev --until-success`, before the "dev" command of `npm-run-all --parallel dev:backend dev:frontend`.

### Chaining with "&&"

For those used to shell scripting, you can run two commands in sequence if the previous one succeeds with `commandA && commandB`. This works on both Windows and Unix (Mac / Linux).

However, there's a couple advantages to just using `pre`-scripts:

1. You can run either command with `npm run dev --ignore-scripts` to not do the "predev" script, or `npm run predev` to explicitly only do the "predev" step.
2. The Ctrl-C behavior is more predictable in my experience. In different shell environments, doing Ctrl-C (which sends an interrupt signal to the current process) would sometimes kill the first script but still run the second script. After many attempts we decided to switch to "predev" as the pattern.

## Run interactive steps first

The first time you [run Convex](https://docs.convex.dev/quickstart/nodejs) by using `npx convex dev` (or `npm run dev` with the above scripts), it will ask you to log in if you aren't already, and ask you to set up your project if one isn't already set up. This is great, but interactive commands that update the output text don't work well when the output is being streamed by multiple commands at once. This is the motivation for running `npx convex dev --until-success` before `npx convex dev`.

- `convex dev` syncs your functions and schema whenever it doesn't match what you have deployed, watching for file changes.
- The `--until-success` flag syncs your functions and schema only until it succeeds once, telling you what to fix if something is wrong and retrying automatically until it succeeds or you Ctrl-C it.
- By running `npx convex dev --until-success`, we can go through the login, project configuration, and an initial sync, all before trying to start up the frontend and backend.
- The initial sync is especially helpful if it catches issues like missing environment variables which need to be set before your app can function.
- This way the frontend doesn't start until the backend is ready to handle requests with the version of functions it expects.

## Seeding data on startup

If you change your "predev" command for Convex to include `--run` it will run a server-side function before your frontend has started.

```json
  "scripts": {
	  //...
    "predev": "convex dev --until-success --run init",
		//...
  },

```

The `--run init` command will run a function that is the default export in `convex/init.ts`. You could also run `--run myFolder/myModule:myFunction`. See [docs on naming here](https://docs.convex.dev/functions/query-functions#query-names).

See the Convex documentation on [query names](https://docs.convex.dev/functions/query-functions#query-names). See this [post on seeding data](https://stack.convex.dev/seeding-data-for-preview-deployments) for more details. In essence, you can define an [internalMutation](https://docs.convex.dev/functions/internal-functions) that checks if the database is empty and, if so, inserts a collection of records for testing or setup purposes.

## tsc?

If you [use TypeScript](https://stack.convex.dev/end-to-end-ts), you can run a type check / compile your typescript files with a bare `tsc`. If your `tsconfig.json` is configured to emit types, it will write out the types. If not, it will just validate the types. This is great to do as part of the build, so you don't build anything that has type errors. This is why the above example did:

```js
    "build": "tsc && vite build",

```

## Passing arguments to `npm run` commands

If you want to pass arguments to a command, for instance passing arguments to your testing command to specify what test to run, you can pass them **after** a `--` to separate the command from the argument. Technically you don't need `--` if your arguments are positional instead of `-`-prefixed, but it doesn't hurt to always do it in case you forget which to do it for.

```sh
npm run test -- --grep="pattern"

```

## Handling common npm script errors

When working with npm run commands, you might encounter various errors. Here are some common issues and how to handle them:

- **Command Not Found**: Ensure the command is installed locally in your node\_modules and correctly referenced in your `package.json` scripts.
- **Permission Denied**: This often occurs on Unix-based systems. You might need to adjust file permissions or use `sudo` cautiously.
- **Syntax Errors**: Double-check your `package.json` for any syntax errors, such as missing commas or incorrect script names.

## Integrating npm run scripts with CI/CD pipelines

Integrating npm run scripts with CI/CD pipelines can automate your development workflow, ensuring consistent builds and deployments. Most CI/CD tools like GitHub Actions, GitLab CI, and Jenkins support running npm scripts as part of their pipeline configuration.

For example, in a [GitHub Actions](https://docs.convex.dev/testing/ci#testing-in-github-actions) workflow:

```
name: Run Tests

on: [pull_request, push]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
      - run: npm ci
      - run: npm run test

```

This yaml file makes sure that every push to your repository triggers the CI pipeline, running your tests and building your project automatically.

## Summary

We looked at some ways of using package.json scripts to simplify our workflows. Who knew how much power could rest behind a simple `npm run dev`? Looking at our original example:

```json
  "scripts": {
    "dev": "npm-run-all --parallel dev:backend dev:frontend",
    "build": "tsc && vite build",
    "dev:backend": "convex dev",
    "dev:frontend": "vite",
    "predev": "convex dev --until-success",
    "test": "vitest"
  },

```

- `dev` runs the frontend and backend in parallel, after `predev`.
- `build` does type checking via `tsc` before building the static site.
- `dev:backend` continuously deploys the backend functions to your development environment as you edit files.
- `dev:frontend` runs a local frontend server that auto-reloads as you edit files.
- `predev` runs before `dev` and does an initial deployment, handling login, configuration, and an initial sync as necessary.
- `test` uses Vitest to run tests. Note: `npm test` is shorthand for `npm run test` along with other commands, but they're special cases. `npm run test` is the habit I suggest.

### Footnotes

1. The way your shell finds which command to run when you type `npm` is to check the shell's `PATH` environment variable (on unix machines anyways). You can see your own with `echo "$PATH"`. It checks all the places specified in `$PATH` and uses the first one. [↩](https://stack.convex.dev/npm-run-dev-with-package-scripts#user-content-fnref-1)

2. Technically you can override & specify where npm installs binaries. [↩](https://stack.convex.dev/npm-run-dev-with-package-scripts#user-content-fnref-2)

3. If you really want to, you can run `npm exec vitest`, `npx vitest` for short, `./npm_modules/.bin/vitest` directly, or add `.npm_modules/.bin` to your PATH. [↩](https://stack.convex.dev/npm-run-dev-with-package-scripts#user-content-fnref-3)

4. Some people use a bare `&` to run one task in the background, but that is not supported on Windows, and interrupting one command won't necessarily kill the other. [↩](https://stack.convex.dev/npm-run-dev-with-package-scripts#user-content-fnref-4)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Observing your app in production

This is one of a series of posts on operational maturity in production. Get more tips for best practices for running apps in production [here](https://stack.convex.dev/operational-maturity-for-production).

Observability and monitoring are umbrella terms covering the various ways to see what’s happening with your app in the wild. This can include things like logs, metrics, exceptions, events, spans, traces, and more. This post will explore progressive steps you can take to increase your ability to introspect your app in production.

### Start with logs

When you’re just getting off the ground, you’ll likely get by for a while with just looking at logs. These will include:

- Debug output, such as `console.debug`.
- Exceptions with stack traces.
- Notable events, such as a user signing up, or interacting with the app.

#### In the dashboard

You can get surprisingly far, especially if you use the tools well. The Convex dashboard has a logs view where you can filter by log type, search, and temporarily clear logs. Failures in the frontend during development will show server-side errors in the console log, but will be hidden in production to avoid leaking server state unintentionally. To see a specific error in production, you can copy the associated [Request ID](https://docs.convex.dev/functions/error-handling/#debugging-errors) and search for it in the logs page.

#### Via the CLI

You can also stream logs into the CLI using `npx convex logs`. By piping it to `grep` or other tools, you can debug verbose output, filtering to the events you’re interested in. One command to try is `npx convex logs | tee ./logs.txt` which will both print out logs and save them to a file that you can inspect and filter later, without relying on your console history.

### Graduating to dedicated observability platforms

The Convex logs are a great starting point, but when you’re shipping an app to production, you will likely want to use industry standards, which come with dedicated features and infrastructure for. In particular, they can give you:

- Infinite history of older logs, enriched with metadata from Convex
- Unified client and server exception reporting
- Graphs and alerts for custom metrics
- Dashboards for insights and debugging
- Trends and triage tools with AI-backed clustering
- Persisted audit logging

Here are a set of actions you can take to leverage these platforms as you mature, in roughly the order to worry about them:

#### Persist your logs to Axiom

It’s useful to debug historical events and this is the easiest way to incrementally develop around a logs-centric approach. [Axiom](https://axiom.co/) and [DataDog](https://www.datadoghq.com/) allow you to stream in logs and work with them as events, and Convex will [enrich them with information about the server function](https://docs.convex.dev/production/integrations/log-streams#log-event-data-model-beta). It will also send logs about each function invocation, including the endpoint, its status, how long it took, and how much data and file storage it read & wrote.

See the docs for setting up log streaming [here](https://docs.convex.dev/production/integrations/log-streams). All you need to do is copy a key and some details from your Axiom/DataDog account into the Convex dashboard.

**Extract metrics from logs for dashboards**

One amazing thing about Axiom is that you can turn a `console.log` into events that you can plot in graphs and set alerts on. You can also make dashboards from the [logs sent for every function invocation](https://docs.convex.dev/production/integrations/log-streams#log-event-data-model-beta), showing errors per endpoint, or percentiles on timing. Using Axiom to turn logs into “wide events,” you can do very powerful things without littering proprietary metrics calls in your codebase.

#### Report your exceptions to Sentry

The baseline concern is whether your app is working. If your app is throwing exceptions, you almost certainly want to know about it and quickly diagnose what’s wrong. Reporting exceptions to [Sentry](https://sentry.io/welcome/?gad_source=1) allows you to see errors grouped by stack trace, and see metadata about exceptions, to figure out what is causing the issue. One tip is to [integrate it with your company’s Slack](https://sentry.io/integrations/slack/) or other messaging tool, so you get notified immediately about issues.

See the docs for reporting server exceptions to Sentry [here](https://docs.convex.dev/production/integrations/exception-reporting). It’s as easy as pasting in your DSN URL to the Convex dashboard. You can use the same Sentry configuration for reporting client-side errors, allowing you to see all of your errors in one place.

#### Set up web analytics with Plausible

A dedicated platform like [Plausible](https://plausible.io/) for looking at website traffic, including referrers, campaigns, and other insights, will help you see changes in website usage which can both indicate issues, but more importantly help you understand how users are interacting with your product. If no one is visiting the pricing page, that’s good information, even if there aren’t any software bugs.

#### Set up paging and on-call duties with PagerDuty

Once you have your exceptions and metrics, use PagerDuty to call and text you during an incident. [Configure Axiom](https://axiom.co/docs/apps/pagerduty) and [Sentry](https://sentry.io/integrations/pagerduty/) to send alerts to PagerDuty, and set up PagerDuty to always break through your Do Not Disturb settings, so you’re never wondering whether there’s an issue you’re missing.

As your team scales, share the responsibilities and set up schedules in PagerDuty that can be traded around, with a secondary person to respond if the primary doesn’t acknowledge the issue after a short amount of time. One useful tip is to [sync the oncall schedule with Slack](https://stack.convex.dev/pagerduty-slack-sync) in an #oncall channel, so anyone at the company can go to that channel to see who is oncall right now.

This responsibility can also extend to responding to support emails and async customer requests, though that is often decoupled to a “product on-call” role that is eventually part of a customer support effort.

The team I ran at Dropbox had the expectation to respond to an issue within 5 minutes or it would escalate to the secondary, then the whole team. This required the active primary and secondary to carry their laptops and a hot spot wherever they went. Your needs will change over time, and should be an ongoing conversation between engineering and product to support the business and promises you make to customers, without over-burdening the team.

### Persist important events to tables

In addition to emitting logs for events, you might want to have more structured data to do analytics on or as part of some business workflow, for instance capturing every time a user creates a new team. You might do some offline processing to find qualified leads for sales, or later define some workflow logic around when to send various engagement emails. Wanting data in a standard, durable, consistent, query-able format is a sign that you want a database in the loop. By making an “events” table, you can write structured events with a schema, and query them later.

#### Inspecting your data in the dashboard

At first, you may be fine just using the Convex dashboard to inspect your data. You can use the [data page’s](https://docs.convex.dev/dashboard/deployments/data) [filters](https://docs.convex.dev/dashboard/deployments/data#filtering-documents) to find relevant documents. You can also use the live query editor in the function runner. You can also run custom `internalQuery` functions [from the CLI](https://docs.convex.dev/cli#run-convex-functions) to generate reports.

However, as your needs grow, you’ll likely want to query your data with an analytics-optimized query interface like SQL.

#### Inspecting data from a snapshot export

You can [export](https://docs.convex.dev/database/import-export/export) your data and inspect it locally for one-off analytics. Unzip the snapshot and use [`jq`](https://jqlang.github.io/jq/) for basic command-line inspection and manipulation on any of the tables.
When you want to do more complex investigation in SQL, including queries joining tables, use [DuckDB](https://duckdb.org/) to run SQL commands on your json data directly:

```sh
1$ npx convex export --prod --path ./snapshot.zip
2$ unzip ./snapshot.zip && cd snapshot
3$ duckdb
D install 'json';
D load 'json';
D SELECT * from 'myTable/documents.jsonl' LIMIT 1;
7┌────────────────────┬──────────────────────────────────┬───────────┬─────────────────────────────────┐
8│   _creationTime    │               _id                │ someField │          otherTableId           │
9│       double       │             varchar              │  varchar  │             varchar             │
10├────────────────────┼──────────────────────────────────┼───────────┼─────────────────────────────────┤
11│ 1705522240446.3655 │ js700yfkncke9xk23ndf3ahmj56hq77t │ foo       │ 3cqbsxb8cexh8stz73be6f9w9hjqa28 │
12└────────────────────┴──────────────────────────────────┴───────────┴─────────────────────────────────┘
D SELECT someField, otherField from 'myTable/documents.jsonl' as myTable
    JOIN 'otherTable/documents.jsonl' as otherTable
    ON myTable.otherTableId = otherTable._id LIMIT 1;
16┌───────────┬────────────┐
17│ someField │ otherField │
18│  varchar  │  boolean   │
19├───────────┼────────────┤
20│ foo       │ true       │
21└───────────┴────────────┘

```

#### Stream tables to a dedicated analytics tool like BigQuery

Once your events are in a table, you can use Convex [streaming export](https://docs.convex.dev/database/import-export/streaming) to export various tables to a dedicated tool like [BigQuery](https://cloud.google.com/bigquery) on an ongoing basis. Analytics (OLAP) databases are optimized to do large queries efficiently, relative to transactional (OLTP) application databases like Convex. From the analytics tools, you can build complex data pipelines to learn about your data and connect it with other products such as a CRM. If you end up generating actionable data that you want to incorporate back into your application, you can stream that data into a Convex table using [streaming import](https://docs.convex.dev/database/import-export/streaming#streaming-import).

## Summary

By setting up dedicated tools, you can get actionable data to help understanding errors, performance, user behavior and allow you respond quickly as data changes.

Get more tips for best practices for running apps in production [here](https://stack.convex.dev/operational-maturity-for-production).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Operational maturity for production

Operational maturity is the umbrella term I like when thinking about scalability, security, observability, and other important aspects of a serious product. Similar to scaling, it isn’t a destination, but a continual process. There is no one checklist that an app goes through once. Rather, you should understand where you are in the journey, what the biggest risks are, and what incremental steps are available.

This post will cover various areas of operational maturity, and link to posts outlining steps to take as your app develops. The advice will specifically reference Convex but the concepts are generally applicable.

I’ve worked on teams and products all along this spectrum, from launching a new GCP product for startups like Clockwork, to greenfield products for established companies like The New York Times, to managing the Dropbox infrastructure responsible for file previews—involving hundreds of servers in multiple data centers handling millions of image requests per day targeting three nines of availability. I can assure you, all of these did not—and should not—have the same level of operational maturity.

## 1\. Prototyping: YOLO

When you’re first building your app or bootstrapping your company, you want to move as quickly as possible. If you’re spending a lot of time thinking about load balancing, connection pooling, data architecture for future-proof sharding, or Kubernetes, then you likely aren’t thinking enough about the human problem you’re trying to solve. For reassurance, I have a heuristic that for every order of magnitude increase in users, an app often gets re-architected or re-written at some layer. Your database schema in your first commit to your git repository does not need to be the data model you launch with. Don’t let perfect be the enemy of good.

#### [Click here for tips on getting to an MVP fast](https://stack.convex.dev/yolo-fast-mvp)

Tips include: version control, liberal logging, interactive database queries, auto-reload, auto-deploys, keeping your stack simple, snapshotting data, seed scripts, deferring auth, loose schemas, manual migrations, and more.

## 2\. Observing your app

When your app is running, observability allows you to see what is happening, how your product is being used, what is going wrong, and help you debug the “why” behind it all. It is a critical piece of running an app in production, where you don’t have debug access to all of the devices interacting with your software.

#### [Learn more about observing your app in production](https://stack.convex.dev/observability-in-production)

You can start with simple logs, and incorporate dedicated tools over time like Axiom, Sentry, Plausible, PagerDuty, Databricks, and more.

## 3\. Testing for peace of mind

From a pragmatic standpoint, testing allows you to validate behavior, catch regressions in performance or functionality, and ultimately give you peace of mind. When you have high confidence in your testing, you will feel confident shipping more frequently.

#### [Learn more about testing patterns](https://stack.convex.dev/testing-patterns)

From end-to-end tests to unit tests, from manual to automated strategies, there are a lot of options to choose from when deciding what to up-level next. Often-overlooked aspects of testing are how you test subjective changes in production, and testing your app from outside of your own ecosystem. The latter helps to catch issues with hard-to-test parts of your stack like networking and configurations that only exist in production.

## 4\. Protecting your app from yourself

Even if your code is well tested, you can still make mistakes in how you interact with the powerful tools at your disposal. The source of many major internet outages have been from someone mis-typing a command, for instance running a destructive—like deleting a table—in production when they meant to run it against a development instance. Over time, you’ll need to invest in safer processes around changing code, configuration, and data in production.

Some areas of investment include:

**Deployments:** push-time checks for environment variable definitions, checking for accidental deletion of large indexes, isolating your production deployment from staging and development workflows, and avoiding breaking and inefficient schema changes.

**Migrations**: codifying mutations in code, verifying them against seed data, validating a dry run, and opt-in automation.

**Scoped data changes:** authenticated, authorized, audit-logged changes to production data through dedicated admin interfaces.

## 5\. Hardening your app

Your app needs protection from more than your own mistakes. When you launch to production, you’ll need to consider how clients might misbehave. A backend needs to protect against bad input, or requests that try to access or modify other users’ data. As your customers start to rely on your site, you’ll need to refine your authentication and authorization story.

Simple steps include:

- [schema validation](https://docs.convex.dev/database/schemas) for data.[1](https://stack.convex.dev/operational-maturity-for-production#user-content-fn-2)
- [argument validation](https://docs.convex.dev/functions/args-validation) for endpoints.
- [Internal functions](https://docs.convex.dev/functions/internal-functions) for calling or scheduling functions from other server functions.
- [Authentication in functions](https://docs.convex.dev/auth/functions-auth) to identify users instead of passing up user identifiers.
- [Standardized authentication patterns](https://stack.convex.dev/custom-functions) for public functions with [lints to enforce usage](https://stack.convex.dev/eslint-setup).
- [Environment variables](https://docs.convex.dev/production/environment-variables) for secrets.
- [Shared secrets for cross-server requests](https://stack.convex.dev/custom-functions#consuming-a-function-argument-for-basic-api-key-auth).
- [Rate limit user actions](https://stack.convex.dev/rate-limiting) such as logins or email resets to discourage hackers.
- [Authorizing data access based on the user](https://stack.convex.dev/row-level-security).

## 6\. Scaling

As your app grows from dozens to thousands to millions of users, the performance and reliability of your app become more important. This can include considerations for organic growth such as:

- [Optimizing your database queries](https://stack.convex.dev/queries-that-scale) to avoid scanning too many documents.
- [Retrying functions](https://stack.convex.dev/retry-actions) that rely on unreliable services.
- [Dynamic client-side throttling](https://stack.convex.dev/throttling-requests-by-single-flighting)
- Using [scheduled functions](https://docs.convex.dev/scheduling/scheduled-functions) as a work queue when you care more about throughput than latency.
- [Rate limiting](https://stack.convex.dev/rate-limiting) expensive requests (such as requests to LLMs) per user, especially for freemium plans.
- [Managing the state of asynchronous workloads](https://stack.convex.dev/background-job-management).
- Using [work stealing](https://stack.convex.dev/work-stealing) pattern when running your own infra and want to optimize for throughput.
- Load testing your app to stay ahead of your users’ growth.

## Summary

Operational maturity is an ongoing process that covers a wide range of topics. We’ve touched on many ways to level up your app, but this list is neither exhaustive nor essential. The important decisions to make are:

- Where are your gaps?
- What is worth investing in next?
- When is the right time to take the next step and re-evaluate?

We’d love to hear from you in our [community Discord](https://convex.dev/community).

And if this has gotten you interested in how we think about the future of product development here at Convex, check out this video:

### Footnotes

1. You can also use [Zod](https://stack.convex.dev/typescript-zod-function-validation) for finer-grained runtime validation. [↩](https://stack.convex.dev/operational-maturity-for-production#user-content-fnref-2)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Take Control of Pagination

_**Note: If you're looking for our post on CRUD APIs, you can find that [here](https://stack.convex.dev/crud-and-rest).**_

When you store a lot of data in Convex, you usually want to display it incrementally, using pagination to show one page at a time.

The Convex framework offers `.paginate(opts)` and `usePaginatedQuery()` to implement infinite-scroll pagination. These functions are powerful and handle the complex edge cases of stitching the pages together seamlessly. However, there are several scenarios they do not support, or at least don't support out-of-the-box:

1. Joins like “list all (paginated) messages for each of my (paginated) contacts”
2. Unions like “list all (paginated) messages for each of my 3 email accounts.”
3. Virtual infinite scroll view where you jump to a point and then scroll up or down. Think “show me the photos from June 2020 and photos before and after”
4. Unloading and unsubscribing from unnecessary pages. If you load 100 pages, those 100 pages of documents stick around in the browser’s memory and keep updating when the data changes, even if the documents are far off-screen.
5. Keeping pages bounded in size. If documents are inserted quickly — e.g. if there are hundreds of inserts per mutation — pages can grow beyond the limits of a Convex function, and throw an error.

These are difficult problems to solve, and a complete solution would require complicating the base interface. For example, if you call `.paginate` twice in a query function, are you aiming for a join pattern or a union? It becomes unclear whether `loadMore` should load more of the first or the last `db.query`. As another example, do you want pagination cursors to be opaque — which is the default with `.paginate` and useful for security in some cases — or do you want to be able to parse them to allow “jump to June 2020, which may already be a loaded page.”

Convex may eventually solve all of these problems with the built-in interface, but for now we give you the power to solve them yourselves, leveraging the versatility of the Convex runtime running arbitrary TypeScript. Introducing `getPage`:

```ts
import { getPage } from "convex-helpers/server/pagination";

```

### What is `getPage`?

This function is a new helper, built on top of existing Convex primitives. It supports many arguments, most of them optional with sensible defaults:

- a start position: ”give me photos starting at June 2020”
- an end position: “give all photos up until August 2020”
- an index: “paginate in order of user surname, instead of creation time”
- an order for the index: “give me messages from newest to oldest”
- a soft limit: “give me 100 messages, but allow more if the page grows”
- a hard limit: “give me at most 500 messages, even if the page grows”

See the [source code](https://github.com/get-convex/convex-helpers/blob/main/packages/convex-helpers/server/pagination.ts) for the full interface and docstrings.

The return value includes a page of documents, whether there are more documents to request, and the index key for each document in the page.

### What’s an index key?

The `getPage` function returns an object:

```ts
const { page, indexKeys, hasMore } = await getPage(...);

```

Each document in `page` has a corresponding index key, so the document `page[3]` has index key `indexKeys[3]`. But what is an index key?

Index keys are locations in the index. For a table like

```ts
contacts: defineTable({
	surname: v.string(),
	givenName: v.string()
4}).index("name", ["surname", "givenName"])

```

an index key would be something like `["Smith", "John", 1719412234000, "jh7evzh9wejnwjv88y1a1g9c7h6vpabd"]`. Documents in the returned page are sorted by the index key. To avoid duplicates, every index key ends with the creation time and ID of the document.

Usually you don’t need to pay attention to what’s in an index key, because you can pass `getPage`'s response `indexKeys` directly to its request `startIndexKey` or `endIndexKey` fields. However, it can be useful to say “start the page at June 2020” by passing `startIndexKey: [Date.parse("2020-06-01")]`: the sort order puts this before all dates in June 2020.

When you fetch a page of documents with `getPage`, you get an index key corresponding to each document, and you can use these to fetch more documents. The last index key `indexKeys[indexKeys.length - 1]` is particularly useful, because it corresponds to the index location at the end of the fetched page.

## Patterns

With `getPage` giving you complete control of your pagination, you can now solve any of the above problems. Let's look at implementing some common patterns with concrete examples.

All of the following examples will use and build off of this data model:

```tsx
contacts: defineTable({
	surname: v.string(),
	givenName: v.string(),
	emailAddress: v.string(),
5}).index("name", ["surname", "givenName"]),
emails: defineTable({
	address: v.string(),
	body: v.string(),
9}).index("address", ["address"]),

```

### Basic Pagination

Let’s start with the most basic query. We list a page of 100 contacts in `_creationTime` order, starting at the beginning of time:

```tsx
// In the convex/contacts.ts file
export const firstPageOfContacts = query((ctx) => {
	return getPage(ctx, { table: "contacts" });
4});
// Then in React, call the query
const { page } = useQuery(api.contacts.firstPageOfContacts);

```

To get the next page of contacts, we ask for the page starting at the index key at the end of the first page.

```tsx
// In convex/contacts.ts
export const pageOfContacts = query((ctx, args) => {
	return getPage(ctx, { table: "contacts", ...args });
4});
// In React
const firstPage = useQuery(api.contacts.pageOfContacts);
const secondPage = useQuery(api.contacts.pageOfContacts, firstPage ? {
	startIndexKey: firstPage.indexKeys[firstPage.indexKeys.length - 1],
9} : "skip");

```

Now you have two pages. If you want a dynamic number of pages, instead of `useQuery` you will want [`useQueries`](https://docs.convex.dev/api/modules/react#usequeries). At some point you’ll want to wrap all this in a hook, similar to the built-in `usePaginatedQuery`.

The return value of `getPage` includes three things:

1. The page of documents
2. The index key for each document, allowing you to fetch related pages
3. A boolean `hasMore` to tell you if there are more pages to fetch

### Use any index

By default, `getPage` uses the index on `_creationTime`, but it can use any database index (text-search and vector indexes are not supported). The index determines the format for index keys, and also the order of returned documents. When specifying an index, you have to tell `getPage` your schema too, so it knows which fields are in the index.

The following query will get the first page of contacts in order of surname, then givenName, because the "name" index is defined as `.index("name", ["surname", "givenName"])`.

```tsx
import schema from "./schema";
const { page, indexKeys } = await getPage(ctx, {
	table: "contacts",
	index: "name",
	schema,
6});

```

### Pagination with a join

Built-in pagination supports simple joins: if I’m paginating over contacts and each contact has a `profilePicId`, I can fetch the profile picture for each contact with the pattern described [here](https://docs.convex.dev/database/pagination#transforming-results). However, you can’t do pagination _within_ this join, because the built-in Convex query currently can’t keep track of multiple pagination cursors in one query.

Suppose I want to fetch the first page of contacts, and the first page of emails for each contact. With `getPage` I can do this:

```tsx
const {
	page: pageOfContacts,
	indexKeys: contactIndexKeys,
4} = await getPage(ctx, { table: "contacts" });
const emails = {};
for (const contact of pageOfContacts) {
	emails[contact.email] = await getPage(ctx, {
		table: "emails",
		index: "address",
		schema,
		startIndexKey: [contact.emailAddress],
		endIndexKey: [contact.emailAddress],
		endInclusive: true,
		absoluteMaxRows: 10,
	});
16}
return { pageOfContacts, contactIndexKeys, emails };

```

You can now fetch subsequent pages of contacts, each with their first page of emails. Or you can fetch subsequent pages of emails for any contact. And this all works because you are tracking the cursors directly.

### Jump to a location and scroll up

Infinite scroll is a common interface, but sometimes you want to jump to a later page. If you’re scrolling through your contacts you may want to jump to those with last name starting with “S”. If you’re scrolling through your photos you may want to jump to those from your vacation last year.

Jumping to a location is easy — it’s even supported by built-in Convex pagination via

```tsx
await ctx.db.query("contacts")
	.withIndex("name", (q)=>q.gte("surname", "S"))
	.paginate(opts);

```

However, you’re now looking at pages of contacts starting with “S”, and you can’t “scroll up” to see those starting with “R”.

When scrolling up, your query becomes inverted, so it looks like this:

```tsx
await ctx.db.query("contacts")
	.withIndex("name", (q)=>q.lt("surname", "S"))
	.order("desc")
	.paginate(opts);

```

You can run this as a separate query, _or_ you can use a single `getPage` to go in either direction:

```tsx
const contacts = await getPage(ctx, {
	table: "contacts",
	index: "name",
	schema,
	startIndexKey: ["S"],
	startInclusive: !isScrollingUp,
	order: isScrollingUp ? "asc" : "desc",
8});

```

### Stitching the pages together

If you’re fetching multiple pages of data into a reactive client, like a React web page, you’ll want the data to update reactively.

Like any Convex query, pages fetched with `getPage` and `useQueries` will automatically re-render when the data updates. However, since pages are initially defined as “the first 100 items” and “the next 100 items after item X”, this can result in gaps or overlaps between pages. This problem is fully described [here](https://stack.convex.dev/fully-reactive-pagination).

The built-in `.paginate()` and `usePaginatedQuery` solve this problem automatically, but `getPage` does not. Instead, you need to replace the queries after they first load, so “the first 100 items” becomes “the items up to item X”, which then seamlessly joins up with “the next 100 items after item X”. This is the primary purpose of the `endIndexKey` field passed to `getPage`.

```tsx
// Fetch the first page like this:
const {
	indexKeys: indexKeys0,
4} = await getPage(ctx, {
	table: "contacts",
6});
// Fetch the second page like this:
const {
	page: page1,
	indexKeys: indexKeys1,
11} = await getPage(ctx, {
	table: "contacts",
	startIndexKey: indexKeys0[indexKeys0.length - 1],
14});
// Re-fetch the first page like this:
const { page: page0 } = await getPage(ctx, {
	table: "contacts",
	endIndexKey: indexKeys0[indexKeys0.length - 1],
19});

```

Suppose initially the 100th contact is John Smith. `page1` is defined as the 100 contacts after John Smith. Meanwhile `page0` is defined as all contacts up to John Smith, which might grow or shrink as the table changes.

This all sounds complicated to implement, which is why Convex’s built-in pagination handles it for you. This pattern of replacing page queries can also double your function calls and bandwidth usage, which the built-in pagination avoids.

### More flexible pagination

With `getPage`, you take control of your pagination. It’s your data, and your access patterns, so you are best equipped to write optimal queries and hooks for fetching pages.

- As you scroll down, you can unsubscribe from pages that are no longer visible.
- If you have subscribed to a page and it grows too large, `getPage` has returned all index keys, so you can use a middle index key to split the page into two.
- You can more flexibly filter out a page’s documents, or filter out fields, or join with another table to add fields.
- You can choose to either store all index keys, which would tell you if an item at an index position was already loaded, or you can encrypt index keys to hide page boundaries.

### Give me the code

Get started writing queries with `getPage` today, by installing [`convex-helpers`](https://www.npmjs.com/package/convex-helpers) and importing

```tsx
import { getPage } from "convex-helpers/server/pagination";

```

If you want a reference implementation for stitching pages together, jumping to a location, and scrolling up, [check out the code here](https://github.com/ldanilek/convex-contacts/blob/main/src/App.tsx#L54) for an example app featuring a list of contacts.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Using Pinecone and Embeddings

Looking to implement semantic search or add on-demand context to a GPT prompt so it doesn’t just make shit up (as much)? [Pinecone](https://www.pinecone.io/) and Convex are a good match when you’re looking to build an app that leverages [embeddings](https://stack.convex.dev/the-magic-of-embeddings) and also has user data. Pinecone stores and queries over vectors efficiently, and Convex stores relational & document data with strong transaction guarantees and nifty end-to-end data reactivity.

Let’s walk through how this shakes out in practice. If you want to see some code you can play around with, check out [this GitHub repo](https://github.com/ianmacartney/embeddings-in-convex/tree/pinecone) where you can add your own data and compare it and search over it using Convex and Pinecone.

## High-level user flow

To start, what’s an **example**? With Pinecone and Convex, you can have a flow like this:

1. A user submits a **question** and starts **subscribing** to the question’s results. Under the hood, Convex has stored the question in a **document** and kicked off an asynchronous **action**. If this question has been asked before, it might re-use previous results.
2. The **action** creates an **embedding** using a service like OpenAI or Cohere. It can persist this embedding for posterity or to be able to search for similar questions.
3. The action uses the embedding to **query** Pinecone (or any vector store) for **related documents**, **products**, or whatever your embeddings represent.
4. The action stores the **results** in the question **document**, which automatically reflows to update the user’s client with the new data - potentially returning materialized data pulled from other documents in the database associated with the results.
5. If this is part of a broader **chain** of operations, it might use the related documents to compose a **prompt** to an **LLM** like [ChatGPT](https://stack.convex.dev/full-stack-chatgpt-app), using both the related documents and the question to get a more **contextual answer**.

### A word on streaming updates

At every step, updates written to the Convex database will update **all** subscribed clients. Unlike raw HTTP streaming, Convex subscriptions can be trivially consumed by multiple clients in parallel and are resilient to network issues or page refreshes. The data received will be from a consistent snapshot of the database state, making it easier to reason about correctness.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

Many of the code snippets below can be found in [this GitHub repo](https://github.com/ianmacartney/embeddings-in-convex/tree/pinecone) which you’re welcome to play around with using your own data and API keys. If you are desperate for a hosted playground, let me know [in Discord](http://discord.gg/convex)!

## Adding data to Convex and Pinecone

Depending on the application, you may have a large mostly-static corpus of data, or be continually adding data — which I’ll refer to as a **source** below. The process looks something like the following:

### Break up your source into bite-sized chunks.

This helps limit how much data you pass (embedding models have context limits), as well as make the embedding more targeted. You could imagine an embedding of this whole post might not rank as highly against “How do you add data to Convex and Pinecone?” as an embedding that just covered this section.

To do this, you can split it yourself or use a library like LangChain’s `RecursiveCharacterTextSplitter`:

```tsx
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";

const textSplitter = new RecursiveCharacterTextSplitter({
  chunkSize: ChunkSize,
5});
const splitTexts = await textSplitter.createDocuments([pageContent]);
const chunks = splitTexts.map((chunk) => ({
  text: chunk.pageContent,
  lines: chunk.metadata.loc.lines,
10}));

```

You can tune the size and algorithm to your own needs. One tip is to add some overlap, so each chunk has some text from the previous and next sections.

### Store the source in the database

The Convex database is a great place to store all the metadata that your app will want. For embeddings based on text, you’ll likely even want to store the chunk of text in the database, so you can quickly access it to return as part of queries for a client or as part of a pipeline. For larger data, like video, it makes more sense to store the data in file storage.

Importantly, you should **not** store the text chunk directly in Pinecone metadata, as it can quickly fill up the index because **all metadata is indexed by default in Pinecone**.

```tsx
async function addSource(
  db: DatabaseWriter,
  name: string,
  chunks: { text: string; lines: { from: number; to: number } }[]
5) {
  const sourceId = await db.insert("sources", {
    name,
    chunkIds: [],
    saved: false,
  });
  const chunkIds = await Promise.all(
    chunks.map(({ text, lines }, chunkIndex) =>
      db.insert("chunks", {
        text,
        sourceId,
        chunkIndex,
        lines,
      })
    )
  );
  await db.patch(sourceId, { chunkIds });
  return (await db.get(sourceId))!;
23}

```

There are a few things to note here:

- I’m both saving a back-reference from chunks to sources, as well as a forward reference from a source to many chunks. As discussed in [this post on database relationships](https://stack.convex.dev/relationship-structures-let-s-talk-about-schemas), this is a way to get quick access in both directions without having to define an extra index when you have a small number of relations (8192 technically but <1k is my rule of thumb).
- I’m saving an empty array at first, then patching it with the chunk IDs once I insert them. Convex generates unique IDs on insertion. At this time you can’t pre-allocate or specify custom primary IDs for documents.
- I’m creating the source with `saved: false` \- we’ll update this once we’ve saved the embeddings into Pinecone. This allows the client to know the insertion status, as well as help with transient failures, which we’ll see later on.

### Kick off a background action

The Convex `mutation` function is transactional but as a result, we can’t perform a non-transactional operation like talking to a third-party service in the middle of a mutation. A Convex `action` is non-transactional and can talk to the outside world. One trick I like to use is to schedule an action to execute after a mutation commits, ensuring that the communication with the outside world only happens if the mutation has successfully run.

Mutations in Convex are transactions and are prohibited from having non-transactional side effects like calling other cloud services. With actions you can make these sorts of calls, but how do you “call” an action from a mutation if the mutation can’t have side effects? A pattern I really like is to schedule the action from the mutation:

```tsx
await ctx.scheduler.runAfter(0, internal.sources.addEmbedding, {
  source,
  texts: chunks.map(({ text }) => text),
4});

```

Thanks to Convex’s strong transaction guarantees, the action is only invoked if the mutation successfully commits, so you’ll never have an action running for a source that doesn’t exist.

### Create an embedding

From our [action](https://docs.convex.dev/functions/actions), we can fetch embeddings. See [this post](https://stack.convex.dev/the-magic-of-embeddings) for more information on what embeddings are. See the [code for fetchEmbeddingBatch here](https://github.com/ianmacartney/embeddings-in-convex/blob/pinecone/convex/lib/embeddings.ts).

```tsx
const { embeddings } = await fetchEmbeddingBatch(texts);

```

### Upsert into Pinecone

Adding data into Pinecone is a straightforward operation. “Upsert” for those unfamiliar is an update if the specified `id` already exists, otherwise it inserts.

```tsx
await upsertVectors(
  "chunks", // namespace
  source.chunkIds.map((id, chunkIndex) => ({
    id,
    values: embeddings[chunkIndex],
    metadata: { sourceId: source._id, textLen: texts[chunkIndex].length },
  }))
8);

```

**Tips:**

- We aren’t including much metadata here - in general, you should **only store metadata** that you might want to use **to limit Pinecone queries** \- such as keywords, categories, or in this case text length[1](https://stack.convex.dev/pinecone-and-embeddings#user-content-fn-1).
- We’re **re-using the Convex document ID** for the pinecone vector. This isn’t required—you could make up your own ID and store that in the Convex document—but I find it very handy. Results of Pinecone queries, without returning metadata, can be used directly with `db.get` which is wicked fast. It also means you can fetch or delete the Pinecone vector for a given chunk, without storing an extra ID.
- I used the table name as the Pinecone namespace for convenience, so queries for chunks wouldn’t return vectors for other data. This isn’t required but helped me with organization and naming fatigue.

Tip: Use the `@pinecone-database/pinecone` Pinecone client for the best experience in Convex.

There are two action runtimes in Convex: our optimized runtime, and a generic node environment. When possible I prefer using the optimized runtime, so I can keep the actions in the same file as the queries and mutations, along with some performance benefits. However, our runtime doesn’t support all npm libraries. Thankfully the pinecone package doesn’t depend on any incompatible packages and just uses the `fetch` standard under the hood. This is also why I prefer using `fetch` and the OpenAI HTTP API directly above. See [here](https://docs.convex.dev/functions/runtimes) for more information on runtimes.

### Mark the source as “saved”

All we need to do to notify the frontend that the data has been saved is to update the source. Any queries that reference the source document will be updated with the latest data automatically.

```tsx
await ctx.runMutation(internal.sources.patch, {
  id: source._id,
  patch: { saved: true, totalTokens, embeddingMs },
4});

```

At this point, our data is in Convex and an embedding vector is saved in Pinecone.

### Extensions

Beyond saving chunks of the source, you might also consider:

- Adding an embedding of a summary of the whole source.
- Add a hierarchy of searches - where you could separately search for a category of documents and then provide that category as a [metadata filter](https://docs.pinecone.io/docs/metadata-filtering) in a later query.
- Namespacing or otherwise segmenting user data so you never accidentally leak context between users.

## Searching for sources

Similarly to inserting data, to do a semantic search over your documents, you can:

1. **Insert the search into a table of searches.** If there’s already an identical search, you could even decide to re-use those results. This is handy for iterating on large pipelines and keeping latency and costs low.





```tsx
const searchId = await ctx.db.insert("searches", { input, count });

```

2. **Kick off an action** transactionally.





```tsx
await ctx.scheduler.runAfter(0, internal.searches.search, {
  input,
  searchId,
  topK: count,
5});

```

3. **Create an embedding** of the search. Aside: I have a hunch there’s a lot of opportunity here for ways of transforming the raw search into a better text input for the embedding.





```tsx
const { embedding } = await fetchEmbedding(input);

```

4. **Use the pinecone query** to find nearby vectors representing chunks.





```tsx
const { matches } = await pinecone.query({
  queryRequest: {
    namespace: "chunks",
    topK,
    vector: embedding,
  },
7});

```

5. **Update the search results** by running a mutation.





```tsx
await ctx.runMutation(internal.searches.patch, {
        id: searchId,
        patch: {
          relatedChunks,
        },
      });

```

6. Optional: **store the search embedding in Pinecone** if you want to be able to search semantically over searches themselves!


Note: you could just do steps 2-4 directly in an action if you don’t care about keeping a cache and storing the search vector.

### Returning results to the client

The client can subscribe to the search document’s ID:

```tsx
const results = useQuery(api.searches.semanticSearch, { searchId });

```

The query looks for the search and returns the related chunks along with their source’s name:

```tsx
export const semanticSearch = query({
  args: { searchId: v.id("searches") },
  handler: async (ctx, { searchId }) => {
    const search = await ctx.db.get(searchId);
    if (!search) throw new Error("Unknown search " + searchId);
    if (!search.relatedChunks) return null;
    return pruneNull(
      await Promise.all(
        search.relatedChunks.map(async ({ id, score }) => {
          const chunk = await ctx.db.get(id);
          if (!chunk) return null;
          const source = await ctx.db.get(chunk.sourceId);
          return { ...chunk, score, sourceName: source!.name };
        })
      )
    );
  },
18});

```

This is parallelized by using `Promise.all` and calls to `db.get` are cached.

## Summary

In this post, we looked at using Pinecone and Embeddings in Convex. One natural extension of this is to then use the sources as part of a GPT prompt template, but I’ll leave that for a future post. Let us know [in discord](https://convex.dev/community) what you think and what you’d like to see next!

### Footnotes

1. At the Pinecone hackathon, there was a discussion of issues of semantic rankings sometimes behaving oddly - in my case, when I searched over a corpus of famous poems for “what is the meaning of life?” one of the top hits was a “hello world” dummy text I had added. One participant mentioned that a useful filter—after listing a plethora of sophisticated ranking strategies—was to just exclude text less than 200 characters. Intuitively this makes some sense - the longer something is, as short phrases probably have higher semantic variance. [↩](https://stack.convex.dev/pinecone-and-embeddings#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Implementing Presence with Convex

In this post, I will share some patterns for incorporating presence into a web app. I will be leveraging some features of Convex which makes it easy to implement, and sharing [some utilities I built along the way](https://github.com/get-convex/convex-presence/) that you’re welcome to use & extend. Check out the code in action in the [convex-demos](https://github.com/get-convex/convex-demos) repo.

## What is presence and why is it important?

Presence, as we’ll use the term here, is about surfacing activity in a UI about other users - surfacing their virtual presence. Some examples you’ve likely seen are the list of people “online” in Messenger, the “…” bubble in Messages when someone is composing a message to you, someone’s cursor in a Google Doc, etc.

The value is a mix of utility and user experience. In a shared document, knowing where someone is typing can help you avoid typing over each other. The more subtle effects, however, tap into our social instincts. Seeing that other people are looking at the same document, seeing active engagement, and gives a sense of aliveness. I personally feel more connected to collaborators than something like a Wiki. In a world where work is increasingly being done in private, I’ll take all the presence I can get.

## Presence in action

![Screenshot](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F1e4087361b56b4154b2cca3c3627cfe61a6bc431-874x430.png&w=3840&q=75)Screenshot

### Presence data

Presence data sits in a middle ground between application state and session state. Application data needs to be carefully updated and stored, and is typically read more than it’s written. Presence data is less critical - it’s ok if you skip a few cursor movements, as long as the UI arrives at the correct end state. However, we still care about durability. Session state is ephemeral and can be held in memory & quickly discarded. Some presence state is like this - where your cursor is, whether you’re typing, etc. However, to know when someone last edited a document, or when a user was last online, you need to store longer-term data.

### Presence performance

Presence data is a great candidate for [single-flighting](https://stack.convex.dev/throttling-requests-by-single-flighting) because we care about latency and we want graceful degradation when many users are online at once. It isn’t critical to get every cursor position, but it should show the final cursor position as quickly as possible. Higher throughput can get a higher frame rate, but if we were to decide between getting more data points with more lag or fewer data points more frequently, we’d choose the latter. We aren’t building a 60fps game, we are just conveying basic information. See [the post on single-flighting](https://stack.convex.dev/throttling-requests-by-single-flighting) to see more about how it enables dynamic back-pressure under load.

### `usePresence`

To make it easy to implement presence features, [I wrote a utility](https://github.com/get-convex/convex-presence/blob/main/hooks/usePresence.ts) that saves presence data in a new `presence` table, segmented by “room” and “user”. A room could be a web page, document, chat room, etc. In my example, a user was identified just by a string randomly generated on the client, but you could use authentication data server-side to ensure a user can only modify their own presence data & read presence data in rooms they’re allowed in.

By default, the utility gives you a `useState`-like API but also includes a list of the state for other users in the same room.

```tsx
const [myPresence, othersPresence, updateMyPresence] = usePresence(
  userId,
  roomId,
  initialData
5);

```

The main difference is that `updateMyPresence` accepts partial data updates, so you can update your avatar in one component, and set whether you’re typing in another, and the resulting data will be the latest values of each. This is important because it allows us to skip some updates via single-flighting. We know the next update to be sent will have the latest values.

### Online detection

![Screenshot](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fe888805e48b052cca9e2d7c281c4135d99e09765-362x102.png&w=3840&q=75)Screenshot

A common way to detect a user’s presence is to periodically send a “heartbeat” message to the server that the client is still there. By checking when a user last updated their presence, you can tell if they’ve gone offline. The more frequently you send it, the faster you can detect that a user is no longer online, but the more resources your app will consume.

The [`usePresence`](https://github.com/get-convex/convex-presence/blob/main/hooks/usePresence.ts) React hook defaults to 5 seconds, and the [demo app](https://github.com/get-convex/convex-presence/blob/main/pages/index.tsx) considers a user to not be online after 10 seconds.

```tsx
const online = othersPresence.filter(
    (presence) => Date.now() - presence.updated < 10000
  );

```

If you’re building your own presence utility, remember you can avoid sending heartbeats when you send other messages, as I do [here](https://github.com/get-convex/convex-presence/blob/main/hooks/usePresence.ts):

```tsx
useEffect(() => {
    void updatePresence({ room, user, data });
    const intervalId = setInterval(() => {
      void heartbeat({ room, user });
    }, heartbeatPeriod);
    return () => clearInterval(intervalId);
  }, [updatePresence, heartbeat, room, user, data, heartbeatPeriod]);

```

### Facepiles

![Screenshot of the facepile UI](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Ff2a56c99f00090b2d4a896fcac4c03281613a5fe-572x220.png&w=3840&q=75)Screenshot of the facepile UI

A “facepile” is a popular term for the visual stack of users in a document - whether they’re profile pictures, initials, avatars, or in the case of my demo app, emojis. See my facepile logic [here](https://github.com/get-convex/convex-presence/blob/main/components/Facepile.tsx) or play around with a demo [here](https://github.com/get-convex/convex-demos/tree/main/presence-facepile). Some things to keep in mind when building them:

- You can use the latest heartbeat to segment users into online & offline groups.
- If you sort by the latest update, your pile will jump around as users send their heartbeats. I chose to sort by online/offline, then by their “created” time - when they first were present in that given room. This way it would be stable and active & newer users would show up on top.
- By default React will only re-render when something changes, so if you want to keep re-computing whether a user is online or offline, you can do something like I do [here](https://github.com/get-convex/convex-presence/blob/main/components/Facepile.tsx) and use a `setInterval` to re-compute the list every second. Note that this does not make new network requests, it just re-computes the UI based on the existing data, so you only consume browser resources, not network bandwidth or server compute time.

### Typing indicator

![Screenshot showing a typing indicator](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fa1d3e9fffa30209ab3e6e9b82234965fabbf4bcd-960x459.gif&w=3840&q=75)Screenshot showing a typing indicator

To make a typing indicator super snappy, you can update presence data to `{typing: true}` when you start typing and explicitly set it back soon after you stop typing. To achieve this, you can use a debounce function from something like `lodash`, or just use a `useEffect` and `setTimeout` as I do [here](https://github.com/get-convex/convex-presence/blob/main/hooks/useTypingIndicator.ts). However, if a user gets disconnected before they can update their presence, they might be stuck in a `typing: true` state, so make sure to take their latest update time into account and exclude offline users.

```tsx
useEffect(() => {
    if (text.length === 0) {
      updateMyPresence({ typing: false });
      return;
    }
    updateMyPresence({ typing: true });
    const timer = setTimeout(() => updateMyPresence({ typing: false }), 1000);
    return () => clearTimeout(timer);
  }, [updateMyPresence, text]);

```

See a working example [here](https://github.com/get-convex/convex-demos/tree/main/presence-typing-indicator)

### Cursors

![Screenshot](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F11b6246507267f73121e998aea876fdb2ecc4982-960x459.gif&w=3840&q=75)Screenshot

Text cursors are an important part of collaborative text editing, where the important piece to get right is how to index your position, given that a pure character offset may be out of sync with the edits you and others are making. You might even embed cursor locations into the data stream of document edits, or pin cursor locations to edits, so new text is always appearing by your cursor on other users’ documents. This is a complex topic worth a post all on its own, so I’ll leave it at that for now.

For mouse cursors, the challenge is giving the illusion of continuous motion when you’re receiving discrete events. Naive implementations will seem very choppy, with the cursor jumping to the latest location immediately. Intermediate implementations will slide around smoothly, though the cursor will always be a little behind. In [my demo](https://spectacular-beijinho-ccf8ab.netlify.app/), I just use a 200ms transition in CSS, which is simple, but still looks a bit jumpy and lags by an extra 200ms (code [here](https://github.com/get-convex/convex-presence/blob/main/components/SharedCursors.tsx)). Advanced implementations may not only smooth between historical points (using bezier or other smoothing algorithms) but also try to anticipate where the cursor is moving.

Sharing mouse cursor positions are the point at which I’d recommend using a dedicated in-memory service, rather than trying to persist that data to a database, since the data is especially ephemeral.

## How Convex makes it easy

Convex helped make this much easier through its built-in WebSocket reactivity and caching scalability.

### Reactivity

Convex’s data model is [reactive by default](https://docs.convex.dev/understanding/convex-fundamentals/functions#caching) \- when you query data, you are automatically subscribed to changes to that data. Because it owns the data retrieval as well as the data mutation, it can intelligently invalidate caches& recompute queries automatically. In this case, querying for data in a given “room” in the presence table meant that every change to presence data in that room resulted in the new data being computed and sent down to clients. Without Convex you’d be either polling or managing a bespoke Pub-Sub / WebSocket system.

### Caching

Another nice feature of Convex queries is its [caching](https://docs.convex.dev/understanding/convex-fundamentals/functions#caching), and cache invalidation. Its cache primarily uses the function arguments as the key, so our query for all the presence data in a given room will be recomputed once per room, rather than once per user. This means that as the number of users in a room (& their associated mutations) grows, the number of function invocations grows linearly, instead of quadratically, which is a big deal, even for dozens of users.

## Next Steps

Some things that aren’t implemented in [the demo](https://github.com/get-convex/convex-presence), but would be natural extensions, would be:

- Implementing access control so you can’t read or write presence data in rooms you’re not part of.
- Adding a way to clear presence data for a room. Currently, the library merges patch data.
- Check whether the data has changed before sending an update. Currently, all calls to `updateMyPresence` will attempt to update the server.
- Add a parameter to `usePresence` for whether to do heartbeat, since not all applications need to know that a user is still “online”.

Let us know in [our discord](https://convex.dev/community) what you think, and if you implement any of these! PRs welcome: [GitHub](https://github.com/get-convex/convex-presence). ❤️

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Queries that scale

As your app grows from tens to hundreds to thousands of users, there are some techniques that will keep your database queries snappy and efficient. I’ve put together a short list of the most common techniques used by teams scaling on Convex In this post we’ll look at some common query pitfalls, and techniques to handle them.

**Common optimization opportunities we’ll explore in depth:**

1. Scanning more than you need. [Optimization: indexing](https://stack.convex.dev/queries-that-scale#1-fetching-exactly-what-you-need-with-indexes).
2. Doing too much at once. [Optimization: pagination](https://stack.convex.dev/queries-that-scale#2-splitting-up-the-work-with-pagination-and-limits).
3. Frequent cache invalidation. [Optimization: data segmentation](https://stack.convex.dev/queries-that-scale#3-optimizing-queries-for-caching).

Before I start, there are some other great resources to check out:

- [Queries](https://docs.convex.dev/functions/query-functions)
- [Introduction to Indexes and Query Performance](https://docs.convex.dev/database/indexes/indexes-and-query-perf)
- [Best Practices](https://docs.convex.dev/production/best-practices)
- [The Zen of Convex](https://docs.convex.dev/zen)
- [Document read limits](https://docs.convex.dev/functions/error-handling/#readwrite-limit-errors)
- [Paginated Queries](https://docs.convex.dev/database/pagination)

Note: while this post is about optimizing a Convex app, the concepts are universal.

## Reminder: don’t prematurely optimize

> “Premature optimization is the root of all evil” - Sir Tony Hoare / Donald Knuth

When you’re in the early stages of a project, iteration speed is crucial. Most projects fail, and frequently this is from iterating too slowly. Nascent projects feed on momentum and feedback. Spending your precious time architecting for your millionth user before you have your first is a great way to stall out a weekend project, or delay a product launch by months. **Until you have accelerating user adoption, it doesn’t matter how beautiful your architecture is.**

Especially if you use a hosted solution like Convex, you’ve already eliminated a whole class of scaling problems:

- How is traffic load-balanced between backends?
- How do I avoid holding open too many database connections?
- How many WebSocket connections can I handle?
- Does my infrastructure have capacity for a spike in traffic if my app lands on Hacker News?
- How big should my database be, and how do I recover if it goes down?

**If you have fewer than thousands of documents in your tables, you can stop reading.**

## 1: Fetching exactly what you need with indexes

These two queries look similar, but have very different efficiencies:

```tsx
// SIMPLE: Scans every document looking for a matching team.
const members = await ctx.db.query("members")
  .filter(q => q.eq(q.field("teamId"), args.teamId)).collect();

// OPTIMIZED: Jumps to the range of documents where the teamId matches.
const members = await ctx.db.query("members")
  .withIndex("by_teamId", q => q.eq("teamId", args.teamId)).collect();

```

### Problem

When you are querying a table in any database and you provide a filter—whether it’s a `WHERE` clause in SQL or [`.filter`](https://docs.convex.dev/database/reading-data#filtering) in Convex—the database uses those constraints to limit what it returns to you. But how does it find the records? In `SQL` it will sometimes use an [index](https://docs.convex.dev/database/indexes/), and other times “scan” every document. An index has all of the documents sorted by one or more columns and can quickly jump to the range of documents to consider. A scan iterates records one by one over your whole table, which can slow down requests, grind your database to a halt, cause memory issues, and more if your table is large. Many of the outages I’ve seen at companies with millions of customers were the result of a query doing a scan instead of an index.

Even a trained eye sometimes can’t determine whether a `SQL` query will use an efficient index, so Convex [intentionally doesn’t provide an unpredictable query planner](https://stack.convex.dev/not-sql#sql-sucks-3-reads-are-too-powerful), and instead offers an explicit syntax that makes it clear what index is being used (if any).

To avoid unpredictable latency and excessive database load, Convex [limits how many documents you can read in a transaction](https://docs.convex.dev/production/state/limits#transactions).

### Solution

As shown above, a query like this is more efficient to get team members on a team:

```tsx
const members = await ctx.db.query("members")
  .withIndex("by_teamId", q => q.eq("teamId", args.teamId))
  .collect();

```

Given a schema like this:

```tsx
// in convex/schema.ts
export default defineSchema({
  members: defineTable({
    teamId: v.id("teams"),
    status: v.union(v.literal("invited"), v.literal("active")),
    // ...
  })
    .index("by_teamId", ["teamId"]),

  teams: defineTable({
    //...
  })
13});

```

**Note:** You can still do further filtering on that range, such as:

```tsx
const activeMembers = await ctx.db.query("members")
  .withIndex("by_teamId", q => q.eq("teamId", args.teamId))
  .filter(q => q.eq(q.field("status"), "active"))
  .collect();

```

However, if the number of non-active members is also expected to be a big number, you should consider making a multi-field index like:

```tsx
  members: defineTable({
    teamId: v.id("teams"),
    status: v.union(v.literal("invited"), v.literal("active")),
    // ...
  })
    .index("by_teamId_status", ["teamId", "status"]),

```

Used like:

```tsx
const members = await ctx.db.query("members")
  .withIndex("by_teamId_status", q => q.eq("teamId", args.teamId).eq("status", "active"))
  .collect();

```

Read in the [section below](https://stack.convex.dev/queries-that-scale#2-splitting-up-the-work-with-pagination-and-limits) about what to do if there are still too many documents being returned.

### Why are indexes more efficient?

Think about an index as an array of documents sorted by a field, and for documents with the same value for that field, sorted by the next field in the index and so on. An index can use binary search to find the start of the range (whether it’s looking for equality or greater / lesser than), which it then can iterate until it hits a document past its range, or it has enough documents in the case of `.first()`, `.unique()` or `.take()`. A `db.get(id)` under the hood is doing this, where the index is on the object’s ID.

Read this article for a more in-depth explanation: [Introduction to Indexes and Query Performance](https://docs.convex.dev/database/indexes/indexes-and-query-perf).

### Codebase audit: search for `.filter((q)`

Look at every call site where you’re filtering database results. Is the table always small? Are you using an index to limit to a small range first? In particular, search for `q.eq(q.field(` as you can likely replace that with an index on that field.

### How much indexing is too much?

Indexes are great for efficiently reducing how many documents you read. However, they aren’t free. Inserting a document involves adding it to every index that you specify. Inserting a document with 16 indexes is comparable to inserting 17 documents. What you might find surprising, however, is that a multi-field index doesn’t incur this overhead. So sharing a multi-field index should be done whenever possible. See [Introduction to Indexes and Query Performance](https://docs.convex.dev/database/indexes/indexes-and-query-perf) to learn more.

## 2: Splitting up the work with pagination and limits

```tsx
// SIMPLE: Reads every document at once.
return await ctx.db.query("posts").order("desc").collect();

// SAFER: Limits how many documents are read ("50+ posts")
return await ctx.db.query("posts").order("desc").take(50);

// OPTIMIZED: Returns one page of documents at a time.
return await ctx.db.query("posts").order("desc").paginate(args.paginationOpts);

```

### Problem

If you try to return all posts for some social app you’re building, that will work fine while you’re testing and only have hundreds of posts. However, as your app (hopefully) gets thousands of posts, this will slow down and eventually break. As mentioned above, to avoid unpredictable latency and excessive database load, Convex [limits how many documents you can read in a transaction](https://docs.convex.dev/production/state/limits#transactions). This helps save your backend from being overloaded by long-running queries.

### Solution

When you expect a large number of documents, you can limit how many you fetch, either by limiting your fetch (with `take`) or paginating ( `paginate`) from some “cursor.” A “cursor” here is a key for the database pointing where in the index to continue from. A `null` cursor will start at the beginning. See [the docs](https://docs.convex.dev/database/pagination) for more info, and learn more about how our pagination seamlessly handles reactivity [in this Stack post](https://stack.convex.dev/fully-reactive-pagination).

[**`.paginate`**](https://docs.convex.dev/api/interfaces/server.OrderedQuery#paginate) returns a chunk of documents, starting at some “cursor.”

- **Use case:** You want to show a subset of data quickly, but allow the UI to load more on-demand (whether automatically as the user scrolls, or by them clicking a “load more” button).

[**`.take`**](https://docs.convex.dev/api/interfaces/server.OrderedQuery#take) limits the number of documents it will return.

- **Use case:** If you’re showing something like “documents” in a UI with a “See all” button, you could just fetch and display the first 25, and say “25+ messages”. To implement the “See all” UI, use pagination.

While pagination is great, I’d argue that a lot of your UI doesn’t need to handle the fully paginated version. Simply showing the most recent 100 (using `.order("desc")`) usually suffices, especially when paired with limits.

### Codebase audit: `.collect()`

Validate that any query I’m calling `.collect()` on is either known to be small, or is using an index to reduce how many documents are being fetched. If it isn’t, consider whether `take` is fine or if you need to handle pagination for this UI.

### Do I have to paginate everything?

One option to call out is that your app can enforce limits at insert time. For instance, you could say that your user can only be associated with up to 100 teams, or that you can only have 10 associated email addresses, or that you can’t have more than 100 items in a single checkout cart. By enforcing constraints there, you don’t have to worry about building a fully-generic pagination UI in every part of your app.

## 3: Optimizing queries for caching

This section is the most nuanced. Read on for more details if this snippet doesn’t make sense.

```tsx
// SIMPLE: invalidates every query referencing the patched user document.
// When the user reports a heartbeat, update the user document.
await ctx.db.patch(userId, { lastSeen: Date.now() });

// OPTIMIZED: invalidates a "heartbeat" document referenced in fewer queries.
// When the user reports a heartbeat, update their related heartbeat document.
await ctx.db.patch(user.heartbeatId, { lastSeen: Date.now() });
// In any query that cares about online status:
const heartbeat = await ctx.db.get(user.heartbeatId);
const tooOld = Date.now() - HEARTBEAT_TOO_OLD;
const online = heartbeat ? tooOld < heartbeat.lastSeen : false;

// WEBSCALE™️: only invalidates the document when it meaningfully changes
// When the user reports a heartbeat, update the related heartbeat and presence documents:
await ctx.db.patch(user.heartbeatId, { lastSeen: Date.now() });
if (!presence.isOnline) await ctx.db.patch(presence._id, { online: true });
// In some cron, update all online users' status:
if (heartbeat.lastSeen < tooOld) await ctx.db.patch(user.presenceId, { isOnline: false });
// In any query that cares about online status:
const online = (await ctx.db.get(user.presenceId))?.isOnline ?? false;

```

### Problem

Convex manages caching for you, along with invalidating the cache and updating your UI whenever you have a subscription, such as using the `useQuery` React hook. This is amazing and powerful, but can sometimes be resources-intensive if the data is updating more often than is useful to the user.

For context, it’s important to understand how Convex queries work. Here’s some docs on [queries,](https://docs.convex.dev/functions/query-functions#caching--reactivity) [realtime](https://docs.convex.dev/realtime) and a [relevant page of the tutorial](https://docs.convex.dev/tutorial/reactor). The gist is that when you’re subscribed to a query from a client, the results automatically update on any change to the documents referenced in the query. This is achieved by tracking all of the documents a query reads from the database, and re-running the query when any of them change.

This can be wasteful if your query reads from frequently-updating documents, as it will be invalidated frequently.

### Solution

We’ll look at solving this through an example and show how to structure your queries to only get invalidated when there’s a meaningful user-facing change. We’ll show breaking out frequently changing data into separate documents, and then a further optimization of batching updates from frequently-changing data.

#### Heartbeat Example

Consider a query that fetches the most recent 10 users who have opened a shared document (think: [Notion](https://www.youtube.com/watch?v=0OaDyjB9Ib8)) and we want to show which users are online. We know whether a user is online with a “heartbeat” - a mutation sent on some interval that tells the server that the client is still connected. There are some clever client-side tricks to this that I’ll explore in a future post, but in this post let’s say that we send a mutation every 10 seconds updating the “last seen” time.

```tsx
// in convex/schema.ts
export default defineSchema({
  users: {
    name: v.string(),
		profilePicUrl: v.string(),
    lastSeen: v.number(),
  }
8});

// in convex/heartbeat.ts
export const heartbeat = mutation({
  args: {},
  handlers: async (ctx) => {
    const user = await getUserOrThrow(ctx);
    await ctx.db.patch(user._id, { lastSeen: Date.now() });
  },
17});

```

#### Part 1: Isolating frequent updates into separate documents

As you can imagine, many queries in your app won’t care about whether the user is online, but will reference (query) at least one of the users. Every 10 seconds the query would be invalidated, since the `lastSeen` field changed for the queried user, regardless of whether the query uses information about the user’s online status. For instance, let's say you had a query that returned the user's name and profile picture:

```ts
export const myUserProfile = query({
  args: {},
  handler: async (ctx, args) => {
    const user = await getUserOrThrow(ctx);
    const { name, profilePicUrl } = user;
    return { name, profilePicUrl };
  },
8});

```

This query doesn't need to know when the `lastSeen` time is, but would be invalidated on every `lastSeen` update. To optimize this, we can avoid frequently updating documents that are widely referenced in queries. Instead of storing `lastSeen` on the user document, we can have a separate table tracking the user’s last seen state, which I call `heartbeats` here:

```tsx
// in convex/schema.ts
export default defineSchema({
  users: defineTable({
    name: v.string(),
		profilePicUrl: v.string(),
    heartbeatId: v.id("heartbeats"),
  }),
  heartbeats: defineTable({
    lastSeen: v.number(),
  })
11});

// in convex/heartbeat.ts
export const updateHeartbeat = mutation({
  args: {},
  handlers: async (ctx) => {
    const user = await getUserOrThrow(ctx);
    await ctx.db.patch(user.heartbeatId, { lastSeen: Date.now() });
  },
20});

```

This way, queries that don’t explicitly fetch the user’s heartbeat document won’t be invalidated when that document is updated. The `heartbeatId` will stay the same. The queries that care about the heartbeat status can fetch that data for the users it cares about, making it depend (and therefore get cached and invalidated by) relevant data.

#### Part 2: Batching updates from frequently-changing data

Let’s say our query for the most recent users uses the `lastSeen` time to determine who is online. If our page has ten users each sending a heartbeat every ten seconds, it will be updating once per second. If we had 100 users, it would be invalidated every 0.1 seconds just to know who is online, even if nobody has left / arrived!

```tsx
// SIMPLE: invalidated on every heartbeat
export const getOnlineStatus = query({
  args: { userIds: v.array(v.id("users")) },
  handler: async (ctx, args) => {
    const tooOld = Date.now() - HEARTBEAT_TOO_OLD;
    return await Promise.all(args.userIds.map( async (userId) => {
      const user = await ctx.db.get(userId);
      const heartbeat = user && await ctx.db.get(user.heartbeatId);
      return !!heartbeat && heartbeat.lastSeen > tooOld;
    }));
  },
12});

```

Instead, for this use-case, we only care when a user’s “online” status changes. It’s nice to immediately see when a user goes online, but we can wait and calculate if they’ve gone offline all at once every 10 seconds. We do this by both isolating the frequently updating data from the query, and calculating the online status asynchronously in batch.

```tsx
// in convex/schema.ts
export default defineSchema({
  users: defineTable({
    name: v.string(),
		profilePicUrl: v.string(),
    presenceId: v.id("presence"),
  }),
  // Stores coarse-grained information about whether a user is online.
  presence: defineTable({
    isOnline: v.boolean(),
    heartbeatId: v.id("heartbeats"),
  }).index("by_isOnline", ["isOnline"]),
  // Stores the frequently-updated data about the last heartbeat.
  heartbeats: defineTable({
    lastSeen: v.number(),
  })
17});

```

The online status now just queries the presence documents, not the heartbeat documents.

```tsx
// OPTIMIZED: only is invalidated with the presence document changes
// (when someone changes between online and offline)
export const getOnlineStatus = query({
  args: { userIds: v.array(v.id("users")) },
  handler: async (ctx, args) => {
    return await Promise.all(args.userIds.map( async (userId) => {
      const user = await ctx.db.get(userId);
      const presence = user && await ctx.db.get(user.presenceId);
      return presence?.isOnline ?? false;
    }));
  },
12});

```

To update a user as online, we can immediately update a previously-offline user when they report a heartbeat, while also updating the heartbeat document as before:

```tsx
// in convex/heartbeat.ts
export const updateHeartbeat = mutation({
  args: {},
  handlers: async (ctx) => {
    const user = await getUserOrThrow(ctx);
    const presence = (await ctx.db.get(user.presenceId))!;
    // If the user just came online, immediately update their status.
    // This will invalidate the `getOnlineStatus` so the UI can immediately update.
    if (!presence.isOnline) await ctx.db.patch(presence._id, { online: true });
    const heartbeat = (await ctx.db.get(presence.heartbeatId))!;
    await ctx.db.patch(heartbeat._id, { lastSeen: Date.now() });
  },
13});

```

To mark the user as offline, we do so often in batches from a cron every 10 seconds\[1\]:

```tsx
// See https://docs.convex.dev/scheduling/cron-jobs to learn more about crons

// in convex/crons.ts
crons.interval("mark users as offline", { seconds: 10 }, internal.crons.markOffline);

export const markOffline = internalMutation({
  args: { cursor: v.optional(v.string()) },
  handler: async (ctx, args) {
    // Fetch one batch. If a cursor was passed in, continue from there.
    const batch = await ctx.db.query("presence")
      // Only fetch online users, since only they need to be checked.
      .withIndex("by_isOnline", q => q.eq("isOnline", true))
      .paginate({
        cursor: args.cursor ?? null, // null is the cursor for the first batch.
        numItems: 100,
      });

    const tooOld = Date.now() - HEARTBEAT_TOO_OLD;
    // Update all presence status in parallel based on the last seen time.
    await Promise.all(batch.page.map(async (presence) => {
      const heartbeat = (await ctx.db.get(presence.heartbeatId))!;
      if (heartbeat.lastSeen < tooOld) {
        await ctx.db.patch(presence._id, { isOnline: false });
      }
    }));
    // If there is still more data to process, we schedule ourselves for the next batch.
    if (!batch.isDone) {
      await ctx.scheduler.runAfter(0, internal.crons.markOffline,
        { cursor: batch.continueCursor });
    }
  },
32});

```

### Codebase audit: `.replace(` and `.patch(`

Scan where you’re replacing and patching data. Are you updating certain documents frequently? If so, what queries are depending on these documents? If the documents are referenced in a lot of queries that don’t care about the field(s) you’re updating, consider splitting the document up into the infrequently-changing fields and the frequently updated ones, and adjusting your queries to only fetch the subset it needs.

## Summary

Convex is built to scale, and by leveraging these patterns as your user base grows, you can improve performance and throughput in your database. To echo earlier advice, be wary of premature optimization. You don’t need to worry about this until your app scales.

Hungry for more?

- If you’re interested in learning more about an ORM-style abstraction that uses indexes efficiently for you, check out [**Convex Ents: Manage your document relationships**](https://stack.convex.dev/ents).
- To learn more about structuring data in a database, check out **[Relationship Structures: Let's Talk About Schemas](https://stack.convex.dev/relationship-structures-let-s-talk-about-schemas)**.

As always, come chat with us [in Discord](https://convex.dev/community) about the article, or anything about Convex.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Application-Layer Rate Limiting

Rate limiting is an important part of building a reliable system that prevents users from adversely affecting each others' traffic. It also helps prevent abuse and costly bills, which is especially important for LLM workloads and other costly, resource-intensive patterns. Especially for apps that have a freemium model or any use that isn’t correlated with revenue, a single user shouldn't be able to fire off thousands of costly requests.

There’s a host of advice and services that can help you solve this problem for different applications, but I’d like to show you how simple it can be to implement when you have fast access to a database with strong ACID guarantees[1](https://stack.convex.dev/rate-limiting#user-content-fn-1).

Specifically, in this post I’m going to look at implementing the following, storing just two numbers per rate limit.

- **Token bucket:** Enable limiting the overall request rate for a sliding window, while also accommodating bounded bursts of traffic after a period of inactivity. For example, the number of requests should be limited to X per hour plus up to Y more “rollover minutes” from previous hours. Tokens become available continuously over time. **This is what I recommend for most use-cases.**
- **Fixed window:** For example, in each hour there can be no more than X requests to some third-party service, to avoid hitting their rate limits. When the hour is up, all tokens are available again. We’ll also discuss using “jitter” to avoid [thundering herds](https://en.wikipedia.org/wiki/Thundering_herd_problem).

For those who just want to use something off-the-shelf, I made a [`rate-limiter` Convex Component](https://www.convex.dev/components/rate-limiter) you should use. Some examples [below](https://stack.convex.dev/rate-limiting#using-rate-limits-for-common-operations) will be using its syntax.

For the sake of this article, when I refer to “tokens” it is using the mental model of rate limiting where you are granted a certain number of tokens per some time period, and when a request successfully “consumes” them it can proceed. I’ll say a “debt” or “deficit” when tokens are over-consumed, as we’ll see later in exploring reservations.

## What is application-layer rate limiting

In this article, we are going to talk about application-layer rate limiting. Specifically, the controls you have available when you are aware of a user and the operation they are trying to perform, rather than the networking layer, which is the responsibility domain of the hosting platform provider. To prevent a request from being made in the first place, you can also look into client-side throttling, such as [single-flighting](https://stack.convex.dev/throttling-requests-by-single-flighting) requests.

In practice, application layer rate limiting is the most useful and only falls down during extreme load, such as a distributed denial of service attack (DDOS) which thankfully are extremely rare. More commonly there is a small number of users, whether malicious or other otherwise, who are consuming more resources than you expected. The cost incurred of such "attacks" are often in the expensive requests to auto-scaling third party services, such as hosted LLMs for AI apps.[2](https://stack.convex.dev/rate-limiting#user-content-fn-2)

### Benefits of these implementations

The rate limits discussed here have these properties:

- **Efficient storage and compute**: in particular, it doesn’t require crons or storage that scales with load. Each rate limit (a combination of a name and a “key”) stores two numbers and does simple math.
- **Transactional evaluation:** You can make multiple decisions using multiple rate limits and be ensured that they’ll all be consumed or none will be (if you roll back by throwing an exception, for instance).
- **Fairness via opt-in credit “reservation”**: By using `reserve: true` below, I’ll show how you can pre-allocate tokens and schedule work that doesn’t require client backoff, and doesn’t starve large requests.
- **Opt-in “rollover” allowance:** Allowing clients that have been under-consuming resources to accumulate tokens that “roll over” to the next period up to some limit, so they can service bursts of traffic while limiting average usage by a token bucket.
- **Deterministic:** The results of these approaches will give you concrete bounds on usage, do not rely on probability, and will not “drift” over time. They also can determine the next time a retry could succeed.
- **Fail closed**: If the system is under heavy load, it won’t fling open the gates for the traffic to overwhelm other services and cause [cascading failure](https://en.wikipedia.org/wiki/Cascading_failure#:~:text=A%20cascading%20failure%20is%20a%20failure%20in%20a,probability%20that%20other%20portions%20of%20the%20system%20fail.), as other “fail open” solutions can. This is an easy property to satisfy, since the application database is being used for the rate limit. If the application database is unavailable, continuing to serve the request is unlikely to succeed anyways. Failing open makes more sense when adding additional infrastructure or services that could introduce a single point of failure (SPOF) such as single-host in-memory service.

## The algebra of rate limits

Here is how you calculate rate limits, using just to numbers: `value` and `ts`. Here is the Convex database schema for it:

```tsx
rateLimits: defineTable({
  name: v.string(),
  key: v.optional(v.string()), // undefined is singleton
  value: v.number(), // can go negative if capacity is reserved ahead of time
  ts: v.number(),
6}).index("name", ["name", "key"]),

```

Each of the following approaches have some basic error checking omitted for brevity, such as checking that the requested number of units is less than the maximum possible (which will never succeed).

See [below](https://stack.convex.dev/rate-limiting#reserving-tokens) for modifications to accommodate reserving tokens.

### Token bucket

Instead of a traditional approach to a sliding window in which there are discrete jumps in value based on past events, we can use a token bucket to provide similar benefits, with a much more efficient storage and runtime footprint.

We model tokens as being continuously provided, with a `capacity` defined in the config. If your configured `rate` is 10 in a `period` of a minute and you use 5 tokens, they will be fully restored in 30 seconds. Since we model it continuously, one credit will be restored every six seconds. So you could be consuming one credit every six seconds, five every thirty seconds, or ten every minute. When you don’t use all your tokens, they can accumulate up to the defined `capacity` amount. With `capacity`, you can use more than the normal rate for a period of time, resting assured that all of that capacity was accumulated during idle time. Because the tokens are issued at a fixed rate, the overall credit consumption is bound to that rate. If it isn’t set, `capacity` defaults to `rate`.

Config:

```tsx
export type TokenBucketRateLimit = {
  kind: "token bucket";
  rate: number;
  period: number;
  capacity?: number; // defaults to rate
  maxReserved?: number;
7};

```

![Token bucket rate limiting works by continuously adding "tokens" at some configured "rate" over a "period" which can be spent by servicing requests. There's a "capacity" after which the tokens don't accumulate. If a request requires more tokens than are available, it can be retried when there will be enough tokens, knowable via the rate.](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F59cf030b9be15f734123b48d88a8a9e86681bffe-1252x809.png&w=3840&q=75)Token bucket rate limiting works by continuously adding "tokens" at some configured "rate" over a "period" which can be spent by servicing requests. There's a "capacity" after which the tokens don't accumulate. If a request requires more tokens than are available, it can be retried when there will be enough tokens, knowable via the rate.

The core calculation is:

```tsx
const now = Date.now();
const elapsed = now - state.ts;

ts = now;

value = Math.min(
  state.value + elapsed * config.rate / config.period,
  config.capacity ?? config.rate
9) - (args.count ?? 1);

```

- We keep track of the last time we calculated the state of the bucket as `ts` and the `value` at that time.
- We calculate the current value since then, capping it at the capacity of the bucket. If there is no capacity configured, we default to the rate. So if you allow 10 per second and don't specify a capacity, you can have up to 10 tokens in the bucket.

**Full code, including handling reservations:**

```tsx
const now = Date.now();
// Fetch the existing value & ts from the database, if present.
// If the key is undefined, it will fetch the shared value for the name.
const existing = await db.query("rateLimits")
  .withIndex("name", (q) => q.eq("name", name).eq("key", key))
  .unique();
// If there isn't a capacity defined, default to the rate
const max = config.capacity ?? config.rate;
const consuming = args.count ?? 1;

// Start of token-bucket-specific code
// Default to the maximum available right now.
const state = existing ?? { value: max, ts: now };
const elapsed = now - state.ts;
const rate = config.rate / config.period; // I appologize for the rate naming.
// The current value is whatever accumulated since the last evaluation up to max.
const value = Math.min(state.value + elapsed * rate, max) - consuming;
const ts = now;
let retryAfter = undefined;
if (value < consuming) { // not enough capacity currently
  retryAfter = -value / rate;
  // End of token-bucket-specific code
  if (!args.reserve || (config.maxReserved && (-value  > config.maxReserved)) {
    return { ok: false, retryAfter };
  }
26}
if (existing) {
  await db.patch(existing._id, { value, ts });
29} else {
  const { name, key } = args;
  await db.insert("rateLimits", { value, ts, name, key });
32}
return { ok: true, retryAfter };

```

#### Some things to keep in mind:

- If you are sensitive to bursts of traffic, for instance if you’re using a third party API that has a hard rate limit cap, note that with this approach you could have as many as `rate + capacity` requests in a single window, if the accumulated capacity is all consumed at once, and then the accumulated tokens consumed at the end of the window. For these scenarios, you can:
  - Use `fixed window` to divide capacity into fixed windows.
  - Set `capacity` and `rate` to both be half of the third party hard cap, so worst case you use a burst of half, then use the accumulated amount before the window is over. The downside is your average consumption is limited to half of what’s available.
  - Set `capacity` to be smaller than `rate`, which allows using more steady-state bandwidth, so long as the requests are small and somewhat frequent. For example if you had an hourly budget of 70 tokens, you could have a rate of 60 and a capacity of 10. You could consume one token per minute, or 5 tokens every five minutes, but if you didn’t consume anything for 15 minutes, you’d only have accumulated 10 tokens.
  - Set `capacity` to zero and always use `reserve` and scheduling to perfectly space requests based on their needs. You lose the benefits of accumulated bandwidth, and all requests will suffer some delay, so only use this for time-insensitive workloads.
- If many clients are waiting for the same rate limit to have bandwidth, and you aren’t using the `reserve` technique, you should add some [jitter](https://stack.convex.dev/rate-limiting#jitter-introducing-randomness-to-avoid-thundering-herds) before returning it to a client, so each client attempts at a different time.

### Fixed window

When you need your rate limiting windows to be rigid, you can use this more traditional approach, where tokens are issued at distinct intervals and can be used during that interval. We also extend it with an optional `capacity` configuration to allow unused tokens to accumulate, allowing us to control the overall usage while accommodating traffic that isn’t consistent.

Config:

```tsx
export type FixedRateLimit = {
  kind: "fixed window";
  rate: number;
  period: number;
  capacity?: number; // defaults to rate
  start?: number;
7};

```

![Fixed window rate limiting adds tokens at discrete intervals to be used to service requests. Requests that need more tokens have to wait until the next window.](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F90d37a967098fe521eff55348a539796c4f96015-1244x871.png&w=3840&q=75)Fixed window rate limiting adds tokens at discrete intervals to be used to service requests. Requests that need more tokens have to wait until the next window.
The core calculation for value at a given time is:

```tsx
const elapsedWindows = Math.floor((Date.now() - state.ts) / config.period);

ts = state.ts + elapsedWindows * config.period;

value = Math.min(
  state.value + config.rate * elapsedWindows,
  config.capacity ?? config.rate
8) - (args.count ?? 1);


```

- We use `ts` to mark the start of the window, and don’t update it until we are consuming resources in a more recent window, at which point we add tokens for each window that started since then.
- `value` holds the tokens available at that timestamp.

**Full code, including reservations:**

```tsx
const now = Date.now();
// Fetch the existing value & ts from the database, if present.
// If the key is undefined, it will fetch the shared value for the name.
const existing = await db.query("rateLimits")
  .withIndex("name", (q) => q.eq("name", name).eq("key", key))
  .unique();
// If there isn't a capacity defined, default to the rate
const max = config.capacity ?? config.rate;
const consuming = args.count ?? 1;

// Start of fixed-window-specific code
const state = existing ?? {
  // If there wasn't a value or start time, default to a random time.
  ts: config.start ?? (Math.random() * config.period),
  value: max, // start at full capacity
16};
const elapsedWindows = Math.floor((Date.now() - state.ts) / config.period);
// Add value for each elapsed window
const value = Math.min(state.value + config.rate * elapsedWindows, max) - consuming;
// Move ts forward to the start of this window
const ts = state.ts + elapsedWindows * config.period;
let retryAfter = undefined;
if (value < 0) {
  const windowsNeeded = Math.ceil(-value / config.rate);
  retryAfter = ts + config.period * windowsNeeded - now;

  // End of fixed-window-specific code
  if (!args.reserve || (config.maxReserved && (-value  > config.maxReserved)) {
    return { ok: false, retryAfter };
  }
31}
if (existing) {
  await db.patch(existing._id, { value, ts });
34} else {
  const { name, key } = args;
  await db.insert("rateLimits", { value, ts, name, key });
37}
return { ok: true, retryAfter };

```

`start` is the offset from `0` UTC, in this case to align the start of the period with midnight in the PDT timezone. This is handy for aesthetically aligning requests with a user’s midnight or starting on the hour or on the minute, but if the rate limit will see a lot of concurrent usage, this can lead to many clients all waiting until midnight to fire off requests and causing a [thundering herd](https://en.wikipedia.org/wiki/Thundering_herd_problem). For these situations you should add [jitter](https://stack.convex.dev/rate-limiting#adding-jitter), or omit `start`. If you don’t provide `start`, it will use the “key” to assign a random time as the start time.

**Note:** if you allow for `capacity`, the maximum number of tokens used in a given period will be `capacity`, whereas the token bucket implementation above could use a maximum `capacity` \+ `rate` for a single period (worst case). This makes fixed windows a good fit for maximizing third party API limits, and `capacity` a nice feature if the third party has an accommodation for “burst” traffic.

## Reserving tokens

When you hit a rate limit with these implementations, the rate limiter knows the next time it could plausibly handle your request. However, by that time a smaller request could have come along and consumed tokens, further delaying the larger request. If you are sure you want to eventually serve a request, it’s more efficient to pre-allocate the work and schedule its execution.[3](https://stack.convex.dev/rate-limiting#user-content-fn-3)

Reserving tokens provides three useful properties:

- **Fairness:** By reserving capacity ahead of time, larger requests can allocate capacity without retrying until enough tokens accumulate.
- **Fire-and-forget:** When you require a client to retry an operation later, there’s a chance the client won't be around - e.g. if a user clicks away or refreshes a website. If you know you eventually want to take some action, you can schedule execution for later and free the client from the responsibility of retrying.
- **“Perfect” scheduling:** Using retries, especially when you add jitter, prevents you from fully utilizing available resources. With reservations, you are given advance authorization to run your operation at the exact time.

The implementation for both strategies is relatively straightforward. Both allow the available tokens to go negative, up to some configurable limit (by default unlimited).

For example, say you had 3 tokens and a request came in for 5.

- You updated the token count to -2 and responded that the work should happen later - specifically when 2 tokens would have been added.
- The caller [schedules](https://docs.convex.dev/scheduling/scheduled-functions) their work to happen at that later time. **It is important to schedule it and not just run the request right away** \- otherwise it's just equivalent to a higher burst `capacity`.
- When the scheduled function runs later, it doesn't need to check rate limits because it's already been approved.
- Later on, when another function call checks the rate limit, it calculates how many tokens to add based on the elapsed time and adds it to the -2 value before deciding whether there are enough tokens for the new call.

Passing `reserve: true` is optional. By default the component will refuse to go negative.

See the [below example](https://stack.convex.dev/rate-limiting#making-llm-requests-with-reserved-capacity) for usage.

## Using rate limits for common operations

To make the rate limit tradeoffs concrete, let’s consider how we’d use rate limiting in our application. I made a [component](https://www.convex.dev/components) for Convex that provides a simple rate limiting API to consume, check, and reset limits. This implementation is Convex-specific, but it will serve as a representative example of how application-layer rate limits might look.

[get-convex/ **rate-limiter**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/get-convex/rate-limiter)

In general, the distinctions here will be between “global” rate limits, for which there is one per application for a given rate limit “name,” and ones where each distinct “key” is rate limited independently.

The examples below assume a flow like:

- A client calls a [mutation](https://docs.convex.dev/functions/mutation-functions) to take some action, which may involve a rate-limited behavior. For those unfamiliar with Convex, a mutation runs server-side and encapsulates a database transaction, providing Serializable isolation and Optimistic Concurrency Control with automatic retries.
- The mutation checks the rate limit before taking the action, and if it fails it returns the time when the client should retry.
- Alternatively, the client could call an [action](https://docs.convex.dev/functions/actions) (a non-transactional non-deterministic general-purpose environment, akin to a normal API endpoint) which could then call a mutation before taking some action.

Configuration can be centralized or provided at the call-site. If you use a limit from more than one place, defining them centrally is best, which will produce type-safe functions auto-completing your rate limit names.

```tsx
const rateLimiter = new RateLimiter(components.rateLimiter, {
  createAThing: { kind: "token bucket", rate: 3, period: HOUR },
  makeAThirdPartyRequest: { kind: "fixed window", rate: 100, period: MINUTE },
4});

```

- `rateLimiter.limit` is what you call to consume resources. It will return whether it succeeded.
- `rateLimiter.check` will do the same thing as `limit`, but return the result without consuming any resources, as a way to tell whether it would have failed.
- `rateLimiter.reset` will reset a given rate limit.

```tsx
export const doAThing = mutation({
  args: { email: v.string() },
  handler: async (ctx, args) => {
    const { ok, retryAfter } = await rateLimiter.limit(ctx, "myRateLimit");
    if (!ok) return { retryAfter };
    await doTheThing(ctx, args.email);
  },
8});

```

- `ok` is whether it successfully consumed the resource and the operation should proceed.
- `retryAfter` is when it could succeed in the future, which can be used by a client to decide when to retry. We’ll discuss “jitter” later which is important here if it’s highly contended.

See the [component docs](https://www.convex.dev/components/rate-limiter) for setup and configuration instructions.

From here on, the mutation context will be assumed. We’ll also use these constants to make it more readable:

```tsx
const SECOND = 1000; // ms
const MINUTE = 60 * SECOND;
const HOUR = 60 * MINUTE;
const DAY = 24 * HOUR;

```

### Failed logins

This will allow 5 failed requests in an hour. Because it’s a bucket implementation, the user will be able to try 5 times immediately if they haven’t tried in an hour, and then can try again every 6 minutes afterwards.

```ts
const rateLimiter = new RateLimiter(components.rateLimiter, {
  failedLogins: { kind: "token bucket", rate: 10, period: Hour },
3});

```

Using the functions to manage failed logins:

```ts
await rateLimiter.check(ctx, "failedLogins", { key: userId, throws: true });
const success = await logInAttempt(ctx, userId, otp);
if (success) {
  // If we successfully logged in, stop limiting us in the future
  await rateLimiter.reset(ctx, "failedLogins", { key: userId });
6} else {
  const { retryAfter } = await rateLimiter.limit(ctx, "failedLogins", { key: userId });
  return { retryAfter }; // So the client can indicated to the user when to try again
9}

```

- `throws` is a convenience to have it throw when `ok` is `false` instead of return the values. It works for `limit` and `check`.

### Account creation via global limit

To prevent a flood of spam accounts, you can set a global limit on signing up for a free trial. This limits sign-ups to an average of 100 per hour.

```ts
await rateLimiter.limit(ctx, "freeTrialSignUp", {
  config: { kind: "token bucket", rate: 100, period: HOUR },
  throws: true,
4});

```

- `config`: The configuration is inlined if you didn’t define it with `new Rate Limiter`.

Note: this is a deterrent for spammers, but means that during a flood of attempts, other users will be impacted. See [below](https://stack.convex.dev/rate-limiting#authenticating-anonymous-users) for tips on authenticating anonymous users.

### Sending messages per user

```ts
const { ok, retryAfter } = await rateLimiter.limit(ctx, "sendMessage", {
  key: userId,
  config: { kind: "token bucket", rate: 10, period: MINUTE, capacity: 20 },
4});

```

- `key` will isolate the rate limiting, in this case to be a per-user limit.
- `capacity` here allows accumulating up to 20 unused tokens so a bursty minute won’t fail. See [above](https://stack.convex.dev/rate-limiting#token-bucket) for details on the implementation.

### Making LLM requests with reserved capacity

If you’re staying on the [OpenAI free tier](https://platform.openai.com/docs/guides/rate-limits/free-tier-rate-limits), you can ensure you don’t go above their rate limits, and when you have too many requests, you can schedule them to happen when you will.

```ts
const { ok, retryAfter } = await rateLimiter.limit(ctx, "chatCompletion", {
  count: numTokensInRequest,
  reserve: true,
4});
if (!ok) return { retryAfter }; // There were too many reserved already.
if (retryAfter) { // We need to wait until later, but we've reserved the tokens.
  // Spread the request across 10s in case of many reservations.
  const withJitter = retryAfter + (Math.random() * 10 * SECOND);
  await ctx.scheduler.runAfter(withJitter, internal.llms.generateCompletion, args);
10} else { // We can run it immediately.
  const result = await generateCompletion(args);
	//...
13}

```

- `count` can decrease the number of tokens by a custom amount. By default it’s 1.
- `reserve: true` instructs it to allow a token deficit if there isn’t enough capacity, provided we are willing to schedule our work for the future time when it would have had enough capacity. See [above](https://stack.convex.dev/rate-limiting#reserving-tokens) for more details.
- `maxReserved` defines how many tokens it should allow to be reserved before refusing to set aside tokens.

Reservations work with either rate limiting approach.

### Jitter: introducing randomness to avoid thundering herds

If we tell all clients to retry just when the next window starts, we are inviting what’s called a “thundering herd” which is about how it sounds. When too many users show up at once, it can cause network congestion, database contention, and consume other shared resources at an unnecessarily high rate. Instead we can return a random time within the next period to retry. Hopefully this is infrequent. This technique is referred to as adding “jitter.”

A simple implementation could look like:

```ts
const withJitter = retryAfter + (Math.random() * period);

```

For the fixed window, we also introduce randomness by picking the start time of the window (from which all subsequent windows are based) randomly if `config.start` wasn’t provided. This helps from all clients flooding requests at midnight and paging your on-call.

## Scaling rate limits with shards

As your usage grows, you’ll want to think about scalability for your rate limiting.

If you are using per-user keys, using each key won’t conflict with the others. However, if you use global rate limits, or a single key might have hundreds of requests per second, you should shard the rate limit by dividing the capacity into multiple rate limits.

For example, if you’re trying to limit the overall (global) number of tokens sent to an LLM API, you could make 10 rate limits, each at 1/10th the bandwidth. When you go to use the rate limit, you can set the `key` to be one of 10 random values, such as `0...9`.

Thankfully the component handles this internally. Just provide `shards` in your config:

```ts
const rateLimiter = new RateLimiter(components.rateLimiter, {
  llmRequests: { kind: "fixed window", rate: 1000, period: MINUTE, shards: 10 },
3});

```

This will decrease your ability to maximize throughput by spreading out the load amongst the shards. It also leverages [The Power of Two Choices in Randomized Load Balancing](https://www.eecs.harvard.edu/~michaelm/postscripts/tpds2001.pdf) and check two shards to keep the overall rates balanced.

## What if I rely on multiple rate limits?

If your operations requires consuming multiple rate limits, you can run into issues if you aren’t careful. You could consume resources that you don’t end up using. This can even deadlock if two operations acquire resources in different orders, for instance:

1. Request A takes 5 unit of x and fails to take 10 units of y, so returns to the client that it should retry later.
2. Request B takes 5 units of y (say there were only 5 units) and fails to take 10 units of x.
3. Request A retries, taking another 5 units of x which had accumulated, and fails to take y.
4. etc.

**Here are two strategies to handle this:**

1. Use `rateLimiter.check` ahead of time for each rate limit you’ll depend on, and only continue to consume them if they are all satisfied, otherwise return the largest `retryAfter` value so the client doesn’t retry before it’d plausibly be accepted.

2. Roll back the transaction by throwing an exception instead of returning. When an exception is thrown, database writes are not committed, oo any rate limits the request already consumed will be reset to their previous values. When a rate limit fails, no state is persisted by the library.

To pass information back to the client, you can use `ConvexError`. This is what the library does if you specify `throws: true`:





```tsx
if (args.throws) {
  throw new ConvexError({
    kind: "RateLimited",
    name: args.name,
    retryAfter,
  });
7}

```





Note: this might not be the maximum value of `retryAfter` for your request, just the first it ran into. Hopefully your application rarely hits rate limits, so it’s ok for the client to retry later and need to wait again.


In general, I’d advise you to consolidate all of your rate limits into a single transaction (mutation) rather than calling out to multiple mutations from an action as you go, if all of the rate limits need to be satisfied for the operation to succeed.

## Authenticating anonymous users

It sounds like an oxymoron, but there are a few strategies for authenticating users that haven’t logged in or authenticated using traditional methods.

- **Client-generated session ID (optimistic):** This ID is generated in the browser and sent with requests to identify the user. This is only meaningful protection if you authorize the session ID using a strategy below, since a malicious user could generate new ones for each request.
- **Associate the session ID with an IP (lossy)**: You can have the client make a one-time HTTP request to an API endpoint that associates the session ID provided with an IP. You then rate-limit behaviors based on IP. This is handy, but ultimately a flawed approach, since many real users may share a virtual IP exposed by their ISP.
- **Use a Captcha or similar to authorize the session ID (robust):** This is what I’d recommend. Anonymous users submit a captcha to prove they’re not bots, and associate the successful captcha with their session ID to be authorized to do any operation. At this point, you can rate limit their session ID as if it were a userId.

## Summary

We looked at implementing application-layer rate limiting to help limit operations, either globally or specific to a user or other key. We looked at implementing both a token bucket and fixed window limits using just two numbers.

This is enabled by having an environment that:

- Provides transactional guarantees to avoid race conditions with reading & writing values.
- Automatically retries conflicting transactions.
- Schedules work transactionally, to allow handling multiple rate limits independently and roll back everything if any of them fail.
- Has fast access to a database with indexed lookups.

Beware: if you plan to implement these with Postgres or similar, beware of the [read-modify-write behavior](https://www.2ndquadrant.com/en/blog/postgresql-anti-patterns-read-modify-write-cycles/) where, by default, you are exposed to data races, even within a transaction.

We also looked at adding the ability to reserve capacity ahead of time to ensure fairness, as well as handle bursts of traffic while still maintaining an overall average limit.

As always, let me know in [our Discord](https://convex.dev/community) what you think and what else you’d like to see out of the library.

### Footnotes

1. Specifically having serializable isolation is really useful for this use case. “Read committed” isolation (the default for Postgres and other SQL variants) is vulnerable to race conditions for the code in this article, [even in a transaction](https://www.2ndquadrant.com/en/blog/postgresql-anti-patterns-read-modify-write-cycles/) unless you jump through some hoops. And if you figure out how to do it for Drizzle [without adding read locks for every row in a transaction](https://orm.drizzle.team/docs/transactions), [this person could use some help](https://github.com/drizzle-team/drizzle-orm/discussions/1337). [↩](https://stack.convex.dev/rate-limiting#user-content-fnref-1)

2. For an article about a load balancing strategy that helps control costs and optimizes for throughput, check out my recent article on [work stealing](https://stack.convex.dev/work-stealing). [↩](https://stack.convex.dev/rate-limiting#user-content-fnref-2)

3. The Convex scheduler is transactional within mutations. If the mutations throws an exception, no database writes will happen and no functions will be scheduled. [↩](https://stack.convex.dev/rate-limiting#user-content-fnref-3)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Automatically Retry Actions

Convex provides strong guarantees so developers usually don’t have to reason about retries or inconsistencies. Queries and mutations execute as database transactions that are automatically retried in a fully-consistent manner. This is not the case for Convex actions however, which execute non-transactionally and with best-effort execution guarantees.

Actions provide an escape hatch from the deterministic world of queries and mutations. You could run a several-minute-long action that talks to a bunch of third-party services and externalizes database state. If one of these actions were to fail it wouldn’t be safe for Convex just to automatically retry it - perhaps your action does something like posting a tweet (an X?) that you wouldn’t want to happen twice if the action is retried.

Many times you know that your action really _is_ safe to retry though. In these cases you’re in luck because you can use Convex scheduling to automatically retry a failed action.

## Just gimme the code

If you want an out-of-the-box solution there is a Convex Component ready to go:
[https://www.convex.dev/components/retrier](https://www.convex.dev/components/retrier)

You can use this component to retry an unreliable action until it succeds:

```ts
import { ActionRetrier } from "@convex-dev/action-retrier";
import { components } from "./convex/_generated/server";

const retrier = new ActionRetrier(components.actionRetrier);

// run this from within an action or mutation
await retrier.run(ctx, internal.module.myAction, { arg: 123 });

```

The rest of this article outlines the principles behind this component.

## How it works

Retries are a great use case to leverage Convex scheduling. Along the way we’ll also learn about using `db.system` to look up system table information and the `makeFunctionReference` helper to generate a reference to a function from its name as a string.

We can schedule a function from either a mutation or an action but since our goal is to build a reliable wrapper around an unreliable action we’re going to use mutations to do this. We’ll start with a mutation called `runAction` that takes in the name of an action and its args, then does some magic to make sure that action gets retried until it succeeds:

```tsx
export const runAction = internalMutation({
  args: {
    action: v.string(),
    actionArgs: v.any(),
  },
  handler: async (ctx, { action, actionArgs }) => {
		...

```

We make this an `internalMutation` for safety since it exposes access to any action via its name. We can use a public mutation to call it for a specific action. The version in `convex-helpers` provides type-safety, unlike the simple example here.

### The algorithm

We’ll use the following logic to retry an action until it succeeds:
![The backoff algorithm](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4523ce713f9881a60b23fd114bb610efce03fd2c-1186x1333.png&w=3840&q=75)The backoff algorithm

In a production app it’s also a good idea just to give up eventually in case the action will never succeed. [The linked source code](https://github.com/JamesCowling/convex-action-retrier/blob/main/convex/retrier.ts) also includes a configurable `maxFailures` check to do so.

### Execute action

The first step of our algorithm is to actually execute the action. You’re probably familiar with triggering an action from a mutation using a scheduling command like:

```tsx
await ctx.scheduler.runAfter(0, api.example.unreliableAction, actionArgs);

```

It’s nice to have the type-safety provided by function references like `api.example.unreliableAction` but in this case we only have the name of the action as a string. Fortunately we can use the `makeFunctionReference` helper that will generate a function reference from its type (query/action/mutation) and name:

```tsx
// const action = "example:unreliableAction"
await ctx.scheduler.runAfter(
	0,
	makeFunctionReference<"action">(action),
	actionArgs
6);

```

Be careful with code like this to ensure you don't expose functions that you don't intend to be public.

The last step is to record the job id for the scheduled function so we can check its status later:

```tsx
const job = await ctx.scheduler.runAfter(
	...

```

### Check job status

The job id we just recorded is actually the `Id` of a document in the Convex [system table](https://docs.convex.dev/database/advanced/system-tables) `_scheduled_functions`. There are a growing set of system tables in Convex that allow you to query internal system state from right within queries and mutations. You can read a system table with the `ctx.db.system.get()` command just like reading a regular table with `ctx.db.get()`. In particular we want to look up the `state.kind` field in the system table document for the job we just scheduled:

```tsx
const status = await ctx.db.system.get(job);
if (!status) {
	throw new Error(`Job ${job} not found`);
4}
switch (status.state.kind) {
	case "pending":
	case "inProgress":
		...
		break;
	case "failed":
		...
		break;
	case "success":
		...
		break;
	case "canceled":
	  ...
		break;
19}

```

Now it’s just a matter of deciding when to retry the action and how long to wait before doing so.

### Back off

You might find it odd that there are two different exponential backoffs in our flowchart above. If you’re not familiar with exponential backoff it basically just means waiting longer every time we retry. It’s a great tool when you don’t know exactly how long to wait but you also don’t want to retry thousands of times in a tight loop.

The first backoff is used to figure out when the action has finished. The wrapper doesn’t know how long the unreliable action is meant to take so it wouldn’t make sense to keep checking every millisecond if it usually takes 5 minutes. Instead we wait 10ms, then 20ms, 40ms, 80ms, 160ms, etc.

The second backoff determines how long to wait before retrying a function. Oftentimes an action will fail because a third-party service is temporarily down. We would want to be hammering that poor service constantly if it’s already drowning under load. Instead we wait 10ms, then 20, then… you get the picture.

The `convex-action-retrier` library allows configuring the specific parameters of the exponential backoff but the nice thing about exponential backoff is that the default parameters should be fine for almost everyone.

## Ready for actions

Now you can implement reliable actions by retrying them until they succeed, but hopefully now you can also build relatively sophisticated workflows by chaining mutations and scheduling. The mental model to maintain is that queries, mutations and scheduling are reliable and transactional but restrictive, whereas actions are the wild west where you trade transactional guarantees for the flexibility to talk to the outside world. Fortunately these components all work together seamlessly so you can have your cake and eat it too.

Hooray!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Row Level Security

With Convex you can implement authorization a number of ways. In this post we’ll look at implementing a row-level security abstraction by adding a layer of indirection which will validate the authorization of the user to read, write, or modify each document they interact with.

## Authorization: limiting access control

One of the goals in making a secure app is restricting which users can do what. Logged-out sessions should not be allowed to view private data, and logged-in users shouldn’t be able to delete other users’ data. I’ve worked on locking down access to Dropbox files, Spark deployments, and [private messages](https://stack.convex.dev/end-to-end-encryption-with-convex). So I got to thinking about how developers using Convex can manage permissions in their apps.

### Authorization via code

Convex allows developers to write arbitrary Javascript, which runs on the server within a transaction, that can check authorization. If you want to enforce an authorization rule, you can define it in code and check it whenever you want. Maybe before a user can “Like” a post, you require that the authenticated user is connected to the post’s author through the graph of friendships.

```tsx
export default likePost = mutation(async ({db, auth}, {postId}) => {
	const post = await db.get(postId);
	if (!await connectedInGraph(db, await auth.getUserIdentity(), post.author)) {
		throw new Error("you can't like that");
	}
	await db.patch(postId, {likes: post.likes + 1});
7});

```

Although Convex allows flexible rules, it could become unruly if you need to do the same authorization check in different places. “Liking” a post should run the same authorization code as “Sharing” or “Reposting,” because the check isn’t a property of the mutation as much as it’s a property of the post. Even if everything is configured perfectly, it could all fall apart if a new engineer joins the team, makes a new mutation, and forgets the authorization check. Suddenly you have an [IDOR vulnerability](https://www.varonis.com/blog/what-is-idor-insecure-direct-object-reference).

### Authorization via row-level security

We want some way of saying “if you’re accessing data in the ‘posts’ table, you need to run the access check.” Finding the right layer to put this access check can be tricky — I spent a year at Dropbox moving access checks for files into a central service. One layer that works well is row-level-security (RLS) where authorization is defined on individual rows, and the checks automatically run whenever code tries to read or write the row. How would you build that in Convex?

Let’s design a simple app where users create messages. Only the message’s author can edit a message or publish it. Logged-in users can view all messages, but logged-out sessions can only view published messages. We can codify these rules in code.

```tsx
// in convex/rls.js
import { customCtx, customMutation, customQuery } from "convex-helpers/server/customFunctions";
import { Rules, wrapDatabaseReader, wrapDatabaseWriter } from "convex-helpers/server/rowLevelSecurity";
import { DataModel } from "./_generated/dataModel";
import { mutation, query, QueryCtx } from "./_generated/server";

async function rlsRules(ctx: QueryCtx) {
  const identity = await ctx.auth.getUserIdentity();
  return {
    messages: {
      read: async ({ auth }, message) => {
        if (identity === null) {
          return message.published;
        }
        return true;
      },
      modify: async ({ auth }, message) => {
        if (identity === null) {
          return false;
        }
        return message.author === identity.tokenIdentifier;
      },
    },
  } satisfies Rules<QueryCtx, DataModel>;
25}


export const queryWithRLS = customQuery(
  query,
  customCtx(async (ctx) => ({
    db: wrapDatabaseReader(ctx, ctx.db, await rlsRules(ctx)),
  })),
33);

export const mutationWithRLS = customMutation(
  mutation,
  customCtx(async (ctx) => ({
    db: wrapDatabaseWriter(ctx, ctx.db, await rlsRules(ctx)),
  })),
40);

```

Here we define some [custom functions](https://stack.convex.dev/custom-functions) along with helper functions in the `rowLevelSecurity` module of the [convex-helpers](https://www.npmjs.com/package/convex-helpers) package. You can then use them like:

```jsx
// in convex/messages.js
import { queryWithRLS, mutationWithRLS } from "./rls";

export const list = queryWithRLS({
  args: {},
	handler: async (ctx) => {
    return await ctx.db.query("messages").collect();
	},
9});

export const publish = mutationWithRLS({
  args: { messageId: v.id("messages") },
	handler: async (ctx, args) => {
    await ctx.db.patch(args.messageId, {published: true});
	},
16});

```

The custom functions wrap the `ctx.db` object. The wrapper intercepts each row that would be returned from `db.get` or `db.query` and filters out rows based on your `read` rules. It intercepts each row that would be modified by `db.patch`, `db.replace`, or `db.delete` and confirms that the write is allowed by `modify` rules, and `db.insert` with the `insert` rules.

Now we have defined the authorization checks in a single place. The access rules can depend on the authorized user through `auth` and they can do database reads through `db`. Convex runs functions close to the database and caches query results, making it efficient to run the same authorization check on each document. However, you can also compose this pattern with other wrappers to provide user-level, team-level, or otherwise checks.

## Extending access functions

### Customizing the rule ctx

The rules you define for reading and writing documents are given the context that is provided to the function, including the `db`, `auth`, and other objects. If you want to optimize and avoid fetching the same thing multiple times, you can customize it with other things you fetch in your [custom functions](https://stack.convex.dev/custom-functions).

```ts
const rules: Rules<{ viewer: User, roles: Role[] }, DataModel> = {
	users: {
		read: async ({ viewer }, user) => {
			if (!viewer) return false;
			return true;
		},
		insert: async ({ roles }, user) => {
			return roles.includes("user.create");
		},
		modify: async ({ viewer, roles }, user) => {
			if (!viewer) throw new Error("Must be authenticated to modify a user");
			if (roles.includes("admin")) return true;
			return viewer._id === user._id;
		},
	},
16}

const myCustomQuery = customQuery(
  query,
  customCtx(async (ctx) => {
	  const viewer = await getCurrentUser(ctx);
		const roles = await getRoles(ctx, user);
		return {
      db: wrapDatabaseReader( { viewer, roles }, ctx.db, rules),
    })),
26);

```

### Mixing RLS with bespoke authorization rules

One somewhat-obvious thing to point out is that, while you can use this abstraction to add RLS to your app, you can also decide where to not use it, or when to do other, more complex authorization with regular functions. Convex queries and mutations run on the server, so you can safely write access checks in code, whereas with some other platforms you’re limited to a special authorization markup and your code only runs on the client.

## Summary

In this post we looked at adding row-level security to endpoints by wrapping the database interface with per-document checks. As long as your documents express a logical concept that can have access control rules, you can implement security in your Convex app today, by using [rowLevelSecurity in convex-helpers](https://www.npmjs.com/package/convex-helpers#row-level-security).

This is one of many ways to authorize access for your Convex app. Please let us know what your favorite way of managing authorization is in [our Discord](https://convex.dev/community). Thanks for reading.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Searching for Sanity

While using one of your favorite apps, have you ever run into something like this?

It’s pretty reasonable to expect that once you add a document to your Notion workspace, the search box will find it! What’s going on here?

## Unsavory search secrets

You may be surprised to learn that there’s nothing particularly unusual about what Notion is doing. In most systems, backend search architectures are structured just so:

In this common design, the system that _stores_ your records is separate from the system that _indexes_ them for search. Specialized systems are chained together, such as MySQL for the database and Elasticsearch for full-text search.

So there is inherently a delay in the pipeline that connects storage and search, and your users might experience a temporary inconsistency–a stored document not yet searchable, just as we saw with Notion. This inconsistency is often only a few seconds, but sometimes can be minutes or hours.

While the ease of leveraging several ready-to-go systems for each task may feel like a pragmatic decision for a software team, it really sucks that it “leaks” internal architectural choices in the form of a confusing user experience.

## Fancy concepts, simple expectations

At Convex, we love deep infrastructure concepts like strong consistency and [ACID](https://stack.convex.dev/dont-drop-acid). But not because distributed systems papers are riveting beach reads. Instead, because we believe the mark of a great platform is facilitating the easy creation of software that Just Works. Convex projects should automatically do what the developer and user expect.

And that’s why Convex’s search is _transactional:_ search indexes in Convex guarantee that the very moment a document is committed to the database, that document shows up in search results. User expectations met!

And while we’re at it, Convex developers expect that everything in our platform is seamlessly reactive. So we made search reactive, too.

## What “just works” looks like

Let’s use Convex to search through a sample of Wikipedia articles!

As a prerequisite, we retrofitted the Convex [tutorial chat app](https://docs.convex.dev/tutorial/welcome-to-convex) by loading 100,000 random Wikipedia articles with the [command line import tool](https://docs.convex.dev/using/cli#import-a-file-into-convex). We assigned the page body to the `body` field and the title to the `author` field of the messages table.

Time to get searching! First, we need to create the search index using [Convex’s schema definition](https://docs.convex.dev/using/schemas). Let’s create an index called “search\_body” that is indexing the `body` field. We’ll do this by using the `searchIndex` method on the schema object:

```tsx
import { defineSchema, defineTable } from "convex/schema";
import { v } from "convex/values";

export default defineSchema({
  messages: defineTable({
    body: v.string(),
    author: v.string(),
  }).searchIndex("search_body", {
    searchField: "body",
  }),
11});

```

Then, we can easily use this search index in our app’s [query functions](https://docs.convex.dev/using/database-queries) by calling our query’s `withSearchIndex` method.

```tsx
export default query(async ({ db }, { bodyQuery }) => {
  const results = await db
    .query("messages")
    .withSearchIndex("search_body", q => q.search("body", bodyQuery))
    .take(5);
  return results;
7});

```

Finally, as usual in React + Convex apps, we’ll leverage the Convex library’s `useQuery` hook to [attach this backend query function](https://docs.convex.dev/using/writing-convex-functions#defining-convex-functions) to a component rendering a list of results:

This principled take on search is just one of the many ways in which Convex nudges your projects toward the [pit of success](https://blog.codinghorror.com/falling-into-the-pit-of-success/). So start a new project today, try out transactional search, and [come show us what you built](https://convex.dev/community)!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Seeding Data for Preview Deployments

No one likes to open up a website and see an empty UI. Or worse, to start up a fresh clone of a project to a host of errors because some configuration is expected to be in your brand-new database. Now that [preview deployments](https://docs.convex.dev/production/hosting/preview-deployments) make it easier than ever to test out backend changes, it’s especially helpful to have a fast way to populate a new database instance during development.. How can you bootstrap your project’s data on a fresh install?

In this post we’ll look at some options for “seeding” your database. You can do this when you first create a project, every time you create a preview deployment, or whenever you want to wipe the slate clean and start over. We’ll look at a few different approaches and their pros and cons, and then I’ll share the workflow that I’ve personally found most useful. We’ll be talking about strategies for Convex, but the concepts are general.

_Short on time? Feel free to skip ahead to [my personal recommendations](https://stack.convex.dev/seeding-data-for-preview-deployments#my-workflow-preference)._

## Three ways to add data to your project

### 1\. Manual entry on the dashboard

The most straightforward way to add data to a project is to add it yourself.

To add data in Convex, go to your [dashboard](https://dashboard.convex.dev/), open or create the table you want to populate, and click “Add Documents” to write (or paste) JSON to define your documents. You can add many objects in an array, or one at a time.

In a SQL-based app, this would look like doing manual `INSERT` statements on your tables on the command line.

**Pros:**

- Dead simple, and fast to iterate on without changing contexts. You can go straight from inserting to editing a document in the dashboard.

**Cons:**

- You can only add documents to one table at a time.
- It’s a lot of typing if you aren’t copying them from a file. If you **are** copying from a file, see the next section for a faster way.

If you’re the only developer not using [preview deployments](https://docs.convex.dev/production/hosting/preview-deployments) and are infrequently making breaking schema changes, this might be all you need. If not, read on.

### 2\. Importing from the CLI

You can use `npx convex import` to add a lot of data at once. If you had an array of JSON objects you were copying into your database using the dashboard, you may as well run this instead. A couple of features to point out:

- The supported data formats are CSV, a JSON array, [a JSONL file](https://jsonlines.org/), or a zip in the format of [`npx convex export`](https://docs.convex.dev/database/import-export/export).
- The command imports data into a single table, or many tables if it's a zip.
- You can pass `--replace` or `--append` if you already have data in that table.
- You have to pass `--prod` to import into the prod DB.
- You can use [`npx convex export`](https://docs.convex.dev/database/import-export/export) to capture a snapshot of data from an app and re-import it without losing any ID references or creation timestamps.

**Pros:**

- You can add a lot of data at once.
- You can skip the “wipe existing data” step if you pass `--replace`.
- You can add documents that have references to each other if you use the zip format.
- You can script it: for previews, you can configure your build command to something like `npx convex deploy --cmd 'npm run build' && npx convex import --table mytable mydata.csv`.

**Cons:**

- If the data doesn’t match your schema, you’re in trouble and will have to edit those data files. If you have schema validation on, the `npx convex import` command will fail (thank you schema validation!). If you have schema validation off (or haven’t specified a schema at all), your app may break when it starts working with the data in the wrong shape.

If you have simple database tables that need to be configured with dynamic data available, this might be your ticket. You can produce CSV, JSON, or zip files as part of a build step, then import them after deploying your code. Reach out to us on [Discord](https://convex.dev/community) if you want support on more complicated setups.

### 3\. Seeding data in code

Why not insert data the same way you would when running your app? Using the same APIs and sharing the same helpers? Here’s how it works:

- In Convex, you write data to the database in a [mutation](https://docs.convex.dev/functions/mutation-functions) [1](https://stack.convex.dev/seeding-data-for-preview-deployments#user-content-fn-1).
- You can call mutations from the Dashboard, or from the CLI with from the CLI with one of these commands:
  - `npx convex run` if you just want to run the command once.
  - `npx convex dev --run` if you want to run it and continuously sync code changes to your development deployment.
  - `npx convex deploy --preview-run` if you want to run the command on a new [preview deploy](https://docs.convex.dev/production/hosting/preview-deployments).
- You can configure your [`package.json` scripts](https://docs.npmjs.com/cli/v10/using-npm/scripts) to run these commands automatically, so you merely run `npm run dev` to both start your app and seed your data.
- If you need to access 3rd party services to get seed data, you can! You can have the function run an [action](https://docs.convex.dev/functions/actions), which can [call mutations](https://docs.convex.dev/functions/actions#action-context) after fetching data from an API.
- Related: see [this post](https://stack.convex.dev/generating-fake-data) for tips on using Faker.js which helps avoid naming fatigue and find bugs.

**Pros:**

- The data can reference the same types you use in your code and database schema, so as things change, your seed scripts stay up to date automatically. Otherwise seed data has a bad habit of getting out of sync with the latest database schema.
- You can re-use helpers to create documents, both in seed data and in your production code. This can keep those codepaths well-used.
- You can have multiple seed scripts that you call from different contexts, for instance setting up dummy data for previews, data with edge cases for tests, and so on.

**Cons:**

- You have to write code, and keep it up to date.
- If you want to import a lot of data, your mutation will need to import that file server-side, where it runs. If this is a lot of data, it can slow down deployment.

This is my favored approach, and the one I generally use when building new Convex apps. In particular, I have the action or mutation as the default export in `convex/init.ts` so I can refer to it on the CLI as merely `init`: `npx convex run init`.

### My workflow preference

In my projects I like to configure “seed” data in code. It can be type-checked against the latest schema and scripted to produce complicated structures.

- In my Convex project, I have a default export in `convex/init.ts` that is either a [mutation](https://docs.convex.dev/functions/mutation-functions) or an [action](https://docs.convex.dev/functions/actions). Running it adds data, or returns if data has already been added, making it safe to call many times. Use an [`internalMutation`](https://docs.convex.dev/functions/internal-functions) here, to prevent any public client from calling your mutation.
- In `package.json` I configure my [scripts](https://docs.npmjs.com/cli/v10/using-npm/scripts) to call the `init` function when first running `npm run dev` with `convex dev --run init`: full scripts setup can be seen [here](https://github.com/get-convex/convex-tour-chat/blob/main/package.json#L9).
- For [preview deploys](https://docs.convex.dev/production/hosting/preview-deployments), I set the build command to be `npx convex deploy --cmd 'npm run build' --preview-run init`.
- When making a breaking change to the schema, I make the change, update the `init` function (usually just chasing down TypeScript errors), clear tables, and re-initialize.

## Summary

Storing seed data is useful for adding configuration data, dummy data for previews or during development, and more. We looked at three ways of seeding data, and you can look forward to more ways coming in the future 🤫. If you want to continue the discussion, come [join us in Discord](https://convex.dev/community)!

### Footnotes

1. **Note** you should use an [`internalMutation`](https://docs.convex.dev/functions/internal-functions) here, to prevent any public client from calling your mutation. You can still run them with `npx convex run myFile:myInternalMutation`, `npx convex dev --run myFile:myInternalMutation`, or `npx convex deploy --cmd 'npm run build' --preview-run myFile:myInternalMutation`. [↩](https://stack.convex.dev/seeding-data-for-preview-deployments#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# SELECT DISTINCT without SQL

### What is SELECT DISTINCT?

The `SELECT DISTINCT` statement is a SQL command commonly utilized to retrieve unique records from the database. The `DISTINCT` clause eliminates duplicate values in the result set, ensuring that each returned row is distinct based on specified criteria. It’s a powerful and useful feature of [most databases](https://stack.convex.dev/convex-vs-relational-databases&sa=D&source=docs&ust=1732326426081485&usg=AOvVaw2-qhGFjbpLGPV4oBfFMyXY).

Suppose you have a table named Customers with the following columns: CustomerID, CustomerName, City, and Country. You want to retrieve a list of unique cities where your customers are located. You would use the following `DISTINCT SQL` query to achieve this:

```sql
SELECT DISTINCT City
FROM Customers;

```

To achieve this functionality, the database does a lot of work behind the scenes. Specifically, it will use its [query planner](https://en.wikipedia.org/wiki/Query_plan) to create a best-effort plan for efficient data retrieval, but crucially, it’s imperfect. This can sometimes lead to `SELECT DISTINCT` not working as expected, especially in complex queries.

From [Wikipedia](https://en.wikipedia.org/wiki/Query_plan):

> When a query is submitted to the database, the query optimizer evaluates some of the different, correct possible plans for executing the query and returns what it considers the best option. Because [query optimizers](https://stack.convex.dev/queries-that-scale) are imperfect, **database users and administrators sometimes need to manually examine and tune the plans produced by the optimizer to get better performance.**

For large tables (on the order of hundreds of thousands of rows or more) or [complex queries](https://stack.convex.dev/complex-filters-in-convex), it’s common that the developer will have to provide hints to the database on how to optimally run a `DISTINCT` statement, which requires that developer to have specialized knowledge of the data design and that database’s optimization features.

Because of [Convex's fundamental design](https://stack.convex.dev/how-convex-works), it obviates these challenges for even the largest tables. You can get consistent, unsurprising [OLTP](https://stack.convex.dev/fivetran-alpha#oltp-and-olap-databases) performance without having to massage the query planner with hints.

### `SELECT DISTINCT` in Convex

Convex doesn’t have a built-in `DISTINCT` statement because it can be accomplished with existing primitive operators. And what do you gain? You get consistent and [predictable `SELECT DISTINCT` performance](https://stack.convex.dev/convex-query-performance)!

However, there is an ergonomic library for doing this. You can [read more about it here](https://stack.convex.dev/merging-streams-of-convex-data), and see the [translation of other SQL statements here](https://stack.convex.dev/translate-sql-into-convex-queries). Here's a taste of what it looks like to get the distinct cities in a given country:

```ts
const distinctCities = stream(ctx.db, stream)
  .query("customers")
	.withIndex("by_country_city", q => q.eq("country", country))
	.distinct(["city"])
	.map(async (customer) => customer.city);

```

Want to understand how this works and how you'd do this yourself? Read on.

With conventional databases, you typically want to minimize the number of SQL statements your code executes against the database. That’s in part because executing statements from your server to the database incurs the overhead of sending the data back and forth for each round-trip. To solve for this potential performance pitfall, [relational databases](https://stack.convex.dev/convex-vs-relational-databases) like MySQL, SQL Server, and Postgres provide special syntax for common operations, like `DISTINCT`. Using this special SQL syntax, the database can offer functionality that requires multiple queries with a single round-trip.

Because [Convex functions](https://docs.convex.dev/functions) run next to the database in the [reactor](https://docs.convex.dev/tutorial/reactor), we don’t require special syntax to get good `SELECT DISTINCT` performance. Here’s an example of how to achieve `SELECT DISTINCT` functionality in [Convex using indexes directly](https://docs.convex.dev/database/indexes/indexes-and-query-perf).

Say you have a simple version history table with columns for service and version. The data includes 1000s of versions across a small handful of services. Here’s a Convex table schema:

```protobuf
export default defineSchema({
  version_history: defineTable({
    service: v.string(),
    version: v.string(),
  }).index("by_service", ["service", "version"]),
6});

```

How would you query for the unique set of `K` services in this table of `N` rows? In SQL, you might write `SELECT DISTINCT(service) FROM version_history` , especially when you have many versions and few services. What is this doing under the hood? It aims to return one entry for each service, but what index can it use to do this efficiently?

Think of a [database as a spreadsheet](https://stack.convex.dev/databases-are-spreadsheets). How would you sort these columns to get a tidy list? As we've explained in our articles about [why SQL reads are too powerful](https://stack.convex.dev/not-sql#sql-sucks-3-reads-are-too-powerfu), [the limitations of SQL query languages](https://stack.convex.dev/convex-vs-relational-databases#query-language), and [how to fetch exactly what you need](https://stack.convex.dev/queries-that-scale#problem), we believe in consistent query performance for OLTP workloads. This performance shouldn't be at the mercy of an opaque query planner.

## How to do it

To efficiently solve this query for this workload, a database must make `K+1` single-row queries to the database on the `by_service` index. Each query skips forward to the next `service` , allowing the workload to be `O(K)` rather than the naive `O(N)`.

In Convex, you can write a [query function](https://docs.convex.dev/functions/query-functions) like this

```protobuf
export const latestVersionForServices = query(async (ctx) => {
  const latestVersions = {};
  let doc = await ctx.db
    .query("version_history")
    .withIndex("by_service")
    .order("desc")
    .first();
  while (doc !== null) {
    latestVersions[doc.service] = doc.version;
    const service = doc.service;
    doc = await ctx.db
      .query("version_history")
      .withIndex("by_service", (q) => q.lt("service", service))
      .order("desc")
      .first();
  }
  return latestVersions;
18});

```

This function efficiently solves this query for cases where the `K << N`, minimizing the [read set](https://stack.convex.dev/how-convex-works#read-and-write-sets) required. A smaller read set leads to fewer [conflicts from mutations](https://docs.convex.dev/error), fewer [query invalidations](https://stack.convex.dev/caching-in), and fewer [function re-executions](https://stack.convex.dev/retry-actions). See [How Convex Works](https://stack.convex.dev/how-convex-works#read-and-write-sets) for more details, but in short, this means that the query function only reads from these intervals, and will only conflict with writes to these intervals. Let’s take this dataset with 8 rows and 3 services.

| service | version |
| --- | --- |
| apple agitator | 1 |
| apple agitator | 3 |
| apple agitator | 7 |
| apple agitator | 9 |
| banana blender | 1 |
| banana blender | 5 |
| cherry crusher | 6 |
| cherry crusher | 7 |

This query function starts by fetching the first row on the `by_service` index descending, leading to the read set of the interval `((cherry crusher), 7), inf)` . Then it queries on the `by_service` index for the next alphabetically earlier service - skipping backwards. This adds a second interval to the read set: `[(banana blender, 5), (cherry crusher, -inf)]`. As we repeat this process, we end up with this final read set:

```protobuf
1(-inf, (apple agitator, -inf)]
2((apple agitator, 9), (banana blender, -inf)]
3((banana blender, 5), (cherry crusher, -inf)]
4((cherry crusher), 7), inf)

```

This means that the query function only invalidates when a new service is added, removed, or the latest version of a given service changes. The query itself can efficiently use the [index](https://docs.convex.dev/database/indexes/) to skip around and calculate the set of services in `O(K)` rather than a [full `O(N)` table scan](https://docs.convex.dev/api/interfaces/server.QueryInitializer#fulltablescan).

### `SELECT DISTINCT` Performance in Convex

Keen observers might be curious about the performance of running `K` select statements in a while loop. Conventionally, the idea of looping through select statements seems expensive in terms of performance. However, [Convex is not conventional](https://stack.convex.dev/searching-for-sanity). With Convex, [functions run _inside the database,_](https://stack.convex.dev/horizontally-scaling-functions#how-does-convex-run-functions) meaning round-trip latency is nominal and makes this approach extremely performant.

And unlike Postgres, where SELECT DISTINCT ON clauses might add some optimization, Convex's approach ensures consistent performance without special syntax.

## Summary

This example is similar to how a query planner might choose to optimize such a query, but with Convex you can get consistent, unsurprising OLTP performance without having to massage the query planner with hints. Whether you're familiar with `SELECT` `DISTINCT` in SQL Server, Postgres, or other databases, Convex's method offers a fresh perspective on selecting distinct rows efficiently.

Read more about the shortcomings of SQL in OLTP workloads [here](https://stack.convex.dev/not-sql#sql-sucks-3-reads-are-too-powerful).

Read more about a how to translate SQL statements into Convex syntax [here](https://stack.convex.dev/translate-sql-into-convex-queries) and check out [this awesome library](https://stack.convex.dev/merging-streams-of-convex-data).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Sessions: Wrappers as "Middleware"

Good news! There's a new set of helpers in `npm i convex-helpers@latest` for session tracking. See this [new post](https://stack.convex.dev/track-sessions-without-cookies) for more details. This post lays out an implementation that has an explicit "sessions" table that requires a server roundtrip before usable on the client, whereas the new implementation has an immediately-available session ID on the client and leans more on foreign keys.

![Store per-session data in Convex](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fd88710666eaa61506b696ba7bf59416e1b149858-4446x3334.jpg&w=3840&q=75)

Session tracking is a common practice for application servers. While most of your data is associated with a user or another document, sometimes you have data specific to a user’s tab, or associated with a user who isn’t logged in. Some of this data is stored on the client, such as in the browser’s `sessionStorage` or `localStorage`, while other data is stored on the server. This post will dive into how to implement session storage with Convex using some helper functions we wrote. The code is [here](https://github.com/get-convex/convex-helpers/tree/npm/0.1.1).

**User data:**

Typically user data is stored on the server to avoid accidental leakage of personal data on public computers. Because this data can exist without a logged-in user, it can enable representing and capturing data about anonymous users. This is great news for building multiplayer experiences where you don’t want to require logging in. This might also be where you store the signed-in user. With [Convex, auth is built in](https://docs.convex.dev/using/auth), your serverless functions execute close to the database, and [queries are cached](https://docs.convex.dev/functions/query-functions#caching--reactivity), so you don’t have to worry about user caching. You can just store a `userId` and look up the latest data each time.

**Ephemeral state:**

Storing session data also provides a more continuous experience for a logged-in user because you can have per-tab information on where they are in the application. Suppose there is a complex multi-step flow, like booking an appointment. In that case, they can book two different appointments simultaneously without losing their progress if they refresh the page and without storing that sensitive data in the browser’s storage.

## How to implement sessions with Convex

Continuing the series of Wrappers as “Middleware,” I built some functions to wrap your serverless functions to provide session data. It stores your session data in a “sessions” table in your Convex backend. Because this also requires keeping track of the session ID in the client, I’ve also written some wrappers for `useQuery` and `useMutation` to make it easy.

**Note:** Since the wrappers series, my recommended workflow for wrapping server-side functions has changed to use "custom functions" which you can read more about [here](https://stack.convex.dev/custom-functions). The syntax for usage is generally the same, but is easier to work with.

### Using sessions:

1. In addition to a `ConvexProvider`, wrap your app with a `SessionProvider`:





```tsx
1<ConvexProvider client={convex}>
  <SessionProvider>
    <App />
  </SessionProvider>
5</ConvexProvider>

```

2. Use `queryWithSession` or `mutationWithSession` as your function:





```ts
export const send = mutationWithSession({
	  args: { body: v.string() },
  handler: async (ctx, { body }) => {
		  const userId = await getOrCreateUserId(ctx.db, ctx.auth, ctx.sessionId);
    await ctx.db.insert("messages", { body, userId });
		},
7});

```


Use `useSessionQuery` or `useSessionMutation` in your React client:

```ts
const sendMessage = useSessionMutation(api.messages.send);
2...
sendMessage({body});

```

1. Write any data that you want to be available in subsequent session
requests to the `sessions` table. E.g. in our `getOrCreateUserId` function we could do this:





```ts
	const anonymousUserId = await db.insert('users', { anonymous: true });
db.patch(sessionId, { userId: anonymousUserId });

```





**Note on session table vs. ID:** In [this post](https://stack.convex.dev/track-sessions-without-cookies) I outline a strategy for having the `sessionId` be client-created, and instead of having a "sessions" table, using the session ID as a foreign key reference into the tables where you store data. The advantage of that, other than avoiding the server roundtrip to make a session document to get the ID, is that your session queries won't al load (and therefore depend) on the same document. If every query loads the session document, then on every update to that document your queries will all be invalidated, even if they didn't need that field of the session document. By storing the session-related data in more targeted tables, you can only be loading the data you need. Read more about query optimizations [here](https://stack.convex.dev/queries-that-scale).


## How it works

Under the hood, what it is doing is quite simple.

1. It creates a new session in the `SessionProvider` context. Whether it creates a server-side document and uses its ID, such as [this older implementation](https://github.com/get-convex/convex-helpers/tree/npm/0.1.1), or creating a session ID client-side like [this post](https://stack.convex.dev/track-sessions-without-cookies), it then stores the session ID in `sessionStorage` or, optionally, `localStorage`.[1](https://stack.convex.dev/sessions-wrappers-as-middleware#user-content-fn-1) Notes on one versus the other are below.
2. It passes that `sessionId` as a parameter in each `query` or `mutation` where you use `useSessionQuery` or `useSessionMutation`.
3. The serverless functions define a `sessionId` parameter manually or automatically with a custom wrapper, and pass it along as a field of `ctx` so the other function arguments aren't cluttered with it.

### `sessionStorage` vs. `localStorage`

If you want the session to be shared between all tabs in a browser, use `localStorage`. I like the behavior of `sessionStorage` for general use:

- When you refresh a page, the data persists. The data is tied to a specific tab.
- If you open a new tab, you start fresh.
- If you use the “Reopen Closed Tab” feature on Chrome, the data is still there.

For `localStorage`:

- `localStorage` is a great place for custom authentication information, since a user generally doesn't want to re-authenticate on every tab they open. However, you should be able to invalidate the sessions server-side, and clear or replace the `sessionId` on the client when they log out. See [this post](https://stack.convex.dev/track-sessions-without-cookies) for more info.
- Remember to account for multiple tabs interacting with the same data. For instance, if you're keeping track of a user's shopping cart, one tab can go through checkout, while the other tab is in a payment selection modal. Thanks to Convex, the data will automatically update on each tab, but it's up to you to design a UI that responds to those updates in a user-friendly way.
- Some data may make sense to be stored at the browser level, such as answering questions like “have I seen this browser before.”
- Keep public computers in mind - the same `localStorage` doesn't always map to the same human.

## Summary

In this post we looked at implementing session storage in Convex, using a custom table and some convenience wrappers which make it easy to use session-specific data in your server-side code. We look forward to seeing what you build with it.

Check out the old code [here](https://github.com/get-convex/convex-helpers/tree/npm/0.1.1) or the newer approach [here](https://stack.convex.dev/track-sessions-without-cookies).

### Footnotes

1. In the newer [`convex-helpers` package](https://www.npmjs.com/package/convex-helpers) you can specify a custom `useStorage` hook that isn't limited to `localStorage` or `sessionStorage`. [↩](https://stack.convex.dev/sessions-wrappers-as-middleware#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Testing patterns for peace of mind

Every engineer knows that testing is a “good thing” but many have the same reluctant acceptance as one might have towards eating their vegetables. Attitudes like aiming for 100% code coverage, or going through the motions of writing meaningless unit tests, often don’t do much to improve the actual correctness of a system despite consuming a lot of engineering effort. I’m not going to argue that you test everything on principle, but rather outline concrete steps you can take at various levels of your stack. As a gut-check, I’d suggest looking them over and see which makes sense for your system, making one targeted investment at a time. As I say in the [parent post about operational maturity](https://stack.convex.dev/operational-maturity-for-production), there isn’t a destination where you’ll be “done” with testing. Rather, treat it as an ongoing process that you improve as your app matures. In general I would encourage investment in roughly the order they’re presented.

#### Manual testing in development environment

Hopefully you try your code locally before having it reviewed or pushing it to production. This might seem obvious, but there are a few best practices to make this more effective. It helps to actually detail in your commit or pull-request message how you manually tested the change. Adding screenshots or print outs of outputs can be helpful for reviewers to double check that your manual test was indeed successful. It’s also important when iterating on a change to always repeat the full manual test on the latest version of your code. Since manual testing takes a lot of time, you should figure out how to automate at least some form of tests as soon as possible.

#### Testing core business logic

The simplest tests assert the basic business behavior of your app. You should start by testing the logic that is core to your value proposition, and anything to do with security or accounting. Encode the guarantees you want the code to make, not just to validate your logic today, but also to catch regressions or accidental changes that may indirectly break a core invariant. For a full-stack app, the backend API is the perfect place to exercise your code and assert its behavior.

Convex comes with a library that mocks the backend running your functions and lets you write tests that execute fast. Fast tests are important so that you can write as many of them as you need, and get a signal back quickly during development and in CI. Check out the [Testing page in Covex docs](https://docs.convex.dev/functions/testing).

### End-to-end testing

#### Manual testing on each PR via preview deployments

Preview deployments allow you to test new code in a production-like environment. This is often triggered by creating a branch and pull request on GitHub, and common with frontend hosting providers like [Vercel](https://docs.convex.dev/production/hosting/vercel#preview-deployments) and [Netlify](https://docs.convex.dev/production/hosting/netlify#deploy-previews). This allows reviewers to play around with your code, without checking out your branch and running it locally. If you’re using SSR, ISR, SSG, RSC, or any other frontend optimizations that change how your app is built, this will also help you see that behavior in a more representative environment than a local instance.

With Convex Pro you can also [provision a preview Convex deployment](https://docs.convex.dev/production/hosting/preview-deployments) to have a per-preview backend alongside your preview frontend and test your full-stack app without affecting the data in your production app.

#### Adding smoke tests as an end-to-end sanity check

“Smoke” tests are very basic tests to ensure there are no glaring issues. The term comes from testing hardware where simply plugging in a device and checking for smoke can catch mistakes, even if none of the advanced functionality is exercised.

For web apps you can write sophisticated tests using a tool like [Cypress](https://www.cypress.io/) or [Playwright](https://playwright.dev/), but you can also catch a surprising number of bugs from a test that simply loads the page. I’d recommend starting here and expanding browser testing as pages and functionality stabilize.

You can run smoke tests against a local backend.

#### Running tests against a local backend

You can spin up a local backend to run tests that go from a client all the way through to the database. Running it locally helps in quickly creating fresh instances to test against, and allows you to scale running these tests without using hosting resources. It won’t catch issues involving your hosted configuration (such as any firewalls between your backend and other resources you might access in tests), for which running tests or manually testing in a hosted backend can help.

[Use the guide here](https://stack.convex.dev/testing-with-local-oss-backend) for running a local open-source Convex backend.

### Testing in production

In addition to tests that run in isolation, there are some places where the thing you are testing is the production ecosystem itself - the hosting, access patterns, unique user behavior, etc.

#### Staging deployments

Before you launch your app to everyone, you can deploy to a project that is set up similarly to production, but only serves a subset of users - usually employees, manual user testers, and alpha users. These deployments can happen more frequently than production, such as on every PR merged into `main` or via a daily cron. This allows developers to see their change “live” and catch any bugs they missed in the preview deployment environment.

In Convex you can use a separate project for either the staging or actual production deployment. See [Production page in docs](https://docs.convex.dev/production#staging-environment).

#### Liveness checks using Pingdom

[Pingdom](https://www.pingdom.com/) is one of many services that will regularly make dummy requests to your application to help catch when your site goes down. Tests that run within your regular environment, or metrics about your site health can fall short of catching issues like a mis-configured DNS record or VPC. Does your app have no issues because it’s bug free or because no one can access it? It can also help detect when you **aren’t** down, but think you are because of a change in metrics reporting. Having an external service execute a basic request once in a while adds another layer of reassurance and debugging information.

#### Data verification via background jobs

Convex is a robust ACID-compliant database with serializable isolation and many great transactional guarantees, but it won’t prevent you from violating your own logical invariants, such as having every user be a member of at least one team. Testing is a layered approach and that layer needs to extend into a running application and verifying that logical invariants are maintained. At scale, some invariants cannot be enforced inside transactions, so you’ll need to periodically verify these asynchronously.

For instance, if you are building a social network, at scale you’ll want to denormalize the number of friends a user has, rather than querying all of their friends when you want to display a count. When you add a friend, you’ll increment their friend count, and when they’re removed, you decrement it. If you change this behavior and introduce a bug, it’s not mission-critical, but it would be good to catch as soon as possible. One way to achieve this is to sanity check the number of friends for all users modified in a mutation. However, this can bloat the transaction and negate the performance benefits of denormalization. A more scalable approach is to routinely walk the data and re-compute derived fields, alerting on any inconsistencies found so a developer can find the bug and patch the incorrect data. These offline checks are not an immediate priority, but are especially helpful as your team grows and data becomes more mission-critical.

#### Feature gating risky changes for instant rollbacks

You can ship new features that are gated behind some remotely configured flag, which allows you to deploy the new code and turn on the new feature at different times. You can also use the flag to turn off features that don’t work as intended. When making riskier changes, it’s safer to leave the code around for the older version, and gradually release the newer version, monitoring for regressions. To start you can [achieve this in Convex](https://stack.convex.dev/feature-gating) with a simple “flags” table. As your needs grow to managing cohorts and gradual rollouts, you’ll likely want a product like [LaunchDarkly](https://launchdarkly.com/) which also has tooling for A/B tests.

## Summary

As your app matures, tests will help you stay sane, and allow you to focus on your product. They come in many shapes and sizes, testing various parts of the stack and anything from business logic to infrastructure configuration. What is the area you feel your app is most vulnerable? Where could you make a small investment with a big potential impact? Pick off one thing at a time and prioritize it against other investments in your app’s operational maturity that you can [read about here](https://stack.convex.dev/operational-maturity-for-production).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# The Magic of Embeddings

How similar are the strings “I care about strong ACID guarantees” and “I like transactional databases”? While there’s a number of ways we could compare these strings—syntactically or grammatically for instance—one powerful thing AI models give us is the ability to compare these semantically, using something called _embeddings_. Given a model, such as OpenAI’s `text-embedding-ada-002`, I can tell you that the aforementioned two strings have a similarity of 0.784, and are more similar than “I care about strong ACID guarantees” and “I like MongoDB” 😛. With embeddings, we can do a whole suite of powerful things:[1](https://stack.convex.dev/the-magic-of-embeddings#user-content-fn-1)

- **Search** (where results are ranked by relevance to a query string)
- **Clustering** (where text strings are grouped by similarity)
- **Recommendations** (where items with related text strings are recommended)
- **Anomaly detection** (where outliers with little relatedness are identified)
- **Diversity measurement** (where similarity distributions are analyzed)
- **Classification** (where text strings are classified by their most similar label)

This article will look at working with raw OpenAI embeddings. If you want to play around with embeddings yourself, check out this repo:

[ianmacartney/ **embeddings-in-convex**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/ianmacartney/embeddings-in-convex)

## What is an embedding?

An embedding is ultimately a list of numbers that describe a piece of text, for a given model. In the case of OpenAI’s model, it’s always a 1,536-element-long array of numbers. Furthermore, for OpenAI, the numbers are all between -1 and 1, and if you treat the array as a vector in 1,536-dimensional space, it has a magnitude of 1 (i.e. it’s “normalized to length 1” in linear algebra lingo).

On a conceptual level, you can think of each number in the array as capturing some aspect of the text. Two arrays are considered similar to the degree that they have similar values in each element in the array. You don’t have to know what any of the individual values correspond to—that’s both the beauty and the mystery of embeddings—you just need to compare the resulting arrays. We’ll look at how to compute this similarity below.

Depending on what model you use, you can get wildly different arrays, so it only makes sense to compare arrays that come from the same model. It also means that different models may disagree about what is similar. You could imagine one model being more sensitive to whether the string rhymes. You could fine-tune a model for your specific use case, but I’d recommend starting with a general-purpose one to start, for similar reasons as to why to generally pick Chat GPT over fine-tuned text generation models.

It’s beyond the scope of this post, but it’s also worth mentioning that we’re just looking at text embeddings here, but there are also models to turn images and audio into embeddings, with similar implications.

## How do I get an embedding?

There are a few models to turn text into an embedding. To use a hosted model behind an API, I’d recommend [OpenAI](https://platform.openai.com/docs/guides/embeddings), and that’s what we’ll be using in this article. For open-source options, you can check out [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2#all-minilm-l6-v2) or [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2).

Assuming you have an [API key](https://platform.openai.com/account/api-keys) in your [environment variables](https://docs.convex.dev/production/hosting/environment-variables), you can get an embedding via a simple `fetch`:

```jsx
export async function fetchEmbedding(text: string) {
  const result = await fetch("https://api.openai.com/v1/embeddings", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: "Bearer " + process.env.OPENAI_API_KEY,
    },
    body: JSON.stringify({
      model: "text-embedding-ada-002",
      input: [text],
    }),
  });
  const jsonresults = await result.json();
  return jsonresults.data[0].embedding;
15}

```

For efficiency, I’d recommend fetching multiple embeddings at once in a batch.

```jsx
export async function fetchEmbeddingBatch(texts: string[]) {
  const result = await fetch("https://api.openai.com/v1/embeddings", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: "Bearer " + process.env.OPENAI_API_KEY,
    },

    body: JSON.stringify({
      model: "text-embedding-ada-002",
      input: texts,
    }),
  });
  const jsonresults = await result.json();
  const allembeddings = jsonresults.data as {
    embedding: number[];
    index: number;
  }[];
  allembeddings.sort((a, b) => a.index - b.index);
  return allembeddings.map(({ embedding }) => embedding);
21}

```

## Where should I store it?

Once you have an embedding vector, you’ll likely want to do one of two things with it:

1. Use it to search for similar strings (i.e. search for similar embeddings).
2. Store it to be searched against in the future.

Vector databases allow you to quickly find nearby vectors for a given input, without having to compare against every vector every time. If you expect to have 100k or fewer vectors, you can store it alongside your other application data in Convex and [use a `vectorIndex`](https://docs.convex.dev/vector-search) \- this allows you to avoid adding another database provider to your stack. If you plan to store millions of vectors, however, I’d recommend using a dedicated vector database like [Pinecone](https://www.pinecone.io/). See [this post](https://stack.convex.dev/pinecone-and-embeddings) for more details on using Pinecone with Embeddings in Convex.

In my case, if I want to suggest [Stack](https://stack.convex.dev/) posts similar to a given post or search, I only need to compare against fewer than 100 vectors, so I can just fetch them all and compare them in a matter of milliseconds using the Convex database.

### How should I store an embedding?

If you’re storing your embeddings in Pinecone, see [this post](https://stack.convex.dev/pinecone-and-embeddings) for a dedicated post on it, but the short answer is you configure a Pinecone “Index” and store some metadata along with the vector, so when you get results from Pinecone you can easily re-associate them with your application data. For instance, you can store the document ID for a row that you want to associate with the vector.

If you’re storing the embedding in Convex, you can [store it as a number array](https://docs.convex.dev/vector-search#defining-vector-indexes) (the way it's returned from APIs like OpenAI).

You can represent the embedding as a field in a table [in your schema](https://docs.convex.dev/database/schemas):

```ts
embeddings: defineTable({
  text: v.string(),
  vector: v.array(v.number()),
4}).vectorIndex("vector", { vectorField: "vector", dimensions: 1536 }),

```

In this case, I store the vector and define a vector index to search by. Read the docs [to see how to use vector search in Convex](https://docs.convex.dev/vector-search#defining-vector-indexes).

Read on to see the underlying math if you want to compare embeddings without using a vector index.

## How to compare embeddings in JavaScript manually

If you’re looking to compare two embeddings from OpenAI without using a vector database, it’s very simple. There’s [a few ways of comparing vectors](https://www.pinecone.io/learn/roughly-explained/distance-between-vectors/), including Euclidean distance, dot product, and cosine similarity. Thankfully, because OpenAI normalizes all the vectors to be length 1, they will all give the same rankings! With a simple [dot product](https://www.notion.so/Product-f8d495cd1e29469289011becf658f547?pvs=21) you can get a similarity score ranging from -1 (totally unrelated) to 1 (incredibly similar). There are optimized libraries to do it, but for my purposes, this simple function suffices:

```jsx
1/**
 * Compares two vectors by doing a dot product.
 *
 * Assuming both vectors are normalized to length 1, it will be in [-1, 1].
 * @returns [-1, 1] based on similarity. (1 is the same, -1 is the opposite)
 */
export function compare(vectorA: number[], vectorB: number[]) {
  return vectorA.reduce((sum, val, idx) => sum + val * vectorB[idx], 0);
9}

```

#### Example

In this example, let’s make a function (a Convex [query](https://docs.convex.dev/functions/query-functions) in this case) that returns all of the embeddings and their similarity scores in order based on some query embedding, assuming a table of `embeddings` as we defined above, and the `compare` function we just defined.

```ts
export const compareTo = query(async (ctx, { embeddingId }) => {
  const target = await ctx.db.get(embeddingId);
  const embeddings = await ctx.db.query("embeddings").collect();
  const scores = await Promise.all(
    embeddings
      .filter((embedding) => !embedding._id.equals(embeddingId))
      .map(async (embedding) => {
        const score = compare(
          target.vector,
          embedding.vector
        );
        return { score, text: vector.text, embddingId: embedding._id };
      })
  );
  return scores.sort((a, b) => b.score - a.score);
16});

```

## Summary

In this post, we looked at embeddings, why they’re useful, and how we can store and use them in Convex. To read more about using the Convex vector search, [check out the docs](https://docs.convex.dev/vector-search). If you want to see how to use embeddings with Pinecone and Convex, check out [this post](https://stack.convex.dev/pinecone-and-embeddings). It covers chunking long input into multiple embeddings and using Pinecone alongside the Convex DB. Let us know in [our Discord](https://convex.dev/community) what you think!

### Footnotes

1. Copied from [OpenAI’s guide](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings) [↩](https://stack.convex.dev/the-magic-of-embeddings#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Throttling Requests by Single-Flighting

Building reactive applications can become an obsession. How much fast can I sync state? How can I keep my app feeling responsive? How can I avoid wasting resources?

Let’s say you want a responsive UI and care about how fast your UI can update. A naive approach would just add up the time to send the request, have it processed on the server, and receive a response. And for actions like clicking buttons, this will be a good approximation. However, it’s important to consider requests within the context of other requests. For something like capturing mouse movements or typing, requests could end up being created faster than they can be processed. If requests pile up in an outgoing queue on the client, or are competing for server resources, they may appear much slower as the user waits for previous requests to be processed. Even if your request itself is fast, if it has to wait for hundreds of prior requests to complete, it can seem slow to the end user. In these cases, it can be useful to limit how many requests the client sends. There are many ways to do this: throttling, debouncing, and server side rate limiting are the most common. Can we do better?

In this article we’ll be looking at an approach called “single flighting” or “singleflighting” and what an implementation looks like in React using Convex for the backend.

## Throttle vs. Debounce vs. Rate limit vs. Singleflight

A quick aside on terminology.

**Debouncing** refers to waiting a specified amount of time before acting on a signal. My first experience with this was in handling a potentially noisy electrical signal. When you press a button, for instance, the voltage may “bounce” for a short period, like so:

![Diagram](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F3037375e7887af09da718a2af77dbe7f53703eb1-1024x721.jpg%3Fw%3D700&w=3840&q=75)Diagram

You don’t want to send “on” and “off” signals in quick succession, you want to wait until it’s settled out and send the value once it’s settled out. You “de-bounce” the signal. In software, this could look like waiting to send a search query until the user has finished typing for some amount of time. Every time the user types another character, it resets the debounce timer. The benefit is avoiding intermediate requests that wouldn’t be used, but the cost is waiting for the debounce period to elapse. If the user keeps typing, they may never see any results!

**Throttling** is the act of spacing out requests that a client sends. In the example with the user continuously typing a search query above, a search could be executed on the first character, and every x seconds after that. So the user could start seeing results from their in-progress query as they continue typing. Under the hood, every time a request is sent, the next request will be held until some time has elapsed. If many keystrokes are issued during that time, only a single request will be sent when the time elapses, with the latest query. This limits the maximum rate at which a single client sends requests.

**Rate limiting** is more commonly referenced on the server side. Rather than clients proactively limiting themselves, this is a way for the server to push back on clients, telling them they’re requesting too much. This is referred to as “back pressure” - the server pushing back on clients when too much is being demanded of it. It can help keep a backend system from being overloaded due to spikes in traffic, though it then relies on clients to handle the request and retry later on. This is a good idea for a reliable system, but should be exceptional, not the only way of limiting client requests. Read more about implementing [rate limiting in Convex here](https://stack.convex.dev/rate-limiting), which includes a library to make it easy.

**Single flighting** is the concept of limiting requests by only ever having one request “in flight.” This is similar to throttling, in that it limits requests from the client. However, the frequency of requests isn’t specified up front, but is a function of how fast the network is, and how fast the request is processed on the server. This second factor also gives it some natural back pressure from the server, which is incredibly valuable. If the server is getting overloaded, that client won’t be sending more requests while it’s waiting for its outstanding one. It also allows us to have gradual performance degradation if many clients are executing requests in parallel. Rather than becoming overwhelmed and failing some subset of requests, the frequency of requests will decrease in each clients as the server hits a bottleneck. The only downside is that your request frequency might be slower than theoretically possible, due to time spent on network transit. Waiting until a response comes back before sending another request is slower than optimistically firing off requests continuously. Alternatively, if your requests return quickly, you might fire off more requests than are necessary and waste CPU & network resources.

As with most things, there are benefits to each, and weighing these strategies is part of the job of the application developer. For this article, we are going to be using single flighting. This plays well with Convex, since the convex client executes mutations serially. With serial execution, debouncing and throttling both risk piling up requests, if they aren’t processed as fast as they’re created. Single flighting helps us avoid this, providing a consistently responsive user experience.

## Implementation: useEffect loop with useLatestValue

One way to achieve single flighting requests is to sit in an infinite loop, waiting for a new value to send and then waiting on the request. This leverages a hook we wrote: `useLatestValue`. This provides two functions: one to update some value, and another that you can await for the latest value, blocking until there’s a newer value than what you’ve already received. It is conceptually similar to a `Promise` where you can keep calling `resolve` with newer values to overwrite the value returned when awaited. Before we talk about how it’s implemented, let’s look at an example of how it might be used:

```tsx
type Pos = {x: number, y: number};

const updatePresence = useMutation(api.presence.update);
const [nextPosition, setPosition] = useLatestValue<Pos>();

useEffect(() => {
  let run = true;
  (async () => {
    while (run) {
		  const position = await nextPosition();
			await updatePresence({ presenceId, position });
    }
  })();
  return () => { run = false; };
15}, [nextPosition, updatePresence]);

return <div onPointerMove={(e) => setPosition({
	x: e.clientX,
  y: e.clientY,
20})}>...</div>

```

This sends position updates whenever a new value is available. The `nextPosition()` promise will resolve when the value is updated. If one or more `setPosition` calls happen before awaiting `nextPosition`, it will immediately return the value from the latest call when it is eventually awaited.

The `useLatestValue` hook helpers are in a working project [here](https://github.com/get-convex/convex-helpers/tree/main/src/hooks). You can use it as is, but for those who are curious how it works, see below.

`useLatestValue` details...

`useLatestValue` uses a `Promise` as a signal that a new value is available. The result of a `Promise` can’t be updated once it’s resolved, so the value is stored separately. When a value is retrieved, the `Promise` is awaited, the latest value returned, and the signal reset. Updating the value just involves updating the value and resolving the `Promise`, relying on the behavior that subsequent calls to `resolve` is a no-op if it’s already been resolved.

```ts
export default function useLatestValue<T>() {
  const initial = useMemo(() => {
    const [promise, resolve] = makeSignal();
    // We won't access data until it has been updated.
    return { data: undefined as T, promise, resolve };
  }, []);
  const ref = useRef(initial);
  const nextValue = useCallback(async () => {
    await ref.current.promise;
    const [promise, resolve] = makeSignal();
    ref.current.promise = promise;
    ref.current.resolve = resolve;
    return ref.current.data;
  }, [ref]);

  const updateValue = useCallback(
    (data: T) => {
      ref.current.data = data;
      ref.current.resolve();
    },
    [ref]
  );

  return [nextValue, updateValue] as const;
25}

const makeSignal = () => {
  let resolve: () => void;
  const promise = new Promise<void>((r) => (resolve = r));
  return [promise, resolve!] as const;
31};

```

## Implementation: useSingleFlight callback

Another model that avoids the scary infinite loop is using a helper we wrote: `useSingleFlight` which will run a given async function at most once at a time. If no calls are in progress, it will call the function immediately. Otherwise, when the current call finishes, it will call the function again, using the most recent arguments.

```tsx
const updatePresence = useMutation(api.presence.update);
const tryUpdate = useSingleFlight(updatePresence);
return <div onPointerMove={(e) => tryUpdate({
	x: e.clientX,
  y: e.clientY,
6})}>...</div>

```

While it isn’t used here, it’s worth mentioning that `tryUpdate` will always return a `Promise`. If the call isn’t executed, the promise will never resolve or reject. If it is called, the result of the call will be passed through. So you could write code like:

```tsx
console.log('trying to update');
const result = await tryUpdate(pos);
console.log('updated: ' + result);

```

which would log `'trying to update'` for all event callbacks, and only log `'updated: ...'` for requests that were actually sent to the server. And if the call failed, it would throw the exception during the `await`.

The `useSingleFlight` hook helper is in a working project [here](https://github.com/get-convex/convex-helpers/tree/main/src/hooks). You can use it as is, but for those who are curious how it works, see below.

`useSingleFlight` details...

`useSingleFlight` keeps track of whether a request is in flight, using a `useRef` hook to store state. If there is a request in flight, it returns a promise, where it has extracted the `resolve` and `reject` functions to fulfill later if it’s still the latest attempt. It updates the state’s `upNext` to keep track of the arguments and promise functions. If there isn’t a request in flight, it calls the function immediately, and also kicks off an async function to check for `upNext` once the request finishes. It will keep executing the follow-up requests until it finishes without `upNext` being updated.

```tsx
export default function useSingleFlight<
  F extends (...args: any[]) => Promise<any>
3>(fn: F) {
  const flightStatus = useRef({
    inFlight: false,
    upNext: null as null | { resolve: any; reject: any; args: Parameters<F> },
  });

  return useCallback(
    (...args: Parameters<F>): ReturnType<F> => {
      if (flightStatus.current.inFlight) {
        return new Promise((resolve, reject) => {
          flightStatus.current.upNext = { resolve, reject, args };
        }) as ReturnType<F>;
      }
      flightStatus.current.inFlight = true;
      const firstReq = fn(...args) as ReturnType<F>;
      void (async () => {
        try {
          await firstReq;
        } finally {
          // If it failed, we naively just move on to the next request.
        }
        while (flightStatus.current.upNext) {
          let cur = flightStatus.current.upNext;
          flightStatus.current.upNext = null;
          await fn(...cur.args)
            .then(cur.resolve)
            .catch(cur.reject);
        }
        flightStatus.current.inFlight = false;
      })();
      return firstReq;
    },
    [fn]
  );
37}

```

### Delta challenges

While the approach may seem simple, there are some nuances worth thinking through. If you are limiting how many requests you’ll be sending, that often means some requests will never be executed, or some results won’t get reported.

Each call to `tryUpdate` above will either:

1. execute `updatePresence` immediately,
2. execute `updatePresence` after some time has elapsed, or
3. never execute `updatePresence`.

In this case, we ignore any intermediate mouse positions. This seems fine for a use case where we’re just sharing cursor location. However, if we were reporting a delta - such as reporting a series of movements rather than absolute positions, then missing intermediate values would be bad news!

Let us know in [our discord](https://convex.dev/community) if you want examples on how to handle those cases.

### Optimistic updates

One thing to keep in mind with our [Optimistic Updates](https://docs.convex.dev/using/optimistic-updates) api is that optimistic updates will only be run as often as your single-flighted function (e.g. your mutation). If you want to update local state faster than the mutations are being executed, you’ll need to manage that state separately. For example:

```tsx
const myMutation = useMutation(api.my.mutation);
const tryUpdate = useSingleFlight(withLocalStore);
const withLocalStore = useCallback((data) => {
  setLocalState(data);
  return tryUpdate(data);
6}, [setLocalState, updatePresence]);
7...

```

Note: your local state may have intermediary values that are never sent to the server, but the server state will eventually have the same final state as you have locally.

## Next Steps

We’ve looked at two ways of implementing single-flighting requests, which is a great way of preventing request pile-up and keeping UIs responsive. To see an implementation of this, check out our post on implemeting Presence in Convex (coming soon!). To get the code for our hooks, check it out [here](https://github.com/get-convex/convex-helpers/tree/main/src/hooks).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Session Tracking Via Parameter Injection

Keeping track of a user doesn't have to be creepy. Storing data associated with a user on a specific tab, or even at the browser-level can be incredibly useful. To name a few use cases:

- Allow anonymous users to view and interact with a page, such as a game where you don't want to ask every user to create an account.
- Keep track of a user's progress through a workflow without storing personal data in their browser or forcing them to log in. If you store form data directly in localStorage and don't (or can't) clean it up from the browser, the next user of the computer has access to the data. By associating the data with them server-side, you can invalidate it remotely and keep your browser storage tidy.
- Enable having a shopping cart before a user logs in, and keep it up to date between all of their tabs.
- Allow a logged-in user to have multiple tabs in different server-persisted states - such as two tabs going through purchasing flows for different concert tickets, without overwriting each other's data.

In this article we'll look at how to track and pass around session IDs in Convex.

Using server-only cookies to store these session IDs is a common approach, however it has some limitations. For one, websocket clients for realtime apps, such as the Convex React client, don't get server-only cookies automatically since headers aren't sent along with WebSocket messages. You can use client-accessible cookies in a similar way to localStorage, but all cookies introduce more risk unless configured defensively - for instance they open you up to "cross-site request forgery" attacks. This post will look at tracking sessions without cookies.

## How it works

By storing an opaque identifier on the client (in our case below, a UUID), we can avoid cluttering the user's browser with potentially private information. And by combining session IDs with authentication & authorization, we can restrict who can access the associated server data.

1. The client checks whether there's already a session ID stored locally. It can check in cookies, localStorage (per-browser), sessionStorage (per-tab), or other places. Our approach will use sessionStorage by default, but be configurable for localStorage or anywhere that you can write a hook to retrieve an ID from.
2. If there isn't already a session ID, the client generates one. This allows a session ID to always be defined and avoid a server roundtrip generating one.
3. The session ID is provided in a React Context, allowing any components mounted underneath to access the session ID when they need to.
4. When the client makes a session-specific request, it passes up the session ID that it gets from the context as a parameter to the function. There are helpers below which automatically pull the ID from context so you just have to provide the non- `sessionId` parameters.
5. The server associates data with this session ID in the database. Future requests with the session ID can then look up the associated data.
6. When a user logs in, it can make a new session and transfer any applicable data before invalidating the old session.
7. When the server wants to invalidate a session, it can delete the associationed data in the database.

## How to do it

If you're new to Convex, you can get started quickly with `npx create convex@latest`. Go read [the docs](https://docs.convex.dev/) for more details on how it all works.

Install [`convex-helpers`](https://www.npmjs.com/package/convex-helpers) via `npm i convex-helpers` if you haven't already.

### Client-side:

#### 1\. Wrap your app with `SessionProvider` to manage the session ID

```jsx
import { SessionProvider } from "convex-helpers/react/sessions";
//...
3<ConvexProvider client={convex}>
	<SessionProvider>
		<App />
	</SessionProvider>
7</ConvexProvider>

```

#### Per-tab vs. per-browser tracking

If you want to track sessions per-browser instead of per-tab, you can use a localStorage storage provider, like `useLocalStorage` in `usehooks-ts`:

```sh
npm i usehooks-ts

```

And pass it into `SessionProvider`:

```jsx
import { useLocalStorage } from "usehooks-ts";
//...
3<ConvexProvider client={convex}>
	<SessionProvider useStorage={useLocalStorage}>
		<App />
	</SessionProvider>
7</ConvexProvider>

```

While not covered here, you could also apply this to storing the value in a client cookie, if you're ok with those implications. Just pass a custom `useStorage` hook.

#### Multiple session IDs on one site

To store multiple session IDs on the same site, you can specify a custom
storage key. I find this useful so different apps I develop on localhost don't wipe out each others' values:

```jsx
1<ConvexProvider client={convex}>
	<SessionProvider storageKey="MyAppSessionId">
		<App />
	</SessionProvider>
5</ConvexProvider>

```

#### Using SSR with sessions

One challenge with `localStorage` or `sessionStorage` solutions is that the value is not available on the server during a server render. You might get hydration issues because the server generates an ID that differs from the client's. Or you might see an error trying to generate an ID with `crypto` which might not be available in your server runtime. To solve for this, the `SessionProvider` React helper has an `ssrFriendly` parameter. With this set, it will:

- Skip queries on the server if they require a session ID.
- Wait for the session ID to initialize before calling mutations or actions.
- Return undefined if you're using the lower-level `useSessionId` hook, as well as a promise that will resolve when the sessionID is available.

You could alternatively explore storing & retrieving the value from cookies by supplying a custom `useStorage` hook that fetches the same value server & client side. If you do, please share your work!

#### 2\. Access the session ID with `useSessionId`

Within the context of the SessionProvider, you can access the Session ID:

```jsx
import {  useSessionId } from "convex-helpers/react/sessions";

const [sessionId] = useSessionId();

```

You can then manually pass the `sessionId` as a parameter:

```js
await convex.query(api.myModule.mySessionQuery, { sessionId });

```

For convenience methods for react hooks that automatically pass the `sessionId` parameter, read on.

#### 2\. Utilities for React hooks

For queries and mutations that want to pass up the session ID, use:

```jsx
import {  useSessionQuery } from "convex-helpers/react/sessions";

const results = useSessionQuery(api.myModule.mySessionQuery, { arg1: 1 });

```

The same exist for `useSessionMutation` and `useSessionAction`.

### Server-side:

#### 1\. Define session functions by accepting a `sessionId` argument

```js
import { SessionIdArg, vSessionId } from "convex-helpers/server/sessions";
import { query } from "./_generated/server";
3![![](https://)](https://)
const mySessionQuery = query({
	args: {
		...SessionIdArg, // equivalent to sessionId: vSessionId,
		arg1: v.number(),
	},
	handler: async (ctx, args) => {
		//...
	}
12})

```

In the handler, `args.sessionId` will be of type `SessionId`. Under the hood, the session ID is just a string, but the type `SessionId` is branded to help you avoid passing the wrong strings around. See [this post](https://stack.convex.dev/using-branded-types-in-validators) for more info on branded types.

#### 2\. Use [Custom Functions](https://stack.convex.dev/custom-functions) to codify the pattern

With helpers like `customMutation`, you can define a replacement for `mutation` that you usually use to define endpoints. These custom builders let you define functions that require extra arguments and/or populate extra fields in `ctx` and `args`:

```js
import {
  customAction,
  customMutation,
  customQuery,
5} from "convex-helpers/server/customFunctions";
import { SessionIdArg } from "convex-helpers/server/sessions";

export const mutationWithSession = customMutation(mutation, {
	args: SessionIdArg,
	input: async (ctx, { sessionId }) => {
		const anonymousUser = await getAnonUser(ctx, sessionId);
		return { ctx: { ...ctx, anonymousUser }, args: {} };
	},
14});

```

Note: this will not pass through `sessionId` as an arg unless you change the last line to `return { ctx: { ...ctx, anonymousUser }, args: { sessionId } };`.

To use the custom builder:

```js
export const doSomething = mutationWithSession({
	args: {},
	handler: async (ctx, args) => {
		// ctx.anonymousUser
	}
6})

```

I'd suggest combining session logic with other customization so you limit how many builders you have in your codebase, making it easier to audit your endpoints for how they authenticate, etc.

To further lock down usage of these functions, check out [this article on setting up ESLint rules to prevent importing the "raw" functions](https://stack.convex.dev/eslint-setup).

#### 3\. For actions use `runSessionFunctions`

Use `runSessionFunctions` to define functions `ctx.runSessionQuery` that are like `ctx.runQuery` but where it injects in the session ID, so you don't have to pass it through manually:

```js
import { SessionIdArg, runSessionFunctions } from "convex-helpers/server/sessions";

export const actionWithSession = customAction(action, {
	args: SessionIdArg,
	input: async (ctx, { sessionId }) => {

		const { runSessionQuery, runSessionMutation, runSessionAction } =
			runSessionFunctions(ctx, sessionId);

	return {
			ctx: {
				...ctx,
				runSessionQuery,
				runSessionMutation,
				runSessionAction,
			},
			args: { sessionId }, // Note: you can also pass it through as an arg.
		};
	},
20});

```

Or in shorthand:

```js
export const actionWithSession = customAction(action, {
	args: SessionIdArg,
	input: async (ctx, { sessionId }) => ({
		ctx: {
			...ctx,
			...runSessionFunctions(ctx, sessionId),
		},
		args: { sessionId }, // Note: you can also pass it through as an arg.
	}),
10});

```

### Best practices

#### Refresh your session IDs

Let's say your application uses session IDs to associate sensitive data with a logged-in user. If the user logs in when a session ID is already on the computer, that session ID could have been left behind by a malicious computer user (say on a public computer). This is called session hijacking. So it's prudent to refresh the session ID once a user logs in. When they log out, you also want to leave the browser in a "fresh" state, without references to the logged-in users's session ID. It's best practice to refresh the session ID after both logging in & logging out.

You can use the function returned as the second element from `useSessionId()` to do this.

```js
const [_, refreshSessionId] = useSessionId();
//...
const newSessionId = await refreshSessionId();

```

In fact, you can even pass in a promise where you can run an async function after the new session ID has been created, but before the previous one has been replaced, in case you want to run a mutation to associate any data server-side before it's updated on the client:

```jsx
const [sessionId, refreshSessionId] = useSessionId();
const doRefresh = useMutation(api.myModule.doRefresh);
//...
await refreshSessionId(async (newSessionId) =>
  // At this point, the new sessionId hasn't been persisted locally.
  // So if this throws, it will abort replacing the local session ID.
  await doRefresh({ old: sessionId, new: newSessionId })
8);
// At this point, the new sessionId has been persisted.

```

**Logging in:** Server-side, you may want to carry some data over from the anonymous session to the new session when a user logs in. You can do that by patching those items with the new session ID:

```js
await ctx.db.patch(shoppingCartId, { sessionId: newSessionId });

```

**Logging out:** you probably don't want to provide any association from the old to the new session ID when the user logs out, since that session should be sanitized for the next user. You should also consider deleting any data that can be accessed with the sessionID alone after logging out.

#### Use session queries sparingly

One thing to know about Convex is that caching happens automatically. If you have a subscription to a query from a client, it will automatically get re-computed when the associated data changes (even if another client / user made the change). The cache is based on the function you're calling, the arguments you provide, and the database queries it makes. This means that when you pass a session ID as a parameter, it will never be a cache hit for a user with a different session ID. So you can improve your cache hit rate by not passing parameters that you don't need. If the data doesn't actually rely on the session ID, don't pass it. For mutations, there isn't a cache, so it's less important to avoid passing extra parameters.

#### Avoid sprawling session documents

If you decide to keep a table with per-user session data, it might become tempting to store all sorts of data in there - the last time you saw them, what their current shopping cart is, what document they're looking at, or even where their cursor is. The problem with this is twofold:

1. As we saw above, if there are queries that read from this sesison data, their caches will be evicted whenever the session data changes - **even if the change was for an unrelated feature that happend to be stored in the same session document**. You'll invalidate fewer queries if you store your data such that for frequently updating information, that data is only read by queries that care about the frequent updates. Having separate tables for heartbeats, shopping carts, presence data, etc. will will better for you.
2. For mutations, Convex provides "serializable isolation" for transactions which is a fancy way of saying "you can write code without worrying about race conditions." Under the hood we run operations in parallel unless they read and write the same data, in which case we detect the possible race condition and retry the one that finished later. This means that if you have many requests that all read and write a big sessions document, there's a higher likelihood of conflict, which slows your request down (and if we keep retrying and hitting conflicts, we'll eventually fail the request). So, for mutations where there are frequent writes (such as cursor tracking), it's best to separate the documents where data is getting written frequently by independent features / tabs / users. Generally you don't have to think about this, but I'd still recommend not having one big document for everything if you'll have a nontrivial amount of read/writes for a specific document.

#### Don't expose it to other clients

If you're using the `sessionId` as anonymous / lightweight authentication, then don't pass it around / down to clients. Here are two options:

1. Use it in a [join table](https://stack.convex.dev/relationship-structures-let-s-talk-about-schemas#relationship-table-scalable): instead of defining a table like `users: defineTable({ sessionId: vSessionId, name: v.string() }).index("by_sessionId", ["sessionId"])` and looking a user up by its `sessionId`, have a table that maps session IDs to users: `logins: defineTable({ sessionId: vSessionId, userId: v.id("users") }).index("by_sessionId", ["sessionId"])`. This also enables a user to have multiple logins.

2. Strip it from documents manually before returning them. If you do have a sessionId directly on a table you're looking up from, be careful to remove it in places where you might return it to clients. For instance:





```js
return users.map((user) => {
  const { sessionId, ...rest } = user;
	return rest;
4});

```





[Zod](https://stack.convex.dev/typescript-zod-function-validation) is helpful in these instances, since you can specify what data you want to return and it will strip the rest of the fields out.


#### Invalidate session IDs

When a user logs in or out, you can immediately invalidate their previous session IDs (see the notes on refreshing above). One benefit of using a session ID tied to state in a database over a JWT is that you don't have to wait for it to expire. If you detect a security breach, you can invalidate all sessions immediately after a patch, instead of waiting around for JWT expiration.

## Summary

You can use a client-generated session ID to associate data with a browser or browser tab. With some helpers, you can automatically pass this value up as a parameter to functions, and can make custom server functions that pull the value back out.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Translate SQL into Convex Queries

Here’s a cheatsheet with examples of conversions between SQL queries and Convex queries. This article is geared towards developers (and LLMs) who have familiarity with SQL and want to translate those familiar patterns into Convex queries. You'll learn how to [`UNION`](https://stack.convex.dev/translate-sql-into-convex-queries#union), [`JOIN`](https://stack.convex.dev/translate-sql-into-convex-queries#one-to-one-join), [`DISTINCT`](https://stack.convex.dev/translate-sql-into-convex-queries#distinct), [`GROUP BY`](https://stack.convex.dev/translate-sql-into-convex-queries#group-by), do [`WHERE`](https://stack.convex.dev/translate-sql-into-convex-queries#arbitrary-filter) clauses, and [`SELECT`](https://stack.convex.dev/translate-sql-into-convex-queries#select-fields) fields.

For this article we’ll imagine you’re building a Slack-like chat app, where “users” send “messages” in “channels”. The translation should work with any app you can imagine building on a relational database with regular BTree-backed indexes. See [this article](https://stack.convex.dev/databases-are-spreadsheets) to help understand how databases are organized by indexes.

While each snippet will describe a single query, you can combine them however you like. In SQL you could use sub-queries, `UNION ALL`, or multiple statements in a transaction. In Convex you can compose the patterns as you would compose any TypeScript code.

**About the snippets:**

The SQL snippet describes what data you’re trying to fetch.

- The query will return the whole data set but could be modified with additional `LIMIT` or `OFFSET` or extra `WHERE` clauses to read incrementally.

- The SQL syntax should usually match PostgreSQL, although similar syntax is usually possible in MySQL or other variants.


Each Convex query snippet shows how to fetch equivalent data in Convex.

- The Convex query will use equivalent indexes and have equivalent performance to the SQL query.

- This translation will `.collect` all results, because yielding results incrementally is difficult without streams.


The Convex [QueryStream helper](https://stack.convex.dev/merging-streams-of-convex-data) enables you to read results incrementally, without collecting them all.

- The snippet shows how to call `.paginate` [1](https://stack.convex.dev/translate-sql-into-convex-queries#user-content-fn-1), although you can also choose to call `.take`, `.first`, `.unique`, or `.collect`.

- To use QueryStreams you would `import { stream, mergedStream } from "convex-helpers/server/stream"`. QueryStreams were added in convex-helpers version 0.1.72.


### Why Translate?

While the Convex queries below may look more complicated, there are a lot of benefits that empower your Convex queries to do exactly what you want:

- They’re guaranteed to be efficient. Unlike SQL, which can decide to stop using an index and do full table scans whenever it wants, your Convex queries use exactly the indexes you specify.
- Using code gives you a lot more expressive power and ability to build abstractions.
- Type-safety from your database schema that match runtime values, instead of templating a sql query string or hoping your ORM schema matches your database at runtime.
- Convex-powered reactivity, where [queries subscribe to changes](https://docs.convex.dev/tutorial/#how-convex-works).

For more SQL comparisons, see [this article](https://stack.convex.dev/not-sql) and [this video](https://www.youtube.com/watch?v=dS9jtih4dI4).

## Union

#### SQL

```sql
CREATE INDEX author ON messages (author, _creationTime);

SELECT * FROM messages WHERE author IN ('Alice', 'Bob')
ORDER BY _creationTime DESC;
5-- or equivalently
SELECT * FROM messages WHERE author = 'Alice' OR author = 'Bob'
ORDER BY _creationTime DESC;
8-- or equivalently
9(SELECT * FROM messages WHERE author = 'Alice') UNION ALL
10(SELECT * FROM messages WHERE author = 'Bob')
ORDER BY _creationTime DESC;

```

#### Convex

Collect results from the two queries, union the arrays, then sort the results[2](https://stack.convex.dev/translate-sql-into-convex-queries#user-content-fn-2).

```tsx
messages: defineTable(...).index("author", ["author"])

async function authoredMessages(author: string) {
  return await ctx.db.query("messages")
    .withIndex("author", q => q.eq("author", author)).order("desc")
    .collect();
7}

const allMessages = await Promise.all(["Alice", "Bob"].map(authoredMessages));
const messages = messages.flat()
  .sort((a, b) => b._creationTime - a._creationTime);

```

#### Convex QueryStreams

```tsx
messages: defineTable(...).index("author", ["author"])

function authoredMessages(author: string) {
  return stream(ctx.db, schema).query("messages")
    .withIndex("author", q => q.eq("author", author)).order("desc");
6}

const messages = mergedStream(
  ["Alice", "Bob"].map(authoredMessages),
  ["_creationTime"],
11);
const results = await messages.paginate(args.paginationOpts);

```

## Arbitrary Filter

Arbitrary filters in Convex let you run TypeScript checks, including async code and code imported from npm libraries. Since they don’t use an index, arbitrary filters end up scanning the entire table, although with pagination they can scan it incrementally.

Note filters can be combined with any other pattern in this article, and in particular filters are great to apply after narrowing down the query to a small index range.

#### SQL

SQL is very restrictive in the filters it supports, compared to Convex which can run any TypeScript code, including code from npm libraries. For this translation example we choose something that SQL _can_ support: calculating the length of a string.

```sql
SELECT * FROM messages WHERE CHAR_LENGTH(body) <= 280;

```

#### Convex

This pattern is described in the [Complex Query Filters](https://stack.convex.dev/complex-filters-in-convex) article.

```tsx
const allMessages = await ctx.db.query("messages").collect();
const messages = allMessages.filter((message) => message.body.length <= 280));

```

#### Convex QueryStreams

```tsx
const messages = stream(ctx.db, schema).query("messages")
  .filterWith(async (message) => message.body.length <= 280);
const results = await messages.paginate(args.paginationOpts);

```

## One-to-One Join

For this example, we assume that users only have access to certain channels, through “channelMemberships”. Each channel membership has a user and a channelId. You can use the channelId to look up the single channel with that ID.

#### SQL

```sql
CREATE INDEX `user` ON channelMemberships (userId, channelId);

SELECT channelMemberships.*, channels.* FROM channelMemberships
  JOIN channels ON channelMemberships.channelId = channels._id
  WHERE channelMemberships.userId = 'Bob'
  ORDER BY channelMemberships.channelId;

```

#### Convex

```tsx
channelMemberships: defineTable(...).index("user", ["userId", "channelId"])

const memberships = await ctx.db.query("channelMemberships")
  .withIndex("user", q => q.eq("userId", "Bob"))
  .collect();
const channels = (await Promise.all(channelMemberships
  .map((membership) => {
    const channel = await ctx.db.get(membership.channelId)!;
    return {...membership, ...channel};
  })
11)).flat();

```

#### Convex QueryStreams

```tsx
channelMemberships: defineTable(...).index("user", ["userId", "channelId"])

const channels = stream(ctx.db, schema).query("channelMemberships")
  .withIndex("user", q => q.eq("userId", "Bob"))
  .map(async (membership) => {
    const channel = await ctx.db.get(membership.channelId)!;
    return {...membership, ...channel};
  });
const results = await channels.paginate(args.paginationOpts);

```

## One-to-Many Join

This example extends the previous one, but instead of joining to get the channel details, we join to get the multiple messages in each channel that a user has access to.

#### SQL

```sql
CREATE INDEX channel ON messages (channelId, _creationTime);
CREATE INDEX `user` ON channelMemberships (userId, channelId);

SELECT channelMemberships.*, messages.* FROM channelMemberships
  JOIN messages ON channelMemberships.channelId = messages.channelId
  WHERE channelMemberships.userId = 'Bob'
  ORDER BY (messages.channelId, messages._creationTime);

```

#### Convex

```tsx
messages: defineTable(...).index("channel", ["channelId"])
channelMemberships: defineTable(...).index("user", ["userId", "channelId"])

const memberships = await ctx.db.query("channelMemberships")
  .withIndex("user", q => q.eq("userId", "Bob"))
  .collect();
const messages = (await Promise.all(memberships.map(async (membership) => {
  const messagesInChannel = await ctx.db.query("messages")
    .withIndex("channel", q => q.eq("channelId", membership.channelId))
    .collect();
  return messagesInChannel.map((message) => ({...channel, ...message}));
12}))).flat();

```

#### Convex QueryStreams

```tsx
messages: defineTable(...).index("channel", ["channelId"])
channelMemberships: defineTable(...).index("user", ["userId", "channelId"])

const memberships = stream(ctx.db, schema).query("channelMemberships")
  .withIndex("user", q => q.eq("userId", "Bob"));

const messages = memberships.flatMap(async (membership) =>
  stream(ctx.db, schema).query("messages")
    .withIndex("channel", q => q.eq("channelId", membership.channelId))
    .map(async (message) => ({...membership, ...message})),
  ["channelId"],
12);
const results = await messages.paginate(args.paginationOpts);

```

## Distinct

If your table has a lot of rows but comparatively few unique values for a particular field, you can find these unique values with a `DISTINCT` query. And in particular you can find the first row for each distinct value of the field.

For our example, we have lots of messages, but they're distributed across few channels. So we can get the most recent message in each channel with a `DISTINCT` query.

#### SQL

```sql
CREATE INDEX channel ON messages (channelId, _creationTime);

SELECT DISTINCT ON (channelId) * FROM messages
ORDER BY channelId DESC, _creationTime DESC;
5-- or equivalently
SELECT channelId, MAX(_creationTime) FROM messages
GROUP BY channelId ORDER BY channelId DESC;

```

#### Convex

This pattern is described in [https://stack.convex.dev/select-distinct](https://stack.convex.dev/select-distinct) .

```tsx
messages: defineTable(...).index("channel", ["channelId"])

const messages = [];
let message = await ctx.db.query("messages")
	.withIndex("channel).order("desc").first();
while (message !== null) {
  messages.push(message);
  message = await ctx.db.query("messages")
    .withIndex("channel", q => q.lt("channelId", message.channelId))
    .first();
11}

```

#### Convex QueryStreams

```tsx
messages: defineTable(...).index("channel", ["channelId"])

const messages = stream(ctx.db, schema).query("messages").withIndex("channel").order("desc")
  .distinct(["channelId"]);
const results = await messages.paginate(args.paginationOpts);

```

## Group By

Grouping By can be thought of as a DISTINCT query combined with a JOIN, so that’s how you would construct it in Convex.

Note for this example we’re doing a COUNT of each group, which requires reading all of the rows, in both SQL and Convex. In Convex you can choose to use the [Aggregate](https://www.convex.dev/components/aggregate) or [Sharded Counter](https://www.convex.dev/components/sharded-counter) components to compute counts faster.

#### SQL

```sql
CREATE INDEX channel ON messages (channelId, _creationTime);

SELECT channelId, COUNT(*) FROM messages
GROUP BY channelId ORDER BY channelId DESC;

```

#### Convex

```tsx
messages: defineTable(...).index("channel", ["channelId"])

const channelCounts = [];
let message = await ctx.db.query("messages").withIndex("channel").order("desc").first();
while (message !== null) {
  const messagesInChannel = await ctx.db.query("messages")
    .withIndex("channel", q => q.eq("channelId", message.channelId))
    .collect();
  channelCounts.push({
    channelId: message.channelId,
    count: messagesInChannel.length,
  });
  message = await ctx.db.query("messages")
    .withIndex("channel", q => q.lt("channelId", message.channelId))
    .first();
16}

```

#### Convex QueryStreams

```tsx
messages: defineTable(...).index("channel", ["channelId"])

const channelCounts = stream(ctx.db, schema).query("messages").withIndex("channel").order("desc")
  .distinct(["channelId"])
  .map(async (message) => {
    const messagesInChannel = await ctx.db.query("messages")
	    .withIndex("channel", q => q.eq("channelId", message.channelId))
	    .collect();
	  return { channelId: message.channelId, count: messagesInChannel.length };
	});
const results = await messages.paginate(args.paginationOpts);

```

## Select fields

Note that in Convex, even with QueryStreams, database queries always read entire documents. They can remove or modify fields in code before returning them to the client. This is not much different from row-based SQL servers, which read the entire row from disk before returning selected fields to the SQL client.

NOTE: Reading entire rows from storage is usually fine because the bandwidth bottleneck is between the client and the server (SQL server or Convex server), not between the server and the underlying storage. However, if you want to isolate large, infrequently-read fields from small, frequently-read ones, you can store them in separate tables and do JOINs when needed.

#### SQL

```tsx
SELECT body FROM messages;

```

#### Convex

```tsx
const messages = await ctx.db.query("messages").collect();
const bodies = messages.map((message) => message.body);
// NOTE this one works with `.paginate` too: call `.map` on `results.page`.
// https://docs.convex.dev/database/pagination#transforming-results

```

#### Convex QueryStreams

```tsx
const bodies = stream(ctx.db, schema).query("messages")
  .map(async (message) => message.body);
const results = await bodies.paginate(args.paginationOpts);

```

## Filter on index fields

This is a straightforward example of Convex's `.withIndex` method, although it's worth reiterating that SQL is not guaranteed to use any index, even if the perfect index exists. I've had a simple lookup of a single row, specified by equality on all fields of the primary key, and Postgres decided to scan a massive table to find the row.

#### SQL

```sql
CREATE INDEX channel ON messages (channelName, _creationTime);

SELECT * FROM messages WHERE channelName = '#general' AND
	_creationTime > (CURRENT_TIMESTAMP - INTERVAL '1 DAY');

```

#### Convex

```ts
const messages = await ctx.db.query("messages")
	.withIndex("channel", q => q.eq("channelName", "#general"))
	.collect();
// .paginate also works here, even without QueryStreams.

```

#### Convex QueryStreams

```ts
const messages = stream(ctx.db, schema).query("messages")
	.withIndex("channel", q => q.eq("channelName", "#general"));
const results = await messages.paginate(args.paginationOpts);

```

## Filter with index fields out of order

This is also known as an [Index Skip Scan in SQL query planners](https://oracle-base.com/articles/9i/index-skip-scanning).

Convex’s `ctx.db.query().withIndex()` will only read from a contiguous index range. So there’s a more complex pattern if the data you want isn’t contiguous within the index. See the [QueryStream article](https://stack.convex.dev/merging-streams-of-convex-data#index-skip-scan) for more description and examples.

#### SQL

```sql
CREATE INDEX priority ON messages (priority, _creationTime);

SELECT * FROM messages WHERE priority > 5 AND
  _creationTime > (CURRENT_TIMESTAMP - INTERVAL '1 DAY');

```

#### Convex

```tsx
messages: defineTable(...).index("priority", ["priority"])

// Get distinct priorities >5
const priorities = [];
let priorityDoc = await ctx.db.query("messages")
  .withIndex("priority", q => q.gt("priority", 5))
  .first();
while (priorityDoc !== null) {
  priorities.push(priorityDoc.priority);
  priorityDoc = await ctx.db.query("messages")
    .withIndex("priority", q => q.gt("priority", priorityDoc.priority))
    .first();
13}
// Get recent messages for each of these priorities
const messages = (await Promise.all((priority) =>
  ctx.db.query("messages").withIndex("priority", q =>
    q.eq("priority", priority).gt("_creationTime", Date.now() - 24*60*60*1000)
  ).collect()
19)).flat();

```

#### Convex QueryStreams

```tsx
messages: defineTable(...).index("priority", ["priority"])

const priorities = stream(ctx.db, schema).query("messages")
  .withIndex("priority", q => q.gt("priority", 5))
  .distinct(["priority"])
  .map(async (message) => message.priority);

const messages = priorities.flatMap(async (priority) =>
  stream(ctx.db, schema).query("messages").withIndex("priority", q =>
    q.eq("priority", priority).gt("_creationTime", Date.now() - 24*60*60*1000)
  )
12);
const results = await messages.paginate(args.paginationOpts);

```

## Composing Patterns

Putting it all together, let's see how you would compose the above patterns to translate a complicated query.

This query gets the message body and distinct emoji reactions for each non-deleted message in channels the user has access to.

This example has many of the above patterns:

- a one-to-many join from channelMemberships to messages
- an arbitrary filter on 'deleted'
- an Index Skip Scan for the `_creationTime` filter
- selecting only the body field of messages
- a DISTINCT query for emoji reactions

#### SQL

```sql
CREATE INDEX channel ON messages (channelId, _creationTime);
CREATE INDEX user ON channelMemberships (userId, channelId);
CREATE INDEX message ON reactions (messageId, _creationTime);

SELECT
  messages._id,
  messages.body,
  messages._creationTime,
  (SELECT ARRAY_AGG(DISTINCT emoji)
   FROM reactions
   WHERE reactions.messageId = messages._id
   ORDER BY reactions._creationTime DESC) AS emojis
FROM messages
JOIN channelMemberships ON channels._id = channelMemberships.channelId
WHERE channelMemberships.userId = $1
  AND messages._creationTime >= $2
  AND messages.deleted = FALSE
ORDER BY messages.channelId DESC, messages._creationTime DESC;

```

#### Convex

```ts
messages: defineTable(...).index("channel", ["channelId"])
channelMemberships: defineTable(...).index("user", ["userId"])
reactions: defineTable(...).index("message", ["messageId", "emoji"])

async function getEmojis(messageId) {
	const emojis = [];
	let reactionDoc = await ctx.db.query("reactions")
		.withIndex("message", q => q.eq("messageId", messageId))
		.first();
	while (reactionDoc !== null) {
		emojis.push(reactionDoc.emoji);
		reactionDoc = await ctx.db.query("reactions")
			.withIndex("message", q => q.eq("messageId", messageId).gt("emoji", reactionDoc.emoji))
			.first();
	}
	return emojis;
17}

const memberships = await ctx.db.query("channelMemberships")
  .withIndex("user", q => q.eq("userId", args.userId))
	.order("desc")
	.collect();
const allMessages = await Promise.all(
	memberships.map((membership) => ctx.db.query("messages")
		.withIndex("channel", q => q.eq("channelId", membership.channelId).gte("_creationTime", args.creationTime))
		.order("desc")
		.collect()
	)
29);
const nonDeletedMessages = allMessages.flat().filter((message) => !message.deleted);
const messages = await Promise.all(nonDeletedMessages.map(
	async (message) => ({
		_id: message._id,
		_creationTime: message._creationTime,
		body: message.body,
		emoji: await getEmojis(message._id),
	})
38);

```

#### Convex QueryStreams

```ts
messages: defineTable(...).index("channel", ["channelId"])
channelMemberships: defineTable(...).index("user", ["userId"])
reactions: defineTable(...).index("message", ["messageId", "emoji"])

const memberships = stream(ctx.db, schema).query("channelMemberships")
	.withIndex("user", q => q.eq("userId", args.userId))
	.order("desc");
const messages = memberships.flatMap(async (membership) =>
	stream(ctx.db, schema).query("messages")
		.withIndex("channel", q => q.eq("channelId", membership.channelId).gte("_creationTime", args.creationTime))
		.order("desc")
12).filterWith(async (message) => !message.deleted)
13.map(async (message) => {
	const emojis = await stream(ctx.db, schema).query("reactions")
		.withIndex("message", q => q.eq("messageId", message._id))
		.distinct("emoji")
		.map(async (reaction) => reaction.emoji)
		.collect();
	return {
		_id: message._id,
		_creationTime: message._creationTime,
		body: message.body,
		emoji: reaction?.emoji,
	};
25});
const results = await messages.paginate(args.paginationOpts);

```

## Recap

Anything that you can query with a SQL database, you can write into a Convex query. The patterns may be trickier to figure out, and for incremental paginated results you may need to use helpers like [Query Streams](https://stack.convex.dev/merging-streams-of-convex-data), but that's because Convex is pushing you towards efficient query plans, to ensure your queries are as fast and cheap as they can be.

### Footnotes

1. If you want to use `.paginate`, make sure to check out the [pagination warnings](https://stack.convex.dev/merging-streams-of-convex-data#pagination-warnings) [↩](https://stack.convex.dev/translate-sql-into-convex-queries#user-content-fnref-1)

2. You can hypothetically merge these results faster, because each array is already sorted. But improving `O(n log n)` CPU time to `O(n)` is unlikely to matter when the bottleneck is probably on the storage fetches. And, for comparison, the SQL engine is likely going to materialize the entire union on disk before sorting, which is much worse. [↩](https://stack.convex.dev/translate-sql-into-convex-queries#user-content-fnref-2)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Database Triggers

Triggers automatically run code whenever data in a table changes. A library in the [`convex-helpers` npm package](https://www.npmjs.com/package/convex-helpers) allows you to attach trigger functions to your Convex database.

Triggers run within the same mutation that changes the data, so they run atomically with the data changing. Queries running in parallel will never see a state where the data has changed but the trigger didn’t run.

Check out the [docs](https://github.com/get-convex/convex-helpers/blob/main/packages/convex-helpers/README.md#triggers) for details on how they work and be sure to check out the [best practices](https://stack.convex.dev/triggers#best-practices) below. In this article we’ll explore use-cases.

![Triggers are wonderful things](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Fdc2a13e1b4e1a36cb15ebf91d5d1b9cb50d2759d-450x312.tif&w=3840&q=75)Triggers are wonderful things

### TL;DR Show me the code

```tsx
npm i convex-helpers@latest

```

Define a function that runs automatically when the “users” table changes

In `convex/functions.ts`:

```tsx
1/* eslint-disable no-restricted-imports */
import { mutation as rawMutation, internalMutation as rawInternalMutation } from "./_generated/server";
3/* eslint-enable no-restricted-imports */
import { DataModel } from "./_generated/dataModel";
import { Triggers } from "convex-helpers/server/triggers";
import { customCtx, customMutation } from "convex-helpers/server/customFunctions";

// start using Triggers, with table types from schema.ts
const triggers = new Triggers<DataModel>();

// register a function to run when a `ctx.db.insert`, `ctx.db.patch`, `ctx.db.replace`, or `ctx.db.delete` changes the "users" table
triggers.register("users", async (ctx, change) => {
  console.log("user changed", change);
14});

// create wrappers that replace the built-in `mutation` and `internalMutation`
// the wrappers override `ctx` so that `ctx.db.insert`, `ctx.db.patch`, etc. run registered trigger functions
export const mutation = customMutation(rawMutation, customCtx(triggers.wrapDB));
export const internalMutation = customMutation(rawInternalMutation, customCtx(triggers.wrapDB));

```

Elsewhere:

```ts
import { mutation } from "./functions";

export const myMutation = mutation({
  handler: async (ctx, args) => {
	  // This will cause the user triggers to run automatically.
	  await ctx.db.insert("users", { ... });
	},
8});

```

Again, check out the [docs](https://github.com/get-convex/convex-helpers/blob/main/packages/convex-helpers/README.md#triggers) for details on how they work and be sure to check out the [best practices](https://stack.convex.dev/triggers#best-practices) below.

## Use-Cases of Triggers

### Logging

Suppose users are getting into a bad state. You want to add logging to debug when it’s happening. With a trigger you can log whenever a user changes, which will give you a timeline and tell which mutation is changing it.

```tsx
triggers.register("users", async (ctx, change) => {
  console.log("user changed", change);
3});

```

Or suppose you need to keep an audit log of what happens to a team, so admins can look at the history to see who did what when. You can store the logs in a separate table.

```tsx
triggers.register("teams", async (ctx, change) => {
  const tokenIdentifier = (await ctx.auth.getUserIdentity())?.tokenIdentifier;
  await ctx.db.insert("teamAuditLog", { teamId: change.id, change, tokenIdentifier });
4});

```

### Denormalizing a field

Indexes are great for organizing data, but sometimes you want to organize based on a derived field. You can use a trigger to calculate that field.

Suppose you’re generating a list of airplane trips, where each trip can have layovers in various cities. When a user scrolls through their options, they want to see the trips with fewest layovers first. So the schema is like this:

```tsx
trips: defineTable({
  flights: v.array(v.object({
    sourceAirport: v.string(),
    destAirport: v.string(),
    startTime: v.number(),
    ...
  }),
  layovers: v.number(),
  price: v.number(),
10}).index("fewestStops", ["layovers", "price"])

```

The `layovers` field is necessary to define the index, but it’s derived from the `flights` field and you don’t want it to be incorrect. So you can keep it updated with a trigger:

```tsx
triggers.register("trips", async (ctx, change) => {
  if (change.newDoc) {
    const layovers = change.newDoc.flights.length;
    if (change.newDoc.layovers !== layovers) {
      await ctx.db.patch(change.id, { layovers });
    }
  }
8});

```

Note we have to check that the denormalized field isn’t already correct, because otherwise the `ctx.db.patch` will trigger an infinite recursion of triggers.

As another example, you may recall one restriction of [text search indexes](https://docs.convex.dev/search/text-search) is they can only search on one field. But we don’t have to let that stop us.

```tsx
books: defineTable({
  title: v.string(),
  author: v.string(),
  summary: v.string(),
  allFields: v.string(),
6}).searchIndex("allFields", { searchField: "allFields" })

```

If we want a universal search bar, to search the book’s title, author, and summary all at once, you can denormalize all of those into a separate field, updated by a trigger.

```tsx
triggers.register("books", async (ctx, change) => {
  if (change.newDoc) {
    const allFields = change.newDoc.title + " " + change.newDoc.author + " " + change.newDoc.summary;
    if (change.newDoc.allFields !== allFields) {
      await ctx.db.patch(change.id, { allFields });
    }
  }
8});

```

### Validating data

Not all data is good data. Convex performs [schema validation](https://docs.convex.dev/database/schemas) to do basic typechecks, but sometimes there are constraints that can’t be represented with types.

For example, an email address is always a string, but there are more constraints on what makes a valid email address. Triggers can throw errors to abort mutations that try to write invalid data.

```tsx
triggers.register("users", async (ctx, change) => {
  if (change.newDoc) {
    // logic can be arbitrarily complex, including importing from npm libraries
    const emailRegex = /^(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|"(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21\x23-\x5b\x5d-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])*")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21-\x5a\x53-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])+)\])$/i;
    if (!emailRegex.test(change.newDoc.email)) {
      throw new Error(`invalid email ${change.newDoc.email}`);
    }
  }
9});

```

When using this pattern, make sure you [don't catch errors](https://stack.convex.dev/triggers#warning-beware-error-catching).

### Authorizing writes

You can implement the write side of [row-level security](https://stack.convex.dev/row-level-security) with triggers. For example, here’s a rule that a message may only be modified by the user who created it.

```tsx
triggers.register("messages", async (ctx, change) => {
  const user = await getAuthedUser(ctx);
  const owner = change.oldDoc?.owner ?? change.newDoc?.owner;
  if (user !== owner) {
    throw new Error(`user ${user} is not allowed to modify message owned by ${owner}`);
  }
7});

```

When using this pattern, make sure you [don't catch errors](https://stack.convex.dev/triggers#warning-beware-error-catching).

#### Warning: beware error catching

Triggers are called after the data has been modified. If the trigger throws an error, it can cause the whole mutation to be rolled back. But if the mutation _catches_ the error, the data modification will still be committed.

```ts
export const tryToUpdateMessage = mutation({
  handler: async (ctx, { id, body }) => {
    try {
      await ctx.db.patch(id, { body });
    } catch (e) {
      console.error("failed to update message");
    }
  },
9});

```

If `tryToUpdateMessage` does a write that conflicts with an authorization or validation trigger and the trigger throws an error, the mutation will print `"failed to update message"`. However, **the message will still be updated**. The trigger runs after the document is patched, so if the mutation returns without throwing any error, the patch will commit.

### Cascade deletes

Sometimes when there are foreign references between documents, a delete should cascade across the link.

For example, when a user gets deleted, you can delete all of the messages they own.

```tsx
triggers.register("users", async (ctx, change) => {
  if (change.operation === "delete") {
    for await (const message of ctx.db.query("messages")
        .withIndex("owner", q=>q.eq("owner", change.id))) {
      await ctx.db.delete(message._id);
    }
  }
8});

```

Note that like all mutations, triggers are bounded by size limits, so cascading deletes will fail if there are too many links. In this case you’ll probably want to schedule the deletes to run async.

Because triggers can trigger other triggers recursively, you can have a graph of foreign references and deletes can cascade through the graph. e.g. deleting a team can delete all of its users, which will then delete all of their messages.

### Asynchronous debounced processing

Running code transactionally when it changes is great, but sometimes you want to process the change asynchronously. This could be because the processing is a Convex action (i.e. it has side effects). Or maybe documents change often within a mutation and you want to only process the final change.

You can schedule the processing with `ctx.scheduler`, and use a global variable to cancel functions that were previously scheduled from the same mutation. In this example, we want to send the final user document to Clerk after it has been committed to Convex.

```tsx
const scheduled: Record<Id<"users">, Id<"_scheduled_functions">> = {};
triggers.register("users", async (ctx, change) => {
  if (scheduled[change.id]) {
    await ctx.scheduler.cancel(scheduled[change.id]);
  }
  scheduled[change.id] = await ctx.scheduler.runAfter(
    0,
    internal.users.updateClerkUser,
    { id: change.id, user: change.newDoc },
  );
11});

```

### Denormalizing a count

You may want to keep track of a denormalized value that accumulates all documents.

For example, here’s how you would keep track of the number of users in a single document, for fast querying.

```tsx
triggers.register("users", async (ctx, change) => {
  // Note writing the count to a single document increases write contention.
  // There are more scalable methods if you need high write throughput.
  const countDoc = (await ctx.db.query("userCount").unique())!;
  if (change.operation === "insert") {
    await ctx.db.patch(countDoc._id, { count: countDoc.count + 1 });
  } else if (change.operation === "delete") {
    await ctx.db.patch(countDoc._id, { count: countDoc.count - 1 });
  }
10});

```

Note that storing the count in a single document means if users are modified frequently, the mutations will slow down due to [OCC conflicts](https://docs.convex.dev/error#1).

#### Triggers are isolated

Denormalizing a count demonstrates how triggers have an unexpected beneficial property: triggers are serializable.

Contrast with an explicit wrapper, where you are likely to write code like this:

```ts
async function insertUser(ctx: MutationCtx, name: string) {
  await ctx.db.insert("users", { name });
  const countDoc = (await ctx.query("userCount").unique())!;
  await ctx.db.patch(countDoc._id, { value: countDoc.value + 1 });
5}
export const addTwo = mutation({
  handler: async (ctx) => {
    await Promise.all([\
      insertUser(ctx, "foo"),\
      insertUser(ctx, "bar"),\
    ]);
  },
13});

```

If you run this code, you'll discover that TypeScript can run async code however it wants. In this case, the `userCount` ends up as 1 even though there are two users. [See if you can figure out why](https://en.wikipedia.org/wiki/Race_condition#Example). The triggers library protects against race conditions so you can register the trigger above and see that `userCount` ends up with the correct value of 2.

```ts
export const addTwo = mutation({
  handler: async (ctx) => {
    await Promise.all([\
      ctx.db.insert("users", { name: "foo" }),\
      ctx.db.insert("users", { name: "bar" }),\
    ]);
  },
8});

```

The triggers library isn't magical; you can add similar [locking semantics](https://github.com/get-convex/convex-helpers/blob/db305ba57baf53d74b0f084948c6273cf1f363ad/packages/convex-helpers/server/triggers.ts#L116) to your own `insertUser` wrapper and it will work just as well.

### Syncing a table into a component

You can use [Convex components](https://convex.dev/components) to super-charge your Convex deployment. Some components latch onto your tables, adding extra structure for efficient querying of counts, sums, or even geospatial data.

Components like [Aggregate](https://www.npmjs.com/package/@convex-dev/aggregate) and [ShardedCounter](https://www.npmjs.com/package/@convex-dev/sharded-counter) have methods that help you construct triggers, to help those components latch onto tables.

```ts
const counter = new ShardedCounter(components.shardedCounter);
triggers.register("mytable", counter.trigger("mycounter"));

```

## Best practices

### Consider explicit function calls instead

Attaching triggers to your data can seem magical. Calling `ctx.db.insert` in one file can call a trigger registered in a different file. You may call this "spooky action at a distance," because your code has side effects that aren't obvious. Using triggers too much can result in surprising effects when your code runs. Think of it similar to language patterns like modifying `Array.prototype.map` in JavaScript, or [overriding an operator in C++](https://isocpp.org/wiki/faq/operator-overloading#law-of-least-surprise-op-ov). You are effectively overriding the built-in Convex functions `ctx.db.insert`, `ctx.db.patch`, `ctx.db.replace`, and `ctx.db.delete`, so proceed with caution.

A more idiomatic way of running code when data changes, so as not to violate the [principle of least astonishment](https://en.wikipedia.org/wiki/Principle_of_least_astonishment), is to make the wrapper explicit. Instead of doing this:

```ts
triggers.register("users", async (ctx, change) => {
  console.log("user changed", change);
3});

export const createMultipleUsers = mutation({
  handler: async (ctx) => {
    // this implicitly calls all triggers registered on the "users" table.
    await ctx.db.insert("users", { name: "foo" });
    await ctx.db.insert("users", { name: "bar" });
  }
11}

```

Do this:

```ts
async function createUser(ctx, name) {
  await ctx.db.insert("users", { name });
  console.log("user created", name);
4}

export const createMultipleUsers = mutation({
  handler: async (ctx) => {
    await createUser(ctx, "foo");
    await createUser(ctx, "bar");
  }
11}

```

By encapsulating all writes to a table in distinct functions like `createUser`, you get the same benefit of running custom code whenever the table changes. But now you can command-click to follow `createUser` to its definition and see what code is getting called.

The advantage of triggers is they allow you to attach custom code without refactoring all usages of `ctx.db.insert`. Use them with caution.

### Always use the wrapper

Triggers are attached to mutations with [custom functions](https://stack.convex.dev/custom-functions). This works by replacing `ctx.db` in the mutation with a wrapped version that has the same interface but also calls the trigger functions. Therefore, trigger functions will only run if the mutation is wrapped in the custom function.

That means triggers do _not_ run in these cases:

- If you forget the wrapper and declare a plain mutation.
- When data is changed directly in the Convex dashboard.
- When data is uploaded through [`npx convex import`](https://docs.convex.dev/database/import-export/import).
- When data is uploaded through [streaming import](https://docs.convex.dev/production/integrations/streaming-import-export#streaming-import).

Here are tips for ensuring your mutations always run trigger functions:

1. Define `triggers`, call `triggers.register`, and call `customMutation` in a file `convex/functions.ts`

- You may register triggers across multiple files, but when you call `customMutation` all triggers should be registered, so it's easiest to do in one file.

1. By declaring our wrapped `customMutation` s to have names `mutation` and `internalMutation`, they become drop-in replacements for the built-ins of the same name. Just import from `'./functions'` instead of `'./_generated/server'`.
2. To make sure you always remember the correct imports, use [an eslint rule](https://stack.convex.dev/eslint-setup#no-restricted-imports).

```tsx
1"no-restricted-imports": [\
  "error",\
  {\
    patterns: [\
      {\
        group: ["*/_generated/server"],\
        importNames: ["mutation", "internalMutation"],\
        message: "Use functions.ts for mutation",\
      },\
    ],\
  },\
12],

```

## Recap

A simple `db.insert` or `db.delete` can cause many changes, to the same document with field denormalization, to other documents with cascading deletes and count denormalization, or to a separate Convex component. The same `db.insert` or `db.delete` can kick off an async function with side effects like sending the data to a third party service. Or it can abort the mutation entirely, to block unauthorized access or make sure invalid data never reaches the database.

Triggers allow you to implement [Dataflow](https://en.wikipedia.org/wiki/Dataflow) algorithms with Convex: whenever data changes, some auxiliary code runs to handle it, and the change propagates through the system.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Types and Validators in TypeScript: A Convex Cookbook

As you become a seasoned Convex developer, you’ll see first-hand how fantastic the developer experience becomes when you’ve got types on your side. The end-to-end TypeScript as you build, and the consistency and security you get from Convex [schema enforcement](https://docs.convex.dev/database/schemas#validators) and [argument validation](https://docs.convex.dev/functions/args-validation) at runtime give you the tools to develop safely with types to help catch bugs early.

However, if you don’t know some of the tricks we’ll show you, your code may feel cumbersome to write. For example, say you’re building a cookbook app and have defined a `recipes` table in your schema. You specify the table’s fields using validators accessed from the `v` object exposed by `convex/values`:

```tsx
// convex/schema.ts
import { v } from "convex/values";
import { defineSchema, defineTable } from "convex/server";

export default defineSchema({
  recipes: defineTable({
    name: v.string(),
		course: v.union(
			v.literal('appetizer'),
			v.literal('main'),
			v.literal('dessert')
		),
		ingredients: v.array(v.string()),
		steps: v.array(v.string())
  }).index("by_course", ["course"]),
16});

```

Your function to add a new recipe argument validators might look like:

```tsx
// in convex/recipes.ts
import { v } from "convex/values";
import { mutation } from "./_generated/server";

export const addRecipe = mutation({
  args: {
    name: v.string(),
		course: v.union(
			v.literal('appetizer'),
			v.literal('main'),
			v.literal('dessert')
		),
		ingredients: v.array(v.string()),
		steps: v.array(v.string()),
  },
  handler: async (ctx, args) => {
    return await ctx.db.insert("recipes", args);
  },
19});

```

And for a regular TypeScript function, you might find yourself defining types like:

```tsx
type Course = 'appetizer' | 'main' | 'dessert';

type Recipe = {
	name: string,
	course: Course,
	ingredients: string[],
	steps: string[],
8};

async function getIngredientsForCourse(recipes: Recipe[], course: Course) {
   ...
12}

```

As you can see, you may get frustrated repeatedly defining the same validators in your schema and functions, and redeclaring similar TypeScript types in different parts of your codebase. Is there a better way? Yes!

The Convex Test Kitchen has cooked up some convenient recipes for busy fullstack chefs like you! Keep these tasty typing tricks at hand, and you’ll be whipping up the types & validators you need in no time - without any cookie-cutter repetition.

### Dish out types from your `DataModel` with `Doc` and `Id`

Once you’ve [defined a schema](https://docs.convex.dev/database/schemas) for your database (or [generated](https://docs.convex.dev/dashboard/deployments/data#generating-a-schema) one from existing data), Convex will serve up your data types on a silver platter!

Convex code generation automatically creates types for all the documents in your tables, exposed via the `Doc<"tablename">` generic type from `convex/_generated/dataModel`. The data model also exposes an `Id<"tablename">` generic type corresponding to a valid [document ID](https://docs.convex.dev/database/document-ids) for a given table. Use these types to ensure the rest of your codebase uses data consistent with your schema:

```tsx
// in src/Cookbook.tsx
import { useQuery } from "convex/react";
import { api } from "../convex/_generated/api";
import type { Doc, Id } from "../convex/_generated/dataModel";

export function Cookbook() {
  const recipes = useQuery(api.recipes.list);
  return recipes?.map((r) => <RecipePreview recipe={r} />);
9}

export function RecipePreview({ recipe }: { recipe: Doc<"recipes"> }) {
  return (
    <div>
      {recipe.name} ({recipe.course})
    </div>
  );
17}

function RecipeDetails({ id }: { id: Id<"recipes"> }) {
  const recipe = useQuery(api.recipes.getById, { id });

  return (recipe && (
    <div>
      <h1>{recipe.name}</h1>
      <h2>{recipe.course}</h2>
      <ShoppingList ingredients={recipe.ingredients} />
      <Instructions steps={recipe.steps} />
    </div>
  ));
30}

```

This `Id<"tablename">` type corresponds to values accepted by `v.id("tablename")` :

```tsx
// in convex/recipes.ts
import { v } from "convex/values";
import { query } from "./_generated/server";

export const getById = query({
  args: {
    id: v.id("recipes"),
  },
  handler: async (ctx, args) => {
    return await ctx.db.get(args.id);
  },
12});

```

### Keep validators from going stale

As we’ve seen, the `v` validators are used not only in your schema but also to [validate arguments](https://docs.convex.dev/functions/args-validation) passed in to your Convex functions. If all you need is a single [`v.id`](http://v.id/) that’s no sweat, but what about when arguments should match your schema definitions? For example:

```tsx
// in convex/recipes.ts
import { query } from "./_generated/server";
import { v } from "convex/values";

export const listByCourse = query({
  args: {
    course: v.union(
			v.literal("appetizer"),
			v.literal("main"),
			v.literal("dessert")
		),
  },
  handler: async (ctx, args) => {
    return await ctx.db.query("recipes")
			.withIndex("by_course", (q) => q.eq("course", args.course))
			.collect();
  },
18});

```

This doesn’t smell so good; it duplicates the `course` validator from your schema, which means not only did you have to repeat yourself (ugh), you also gave yourself the burden to remember to update this function whenever you update your schema (double ugh)!

To keep arguments in sync with schema changes, refactor `convex/schema.ts` to first define and export your field validators, then use them to define your tables:

```tsx
// convex/schema.ts
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export const courseValidator = v.union(
	v.literal('appetizer'),
	v.literal('main'),
	v.literal('dessert')
9);

export default defineSchema({
  recipes: defineTable({
	  name: v.string(),
	  course: courseValidator,
	  ingredients: v.array(v.string()),
	  steps: v.array(v.string()),
	}).index("by_course", ["course"]),
18});

```

Now you can reuse those validators in your Convex functions as needed:

```tsx
// in convex/recipes.ts
import { query } from "./_generated/server";
import { courseValidator } from "convex/schema.ts";

export const listByCourse = query({
  args: {
    course: courseValidator
  },
  handler: async (ctx, args) => {
    return await ctx.db.query("recipes")
			.withIndex("by_course", (q) => q.eq("course", args.course)
			.collect();
  },
14});

```

This keeps data consistent throughout your entire backend.

Pro tip: once you get the hang of this pattern, you might drop the "Validator," just "course" - it's cleaner.

But how can you make sure that other parts of your codebase, say, your frontend UI, are using TypeScript types that match those validators?

### Add a drop of ~~vanilla~~ TypeScript extract

For exactly that purpose, `convex.values` also provides a handy `Infer` type that lets you [extract TS types from your validators](https://docs.convex.dev/functions/args-validation#extracting-typescript-types):

```tsx
// in convex/schema.ts
import { defineSchema, defineTable } from "convex/server";
import { v, Infer } from "convex/values";

export const courseValidator = v.union(
  v.literal('appetizer'),
  v.literal('main'),
  v.literal('dessert')
9);
export type Course = Infer<typeof courseValidator>;

// ...

```

You can expose the extracted types for use in other parts of your codebase:

```tsx
// in src/Menu.tsx
import { useState } from "react";
import type { Course } from '../convex/schema.ts';

export default function Menu() {
  const [course, setCourse] = useState<Course>('main');

  // Then, in response to some user input...
  setCourse('side dish'); // TS error: invalid Course!
  // ...
11}

```

### Sift out the system fields

The generated `Doc` type seen earlier includes the “system fields” automatically added by Convex to every document: `_id` and `_creationTime`. But often, for example when creating a new document, you want to make sure those fields aren’t included in your data. The `"convex/server"` module provides a handy `WithoutSystemFields<document>` generic type for just such a situation:

```tsx
// in src/NewRecipePage.tsx

import { api } from "../convex/_generated/api";
import type { Doc } from "../convex/_generated/dataModel";
import type { WithoutSystemFields } from "convex/server";

export function SaveRecipeButton({ recipeData }:
	{ recipeData: WithoutSystemFields<Doc<"recipes">> }
9) {
  const createRecipe = useMutation(api.recipes.create);
  return (
    <button onClick={() => createRecipe(recipeData)}>
      Save recipe
    </button>
  );
16}

```

But what about the corresponding argument validator? Rather than redefine the same shape of data that you’ve already defined in your schema, you can refactor your schema to export an object with the field validators for a given table, and import that object for use in your functions:

```tsx
// in convex/schema.ts
// ...
export const recipeFields = {
  name: v.string(),
  course: courseValidator,
  ingredients: v.array(v.string()),
  steps: v.array(v.string()),
8};

export default defineSchema({
  recipes: defineTable(recipeFields)
    .index("by_course", ["course"]),
13});

```

```tsx
// in convex/recipes.ts
// ...
import { recipeFields } from "./schema";

export const addRecipe = mutation({
  args: recipeFields,
  handler: async (ctx, args) => {
    return await ctx.db.insert("recipes", args);
  },
10});

```

No repetition needed, and any changes to the shape of the `recipes` table will percolate automatically from `schema.ts`. Now we’re cooking! By the way, if you like this pattern, you’ll probably like Ian’s `Table` utility in the convex-helpers npm package - post on it coming soon.

### Boiling it all down

To recap, with a little bit of reorganization your Convex codebase can be sweeter than ever, with no repetition or risk of stale data shapes!

- In `schema.ts` , define and export your document fields and their validators separately, then pass them in to `defineTable()`
- In your Convex functions, validate arguments with the imported validators from your schema instead of repeating yourself
- In your frontend, use Convex-generated types `Doc<table>` and `Id<table>`, along with type utilities like `Infer<validator>` and `WithoutSystemFields<doc>` to convert your schema-defined validators to the TypeScript types you need

Hungry for more tidbits like this to help manage, modify, and manipulate your types and validators? Check out [this post](https://stack.convex.dev/argument-validation-without-repetition) for recipes to re-use code for argument validation and schemas.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started


---

# Zod with TypeScript for Server-side Validation and End-to-End Types

Want to use [Zod](https://zod.dev/) with your TypeScript project to validate function arguments? Read on to see how, along with resources to allow you to specify Zod validation for Convex server function arguments. Want to jump right into code? It’s [down here](https://stack.convex.dev/typescript-zod-function-validation#using-zod-for-argument-validation-server-side).

## What is Zod?

[Zod](https://zod.dev/) by their own definition is:

> TypeScript-first schema validation with static type inference

It lets you define the format of data and validate it. It’s often used for form validation on a website or argument validation on a server. It can be used in JavaScript, but a big benefit comes from providing great TypeScript types to avoid duplicating a type definition from a validation specification.

For terminology, I’m using the term “validate” here. They like to say “ [parse, don’t validate](https://zod.dev/#:~:text=parse%2C%20don%27t%20validate),” but that nuance isn’t important to how we’ll talk about it.[1](https://stack.convex.dev/typescript-zod-function-validation#user-content-fn-1) The important thing is you have:

```jsx
const untrustedData: any;
const trustedData = z.string().email().parse(untrustedData);

```

If your untrustedData is an email, hooray! You have a safe value to use. If not, it will throw a `ZodError` which, in the case of form validation, you can catch to inform the user which field is invalid.

### Why use Zod?

Zod allow you to:

- Validate types at runtime: remember that defining TypeScript types doesn’t guarantee that the values at runtime will match! Especially when receiving JSON payloads, it’s important to ensure the data matches your expectation.
- Avoid repeating type definitions and data validators.
- Do the same runtime validation on the client and server: doing it on the client allows you to give the user quick feedback, and doing it on the server guards against malformed requests and untrusted clients.

### How to use Zod

You can install Zod:

```bash
npm i zod

```

Then define your schema, like:

```jsx
const myData: z.object({
	email: z.string().email(),
  num: z.number().min(0),
  bool: z.boolean().default(false),
  array: z.array(z.string()),
  object: z.object({ a: z.string(), b: z.number() }),
  union: z.union([z.string(), z.number()]),
8});

```

And parse (validate) the data:

```jsx
// Throws when the data is invalid
const result = myData.parse(untrustedData);
// Returns an error object instead
const { success, error, data } = myData.safeParse(untrustedData);

```

## Using Zod for argument validation server-side

When you want to validate your endpoint’s arguments, you can do it manually on the data passed in by your framework. However, it’s more powerful to expose this data, so it can also inform end-to-end type safety, for instance with tRPC or Convex.

### Using Zod with tRPC

For tRPC projects, you can provide a Zod object to `.input`:

```jsx
const t = initTRPC.create();

const appRouter = t.router({
  greeting: t.publicProcedure
    .input(z.object({ name: z.string() }))
    .query((opts) => {
      const { input } = opts;
      return `Hello ${input.name}`;
  }),
10});

```

### Using Zod with Convex

With Convex, argument validation is usually done with the same validators used to define your [database schema](https://docs.convex.dev/database/schemas) (note the `v` instead of `z`!):

```jsx
export const greeting = query({
  args: { name: v.string() },
  handler: async (ctx, args) => {
    return `Hello ${args.name}`;
  }
6});

```

However, if you’re already using Zod elsewhere in your project, or want to validate more refined types, wouldn’t it be nice to validate your arguments with the same object? To make this possible, I wrote some helpers.

```bash
npm i convex-helpers@latest

```

These build off of [this post](https://stack.convex.dev/custom-functions) where I show how to customize functions generally. See that post for the details on the API and why it’s preferable to typical middleware.

If you aren’t doing any customization and just want to use Zod arguments, you can use the functions exported from `convex-helpers/server/zod`:

```jsx
import { z } from "zod";
import { NoOp } from "convex-helpers/server/customFunctions";
import { zCustomQuery } from "convex-helpers/server/zod";
import { query } from "./_generated/server";

// Make this once, to use anywhere you would have used `query`
const zQuery = zCustomQuery(query, NoOp);

export const greeting = zQuery({
  args: { name: z.string() },
  handler: async (_ctx, args) => {
    return `Hello ${args.name}`;
  },
14});

```

Let’s walk through what’s happening:

1. First we make `zQuery`, which is like `query` but modified by `zCustomQuery` to accept Zod arguments, along with any customization you provide in the second argument. We’re passing `NoOp` which doesn’t modify the defined query endpoint’s arguments (a.k.a. no-op or identity function).
2. We use `zQuery` like we’d normally use `query` , but this time we get to pass in zod validators for arguments.

Internally, this does two things:

1. It turns the Zod validator into a Convex validator using `zodToConvex`. This allows Convex to know generally what types the function expects (which helps suggest arguments when you [run your functions from the Dashboard](https://docs.convex.dev/dashboard/deployments/functions#running-functions)). This also allows Convex to validate the `v.id("tablename")` type, which ensures IDs match the expected table name.
2. It runs the Zod validator before the function runs, since Zod types can be more specific than Convex types (e.g. `z.string().email()` vs. `v.string()`).

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

### `v.id(tablename)` → `zid(tablename)`

When you want to validate a [Convex Document ID](https://docs.convex.dev/database/document-ids), since Zod doesn’t have a built-in type, you can use `zid`:

```jsx
1...
import { zCustomQuery, zid } from "convex-helpers/server/zod";

const zQuery = zCustomQuery(query, NoOp)

export const getUser = zQuery({
  args: {userId: zid("users")},
  handler: async (ctx, args) => {
    const user = await ctx.db.get(args.userId);
    return user && { id: user._id, name: user.name };
  },
12});

```

This creates a `v.id` validator under the hood, which ensures you don’t return data from the wrong table if someone passes an ID to another table to `getUser`.

However, note that `zid` doesn’t do the table name validation when you do `.parse()`. It does this by converting it into a `v.id` which is passed to the Convex argument validation. So keep in mind that if you’re validating a `zid` in a browser, it will only check that it is a string.

### Output validation

In addition to validating function inputs, you can also use Zod to validate the output data, similar to defining an explicit TypeScript return type on your function. While this is less critical, since the data you return is generally more trusted than what’s provided by a user, it does have a nice benefit of _**limiting**_ what you return. If your return TypeScript type is `{ name: string }` and you return a `User: { name: string, email: string }`, then TypeScript will say it’s ok, but you would be leaking the user’s email, since TypeScript’s typing on objects isn’t exact. By specifying a Zod validator for your output, it will both set the TypeScript return type, but also strip out fields that you don’t specify. For example:

```jsx
const user = { name: "Sam", email: "sam@example.com" };
const output = z.object({ name: z.string() });
const limited = output.parse(user);
console.log(limited)
// { name: 'Sam' }

```

To do this you could just do it in your function:

```jsx
export const getUser = zQuery({
  args: {userId: zid("users")},
  handler: async (ctx, args) => {
    const user = (await ctx.db.get(args.userId))!;
    const output = z.object({ name: z.string() });
    return output.parse(user);
  },
8});

```

But with the `zCustomQuery` , `zCustomMutation`, or `zCustomAction`, you can specify it like:

```jsx
export const getUser = zQuery({
  args: {userId: zid("users")},
  handler: async (ctx, args) => {
    const user = (await ctx.db.get(args.userId))!;
    return user;
  },
  returns: z.object({ name: z.string() }),
8});

```

### Customizing the function

Similar to [`customFunctions` described here](https://stack.convex.dev/custom-functions), you can customize `zCustomFunction`.

Here we modify the `ctx` object passed into `greeting`:

```jsx
import { z } from "zod";
import { customCtx } from "convex-helpers/server/customFunctions";
import { zCustomQuery } from "convex-helpers/server/zod";
import { query } from "./_generated/server";
import { getUser } from "./users";

const userQuery = zCustomQuery(
  query,
  customCtx(async (ctx) => {
    const user = await getUser(ctx);
    return { user };
  })
13);

export const greeting = userQuery({
  args: { greeting: z.string() },
  handler: async (ctx, args) => {
    return `${args.greeting} ${ctx.user.name}`;
  },
20});

```

Here we add `session` to the `ctx` , stripping off `sessionId` from the arguments:

```jsx
const zQuery = zCustomQuery(query, {
  args: { sessionId: v.id("sessions") },
  input: async (ctx, args) => {
    const session = await ctx.db.get(args.sessionId);
    return { ctx: { ...ctx, session }, args: {} };
  },
7});

```

Note: we use normal Convex validators ( `v.`) for the customization, so it is easy to extend behavior with helpers that don’t use Zod.

### Error handling

If an error occurs, it will throw a [`ConvexError`](https://docs.convex.dev/functions/error-handling/application-errors#throwing-application-errors) with `{ ZodError }` as the data. This allows you to inspect the full error object on the client-side, without leaking the server’s stack trace.

### Can I use Zod to define my database types too?

With the `zodOutputToConvex` function, you can turn your Zod validators into Convex types that not only work in argument validation, but also can be used to define tables (via `defineTable`, see [here](https://docs.convex.dev/database/schemas)). Is this a good idea? It depends.

The data at rest is guaranteed to match the defined schema (assuming you have [schema enforcement turned on](https://docs.convex.dev/database/schemas#options)). However, if your Zod type is more refined (like a `z.string().email()`), then there isn’t a guarantee that the data at rest matches it. For some types, like `z.tuple`, the definition looks more like `z.array(z.union([...]))`.

Note: there are two related functions. `zodToConvex` will make a Convex validator that enforces the **input** you'd pass to the zod validator. `zodOutputToConvex` will make a validator for the **output** from zod. If you run your zod validator **before inserting**, then you'd want to use `zodOutputToConvex` for your schema. If you run your zod validator **after reading**, then `zodToConvex` will match it. This only comes up for the case of defaults (where the value is optional on one side and required on the other), pipelines (coercing a Date into a number), and transforms (effects), which don't have a defined validator for the output type (and result in a `v.any()` convex validator).

#### So what can you do?

- You can wrap `ctx.db` in mutations to validate the more specific data types before writing data, using a wrapper like `convex-helpers/server/rowLevelSecurity`. This can ensure the **new** data you’re writing is the right format.
- You can wrap `ctx.db` in queries & mutations to validate the data on reads. This will ensure the data you retrieve is the right format. It’s an open question how you should handle invalid data on reads. If you change your schema and read an old invalid value, you could fail the request, omit the result, or try to transform it into the right shape. This is pretty messy.
- You can run a migration over your data, validating the Zod schema when you change it. Similar to other migrations, I’d suggest first changing the data writers to validate on insert, then run a migration over older documents and manually resolve errors.

Note: if a developer edits data in the dashboard or uploads data via the CLI, your validators won’t run. The validation here is best effort, and up to you.

#### What would I do?

I’d use Zod validation for server arguments, and trust that the server code will write valid data. If it’s very important, I’d consolidates those writes to a function where I manually validate the data & business logic before writing it. If your server is modifying a lot of data that needs to be a certain shape, consider validating it right there. If I had more specific types that I expect from the data (e.g. z.tuple), I’d use Zod on the read side to give better types while asserting the structure.

I might use `zodOutputToConvex` to define the table schema from the Zod types, but I’d add a big comment block making it clear that the validation isn’t guaranteed. I do like that my table definition would be more self-documenting. An `.email()` is more meaningful than `v.string()`.

## In summary

We looked at using Zod to validate function arguments (and more) to provide both type safety and runtime data validation for your TypeScript projects. By using `convex-helpers` you can validate your Convex functions, and translate from a Zod schema to a Convex validator. If you want to see the code, you can check it out / fork it / submit a PR here:

[get-convex/ **convex-helpers**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/get-convex/convex-helpers)

### Footnotes

1. For those curious, the distinction they draw is that parsing returns data with the new type, whereas validation only checks the type of an object, which leaves the type unchanged from the language’s perspective. [↩](https://stack.convex.dev/typescript-zod-function-validation#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Using branded types in validators

If you have a more specific type than what you can express with Convex validators, you can still document that at the type level in Convex by casting once in your schema definition.

If you have a type that you use to distinguish different strings, for instance, you might want to make sure you're passing just those types around. E.g. you might have a type:

```
type MyStringType = string & { __myStringType: never };

```

### brandedString helper

If you just want to get to the code, you can use the [convex-helpers](https://www.npmjs.com/package/convex-helpers#validator-utilities) helper:

```ts
import { brandedString } from "convex-helpers/validators";
import { Infer } from "convex/values";

export const emailValidator = brandedString("email");
export type Email = Infer<typeof emailValidator>;

```

Read on to learn more about casting in different scenarios.

### Casting schema validators

If you want to use this type for Convex, you can only set a field validator as `v.string()`. However, if you cast it in your schema definition, you'll get the types everywhere automatically:

```ts
import { defineSchema, defineTable } from "convex/server";
import { Validator, v } from "convex/values";

defineSchema({
  myTable: defineTable({
    myField: v.string() as Validator<MyStringType>
  })
8)}

```

`field` will be typed as `MyStringType`. When you have a query like:

```ts
const doc = ctx.db
  .query("myTable")
	.filter(q => q.eq(q.field("myField"), foo)
	.first();

```

You will have type hints that the parameter for `foo` needs to be of type `MyStringType` and you'll get type errors if your type doesn't match.

You'll also see that `doc.myField` has the type `MyStringType` when you retrieve it.

### Casting argument validators

The same logic applies to function arguments:

```ts
export const foo = query({
  args: { bar: v.string() as Validator<MyStringType>},
  handler: async (ctx, args) => {
    //... args.bar is type MyStringType
  },
6});

```

On the client, you'll get type errors if you don't pass `MyStringType` as the `bar` parameter.

### Can I get into trouble?

Yes! Whenever you use `as` in TypeScript, you're saying "hey compiler, I know better than you here, so just trust me, k?". Casting to a branded string is less risky than `as any`. Thankfully, TypeScript will try to save you from glaring errors. For instance, if you do:

```ts
    counter: v.number() as Validator<string>,

```

you could get into a situation where the field expects to be compared to a string as a type, but at runtime will be validated as a number.
Thankfully, in situations this embarrassing TypeScript will give you an error:

```
Conversion of type 'Validator<number, false, never>' to type 'Validator<string, false, never>' may be a mistake because neither type sufficiently overlaps with the other. If this was intentional, convert the expression to 'unknown' first.
  Type 'number' is not comparable to type 'string'.ts

```

TypeScript will only let you cast when it's plausible. This doesn't mean you can't make a mistake, but it will hopefully save you most of the time. And if you really think you know better than the compiler, you can do `v.number() as unknown as Validator<LiterallyAnythingGoesAtThisPoint>`, just don't send it to me in a pull request :).

### What happens at runtime?

At runtime, it will just be validated with `v.string()`. These types disappear when the TypeScript is compiled to JavaScript, and you'll observe `typeof myField === "string"`. TypeScript is not static typing. It's some fairy dust sprinkled on top of JavaScript that gets baked off during transpilation to js (e.g. when you run `tsc`).

### What is string branding?

String "branding" is where you annotate a type that is different than a normal string at the type level, even though it's just a string at the runtime level. For instance, a Convex `Id<"users">` is the type `string & { __tableName: "users" }`. This means if I try to assign `const foo: Id<"users"> = "bar";`, I will get a type error. It's fine to do `const foo: string = "bar" as Id<"users">;` however, since `Id` is just a more "refined" type of `string`.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Work Stealing: Load-balancing for compute-heavy tasks

For fast, light-weight workloads, you can often get away with a small number of powerful machines. Even when load isn’t distributed evenly, a single backlogged machine won’t noticeably impact a user’s experience.

However, when your app requires heavy operations, such as running requests on an LLM, transcoding a video, or intensive cryptography, you need a better strategy for handling concurrency.

Requests that monopolize many CPU or GPU cores require more machines, as each machine is able to handle less parallelism. When you factor in slow requests, a single backlogged machine can cause significant delays and p95 performance degredation, even if the overall system has extra bandwidth.

So how can you distribute the load across many workers?

#### tl;dr

In this post I’ll explain the “work stealing”[1](https://stack.convex.dev/work-stealing#user-content-fn-1) strategy for task distribution and why you should consider it for workloads that:

1. Take significant time to execute.
2. Do not share resources well, such as GPU-intensive computation.
3. Prioritize throughput and utilization over average-case latency.
4. Run locally, behind a NAT, or are otherwise not discoverable from a web server.

## Overview

We will look at two strategies for managing resource-intensive workloads:

1. **Push-based** routing: a load balancer decides where to send requests and waits for a response from the worker, which it then returns to the client.
2. **Pull-based** “work stealing”: an incoming request is put on one or more queues from which workers pull. They publish results which can be included in the response to the original request, or pulled from the client via a subscription, allowing the original response to return early. Multiple clients can subscribe to the result.

One way to think about this is ordering food at a restaurant.

A push-based approach would assign you to a chef when you walked in the door, as a load balancer forwards a request. You’d wait for all other parties assigned to the chef to be served, hoping there aren’t many time-intensive dishes ahead of you, and wondering if anyone else was lucky enough to be assigned to an idle chef. If you left the restaurant for any reason, you’d be re-assigned when you came back in, losing your place in line.

A pull-based approach is more similar to getting an order number. All guests have their orders taken when they walk in, and chefs work on the next order as they become available. You can walk around with your order number, check in on its status, or even cancel your order if it hasn’t been started. It’s more efficient for the chefs, but it requires writing things down and having a way to notify you when your food is ready, since you might not be standing next to the chef waiting.

As a concrete code example, I recently put out a demo of distributed LLM computing: [llama farm](https://labs.convex.dev/llama-farm), where requests to the website that require llama3 are farmed out to workers. I can run these workers from the command line on a spare laptop, in containers hosted on [fly.io](https://fly.io/), or even from browsers using [web-llm](https://github.com/mlc-ai/web-llm). The repo is an implementation of “work stealing,” which enables these llama workers to pull and process jobs at their discretion without exposing a port to http requests or requiring service discovery. Read [this post](https://stack.convex.dev/implementing-work-stealing) about the implementation, or check out the [code](https://github.com/get-convex/llama-farm-chat).

To learn more about work stealing and how it compares to more traditional load balancing, read on. For the sake of this article, I’ll use the example of processing LLM requests, but the techniques naturally extend to any high-latency or hardware-intensive workload.

### Do I need this?

**Note:** This decision assumes you are controlling your own infrastructure. If you are using a cloud service, such as using [Replicate](https://replicate.com/) to serve and scale your models, you don’t have to worry about this - you are paying them to make these decisions and scale transparently. Most of the time this is the right way to start.

Some reasons you might benefit from scaling your own infrastructure:

- **Controlling data**: If you are unwilling to send data to a third party LLM, you can run your own machines and know how your data is being handled and used. This is especially important if you have data governance requirements preventing it from leaving a private network.
- **Controlling costs**: Cloud providers allow you to scale more granularly at a higher per-request cost. By deciding when and how many machines you run, you control your scale.

  - Note: I say controlling rather than reducing because, until you utilize your machines well, this is unlikely to save you money. In the case of [llama farm](https://labs.convex.dev/llama-farm), however, we avoid paying for dedicated GPUs altogether by leveraging existing idle hardware.
- **Controlling latency**: By controlling the routing and prioritization of requests, you can ensure tighter bounds on latency than you may get from a cloud provider, which is likely sharing resources with other customers and may not expose a mechanism for you to prioritize or cancel requests. Note: you’ll need to decide how to absorb spikes of traffic. Options include:

  - **Over-provisioning** (or auto-scaling) your hardware to accept additional load.
  - **Shedding load** by rejecting requests (often with a 429 status code) and relying on clients to retry later.
  - **Accepting high latency** during these periods, ideally isolated to low-priority traffic.

## Push-based routing

WorkerAPI ServerWorkerAPI ServerResource-intensive taskClientRequestRequestResultResultClient

Traditionally, the web works via pushing, or sending, requests. A request (usually HTTP) gets routed to a machine based on its IP address. For compute-intensive tasks, a client typically hits an API endpoint, which doesn’t do the CPU-intensive operation itself but rather makes its own request to a pool of dedicated workers. Forwarding the work to other machines isolates the API server’s resources so it is available to serve other requests, while also allowing you to scale the workers on use-case-specific hardware, such as machines with GPUs, separately from the web servers. The API server returns the (potentially streamed) results to the client.

#### Benefits:

- **Serverless hosting**. On platforms where you only pay for the duration of a request, you can avoid running the machine between requests. For a worker to pull requests, it needs to be running continuously or auto-scaled by a monitoring service.
- **Standard**. It is easier to reason about latency, errors, and work attribution for a traditional request. By comparison, when a worker pulls work and publishes results, it is no longer within the call graph of the original request.
- **Stateless**. When you hold open the client request and return the result directly from a worker, you don’t have to persist any state if you don’t want to.

#### Challenges:

- **Load balancing** needs to keep track of workers.

  - You have to guess which backend to send work to, or poll every worker for their state.
  - When a backend starts or stops, something needs to update, whether it’s [Consul](https://www.consul.io/), [kube-proxy](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/), [ELB](https://aws.amazon.com/elasticloadbalancing/), or otherwise. To stop a worker without incurring failures, you need to prevent the load balancer from sending new requests and then finishing existing ones.
  - These updates can fail or take some time.
  - All workers need to be discoverable and exposed to inbound http traffic. To run a worker on your local machine, you could use a service like [Tunnelmole](https://tunnelmole.com/) or [ngrok](https://ngrok.com/) to proxy traffic, which exposes you to public internet traffic.
- **Isolated queues**: if a worker has too many requests, it can only queue or reject.

  - Requests might not be started in the order they were received, and higher priority requests may be queued behind lower priority ones.
    - Often the queueing happens in the TCP socket connection, which can’t distinguish application-layer details, such as request priority or expected duration.
  - Per-machine queues [can cause high tail latency in distributed systems](https://cacm.acm.org/research/the-tail-at-scale/#body-4).

    - Some workers might be idle while others have a backlog of slow requests.
- **HTTP connection lifecycle**: the API request needs to hold open both incoming and outgoing connections for the duration of the work.

  - If the client loses the connection, the operation can’t easily resume. Even with sticky connections, an API server could come up on a new machine during a deploy.
  - This can results in low CPU utilization on the API server. If this is a serverless function, you may be paying for this idle time.

## Pull-based work stealing

WorkerAPI ServerWorkerAPI ServerAdded to queueResource-intensive taskSubscription triggeredClientRequestSuccessfully queuedClaim work​ResultResultClient

Compared to push-based, in a pull-based system, workers take on or ”steal” work when they have capacity, and then publish the result. To see an implementation of work stealing, check out [this post](https://stack.convex.dev/implementing-work-stealing) and this GitHub repo where I implement it for LLM-powered group chat:

**[Implementing work stealing with a reactive database](https://stack.convex.dev/implementing-work-stealing)**

[get-convex/ **llama-farm-chat**\\
\\
![GitHub logo](https://stack.convex.dev/logos/github.svg)](https://github.com/get-convex/llama-farm-chat)

#### Benefits

- **Optimizing throughput** with consistent concurrency.

  - In non-user-facing workloads you want to utilize machines as efficiently as possible, which is especially common in AI applications where you want to crawl large amounts of data to generate embeddings. Instead of controlling how fast you push work and to which machines, having a large work queue consumed by workers that you can dynamically spin up allows for optimal utilization.
  - For user-facing workloads, during spikes in load the API server knows how much work is in flight and can decide whether to reject or enqueue the work, as well as whether to re-order or cancel existing jobs based on priority.
- **No load-balancing** or service discovery.

  - Workers can come and go without updating anything - they simply start requesting work.
  - Workers only make outbound requests: they can safely run behind a NAT.
- **No isolated queues**: workers don’t accumulate their own backlog.

  - By sharing a global queue, performance (latency) is more uniform and can be FIFO or globally prioritized.
  - Workers decide when to take on work, and how much.
  - To stop, they finish their requests and don’t request more.
- **Multiplexed subscriptions**: clients can start jobs, disconnect, and re-subscribe to results. In fact, many clients can be subscribed to the result, since it is persisted outside of the scope of an active http request.

#### Challenges

- **Serverless hosting ecosystem**: workers need to be subscribed and are harder to dynamically wake up, compared to serverless hosting models that [wake on incoming HTTP requests](https://fly.io/docs/apps/autostart-stop/).
- **Failures are harder to detect**: the worker needs to periodically let the server know it’s still working. With “push” HTTP requests, failure can be detected automatically by the connection closing.
- **Additional overhead**: every request is persisted and flows through a subscription mechanism such as a pub/sub service, or database queries in Convex.

  - If the request is otherwise fast, the additional latency might be noticeable. It will affect the "average case" or "p50" performance.
  - If the requests are frequent and don’t otherwise require much database bandwidth, the overhead of tracking requests might be noticeable.

## Making the call: my experience

While pull-based solutions have a lot of benefits, this decision is highly sensitive to your application’s needs. I’ll contextualize this with my own experience deciding between push- and pull-based solutions for task distribution.

I used to run the team at Dropbox responsible for generating previews of user documents. If you’ve ever used the Dropbox website and looked through images, watched a video, or looked at a pdf preview of a Microsoft Office document, that file was processed by the system my team built and maintained. We thought deeply about load balancing, caching, and reliability. One fun statistic: if you removed the cache and processed the full file for every user’s request, it would amount to processing over one exabyte of data per day.

When we were re-architecting it, we considered both push & pull.

#### Why we wanted a pull-based solution:

1. **System utilization and maximizing throughput**. We had different classes of services optimized for different operations - video transcoding, windows emulation for office documents, etc. These machines knew their capabilities, and we were excited about a workflow where a machine could take on different types and quantities of work based on its available memory and CPU utilization.
2. **Absorbing and shedding load.** There were occasionally spikes of load that meant either failing requests, or saturating each service’s http queue and driving up latency for all users. With a queue we could have had more control over which requests we dropped and which requests we could continue to prioritize.
3. **Avoids service discovery.** Keeping track of which machines to route to introduces many opportunities for failure, especially during deployments:

1. When a backend dies, how soon will service discovery adapt?
2. When a machine comes online, how soon will it be discovered?
3. When service discovery fails (it does), how well can you keep serving traffic?

#### Why we ended up with a push-based solution:

1. **Our database wasn’t reactive:** determining from the backend when a job was available, or detecting when it was finished from the API server would have involved additional infrastructure.
2. **Predictability:** our infrastructure was based around discrete HTTP requests that flowed into gRPC services, not WebSockets and subscriptions. This influenced what tooling was readily available.
3. **High volume, low latency**: although occasional requests took minutes, most of our traffic was very high volume and low latency (~5ms). Incurring a database write per request would have overwhelmed the database, and a pub/sub subscription was too heavyweight.
4. **Uniformity:** there was a case for doing pull-based requests only for heavy operations like video transcoding, but we were a small team and didn’t want to maintain two sets of infrastructure.
5. **Monitoring:** we wanted to track latency and success statistics in a centralized place close to the request. Splitting the status across multiple metrics reported from different services and machines would have complicated our monitoring setup.

I don’t regret making that decision at the time. However, I do think some things have changed since then that enable the work stealing pattern for modern apps, such as **reactive databases**.

## Why reactive databases change the game

One big challenge with workers pulling work is connecting the result back to the client. If you want to return it in the client’s original request, the worker needs to know which API server to send the work to, and get the result to the right thread or process waiting for the request. Or it needs to leverage a pub/sub system where the worker is subscribed only for its own results. This “return address” problem ends up requiring a lot of nuance to get right at scale. For example, how long should the pub/sub system wait before dropping the message?

Since using Convex, I’ve come to appreciate separating data flow between queries, which are read-only, side-effect-free, consistent views of data, and mutations which are read-write transactions. This is an increasingly common separation, and greatly simplifies how you reason about data moving through a system, including for work stealing.

- A client subscribes to a view of data with a query. In the case of a chat app, it subscribes to recent messages in a channel. Whenever those messages are updated, regardless of who updated them, it gets a fresh view of the data.
- The work can be submitted to the API server (Convex in my case) whether it’s within the context of a client request or not. In the case of my chat app, the original request creates a placeholder message, and submits a job to fill out the message. When the worker generates and submits the message — whether it’s a partial update or the final result — all the API endpoint needs to know is what record(s) to update in the database.
- The communication channel — how users end up seeing the message — is the same as the application’s transactional data persistence: the reactive database. There’s never a case where a client receives a result but the result was never persisted, or where the result was recorded but the client missed the update.

I was pleasantly surprised how quickly this pattern came together for [llama farm](https://github.com/get-convex/llama-farm-chat), and am excited to see what novel architectures this enables.

## Summary

In this post we compared push-based load balancing with pull-based work stealing, as ways of distributing resource-intensive workloads. While the former is the traditional strategy, the latter brings a lot of benefits, provided you are able to separate your reads and writes.

Next steps:

- To learn more about optimizing for latency, I recommend reading the paper “ [The Tail at Scale](https://cacm.acm.org/research/the-tail-at-scale/)” if you haven’t read it already.
- To see an implementation of work stealing, read [this post](https://stack.convex.dev/implementing-work-stealing) about implementing llama farm, or read the code [here](https://github.com/get-convex/llama-farm-chat).
- Learn more about how Convex works [here](https://stack.convex.dev/how-convex-works).

### Footnotes

1. If you’re curious where the term “work stealing” comes from, [it is a scheduling algorithm for parallel computing](https://en.wikipedia.org/wiki/Work_stealing), specifically when there is one queue of tasks per process where another process can “steal” tasks (threads to execute) while idle. In our example, we simplify it to have one queue for the sake of explanation. At high scale, this technique at scale involves dividing requests into multiple queues, and having each worker interact primarily with a one or a subset of them, and stealing work from other queues when idle. Let me know [in Discord](https://convex.dev/community) if you'd be interested in an article on doing this at scale. [↩](https://stack.convex.dev/work-stealing#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Authentication: Wrappers as “Middleware”

Exciting news! There is an easier way to customize your queries, mutations, and actions. Check out [this post](https://stack.convex.dev/custom-functions) to see how to use `customFunction` helpers from the `convex-helpers` npm package.

![Layers. Photo by Hasan Almasi: @hasanalmasi on Unsplash](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F656924fff89ee5c82694a382bac01d90d5f804a8-5184x3456.jpg&w=3840&q=75)

In this post, I’ll introduce a pattern that, like middleware, can add functionality before or after a request but is explicit and granular, unlike middleware. This is the first of a series of posts on pseudo-middleware patterns to help structure your Convex code. Let us know in Discord what else you want to see! If you want to see a typescript version of the code, you can reference it [here](https://github.com/get-convex/convex-helpers/blob/main/convex/lib/withUser.ts).

## The problem

[Setting up auth](https://docs.convex.dev/using/auth) in Convex is easy. However, the resulting code can end up cluttering your functions if you aren’t careful. Consider our [auth demo’s](https://github.com/get-convex/convex-demos/tree/main/users-and-auth) function to [send a message](https://github.com/get-convex/convex-demos/tree/main/users-and-auth/convex):

```tsx
export default mutation(async ({ db, auth }, { body }) => {
  const identity = await auth.getUserIdentity();
  if (!identity) {
    throw new Error("Unauthenticated call to mutation");
  }
  // Note: If you don't want to define an index right away, you can use
  // db.query("users")
  //  .filter(q => q.eq(q.field("tokenIdentifier"), identity.tokenIdentifier))
  //  .unique();
	const user = await db
    .query("users")
    .withIndex("by_token", q =>
      q.eq("tokenIdentifier", identity.tokenIdentifier)
    )
    .unique();
  if (!user) {
    throw new Error("Unauthenticated call to mutation");
  }

  const message = { body, user: user._id };
  await db.insert("messages", message);
22});

```

All of the endpoint logic is in the last few lines!

## The goal

We want to provide a `user` where we’d normally access the [`auth`](https://docs.convex.dev/api/interfaces/server.Auth) object.

```tsx
export default mutation(
  withUser(async ({ db, user }, { body }) => {
    const message = { body, user: user._id };
    await db.insert("messages", message);
  })
6);

```

## The `withUser` solution

Our wrapper function, provided below, may look a little complicated, so let’s talk about what it’s doing. Like `mutation` and `query`, `withUser`'s only argument is a function. However, this function wants to be called with the `user` populated in the first parameter. So you can see in the call `func({ ...ctx, user }, args)`, we are passing in the user that we looked up. Popping out a layer, `withUser` itself returns an async function that can be passed to `query` or `mutation`. So we define an inline async function that, given the normal `ctx` and arguments, will call the passed-in function `func` with the same arguments and the first parameter augmented. If this bends your brain, you’re not alone. Feel free to copy-paste. And for those nervous about how you’d type this in typescript, don’t worry. You can copy it from [here](https://github.com/get-convex/fast5/blob/main/convex/lib/withUser.ts).

```tsx
1/**
 * Wrapper for Convex query or mutation functions that provides a user.
 *
 * @param - func Your function that can now take in a `user` in the ctx.
 * @returns A function to be passed to `query` or `mutation`.
 */
export const withUser = (func) => {
  return async (ctx, ...args) => {
    const identity = await ctx.auth.getUserIdentity();
    if (!identity) {
      throw new Error(
        'Unauthenticated call to a function requiring authentication'
      );
    }
    // Note: If you don't want to define an index right away, you can use
    // db.query("users")
    //  .filter(q => q.eq(q.field("tokenIdentifier"), identity.tokenIdentifier))
    //  .unique();
    const user = await ctx.db
      .query('users')
      .withIndex('by_token', (q) =>
        q.eq('tokenIdentifier', identity.tokenIdentifier)
      )
      .unique();
    if (!user) throw new Error('User not found');
    return await func({ ...ctx, user }, ...args);
  };
28};

```

### Why extend the first argument with new parameters?

In python, the language I’ve worked with this pattern the most, the common practice for wrapper functions is to pass new parameters as the new first arguments to a wrapped function. However, for Convex we can leverage the fact that the first argument to functions is always [`ctx`](https://docs.convex.dev/generated-api/server#queryctx), and extending it comes with some great ergonomics. Using the fact that it’s an object, we can:

- Flexibly add middleware-like parameters while maintaining the aesthetic of positional arguments matching the positional arguments on the client.
- Add more wrappers in the future without having to keep track of which order the injected parameters are in, or knowing how many parameters they inject.
- Use a middleware wrapper without using its provided value(s).

## Codifying patterns

Those familiar with factories, decorators, or middleware will recognize this pattern. Rather than requiring every user to repeat the same lines of code at the start or end of a function, you can codify that pattern into a function. Beyond saving some time, leveraging patterns like this helps:

- Keep your code [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself).
- Increase the density of meaningful code.
- Organize code by logical function. See [aspect-oriented programming](https://en.wikipedia.org/wiki/Aspect-oriented_programming) for an extreme perspective on this.
- Give the code reviewer shortcuts.

I’ll expand on this last point. By noticing that it’s using the `withUser` helper, a reviewer can rest assured that this function will only be executed with a logged-in user. This becomes a more powerful reassurance when you compose these functions, such as `withTeamAdmin`, which we’ll see below.

## Composing functions

The exciting part of using this sort of pattern is that it’s easy to compose it with other functions. In a simple example, we can combine `mutation` and `withUser` like so:

```tsx
export const mutationWithUser = (func) => {
  return mutation(withUser(func));
3};

```

This has the ergonomic benefit of decreasing the indentation level of your function, if you use [prettier](https://prettier.io/). However, you can imagine much more interesting compositions, like:

```tsx
export const withTeamAdmin = (func) => {
  return withUser(withTeam(async (ctx, args) => {
    const {user, team} = ctx;
    const admin = await getTeamAdmin(user, team);
    if (!admin) throw new Error('User is not an admin for this team.')
    return await func({...ctx, admin}, args)
  }));
8}

export const setTeamName = mutation(
  withTeamAdmin(async ({ db, team, admin }, { name }) => {
    console.log(`${admin.name} is changing team name`);
    await db.patch(team._id, {name});
  });
15);

```

## Why wrap at all?

You might be thinking to yourself that this is a lot of indirection for what could be a series of regular functions. Indeed, this pattern can introduce complexity for someone looking at the code for the first time. Where did the `user` arg come from? Why is my stack trace full of `withX` calls? Sometimes, it is clearer and less surprising to call regular functions. Here are some **scenarios when wrapping is useful**:

- You want to control what the function returns.
- You want to do work before and after the function, such as opening and closing a file.
- You need to clean up if the called function throws an exception.
- Misusing a function (such as forgetting to await it or handle its response correctly) would have serious implications.
- You want to compose your behavior with the above scenarios consistently.
- You will reuse these wrappers frequently.

## Wrapping up

Using wrapper functions like `withUser` can help you organize your code into middleware-like blocks that you can compose to keep your function logic concise. A typescript version of the code is [here](https://github.com/get-convex/convex-helpers/blob/npm/0.1.1/convex/lib/withUser.ts), and used by [Fast5](https://fast5.live/) [here](https://github.com/get-convex/fast5/blob/main/convex/lib/withUser.ts). Let us know in [Discord](https://discord.com/channels/1019350475847499849/1066114385543692338) what you think and what you’d like to see next!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Zod Validation: Wrappers as “Middleware”

Loading...

![Convex loves zod](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F8e2010604289193a42bdd00ec1a48d7f0d746d27-1200x628.jpg&w=3840&q=75)

Following up on the previous post on using `withUser` to add authentication context to your [Convex functions](https://docs.convex.dev/using/writing-convex-functions), now let’s look at adding function validation using a popular npm package `zod`. Check out the code in action in the [convex-demos](https://github.com/get-convex/convex-demos/tree/main/zod-validation-ts) repo.

Function validation is important for a production app, because you can’t always control which clients are talking to your server. Consider the following code from [our tutorial](https://github.com/get-convex/convex-demos/blob/main/tutorial/convex/sendMessage.js):

```js
// convex/sendMessage.js
export default mutation(async ({ db }, { body, author }) => {
  const message = { body, author };
  await db.insert("messages", message);
5});

```

This code runs in the server, and stores a message in the “messages” table. That’s great, assuming the client sends data in the right format. Most of the time, that will be the case. If you use typescript, we’ll even warn you in your frontend React code when the parameters to your server function are the wrong type. See what this looks like in our [typescript demo](https://github.com/get-convex/convex-demos/blob/main/typescript/convex/sendMessage.ts):

```ts
// convex/sendMessage.ts
export default mutation(
  async ({ db }, { body, author }: { body: string; author: string }) => {
    const message = { body, author };
    await db.insert("messages", message);
  }
7);

```

However, a friendly internet stranger might connect to your backend and send any number of things: wrong types, binary data, nested objects, etc.. Typescript doesn’t enforce types at runtime, it only helps you with static analysis. What does that mean? While Typescript can help catch developer errors where you’re using types incorrectly in code, once the application is running the Typescript types aren’t being enforced by the runtime. For serverless applications that have unauthenticated endpoints, you need to be especially defensive with your function arguments, since a fake client could connect to your backend and pass whatever arguments it wants. Just declaring the type of `body` to be `string` doesn’t make it so. So what can we do?

## Using Convex input validation

Update: At the original time of this post, we didn't have input validation as part of Convex.
With 0.13.0 and later, however, you can add input validation like this:

```js
export default mutation({
  args: {
    body: v.string(),
    author: v.string(),
  },
  handler: async ({ db }, { body, author }) => {
    const message = { body, author };
    await db.insert("messages", message);
  }
10});

```

And it'll validate the types of the arguments! Keep reading to learn how to use Zod to do even more validation, for instance validating string lengths or things our syntax doesn't support (yet).

## Using `withZod` for input validation

Using the popular `zod` library, we can define the types that we expect for our function. When it gets invoked, the inputs will be validated. To make this convenient, I’ve written a `withZod` wrapper so you can type your function arguments, and not have to worry about validating the first `{ db, ... }` argument, which is provided by the query, mutation, or action. So now your code looks like this:

```tsx
export default mutation(
  withZod({
    args: {
	  body: z.string(),
	  author: z.string(),
	},
    handler: async ({ db }, { body, author }) => {
      const message = { body, author };
      return await db.insert("messages", message);
    }
  })
12);

```

Note: For a typescript version of everything in this post, you can look [here](https://github.com/get-convex/convex-helpers/blob/npm/0.1.1/convex/lib/withZod.ts). In there are also various helpers for combining with `query`, `mutation`, and `action`, as well as helpers for if you want to pass in a whole custom zod function rather than just the arguments and return type.

#### Aside: the above is already valid typescript!

By leveraging zod to give us validation, it is also giving us the types of our parameters. So we can avoid duplicating that definition, while still getting type hints, both in the server code **and in the client**. Convex has always had canonical end-to-end typing: from your data model definition to the client, it’s all in typescript. Now, the typescript types for your functions are generated from your validator, so your code is safe by default!

#### zId Helper

You’ll note above we used `zId`. This is a helper, meant to resemble `s.id("messages")` in [your `schema.ts` file](https://docs.convex.dev/database/schemas), but for zod. Feel free to make any other helpers you’d like and share them with us [in Discord](https://convex.dev/community).

```jsx
export const zId = (tableName: TableName) =>
  z.custom((val) => val instanceof Id && val.tableName === tableName);

```

## Implementing withZod

For those curious, or who want to copy and extend this pattern, this is what we are doing under the hood:

```jsx
export const withZod = ({ args, handler }) => {
  const zodType = z.function(z.tuple([z.object(args)]));
  return (ctx, args) => {
    const innerFunc = (validatedArgs: z.output<z.ZodObject<Args>>) =>
      handler(ctx, validatedArgs);

    return zodType.implement(innerFunc)(args);
  };
9};

```

We are using a `z.function` and passing in the untrusted arguments, while just passing through the `ctx` argument.

Note: For a typescript version, go [here](https://github.com/get-convex/convex-helpers/blob/npm/0.1.1/convex/lib/withZod.ts).

## Combining with other wrappers

As with our previous post, you can combine it with other wrappers or one of the [Convex function](https://docs.convex.dev/using/writing-convex-functions) generators to reduce duplicate code, and reduce the indentation of your function definition:

```jsx
const mutationWithZod = ({ args, handler }) => mutation(withZod({ args, handler }));

```

```tsx
export default mutationWithZod({
  args: {
    body: z.string(),
	author: z.string(),
  },
  handler: async ({ db }, { body, author }) => {
    const message = { body, author };
    return await db.insert("messages", message);
  },
10});

```

See [here](https://github.com/get-convex/convex-helpers/blob/npm/0.1.1/convex/lib/withZod.ts) for implementations of this and others in typescript.

### Zod without withZod 🤯:

You can do all this yourself, without our fancy `withZod` wrapper, by putting your application code inside an `implements` or `strictImplements` definition for a [zod function](https://zod.dev/?id=functions).

```tsx
export default mutation(async ({ db }, { body, author }) => {
  return z
    .function()
    .args([z.object({body: z.string(), author: z.string()})])
    .returns(z.promise(z.object({ _id: zId("messages") })))
    .implement(async ({ body, author }) => {
      const message = { body, author };
      const id = await db.insert("messages", message);

      return (await db.get(id))!;
    })({ body, author });
12});

```

## In summary

In this post, we looked at a way to add type validation to [Convex functions](https://docs.convex.dev/using/writing-convex-functions) by using the [`zod` npm](https://www.npmjs.com/package/zod) package. You can grab the library code from [here](https://github.com/get-convex/convex-helpers/blob/npm/0.1.1/convex/lib/withZod.ts), or play around with a demo app [here](https://github.com/get-convex/convex-demos/tree/main/zod-validation-ts)! As always, let us know in [our Discord](https://convex.dev/community) what you think!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

---

# Edge to Butt: Wrappers as "Middleware"

Exciting news! There is an easier way to customize your queries, mutations, and actions. Check out [this post](https://stack.convex.dev/custom-functions) to see how to use `customFunction` helpers from the `convex-helpers` npm package. It's it great living on the butt?

![The Edge](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F6197d11250ac102dd72454ac366a5c54f211fb71-1000x563.jpg&w=3840&q=75)

I loved reading the informative and useful [Wrappers as Middleware: Authentication](https://stack.convex.dev/wrappers-as-middleware-authentication) from Ian Macartney. But it’s time to get serious and Enterprise in here. Let’s focus on a piece of Convex middleware **real** projects need.

Years ago, an inspired soul created a “Cloud to Butt” movement wherein millions of Internet denizens installed a cheeky [Chrome extension](https://chrome.google.com/webstore/detail/cloud-to-butt-plus/apmlngnhgbnjpajelfkmabhkfapgnoai?hl=en). Within Chrome, this extension transformed all web content uses of the word “cloud”, or “the cloud”, to "butt", “my butt”, and so on. Resulting in childishness like this:

![Screenshot](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F10f0cacdaad31ce5dcb9eaeef4c8632c650904ad-960x511.jpg%3Fw%3D450&w=3840&q=75)Screenshot

This whole phenomenon was clearly a cheap attempt to capitalize on our collective cynical, weary leeriness at the growing ubiquity of the word “cloud”. Everything we used to just call the Internet, or servers, or whatever, started being labeled “the cloud” one day by breathless digital marketers. So we responded by channeling our inner seven-year-olds and using potty humor.

But it’s not 2014, it’s 2023. We’ve all matured, and we’ve even come to embrace the term _cloud_ as a warm friend–of _course_ the cloud is here, and it generously runs everything for us for an oh-so reasonable fee, and we embrace it! We wouldn’t _dream_ of offending the cloud!

Now the new intruder we’re rolling our eyes at is “the edge”. The edge is nothing like the cloud. It’s mysterious and coming for us. Everyone is starting to say it and we’re starting to feel inadequate that we’re not using it enough or talking about it the right way at parties!

## Problem solved.

Introducing the newest piece of Convex middleware, Edge-to-Butt. Just drop this little beauty into your Convex queries and mutations, and your website will thumb its nose at this snot-nosed newcomer they're calling “the edge”.

First, let’s write a function that traverses any object or array recursively and looks for strings:

```tsx
// Recursively explore objects/arrays and scalar values, looking for strings
// to transform from 'edge' into 'butt'.
function buttify(value: any): any {
  const isArr = Array.isArray(value);
  if (isArr) {
		// recurse for all items in the array
    value.forEach((v, i) => {
      value[i] = buttify(v);
    });
    return value;
  }
  const valueType = typeof value;
  if (valueType === "object") {
    for (var key of Object.keys(value)) {
			// recurse for all fields on the object
      value[key] = buttify(value[key]);
    }
    return value;
  }
  if (valueType === "string") {
    // String! replace "edge" with "butt", as one does.
    return value.replace(/(^|\W)(edge)(\W|$)/gim, caseStableButtification);
  }
  return value;
25}

```

Now, the key to this whole system is this `caseStableButtification` function. This is Enterprise software, so we need to get the details right. We want to make sure we only change the word ‘edge’, not ‘ledge’. And we want to preserve the case, so if someone says “Edge computing is the future”, we’ll want a capital B on that baby.

Here’s what that function looks like, operating on the groups of our matched regex:

```tsx
// Convert 'edge'  to 'butt' while preserving case and surrounding syntax.
function caseStableButtification(
  _: string,
  prefix: string,
  edge: string,
  suffix: string
7): string {
  const fixEdge = (s: string): string => {
    var buttLetters = [...s].map((l, i) => {
      if (l.toLocaleUpperCase() === l) {
        return BUTT.charAt(i).toLocaleUpperCase();
      } else {
        return BUTT.charAt(i);
      }
    });
    return buttLetters.join("");
  };
  return prefix + fixEdge(edge) + suffix;
19}

```

Finally, we need our Convex wrapper, and we'll use it on the standard `listMessages` query from the [Convex tutorial](https://docs.convex.dev/tutorial/welcome-to-convex):

```tsx
1/**
 * Wrapper for Convex query or mutation functions turns all use of "edge" to
 * butt.
 *
 * @param - func: your Convex query function.
 * @returns A return value with all strings having "edge" transformed
 * into "butt".
 */
export const withEdgeToButt = (func: any) => {
  return async (...args: any[]) => {
    let result = await func(...args);
    buttify(result);
    return result;
  };
15};

// Retrieve all chat messages from the database with a sprinkle of 7-year old humor.
export default query(
  withEdgeToButt(async ({ db }: any) => {
    console.log("getting messages again");
    return await db.query("messages").collect();
  })
23);

```

## On the edge of your seat?

Are we ready for production? You tell me:

![Screenshot of the final app](https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2Ffb156dc6c77469890279c007e832238f870938d3-1920x1080.gif%3Fw%3D450&w=3840&q=75)Screenshot of the final app

I’m sure for many of you, this was the final Convex capability you were waiting for before taking the leap and using Convex on your next project. Please be patient with the team while we manage the influx of interest. Your call is important to us.

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# YOLO: Get to an MVP fast

Before you have shipped a product, don’t let “industry best practices” bog down your iteration speed. However, you also don’t want to paint yourself into a corner and have to immediately rewrite your app once things get real. Here are some ideas for how to move quickly early in the development lifecycle, without boxing yourself into irreversible patterns. This is one of a series of posts on operational maturity in production. Get more tips for best practices for running apps in production [here](https://stack.convex.dev/operational-maturity-for-production).

## Tips when starting out

#### Commit your code, especially when it’s working and before big changes

It’s very easy to lose time debugging when too many variables have changed and you can’t remember how to get back to a working state. Committing your code to `git` allows you to see what you’ve changed, and get back to a working state when you’ve lost the plot. Even if you don’t push to GitHub, you can `git init` locally.

#### Use logs liberally, and use log levels to organize them

As you develop, drop in `console.debug` statements in your Convex functions to capture state and events at various places. If you’re [in the dashboard logs view](https://docs.convex.dev/dashboard/deployments/logs) and it’s too verbose, you can hide the debug entries. When you’re reproducing an issue, you can also use the “Clear” button to start with an empty logs view, to just look at new logs that come in (without permanently deleting the past logs).

#### Play with queries interactively

Instead of editing and syncing functions, you can write queries directly in the dashboard and experiment with the syntax until you get the results you want, then you can copy that code into your repo. This is similar to iterating on raw SQL statements, then figuring out how to translate that to your language-specific query builder once you get it right.

#### Use auto reload and code sync for fast feedback in your dev environment

Avoid developing on a stack that requires explicit commands to build, compile, redeploy, and reload when you make code changes. In particular, don’t let your feedback cycle depend on `docker build`![1](https://stack.convex.dev/yolo-fast-mvp#user-content-fn-1) Tools like [Vite](https://vitejs.dev/) and [Next.js](https://nextjs.org/) do a great job of providing Hot Module Reload (HMR) which reloads your UI as you edit your frontend code, provided they’re run in the same file system as the code changes. Picking a backend like Convex for TypeScript or [uvicorn](https://www.uvicorn.org/) for [FastAPI](https://fastapi.tiangolo.com/) for Python will automatically re-build. Convex is especially powerful, in that you can develop locally against an open source build, or develop against a cloud-hosted dev environment, and both will watch for file changes, analyze for TypeScript errors, deploy the code to the server (whether local or remote), **and** re-execute any changed queries from your frontend automatically. No page refresh needed to fetch new database data!

#### Set up deploys on code pushes for fast feedback in production

Instead of deploying to production when you get around to it, set up deploy commands in your hosting provider like [Vercel](https://docs.convex.dev/production/hosting/vercel) or [Netlify](https://docs.convex.dev/production/hosting/netlify). By deploying on every push (whether you configure it to deploy only on changes to `main` or a dedicated branch like `prod`), you make it more likely that your live prototype will stay up to date, and you’ll get feedback faster from any early adopters. The sooner you catch issues, the fewer commits you have to check to find the bug.

#### Avoid stack overflows

I’m not talking about infinite recursion, but about the tendency to add unnecessary tooling to your infrastructure stack prematurely. In particular, these are tempting to add early on but time sinks:

- **Containerization** like `docker compose`, `kubernetes`, or `nomad`. Only use containers to recreate hard-to-reproduce environments that you need to share between collaborators or servers. Developing locally initially will let you experiment with changes faster than continually rebuilding the world from scratch.
- **CI/CD** such as GitHub Actions, and any containerized testing that can diverge from your development stack.
- **SSR** (server-side rendering), **RSC** (React server components), **SSG** (static site generation), **ISR** (incremental site regeneration), and other frontend optimizations where you’ll lose time debugging the difference between rendering in different environments, or in building development versus production.
- Low-level cloud platforms such as **AWS** or bare metal hosting like Digital Ocean. There is almost always a startup wrapping the AWS product you want to use, who have optimized for ease of integration, sane defaults and fast iteration. If your app becomes wildly successful, you can hire a team of experts to configure an optimized stack on lower level hardware. Until then, the cost in time and developer salaries of building things from scratch will vastly outweigh any pricing benefits.
- **Non-transactional data storage** such as Redis, Upstash, or edge databases. It’s hard enough to reason about data correctness in a new app without adding the combinatorial complexity of incorporating data stores that are not transactional with the rest of your application. Resist the temptation to trade off correctness for latency until you absolutely have to.

#### Use snapshot export to experiment with big changes

If you’re considering doing a radically different approach, you can use the [`npx convex export`](https://docs.convex.dev/cli#export-data-to-a-file) command in Convex or a SQL dump elsewhere to capture the database state beforehand. Then, if your changes don’t pan out, you can run [`npx convex import --replace`](https://docs.convex.dev/database/import-export/import) or the equivalent SQL load utility with the old snapshot to restore your data. This is a nifty tool for general development, but you can even do this for production data if you are feeling scrappy and want to do it live.

#### Delete dev data liberally and maintain a seed script to re-initialize

Instead of migrating data every time you change your schema, just delete the data that doesn’t match, and have a [seed mutation that inserts the correct data](https://stack.convex.dev/seeding-data-for-preview-deployments). When you edit the schema, you just edit the seed script (which will have type errors to help you find where to change). See [this post](https://stack.convex.dev/seeding-data-for-preview-deployments) for how to run these seed mutations automatically during development and for preview deployments. This is especially valuable for branch-based development, where you can switch branches, wipe your data, and re-seed your data.

To delete a table in Convex from the command line, here’s a nifty one-liner that deletes all documents by “importing” an empty file in “replace” mode:

```bash
npx convex import --table $TABLE --replace --format jsonLines /dev/null

```

And to delete from every table in one line:

```bash
for tableName in `npx convex data`; do npx convex import --table $tableName --replace -y --format jsonLines /dev/null; done

```

## Cutting corners: explicit immaturity

Here are some corners to cut in the name of iterating quickly that you can graduate out of over time. Whereas you can continue using the above tips, these tips are better left behind as your app matures.

#### Build an auth-free single-player version first

Instead of configuring [Clerk](https://docs.convex.dev/auth/clerk) on day one, first get your app working without any users. Figure out the core functionality before taking on the complexity of auth. I’ve seen a lot of projects stall out due to some mismatch between different environment variables, configurations, cookies, or otherwise. You can always layer auth on later.

#### Turn off schema validation

You can add data to a table [without defining a schema](https://docs.convex.dev/database/advanced/schema-philosophy) in Convex. However, you don’t get type safety or auto-complete until you [define your schema](https://docs.convex.dev/database/schemas) (which can be [auto-generated in the dashboard](https://docs.convex.dev/dashboard/deployments/data#generating-a-schema) by the way). One lesser-known feature, however, is that you can [disable schema validation](https://docs.convex.dev/database/schemas#schemavalidation-boolean) so you get all of the type benefits without having to keep your database data up to date with your schema changes.

You can also keep schema validation on, but [allow reading and writing to tables not specified in your schema](https://docs.convex.dev/database/schemas#stricttablenametypes-boolean), if you want to iterate on a feature that uses a new table, without losing the guarantees for other tables.

#### Migrate data by hand

[Edit your database data using the dashboard](https://stack.convex.dev/lightweight-zero-downtime-migrations) instead of writing code to update database data. For SQL, this is akin to running statements in a sql REPL on the command line, or running a tool like [adminer](https://www.adminer.org/). Writing and tuning migrations to edit 100 documents is a waste of time. Better yet, wipe the database and re-create it, as outlined above.

#### Put off building an admin dashboard

Building a dashboard to resolve user issues and dig through data is a common source of tech debt and security holes. You can view and edit production data in the Convex dashboard, and write [internal functions](https://docs.convex.dev/functions/internal-functions) to do more complicated changes that you can [run in the dashboard](https://docs.convex.dev/dashboard/deployments/functions#running-functions) or [from the CLI](https://docs.convex.dev/cli) to resolve user issues. Avoid accumulating the tech debt of building a second app until necessary.

## Summary

Before you burden yourself with “best practices” for large-scale companies, focus on what will reduce your feedback cycles and help you ship early and often. Think about your use case, not your toolbox.

When your app ready is ready, check out [this guide](https://stack.convex.dev/operational-maturity-for-production) for operational maturity for running apps in production.

### Footnotes

1. If you insist on using a docker container for development, ensure you’re either editing your code inside the container or mounting your repo’s directory into the docker container so code is immediately updated there. The latter is what I do for container-backed projects using `docker compose` or `k8s` locally. [↩](https://stack.convex.dev/yolo-fast-mvp#user-content-fnref-1)


Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Can your database do this? Ep 3: Zero-downtime, type-safe migrations

Convex's migrations component makes it easy and safe to run complex database migrations without causing any interruption to live traffic.

In this video, Jamie Turner walks through a migration on his "Fancy Movie Database" project. Fancy roman numerals were added to fancy movie copyrights effortlessly!

Build in minutes, scale forever.

Convex is the backend platform with everything you need to build your full-stack AI project. Cloud functions, a database, file storage, scheduling, workflow, vector search, and realtime updates fit together seamlessly.

Get started

We use third-party cookies to understand how people interact with our site.

See our [Privacy Policy](https://www.convex.dev/legal/privacy/) to learn more.

DeclineAccept

---

# Helper Utilities

# convex-helpers

A collection of useful code to complement the official packages.

Table of contents:

- [convex-helpers](#convex-helpers)
  - [Custom Functions](#custom-functions)
  - [Relationship helpers](#relationship-helpers)
  - [Action retries](#action-retries)
  - [Stateful migrations](#stateful-migrations)
  - [Rate limiting](#rate-limiting)
  - [Session tracking via client-side sessionID storage](#session-tracking-via-client-side-sessionid-storage)
  - [Richer useQuery](#richer-usequery)
  - [Row-level security](#row-level-security)
  - [Zod Validation](#zod-validation)
  - [Hono for advanced HTTP endpoint definitions](#hono-for-advanced-http-endpoint-definitions)
  - [CRUD utilities](#crud-utilities)
  - [Validator utilities](#validator-utilities)
  - [Filter](#filter)
  - [Manual Pagination](#manual-pagination)
    - [Examples](#examples)
    - [`paginator`: manual pagination with familiar syntax](#paginator-manual-pagination-with-familiar-syntax)
  - [Composable QueryStreams](#composable-querystreams)
    - [Example 1: Paginate all messages by a fixed set of authors](#example-1-paginate-all-messages-by-a-fixed-set-of-authors)
    - [Example 2: Paginate all messages whose authors match a complex predicate.](#example-2-paginate-all-messages-whose-authors-match-a-complex-predicate)
    - [Example 3: Order by a suffix of an index.](#example-3-order-by-a-suffix-of-an-index)
    - [Example 4: Join tables.](#example-4-join-tables)
  - [Query Caching](#query-caching)
  - [TypeScript API Generation](#typescript-api-generation)
  - [Open API Spec Generation](#open-api-spec-generation)
  - [Triggers](#triggers)
    - [What can you do with triggers?](#what-can-you-do-with-triggers)
    - [Trigger semantics](#trigger-semantics)
  - [CORS support for HttpRouter](#cors-support-for-httprouter)
  - [Standard Schema support](#standard-schema)

## Custom Functions

Build your own customized versions of `query`, `mutation`, and `action` that
define custom behavior, allowing you to:

- Run authentication logic before the request starts.
- Look up commonly used data and add it to the ctx argument.
- Replace a ctx or argument field with a different value, such as a version
  of `db` that runs custom functions on data access.
- Consume arguments from the client that are not passed to the action, such
  as taking in an authentication parameter like an API key or session ID.
  These arguments must be sent up by the client along with each request.

See the associated [Stack Post](https://stack.convex.dev/custom-functions)

For example:

```js
import { customQuery } from "convex-helpers/server/customFunctions.js";

const myQueryBuilder = customQuery(query, {
  args: { apiToken: v.id("api_tokens") },
  input: async (ctx, args) => {
    const apiUser = await getApiUser(args.apiToken);
    const db = wrapDatabaseReader({ apiUser }, ctx.db, rlsRules);
    return { ctx: { db, apiUser }, args: {} };
  },
});

// Use the custom builder everywhere you would have used `query`
export const getSomeData = myQueryBuilder({
  args: { someArg: v.string() },
  handler: async (ctx, args) => {
    const { db, apiUser, scheduler } = ctx;
    const { someArg } = args;
    // ...
  },
});
```

## Relationship helpers

Traverse database relationships without all the query boilerplate.

See the [Stack post on relationship helpers](https://stack.convex.dev/functional-relationships-helpers)
and the [relationship schema structures post](https://stack.convex.dev/relationship-structures-let-s-talk-about-schemas).

Example:

```js
import {
  getOneFromOrThrow,
  getManyFrom,
  getManyViaOrThrow,
} from "convex-helpers/server/relationships.js";
import { asyncMap } from "convex-helpers";

const author = await getOneFromOrThrow(db, "authors", "userId", user._id);
const posts = await asyncMap(
  // one-to-many
  await getManyFrom(db, "posts", "authorId", author._id),
  async (post) => {
    // one-to-many
    const comments = await getManyFrom(db, "comments", "postId", post._id);
    // many-to-many via join table
    const categories = await getManyViaOrThrow(
      db,
      "postCategories",
      "categoryId",
      "postId",
      post._id,
    );
    return { ...post, comments, categories };
  },
);
```

## Action retries

Use helper functions to retry a Convex action until it succeeds.
An action should only be retried if it is safe to do so, i.e., if it's
idempotent or doesn't have any unsafe side effects.

**Note**: this is now an [`action-retrier` component](https://www.convex.dev/components/retrier).
I recommend using that (`npm i @convex-dev/action-retrier`).

See the [Stack post on retrying actions](https://stack.convex.dev/retry-actions)

Example:

```ts
 // in convex/utils.ts
 import { makeActionRetrier } from "convex-helpers/server/retries";

 export const { runWithRetries, retry } = makeActionRetrier("utils:retry");

 // in a mutation or action
 export const myMutation = mutation({
   args: {...},
   handler: async (ctx, args) => {
     //...
     await runWithRetries(ctx, internal.myModule.myAction, { arg1: 123 });
   }
 });
```

## Stateful migrations

A helper to define and run migrations. You can persist the migration state to a
table so you can query the status, or use it without persistence.

Note: there is now a [migration component](https://www.convex.dev/components/migrations)
for you to use instead of this approach. The component has the benefit of not
needing to add any tables to your schema. (`npm i @convex-dev/migrations`)

See the [Stack post on migrations](https://stack.convex.dev/migrating-data-with-mutations)
and the [migration primer Stack post](https://stack.convex.dev/intro-to-migrations).

To see the library code and usage, see the [migrations.ts file](./server/migrations.ts).

Example migration:

```ts
export const myMigration = migration({
  table: "users",
  migrateOne: async (ctx, doc) => {
    await ctx.db.patch(doc._id, { newField: "value" });
  },
});
```

## Rate limiting

Configure and use rate limits to avoid product abuse.

**Note**: this is now a [`rate-limiter` component](https://www.convex.dev/components/rate-limiter) I recommend you use instead.

See the associated Stack post for details:

https://stack.convex.dev/rate-limiting

For usage details, see the [rateLimit.ts file](./server/rateLimit.ts).

## Session tracking via client-side sessionID storage

Store a session ID on the client and pass it up with requests to keep track of
a user, even if they aren't logged in.

Use the client-side helpers in [react/sessions](./react/sessions.ts) and
server-side helpers in [server/sessions](./server/sessions.ts).

See the associated [Stack post](https://stack.convex.dev/track-sessions-without-cookies) for more information.

Example for a query (action & mutation are similar):

In your React's root, add the `SessionProvider`:

```js
import { SessionProvider } from "convex-helpers/react/sessions";
//...
<ConvexProvider client={convex}>
  <SessionProvider>
    <App />
  </SessionProvider>
</ConvexProvider>;
```

Pass the session ID from the client automatically to a server query:

```js
import { useSessionQuery } from "convex-helpers/react/sessions";

const results = useSessionQuery(api.myModule.mySessionQuery, { arg1: 1 });
```

Define a server query function in `convex/myModule.ts`:

```js
export const mySessionQuery = queryWithSession({
  args: { arg1: v.number() },
  handler: async (ctx, args) => {
    // ctx.anonymousUser
  },
});
```

Using `customQuery` to make `queryWithSession`:

```js
import { customQuery } from "convex-helpers/server/customFunctions";
import { SessionIdArg } from "convex-helpers/server/sessions";

export const queryWithSession = customQuery(query, {
  args: SessionIdArg,
  input: async (ctx, { sessionId }) => {
    const anonymousUser = await getAnonUser(ctx, sessionId);
    return { ctx: { ...ctx, anonymousUser }, args: {} };
  },
});
```

**Note:** `getAnonUser` is some function you write to look up a user by session.

## Richer useQuery

Use in place of `useQuery` from "convex/react" to fetch data from a query, with
a richer return value.

By default, `useQuery` will throw an error when the server throws. It also
returns `undefined` to indicate a "loading" state. This helper returns:

```ts
import { makeUseQueryWithStatus } from "convex-helpers/react";
import { useQueries } from "convex/react";
// Do this once somewhere, name it whatever you want.
export const useQueryWithStatus = makeUseQueryWithStatus(useQueries);

const { status, data, error, isSuccess, isPending, isError } =
  useQueryWithStatus(api.foo.bar, { myArg: 123 });
```

The types of the return is:

```ts
type ret =
  | {
      status: "success";
      data: FunctionReturnType<Query>;
      error: undefined;
      isSuccess: true;
      isPending: false;
      isError: false;
    }
  | {
      status: "pending";
      data: undefined;
      error: undefined;
      isSuccess: false;
      isPending: true;
      isError: false;
    }
  | {
      status: "error";
      data: undefined;
      error: Error;
      isSuccess: false;
      isPending: false;
      isError: true;
    };
```

## Row-level security

See the [Stack post on row-level security](https://stack.convex.dev/row-level-security)

Use the [RowLevelSecurity](./server/rowLevelSecurity.ts) helper to define
database wrappers to add row-level checks for a server-side function.
Any access to `db` inside functions wrapped with these
will check your access rules on read/insert/modify per-document.

```ts
import {
  customCtx,
  customMutation,
  customQuery,
} from "convex-helpers/server/customFunctions";
import {
  Rules,
  wrapDatabaseReader,
  wrapDatabaseWriter,
} from "convex-helpers/server/rowLevelSecurity";
import { DataModel } from "./_generated/dataModel";
import { mutation, query, QueryCtx } from "./_generated/server";

async function rlsRules(ctx: QueryCtx) {
  const identity = await ctx.auth.getUserIdentity();
  return {
    users: {
      read: async (_, user) => {
        // Unauthenticated users can only read users over 18
        if (!identity && user.age < 18) return false;
        return true;
      },
      insert: async (_, user) => {
        return true;
      },
      modify: async (_, user) => {
        if (!identity)
          throw new Error("Must be authenticated to modify a user");
        // Users can only modify their own user
        return user.tokenIdentifier === identity.tokenIdentifier;
      },
    },
  } satisfies Rules<QueryCtx, DataModel>;
}

const queryWithRLS = customQuery(
  query,
  customCtx(async (ctx) => ({
    db: wrapDatabaseReader(ctx, ctx.db, await rlsRules(ctx)),
  })),
);

const mutationWithRLS = customMutation(
  mutation,
  customCtx(async (ctx) => ({
    db: wrapDatabaseWriter(ctx, ctx.db, await rlsRules(ctx)),
  })),
);
```

## Zod Validation

Convex has argument validation, but if you prefer the [Zod](https://zod.dev)
features for validating arguments, this is for you!

See the [Stack post on Zod validation](https://stack.convex.dev/typescript-zod-function-validation) to see how to validate your Convex functions using the [zod](https://www.npmjs.com/package/zod) library.

Example:

```js
import { z } from "zod";
import { zCustomQuery, zid } from "convex-helpers/server/zod";
import { NoOp } from "convex-helpers/server/customFunctions";

// Define this once - and customize like you would customQuery
const zodQuery = zCustomQuery(query, NoOp);

export const myComplexQuery = zodQuery({
  args: {
    userId: zid("users"),
    email: z.string().email(),
    num: z.number().min(0),
    nullableBigint: z.nullable(z.bigint()),
    boolWithDefault: z.boolean().default(true),
    null: z.null(),
    array: z.array(z.string()),
    optionalObject: z.object({ a: z.string(), b: z.number() }).optional(),
    union: z.union([z.string(), z.number()]),
    discriminatedUnion: z.discriminatedUnion("kind", [
      z.object({ kind: z.literal("a"), a: z.string() }),
      z.object({ kind: z.literal("b"), b: z.number() }),
    ]),
    literal: z.literal("hi"),
    enum: z.enum(["a", "b"]),
    readonly: z.object({ a: z.string(), b: z.number() }).readonly(),
    pipeline: z.number().pipe(z.coerce.string()),
  },
  handler: async (ctx, args) => {
    //... args at this point has been validated and has the types of what
    // zod parses the values into.
    // e.g. boolWithDefault is `bool` but has an input type `bool | undefined`.
  },
});
```

## Hono for advanced HTTP endpoint definitions

[Hono](https://hono.dev/) is an optimized web framework you can use to define
HTTP api endpoints easily
([`httpAction` in Convex](https://docs.convex.dev/functions/http-actions)).

See the [guide on Stack](https://stack.convex.dev/hono-with-convex) for tips on using Hono for HTTP endpoints.

To use it, put this in your `convex/http.ts` file:

```ts
import { Hono } from "hono";
import { HonoWithConvex, HttpRouterWithHono } from "convex-helpers/server/hono";
import { ActionCtx } from "./_generated/server";

const app: HonoWithConvex<ActionCtx> = new Hono();

// See the [guide on Stack](https://stack.convex.dev/hono-with-convex)
// for tips on using Hono for HTTP endpoints.
app.get("/", async (c) => {
  return c.json("Hello world!");
});

export default new HttpRouterWithHono(app);
```

## CRUD utilities

To generate a basic CRUD api for your tables, you can use this helper to define
these functions for a given table:

- `create`
- `read`
- `update`
- `delete`
- `paginate`

See the associated [Stack post](https://stack.convex.dev/crud-and-rest).
**Note: I recommend only doing this for prototyping or [internal functions](https://docs.convex.dev/functions/internal-functions) unless you add Row Level Security**

Example:

```ts
// in convex/users.ts
import { crud } from "convex-helpers/server/crud";
import schema from "./schema.js";

export const { create, read, update, destroy } = crud(schema, "users");

// in some file, in an action:
const user = await ctx.runQuery(internal.users.read, { id: userId });

await ctx.runMutation(internal.users.update, {
  id: userId,
  patch: {
    status: "inactive",
  },
});
```

## Validator utilities

When using validators for defining database schema or function arguments,
these validators help:

1. Add shorthand for a union of `literals`, a `nullable` field, a `deprecated`
   field, a `partial` object, and `brandedString`.
   To learn more about branded strings see
   [this article](https://stack.convex.dev/using-branded-types-in-validators).
2. A `validate(validator, data)` function validates a value against a validator.
   Warning: this does not validate that the value of v.id is an ID for the given table.
3. Add utilties for `partial`, `pick` and `omit` to match the TypeScript type
   utilities.
4. Add a `doc(schema, "tableName")` helper to validate a document with system
   fields included.
5. Add a `typedV(schema)` helper that is a `v` replacement that also has:
   - `doc("tableName")` that works like `doc` above.
   - `id("tableName")` that is typed to tables in your schema.
6. Add a `Table` utility that defines a table and keeps references to the fields
   to avoid re-defining validators. To learn more about sharing validators, read
   [this article](https://stack.convex.dev/argument-validation-without-repetition),
   an extension of [this article](https://stack.convex.dev/types-cookbook).

Example:

```ts
// convex/schema.ts
import { literals, deprecated, brandedString } from "convex-helpers/validators";
import { Infer } from "convex/values";

// Define a validator that requires an Email string type.
export const emailValidator = brandedString("email");
// Define the Email type based on the branded string.
export type Email = Infer<typeof emailValidator>;

export default defineSchema({
  accounts: defineTable({
    balance: nullable(v.bigint()),
    status: literals("active", "inactive"),
    email: emailValidator,
    oldField: deprecated,
  }).index("status", ["status"]),
  //...
});

// some module
import { doc, typedV, partial } from "convex-helpers/validators";
import { omit, pick } from "convex-helpers";
import schema from "./schema";

// You could export this from your schema file, or define it where you need it.
const vv = typedV(schema);

export const replaceUser = internalMutation({
  args: {
    id: vv.id("accounts"),
    replace: object({
      // You can provide the document with or without system fields.
      ...schema.tables.accounts.validator.fields,
      ...partial(systemFields("accounts")),
    }),
  },
  returns: doc(schema, "accounts"), // See below for vv.doc
  handler: async (ctx, args) => {
    await ctx.db.replace(args.id, args.replace);
    return await ctx.db.get(args.id);
  },
});

// A validator just for balance & email: { balance: v.union(...), email: ..}
const balanceAndEmail = pick(vv.doc("accounts").fields, ["balance", "email"]);

// A validator for all the fields except balance.
const accountWithoutBalance = omit(vv.doc("accounts").fields, ["balance"]);

// Validate against a validator. Can optionally throw on error.
const value = { balance: 123n, email: "test@example.com" };
validate(balanceAndEmail, value);

// This will throw a ValidationError if the value is not valid.
validate(balanceAndEmail, value, { throw: true });

// Warning: this only validates that `accountId` is a string.
validate(vv.id("accounts"), accountId);
// Whereas this validates that `accountId` is an id for the accounts table.
validate(vv.id("accounts"), accountId, { db: ctx.db });
```

## Filter

See the [guide on Stack](https://stack.convex.dev/complex-filters-in-convex)
for an analysis of complex filters on Convex.

The `filter` helper composes with `ctx.db.query` to apply arbitrary TypeScript
or JavaScript filters to a database query.

Examples:

```js
import { filter } from "convex-helpers/server/filter";

export const evens = query({
  args: {},
  handler: async (ctx) => {
    return await filter(
      ctx.db.query("counter_table"),
      (c) => c.counter % 2 === 0,
    ).collect();
  },
});

export const lastCountLongerThanName = query({
  args: {},
  handler: async (ctx) => {
    return await filter(
      ctx.db.query("counter_table"),
      (c) => c.counter > c.name.length,
    )
      .order("desc")
      .first();
  },
});
```

## Manual Pagination

Note Convex provides built-in pagination through `.paginate()` and
`usePaginatedQuery()`.

The `getPage` helper gives you more control of the pagination. You can specify
the index ranges or do multiple paginations in the same query.
An index range is all of the documents between two index keys: (start, end].
An index key is an array of values for the fields in the specified index.
For example, for an index defined like `defineTable({ a: v.number(), b: v.string() }).index("my_index", ["a", "b"])`
an index key might be `[ 3 ]` or `[ 3, "abc" ]`. By default the index is the built-in "by_creation_time" index.
The returned index keys are unique, including the two fields at the end of every index: `_creationTime` and `_id`.

However, you have to handle edge cases yourself, as described in
https://stack.convex.dev/fully-reactive-pagination.

More details and patterns will appear in upcoming articles.

### Examples

Fetch the first page, by creation time:

```js
const { page, indexKeys, hasMore } = await getPage(ctx, {
  table: "messages",
});
```

Fetch the next page:

```js
const {
  page: page2,
  indexKeys: indexKeys2,
  hasMore: hasMore2,
} = await getPage(ctx, {
  table: "messages",
  startIndexKey: indexKeys[indexKeys.length - 1],
});
```

You can change the page size and order by any index:

```js
import schema from "./schema";
const { page, indexKeys, hasMore } = await getPage(ctx, {
  table: "users",
  index: "by_name",
  schema,
  targetMaxRows: 1000,
});
```

Fetch of a page between two fixed places in the index, allowing you to display
continuous pages even as documents change.

```js
const { page } = await getPage(ctx, {
  table: "messages",
  startIndexKey,
  endIndexKey,
});
```

Fetch starting at a given index key.
For example, here are yesterday's messages, with recent at the top:

```js
const { page, indexKeys, hasMore } = await getPage(ctx, {
  table: "messages",
  startIndexKey: [Date.now() - 24 * 60 * 60 * 1000],
  startInclusive: true,
  order: "desc",
});
```

### `paginator`: manual pagination with familiar syntax

In addition to `getPage`, convex-helpers provides a function
`paginator` as an alternative to the built-in `db.query.paginate`.

- The built-in `.paginate` is currently limited to one call per query, which allows
  it to track the page's "end cursor" for contiguous reactive pagination client-side.
- `paginator` can be called multiple times from a query,
  but does not subscribe the query to the end cursor automatically.

The syntax and interface for `paginator` is so similar to `.paginate` that it is
nearly a drop-in replacement and can even be used with `usePaginatedQuery`.
This makes it more suitable for non-reactive pagination usecases,
such as iterating data in a mutation. Note: it supports `withIndex` but not `filter`.

For more information on reactive pagination and end cursors, see
https://stack.convex.dev/fully-reactive-pagination
and
https://stack.convex.dev/pagination

As a basic example, consider replacing this query with `paginator`.
It has the same behavior, except that the pages might not stay contiguous as
items are added and removed from the list and the query updates reactively.

```ts
import { paginator } from "convex-helpers/server/pagination";
import schema from "./schema";

export const list = query({
  args: { opts: paginationOptsValidator },
  handler: async (ctx, { opts }) => {
    // BEFORE:
    return await ctx.db.query("messages").paginate(opts);
    // AFTER:
    return await paginator(ctx.db, schema).query("messages").paginate(opts);
  },
});
```

You can order by an index, restrict the pagination to a range of the index,
and change the order to "desc", same as you would with a regular query.

```ts
import { paginator } from "convex-helpers/server/pagination";
import schema from "./schema";

export const list = query({
  args: { opts: paginationOptsValidator, author: v.id("users") },
  handler: async (ctx, { opts, author }) => {
    return await paginator(ctx.db, schema)
      .query("messages")
      .withIndex("by_author", (q) => q.eq("author", author))
      .order("desc")
      .paginate(opts);
  },
});
```

## Composable QueryStreams

In Convex queries, you can read data from many tables in many ways, and combine
the data before returning to to the client. However, some patterns aren't so
easy without these helpers. In particular, these helpers will allow you to take
a union of multiple queries, filter out some of them, join with other tables,
and paginate the result.

- A `QueryStream` is an
  [async iterable](https://javascript.info/async-iterators-generators)
  of documents, ordered by indexed fields.

The cool thing about QueryStreams is you can make more QueryStreams from them,
with operations equivalent to SQL's `UNION ALL`, `WHERE`, and
`JOIN`. These operations preserve order, so the result
is still a valid QueryStream. You can combine streams as much as you want, and
finally treat it like a Convex query to get documents with `.first()`,
`.collect()`, or `.paginate()`.

For example, if you have a stream of "messages created by user1" and a stream
of "messages created by user2", you can get a stream of
"messages created by user1 or user2" where the messages are interleaved
by creation time (or whatever the order is of the index you're using). You can
then filter the merged stream to get a stream of "messages created by user1 or user2 that are unread". Then you
can paginate the result.

Concrete functions you can use:

- `stream` constructs a stream using the same syntax as `DatabaseReader`.
  - e.g. `stream(ctx.db, schema).query("messages").withIndex("by_author", (q) => q.eq("author", "user1"))`
- `mergedStream(streams, fields)` combines multiple streams into a new stream, ordered by the same index fields.
- `.flatMap` expands each document into its own stream, and they all get chained together.
- `.map` modifies each stream item, preserving order.
- `.filterWith` filters out documents from a stream based on a TypeScript predicate.
- Once your stream is set up, you can get documents from it with the normal
  Convex query methods: `.first()`, `.collect()`, `.paginate()`, etc.

Beware if using `.paginate()` with streams in reactive queries, as it has the
same problems as [`paginator` and `getPage`](#manual-pagination): you need to
pass in `endCursor` to prevent holes or overlaps between the pages.

### Example 1: Paginate all messages by a fixed set of authors

```ts
import { stream, mergedStream } from "convex-helpers/server/stream";
import schema from "./schema";
// schema has messages: defineTable(...).withIndex("by_author", ["author"])

export const listForAuthors = query({
  args: {
    authors: v.array(v.id("users")),
    paginationOpts: paginationOptsValidator,
  },
  handler: async (ctx, { authors, paginationOpts }) => {
    // This is an array of streams, where each stream consists of messages by a
    // single author.
    const authorStreams = authors.map((author) =>
      stream(ctx.db, schema)
        .query("messages")
        .withIndex("by_author", (q) => q.eq("author", author)),
    );
    // Create a new stream of all messages authored by users in `args.authors`,
    // ordered by the "by_author" index (i.e. ["author", "_creationTime"]).
    const allAuthorsStream = mergedStream(authorStreams, [
      "author",
      "_creationTime",
    ]);
    // Paginate the result.
    return await allAuthorsStream.paginate(paginationOpts);
  },
});
```

### Example 2: Paginate all messages whose authors match a complex predicate.

There are actually two ways to do this. One uses "post-filter" pagination,
where the filter is applied after fetching a fixed number of documents. To do that, you can
use the `filter` helper described [above](#filter). The advantage is that the
queries read bounded data, but the disadvantage is that the returned pages might
be small or empty.

The other does "pre-filter" pagination, where the filter is applied before
picking the page size. Doing this with a filter that excludes most documents may
result in slow queries or errors because it's reading too much data, but if the
predicate often returns true, it's perfectly fine. To avoid edge cases where you
accidentally read too much data, you can pass `maximumRowsRead` in pagination
options to limit the number of rows read. Let's see how to do
pre-filtering with streams.

```ts
import { stream } from "convex-helpers/server/stream";
import schema from "./schema";

export const list = query({
  args: { paginationOpts: paginationOptsValidator },
  handler: async (ctx, { paginationOpts }) => {
    const allMessagesStream = stream(ctx.db, schema)
      .query("messages")
      .order("desc")
      .filterWith(async (message) => {
        const author = await ctx.db.get(message.author);
        return author !== null && author.verified;
      });
    // The pagination happens after the filtering, so the page should have size
    // `paginationOpts.numItems`.
    // To avoid reading too much data unexpectedly, you can optionally set maximumRowsRead.
    return await messagesByVerifiedAuthors.paginate({
      ...paginationOpts,
      maximumRowsRead: 100,
    });
  },
});
```

As with any usage of [`paginator`](#paginator-manual-pagination-with-familiar-syntax), remember to use `endCursor` in reactive queries to keep pages contiguous.

### Example 3: Order by a suffix of an index.

Suppose you have an index on `["author", "unread"]` and you want to get the
most recent 10 messages for an author, ignoring whether a messages is unread.

Normally this would require a separate index on `["author"]`, or doing two
requests and manually picking the 10 most recent. But with streams, it's cleaner:

```ts
import { stream, MergedStream } from "convex-helpers/server/stream";
import schema from "./schema";
// schema has messages: defineTable(...).index("by_author", ["author", "unread"])

export const latestMessages = query({
  args: { author: v.id("users") },
  handler: async (ctx, { author }) => {
    // These are two streams of messages, each ordered by _creationTime descending.
    // The first has read messages, the second has unread messages.
    const readMessages = stream(ctx.db, schema)
      .query("messages")
      .withIndex("by_author", (q) => q.eq("author", author).eq("unread", false))
      .order("desc");
    const unreadMessages = stream(ctx.db, schema)
      .query("messages")
      .withIndex("by_author", (q) => q.eq("author", author).eq("unread", true))
      .order("desc");
    // Since each stream is ordered by ["_creationTime"], we can merge them and
    // maintain that ordering.

    // Aside: We could instead choose to merge the streams ordered by ["unread", "_creationTime"]
    // or ordered by ["author", "unread", "_creationTime"].

    // `allMessagesByCreationTime` is a single stream of all messages authored by
    // `args.author`, ordered by _creationTime descending.
    const allMessagesByCreationTime = new MergedStream(
      [readMessages, unreadMessages],
      ["_creationTime"],
    );
    return await allMessagesByCreationTime.take(10);
  },
});
```

### Example 4: Join tables.

Suppose you have a table of channels, and another table of messages.
You want to paginate all messages in a user's channels, grouped by channel.
You could do this from the client with a `usePaginatedQuery` for each channel,
or you can do it with streams, like so:

```ts
import { stream } from "convex-helpers/server/stream";
import schema from "./schema";
// schema has:
//   channelMemberships: defineTable(...).index("userId", ["userId", "channelId"])
//   channels: defineTable(...)
//   messages: defineTable(...).index("channelId", ["channelId"])

// Return a paginated stream of { ...channel, ...message }
// ordered by
// [channelMembership.channelId, channelMembership._creationTime, message.channelId, message._creationTime],
// i.e. ordered by [channel._id, message._creationTime]
// if we assume the channelMemberships.userId index is unique
export const latestMessages = query({
  args: { paginationOpts: paginationOptsValidator },
  handler: async (ctx, { paginationOpts }) => {
    // Get the channels the user is a member of
    const channelMemberships = stream(ctx.db, schema)
      .query("channelMemberships")
      .withIndex("userId", q => q.eq("userId", await getAuthedUserId(ctx)));
    // Map membership to the channel info (including channel name, etc.)
    const channels = channelMemberships.map(async (membership) => {
      return (await ctx.db.get(membership.channelId))!;
    });
    // For each channel, expand it into the messages in that channel,
    // with the channel's fields also included.
    const messages = channels.flatMap(async (channel) =>
      stream(ctx.db, stream)
        .query("messages")
        .withIndex("channelId", q => q.eq("channelId", channel._id))
        .map(async (message) => { ...channel, ...message }),
      ["channelId", "_creationTime"]
    );
    return await messages.paginate(paginationOpts);
  },
});
```

## Query Caching

Utilize a query cache implementation which persists subscriptions to the
server for some expiration period even after app `useQuery` hooks have all
unmounted. This allows very fast reloading of unevicted values during
navigation changes, view changes, etc.

Related files:

- [cache.ts](./react/cache.ts) re-exports things so you can import from a single convenient location.
- [provider.tsx](./react/cache/provider.tsx) contains `ConvexQueryCacheProvider`,
  a configurable cache provider you put in your react app's root.
- [hooks.ts](./react/cache/hooks.ts) contains cache-enabled drop-in
  replacements for both `useQuery` and `useQueries` from `convex/react`.

To use the cache, first make sure to put a `<ConvexQueryCacheProvider>`
inside `<ConvexProvider>` in your react component tree:

```jsx

import { ConvexQueryCacheProvider } from "convex-helpers/react/cache";
// For Next.js, import from "convex-helpers/react/cache/provider"; instead

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body className={inter.className}>
        <ConvexClientProvider>
          <ConvexQueryCacheProvider>{children}</ConvexQueryCacheProvider>
        </ConvexClientProvider>
      </body>
    </html>
  );
}
```

This provider takes three optional props:

- **expiration** (number) -- Milliseconds to preserve unmounted subscriptions
  in the cache. After this, the subscriptions will be dropped, and the value
  will have to be re-fetched from the server. (Default: 300000, aka 5 minutes)
- **maxIdleEntires** (number) -- Maximum number of unused subscriptions
  kept in the cache. (Default: 250).
- **debug** (boolean) -- Dump console logs every 3s to debug the state of
  the cache (Default: false).

Finally, you can utilize `useQuery` (and `useQueries`) just the same as
their `convex/react` equivalents.

```jsx
import { useQuery } from "convex-helpers/react/cache";
// For Next.js, import from "convex-helpers/react/cache/hooks"; instead

// ...

const users = useQuery(api.todos.getAll);
```

## TypeScript API Generation

Generate Convex API objects to use Convex with type-safety in separate repositories.
Once in the Convex folder whose functions you want to make an API for, you can run

```bash
npx convex-helpers ts-api-spec
```

By default, this connects to your Convex dev deployment, but you can pass in `--prod`
to read from your production deployment.

This command writes a `convexApi{msSinceEpoch}.ts` file that can be used in external repositories to
use your Convex functions with type-safety. It includes your internal functions, but you
can feel free to remove them.

## Open API Spec Generation

Generate an Open API spec to create a client in a language that Convex doesn't currently
support or connect with tools like Retool. Once in the Convex folder whose functions you
want to generate a specification for, you can run

```bash
npx convex-helpers open-api-spec
```

By default, this connects to your Convex dev deployment, but you can pass in `--prod`
to read from your production deployment.

This command writes a `convex-spec-{msSinceEpoch}.yaml` file that can be used in external repositories to
use your Convex functions with type-safety. It includes your internal functions, but you
can feel free to remove them.

## Triggers

Register trigger functions to run whenever data in a table changes via
`ctx.db.insert`, `ctx.db.patch`, `ctx.db.replace`, or `ctx.db.delete`. The
functions run in the same transaction as the mutation, atomically with the data
change.

Triggers pair with [custom functions](#custom-functions) to hook into each
Convex mutation defined. Here's an example of using triggers to do four things:

1. Attach a computed `fullName` field to every user.
2. Keep a denormalized count of all users.
3. After the mutation, send the new user info to Clerk.
4. When a user is deleted, delete their messages (cascading deletes).

```ts
import { mutation as rawMutation } from "./_generated/server";
import { DataModel } from "./_generated/dataModel";
import { Triggers } from "convex-helpers/server/triggers";
import {
  customCtx,
  customMutation,
} from "convex-helpers/server/customFunctions";

const triggers = new Triggers<DataModel>();

// 1. Attach a computed `fullName` field to every user.
triggers.register("users", async (ctx, change) => {
  if (change.newDoc) {
    const fullName = `${change.newDoc.firstName} ${change.newDoc.lastName}`;
    // Abort the mutation if document is invalid.
    if (fullName === "The Balrog") {
      throw new Error("you shall not pass");
    }
    // Update denormalized field. Check first to avoid recursion
    if (change.newDoc.fullName !== fullName) {
      await ctx.db.patch(change.id, { fullName });
    }
  }
});

// 2. Keep a denormalized count of all users.
triggers.register("users", async (ctx, change) => {
  // Note writing the count to a single document increases write contention.
  // There are more scalable methods if you need high write throughput.
  const countDoc = (await ctx.db.query("userCount").unique())!;
  if (change.operation === "insert") {
    await ctx.db.patch(countDoc._id, { count: countDoc.count + 1 });
  } else if (change.operation === "delete") {
    await ctx.db.patch(countDoc._id, { count: countDoc.count - 1 });
  }
});

// 3. After the mutation, send the new user info to Clerk.
// Even if a user is modified multiple times in a single mutation,
// `internal.users.updateClerkUser` runs once.
const scheduled: Record<Id<"users">, Id<"_scheduled_functions">> = {};
triggers.register("users", async (ctx, change) => {
  if (scheduled[change.id]) {
    await ctx.scheduler.cancel(scheduled[change.id]);
  }
  scheduled[change.id] = await ctx.scheduler.runAfter(
    0,
    internal.users.updateClerkUser,
    { user: change.newDoc },
  );
});

// 4. When a user is deleted, delete their messages (cascading deletes).
triggers.register("users", async (ctx, change) => {
  // Using relationships.ts helpers for succinctness.
  await asyncMap(
    await getManyFrom(ctx.db, "messages", "owner", change.id),
    (message) => ctx.db.delete(message._id),
  );
});

// Use `mutation` to define all mutations, and the triggers will get called.
export const mutation = customMutation(rawMutation, customCtx(triggers.wrapDB));
```

Now that you have redefined `mutation`, add an
[eslint rule](https://stack.convex.dev/eslint-setup#no-restricted-imports) to
forbid using the raw mutation wrappers which don't call your triggers.

### What can you do with triggers?

- Denormalize computed fields onto the same table or into a different table.
  - Such fields can be indexed for more efficient lookup.
- By default, triggers will trigger more triggers.
  - This can be useful to ensure denormalized fields stay consistent, no matter
    where they are modified.
  - Watch out for infinite loops of triggers.
  - Use `ctx.innerDb` to perform writes without triggering more triggers.
- Use global variables to coordinate across trigger invocations, e.g. to batch
  or debounce or single-flight async processing.
- Combine with other custom functions that can pre-fetch data, like fetching the
  authorized user at the start of the mutation.
- Throw errors, which can prevent the write by aborting the mutation.
  - Validate constraints and internal consistency.
  - Check row-level-security rules to validate the write is authorized.
- Components like
  [Aggregate](https://www.npmjs.com/package/@convex-dev/aggregate) can define
  triggers by exposing a method like `TableAggregate.trigger()` that returns a
  `Trigger<Ctx, DataModel, TableName>`. This "attaches" the component to a
  table.

### Trigger semantics

- The `change` argument tells you exactly how the document changed via a single
  `ctx.db.insert`, `ctx.db.patch`, `ctx.db.replace`, or `ctx.db.delete`.
  If these functions are called in parallel with `Promise.all`, they will be
  serialized as if they happened sequentially.
- A database write is executed atomically with all of its triggers, so you can
  update a denormalized field in a trigger without worrying about parallel
  writes getting in the way.
- If a write kicks off recursive triggers, they are executed with a queue,
  i.e. breadth-first-search order.
- If a trigger function throws an error, it will be thrown from the database
  write (e.g. `ctx.db.insert`) that caused the trigger.
  - If a trigger's error is caught, the database write can still be committed.
  - To maximize fairness and consistency, all triggers still run, even if an
    earlier trigger threw an error. The first trigger that throws an error will
    have its error rethrown; other errors are `console.error` logged.

> Warning: Triggers only run through `mutation`s and `internalMutation`s when
> wrapped with `customFunction`s.
>
> If you forget to use the wrapper, the triggers won't run (use
> [eslint rules](https://stack.convex.dev/eslint-setup#no-restricted-imports)).
>
> If you edit data in the Convex dashboard, the triggers won't run.
>
> If you upload data through `npx convex import`, the triggers won't run.
> const users = useQuery(api.users.getAll);

## CORS support for HttpRouter

Add CORS support to your Convex httpAction routes by registering a
handler for OPTIONS preflight requests and returning the appropriate headers.
Supports configuring allowed origins, allowed headers, exposed headers, allowing credentials, and browser cache max age, both for the entire router and per route overrides.

Here's a snippet from our `http.ts` file demonstrating how to use the `corsHttpRouter`:

```typescript
import { corsRouter } from "convex-helpers/server/cors";
import { httpRouter } from "convex/server";
import { httpAction } from "./_generated/api";

// Your standard Convex http router:
const http = httpRouter();

// Your CORS router:
const cors = corsRouter(
  http,
  // Optional configuration, can be omitted entirely
  {
    allowedOrigins: ["http://localhost:8080"], // Default: ["*"]
    allowedMethods: ["GET", "POST"], // Defaults to route spec method
    allowedHeaders: ["Content-Type"], // Default: ["Content-Type"]
    exposedHeaders: ["Custom-Header"], // Default: ["Content-Range", "Accept-Ranges"]
    allowCredentials: true, // Default: false
    browserCacheMaxAge: 60, // Default: 86400 (1 day)
    debug: true, // Default: false
  },
);

cors.route({
  path: "/foo",
  method: "GET",
  handler: httpAction(async () => {
    return new Response("ok");
  }),
});

cors.route({
  path: "/foo",
  // You can register multiple methods for the same path
  method: "POST",
  handler: httpAction(async () => {
    return new Response("ok");
  }),
  // You can provide configuration per route
  allowedOrigins: ["http://localhost:8080"],
});

// Non-CORS routes still work, provided they're on different paths.
http.route({
  path: "/notcors",
  method: "GET",
  handler: httpAction(async () => {
    return new Response("ok");
  }),
});
// Export http (or cors.http)
export default http;
```

## Standard Schema

[Standard Schema](https://github.com/standard-schema/standard-schema)
is a specification for validating data.
To convert a Convex validator to a Standard Schema, use `toStandardSchema`:

```typescript
import { toStandardSchema } from "convex-helpers/standardSchema";

const standardValidator = toStandardSchema(
  v.object({
    name: v.string(),
    age: v.number(),
  }),
);

standardValidator["~standard"].validate({
  name: "John",
  age: 30,
});
```


---

# Official Documentation

# home.mdx

<!-- Source: home.mdx -->

---
title: "Convex Docs"
slug: "home"
hide_table_of_contents: true
---

import TutorialGraphic from "@site/static/img/tutorial-graphic.svg";
import {
  QuickFrameworksList,
  QuickLanguagesList,
} from "@site/src/QuickstartsList.tsx";
import { LargeCardList } from "@site/src/QuickstartsList.tsx";
import { YouTubeList } from "@site/src/YouTubeLink.tsx";
import Link from "@docusaurus/Link";

Convex is the open source, reactive database where queries are TypeScript code
running right in the database. Just like React components react to state
changes, Convex queries react to database changes.

Convex provides a database, a place to write your server functions, and client
libraries. It makes it easy to build and scale dynamic live-updating apps.

<LargeCardList
  items={[
    {
      title: "Tutorial: Build a chat app",
      description:
        "Follow a step-by-step tutorial to build your first Convex app - a real-time chat application.",
      href: "/tutorial",
    },
    {
      title: "Understanding Convex",
      description:
        "Learn about the core concepts and architecture that make Convex unique and powerful.",
      href: "/understanding",
    },
  ]}
/>

## Get Started

<CardLink
  className="convex-hero-card"
  item={{
    href: "https://chef.convex.dev",
    label: "Prompt to start an app with Convex Chef",
  }}
/>

Your favorite frameworks:

<QuickFrameworksList />

Your favorite languages:

<QuickLanguagesList />

## Why Convex?

<YouTubeList
  items={[
    {
      src: "https://www.youtube.com/embed/Xjud1weG4z8?si=OMMfKzK_Dp8RgmgM",
      label: "Backends for Product Developers",
    },
    {
      src: "https://www.youtube.com/embed/UVvd7BF99-4?si=Z9_pLHMnpL9kaduE",
      label: "Intro to Convex",
    },
    {
      src: "https://www.youtube.com/embed/V6En7UO4Ui0?si=kcj1aftxV-tqe9Q-",
      label: "Supercharging your app with a reactive backend",
    },

    {
      src: "https://www.youtube.com/embed/O_HXVAMPEbc?si=qtA8nLyGjGUsXVkL",
      label: "Why I use Convex over Supabase as my BaaS",
    },

]} />

Read the team's Perspectives on [Stack](https://stack.convex.dev):

<DocCardList
  items={[
    {
      type: "link",
      href: "https://stack.convex.dev/convex-vs-relational-databases",
      label: "Convex vs Relational Databases",
    },
    {
      type: "link",
      href: "https://stack.convex.dev/convex-vs-firebase",
      label: "Convex vs Firebase",
    },
    {
      type: "link",
      href: "https://stack.convex.dev/how-convex-works",
      label: "How Convex Works",
    },
  ]}
/>

## Learn Convex

<YouTubeList
  items={[
    {
      src: "https://www.youtube.com/embed/vaQZYRSiimI?si=JLfdVVs3QkCLTZwc",
      label: "Convex with Next.js Quickstart",
    },
    {
      src: "https://www.youtube.com/embed/0OaDyjB9Ib8?si=V5_9FN3UieZmnOM5",
      label: "Notion Clone: Next.js 13, React, Convex, Tailwind",
    },
    {
      src: "https://www.youtube.com/embed/zfAb95tJvZQ?si=PaiBxNxCO0s2BuEZ",
      label: "Build a Saas Podcast Platform in Next.js",
    },
    {
      src: "https://www.youtube.com/embed/Vjtn9pWAZDI?si=of21uqly5laJQJAs",
      label: "Building a Subscription Based SaaS with Stripe",
    },

]} />

See more walkthroughs and patterns on [Stack](https://stack.convex.dev)

<DocCardList
  items={[
    {
      type: "link",
      href: "https://stack.convex.dev/tag/AI",
      label: "Build AI Apps",
    },
    {
      type: "link",
      href: "https://stack.convex.dev/tag/Patterns",
      label: "Convex Patterns",
    },
    {
      type: "link",
      href: "https://stack.convex.dev/tag/Walkthroughs",
      label: "Convex Walkthroughs",
    },
  ]}
/>


---

# agents.mdx

<!-- Source: agents.mdx -->

---
title: "AI Agents"
sidebar_position: 100
description: "Building AI Agents with Convex"
---

# Building AI Agents with Convex

Convex provides a powerful platform for building AI agents through its robust
set of components.

## Why Convex for AI Agents?

Convex offers several advantages for building AI agents:

1. **Durable Execution**: Long-running workflows that survive server restarts
2. **Real-time State Management**: Reactive state updates for agent progress
3. **Built-in Persistence**: Store conversation history and agent state
4. **Parallel Processing**: Run multiple agent tasks concurrently
5. **Error Handling**: Robust retry mechanisms for API calls

## Core Components

The [Agent](https://www.convex.dev/components/agent) and
[Workflow](https://www.convex.dev/components/workflow) components can be used
together to create powerful long running agents with memory.

import { ComponentCardList } from "@site/src/components/ComponentCard";

<ComponentCardList
  items={[
    {
      title: "Agent",
      description:
        "Agents organize your AI workflows into units, with message history and vector search built in.",
      href: "https://www.convex.dev/components/agent",
    },
    {
      title: "Workflow",
      description:
        "Simplify programming long running code flows. Workflows execute durably with configurable retries and delays.",
      href: "https://www.convex.dev/components/workflow",
    },
  ]}
/>

Learn more by reading:
[AI Agents with Built-in Memory](https://stack.convex.dev/ai-agents).

Sample code:

```typescript
// Define an agent similarly to the AI SDK
const supportAgent = new Agent(components.agent, {
  chat: openai.chat("gpt-4o-mini"),
  textEmbedding: openai.embedding("text-embedding-3-small"),
  instructions: "You are a helpful assistant.",
  tools: { accountLookup, fileTicket, sendEmail },
});

// Use the agent from within a normal action:
export const createThread = action({
  args: { prompt: v.string() },
  handler: async (ctx, { prompt }) => {
    const { threadId, thread } = await supportAgent.createThread(ctx);
    const result = await thread.generateText({ prompt });
    return { threadId, text: result.text };
  },
});

// Pick up where you left off, with the same or a different agent:
export const continueThread = action({
  args: { prompt: v.string(), threadId: v.string() },
  handler: async (ctx, { prompt, threadId }) => {
    // This includes previous message history from the thread automatically.
    const { thread } = await anotherAgent.continueThread(ctx, { threadId });
    const result = await thread.generateText({ prompt });
    return result.text;
  },
});

// Or use it within a workflow, specific to a user:
export const supportAgentStep = supportAgent.asAction({ maxSteps: 10 });

const workflow = new WorkflowManager(components.workflow);
const s = internal.example; // where steps are defined

export const supportAgentWorkflow = workflow.define({
  args: { prompt: v.string(), userId: v.string(), threadId: v.string() },
  handler: async (step, { prompt, userId, threadId }) => {
    const suggestion = await step.runAction(s.supportAgentStep, {
      threadId,
      generateText: { prompt },
    });
    const polished = await step.runAction(s.adaptSuggestionForUser, {
      suggestion,
      userId,
    });
    await step.runMutation(s.sendUserMessage, {
      userId,
      message: polished.message,
    });
  },
});
```

## Other Components

Convex also provides other components to help you build reliable AI
applications.

<ComponentCardList
  items={[
    {
      title: "Persistent Text Streaming",
      description:
        "Stream text from HTTP actions while storing data in the database, enabling access after the stream ends or by other users.",
      href: "https://www.convex.dev/components/persistent-text-streaming",
    },
    {
      title: "Action Retrier",
      description:
        "Add reliability to unreliable external service calls. Retry idempotent calls with exponential backoff until success.",
      href: "https://www.convex.dev/components/retrier",
    },
    {
      title: "Workpool",
      description:
        "Create tiers of parallelism to manage and prioritize large numbers of external requests efficiently.",
      href: "https://www.convex.dev/components/workpool",
    },
  ]}
/>


---

# convex-mcp-server.mdx

<!-- Source: ai/convex-mcp-server.mdx -->

---
title: "Convex MCP Server"
sidebar_position: 300
description: "Convex MCP server"
---

The Convex
[Model Context Protocol](https://docs.cursor.com/context/model-context-protocol)
(MCP) server provides several tools that allow AI agents to interact with your
Convex deployment.

## Setup

Add the following command to your MCP servers configuration:

`npx -y convex@latest mcp start`

See editor specific instructions:

- [Cursor](/ai/using-cursor.mdx#setup-the-convex-mcp-server)
- [Windsurf](/ai/using-windsurf.mdx#setup-the-convex-mcp-server)
- [VS Code](/ai/using-github-copilot.mdx#setup-the-convex-mcp-server)

## Available Tools

### Deployment Tools

- **`status`**: Queries available deployments and returns a deployment selector
  that can be used with other tools. This is typically the first tool you'll use
  to find your Convex deployment.

### Table Tools

- **`tables`**: Lists all tables in a deployment along with their:

  - Declared schemas (if present)
  - Inferred schemas (automatically tracked by Convex)
  - Table names and metadata

- **`data`**: Allows pagination through documents in a specified table.

- **`runOneoffQuery`**: Enables writing and executing sandboxed JavaScript
  queries against your deployment's data. These queries are read-only and cannot
  modify the database.

### Function Tools

- **`functionSpec`**: Provides metadata about all deployed functions, including:

  - Function types
  - Visibility settings
  - Interface specifications

- **`run`**: Executes deployed Convex functions with provided arguments.

### Environment Variable Tools

- **`envList`**: Lists all environment variables for a deployment
- **`envGet`**: Retrieves the value of a specific environment variable
- **`envSet`**: Sets a new environment variable or updates an existing one
- **`envRemove`**: Removes an environment variable from the deployment

[Read more about how to use the Convex MCP Server](https://stack.convex.dev/convex-mcp-server)


---

# using-cursor.mdx

<!-- Source: ai/using-cursor.mdx -->

---
title: "Using Cursor with Convex"
sidebar_position: 100
description: "Tips and best practices for using Cursor with Convex"
slug: "using-cursor"
---

[Cursor](https://cursor.com), the AI code editor, makes it easy to write and
maintain apps built with Convex. Let's walk through how to setup Cursor for the
best possible results with Convex.

## Add Convex `.cursor/rules`

To get the best results from Cursor put the model specific `.mdc` files in your
project's `.cursor/rules` directory.

- [Convex Cursor Rules](https://convex.link/convex_rules.mdc)

<video
  src="/video/showing_where_to_put_convex_rules.mp4"
  autoPlay
  loop
  controls
></video>

We're constantly working on improving the quality of these rules for Convex by
using rigorous evals. You can help by
[contributing to our evals repo](https://github.com/get-convex/convex-evals).

## Setup the Convex MCP Server

The Convex CLI comes with a
[Convex Model Context Protocol](/ai/convex-mcp-server.mdx) (MCP) server built
in. The Convex MCP server gives your AI coding agent access to the your Convex
deployment to query and optimize your project.

To get started with Cursor, open "Cursor Settings > MCP", click on "Add new
global MCP server", and add a "convex" section to "mcpServers" in the `mcp.json`
file that's opened.

```json
{
  "mcpServers": {
    "convex": {
      "command": "npx",
      "args": ["-y", "convex@latest", "mcp", "start"]
    }
  }
}
```

After adding the server, ensure the "convex" server is enabled and lit up green
(you may need to click "Disabled" to enable it). Here's an example of Cursor
configured successfully:

![Chat UI](/img/cursor-with-convex/convex_mcp_setup.webp)

If you're running into issues, confirm you're using Cursor version **0.47** or
later (check under "Cursor > About Cursor" on macOS).

Now start asking it questions like:

- Evaluate and convex schema and suggest improvements
- What are this app's public endpoints?
- Run the `my_convex_function` query

## Tips and tricks

### Install and run Convex yourself

Keeping Convex running is crucial because
[it automatically generates](https://docs.convex.dev/cli#run-the-convex-dev-server)
the client-side types. Without this, the agent can get stuck in a linting loop
since it can't access the types for the queries and mutations it created.

We recommended that you install (`npm install convex`) and run convex
(`npx convex dev`) yourself in a terminal window.

### Keep your requests small

The best results when using agentic LLMs can be found when keeping the amount of
changes you want to make small and git commit frequently. This lets you be more
specific around the context you provide the agent and it means the agent doesn't
need to do a lot of searching for context.

After each successful prompt or series of prompts it is a good idea to commit
your changes so that its simple to rollback to that point should the next prompt
cause issues.

### Update and reference your `README.md`

The agent needs context about the specific business goals for your project.
While it can infer some details from the files it reads, this becomes more
challenging as your project grows. Providing general information about your
project gives the agent a helpful head start.

Rather than including this information in each prompt, it's better to write a
comprehensive README.md file in your project root and reference it.

[Some people](https://youtu.be/2PjmPU07KNs?t=145) advocate for crafting a
Product Requirements Document (PRD), this may be a good idea for more complex
projects.

### Add Convex docs

Adding Convex docs can let you specifically refer to Convex features when
building your app.

From **`Cursor Settings`** > **`Features`** > **`Docs`** add new doc, use the
URL "https://docs.convex.dev/"

![Chat UI](/img/cursor-with-convex/adding_convex_docs.webp)

Cursor will then index all of the Convex docs for the LLM to use.

![Chat UI](/img/cursor-with-convex/indexed_docs.webp)

You can then reference those docs in your prompt with the `@Convex` symbol.

![Chat UI](/img/cursor-with-convex/reference_convex_docs.webp)

<Admonition type="tip" title="Add more Convex knowledge">

You can perform the above steps for https://stack.convex.dev/ too if you would
like to provide even more context to the agent.

</Admonition>


---

# using-github-copilot.mdx

<!-- Source: ai/using-github-copilot.mdx -->

---
title: "Using GitHub Copilot with Convex"
sidebar_position: 200
description: "Tips and best practices for using GitHub Copilot with Convex"
slug: "using-github-copilot"
---

[GitHub Copilot](https://github.com/features/copilot), the AI built into VS
Code, makes it easy to write and maintain apps built with Convex. Let's walk
through how to setup GitHub Copilot for the best possible results with Convex.

## Add Convex Instructions

Add the following
[instructions](https://code.visualstudio.com/docs/copilot/copilot-customization#_instruction-files)
file to your `.github/instructions` directory in your project and it will
automatically be included when working with Typescript or Javascript files:

- [convex.instructions.md](https://convex.link/convex_github_copilot_instructions)

![Showing Where to Put GitHub Copilot Instructions](/img/showing-where-to-put-convex-instructions.png)

If you would rather that the instructions file is NOT automatically pulled into
context then open the file in your editor and alter the `applyTo` field at the
top. Read more about instructions files here:
https://code.visualstudio.com/docs/copilot/copilot-customization#_use-instructionsmd-files

We're constantly working on improving the quality of these rules for Convex by
using rigorous evals. You can help by
[contributing to our evals repo](https://github.com/get-convex/convex-evals).

## Setup the Convex MCP Server

The Convex CLI comes with a
[Convex Model Context Protocol](/ai/convex-mcp-server.mdx) (MCP) server built
in. The Convex MCP server gives your AI coding agent access to the your Convex
deployment to query and optimize your project.

To get started with
[MCP in VS Code](https://code.visualstudio.com/docs/copilot/chat/mcp-servers)
then create a file in `.vscode/mcp.json` and add the following:

```json
{
  "servers": {
    "convex-mcp": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "convex@latest", "mcp", "start"]
    }
  }
}
```

Once this is done it will take a few seconds to start up the MCP server and then
you should see the Convex tool listed in the codelens:

![Convex Tool in Codelens](/img/convex-tool-in-codelens.png)

and in the selection of tools that the model has access to in chat:

![Convex Tool in Chat](/img/convex-tools-in-chat.png)

Now start asking it questions like:

- Evaluate and convex schema and suggest improvements
- What are this app's public endpoints?
- Run the `my_convex_function` query

If you want to use the MCP server globally for all your projects then you can
add it to your user settings, please see these docs for more information:
https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server-to-your-user-settings


---

# using-windsurf.mdx

<!-- Source: ai/using-windsurf.mdx -->

---
title: "Using Windsurf with Convex"
sidebar_position: 200
description: "Tips and best practices for using Windsurf with Convex"
slug: "using-windsurf"
---

[Windsurf](https://codeium.com/windsurf), the AI code editor, makes it easy to
write and maintain apps built with Convex. Let's walk through how to setup
Windsurf for the best possible results with Convex.

## Add Convex Rules

Add the following rules file to your project and refer to it directly when
prompting for changes:

- [Convex Rules](https://convex.link/convex_rules.txt)

We're constantly working on improving the quality of these rules for Convex by
using rigorous evals. You can help by
[contributing to our evals repo](https://github.com/get-convex/convex-evals).

## Setup the Convex MCP Server

The Convex CLI comes with a
[Convex Model Context Protocol](/ai/convex-mcp-server.mdx) (MCP) server built
in. The Convex MCP server gives your AI coding agent access to the your Convex
deployment to query and optimize your project.

To get started with Windsurf, open "Windsurf Settings > Cascade > Model Context
Protocol (MCP) Servers", click on "Add Server", click "Add custom server", and
add the following configuration for Convex.

```json
{
  "mcpServers": {
    "convex": {
      "command": "npx",
      "args": ["-y", "convex@latest", "mcp", "start"]
    }
  }
}
```

After adding the server return to the "Windsurf Settings > Cascade > Model
Context Protocol (MCP) Servers" screen an click "Refresh" button for Windsurf to
pick up the new server.

Once this is done you should see the Convex tool listed in the servers:

![Chat UI](/img/windsurf-with-convex/windsurf_convex_mcp.png)

Now start asking it questions like:

- Evaluate and convex schema and suggest improvements
- What are this app's public endpoints?
- Run the `my_convex_function` query


---

# ai.mdx

<!-- Source: ai.mdx -->

---
title: AI Code Generation
hide_table_of_contents: true
---

<CardLink
  className="convex-hero-card"
  item={{
    href: "https://chef.convex.dev",
    label: "Prompt to build an app with Convex Chef",
  }}
/>

Convex is designed around a small set of composable abstractions with strong
guarantees that result in code that is not only faster to write, it’s easier to
read and maintain, whether written by a team member or an LLM. Key features make
sure you get bug-free AI generated code:

1. **Queries are Just TypeScript** Your database queries are pure TypeScript
   functions with end-to-end type safety and IDE support. This means AI can
   generate database code using the large training set of TypeScript code
   without switching to SQL.
1. **Less Code for the Same Work** Since so much infrastructure and boiler plate
   is automatically manged by Convex there is less code to write, and thus less
   code to get wrong.
1. **Automatic Reactivity** The reactive system automatically tracks data
   dependencies and updates your UI. AI doesn't need to manually manage
   subscriptions, WebSocket connections, or complex state synchronization—Convex
   handles all of this automatically.
1. **Transactional Guarantees** Queries are read-only and mutations run in
   transactions. These constraints make it nearly impossible for AI to write
   code that could corrupt your data or leave your app in an inconsistent state.

Together, these features mean AI can focus on your business logic while Convex's
guarantees prevent common failure modes. For up-to-date information on which
models work best with Convex, check out our LLM
[leaderboard](https://convex.dev/llm-leaderboard).

## Convex AI rules

AI code generation is most effective when you provide it with a set of rules to
follow.

See these documents for install instructions:

- [Cursor](/ai/using-cursor.mdx#add-convex-cursorrules)
- [Windsurf](/ai/using-windsurf.mdx#add-convex-rules)
- [GitHub Copilot](/ai/using-github-copilot.mdx#add-convex-instructions)

For all other IDEs, add the following rules file to your project and refer to it
when prompting for changes:

- [convex_rules.txt](https://convex.link/convex_rules.txt)

We're constantly working on improving the quality of these rules for Convex by
using rigorous evals. You can help by
[contributing to our evals repo](https://github.com/get-convex/convex-evals).

## Convex MCP Server

[Setup the Convex MCP server](/ai/convex-mcp-server.mdx) to give your AI coding
agent access to your Convex deployment to query and optimize your project.


---

# custom-auth.mdx

<!-- Source: auth/advanced/custom-auth.mdx -->

---
title: "Custom OIDC Provider"
sidebar_label: "Custom OIDC Provider"
sidebar_position: 3
---

**Note: This is an advanced feature!** We recommend sticking with the
[supported third-party authentication providers](/auth.mdx).

Convex can be integrated with any identity provider supporting the
[OpenID Connect](https://openid.net/connect/) protocol. At minimum this means
that the provider can issue
[ID tokens](https://openid.net/specs/openid-connect-core-1_0.html#IDToken) and
exposes the corresponding
[JWKS](https://auth0.com/docs/secure/tokens/json-web-tokens/json-web-key-sets).
The ID token is passed from the client to your Convex backend which ensures that
the token is valid and enables you to query the user information embedded in the
token, as described in [Auth in Functions](/auth/functions-auth.mdx).

## Server-side integration

Just like with [Clerk](/auth/clerk.mdx) and [Auth0](/auth/auth0.mdx), the
backend needs to be aware of the domain of the Issuer and your application's
specific applicationID for a given identity provider.

Add these to your `convex/auth.config.js` file:

```js noDialect title="convex/auth.config.js"
export default {
  providers: [
    {
      domain: "https://your.issuer.url.com",
      applicationID: "your-application-id",
    },
  ],
};
```

The `applicationID` property must exactly match the `aud` field of your JWT and
the `domain` property must exactly match the `iss` field of the JWT. Use a tool
like [jwt.io](https://jwt.io/) to view an JWT and confirm these fields match
exactly.

If multiple providers are provided, the first one fulfilling the above criteria
will be used.

If you're not able to obtain tokens with an `aud` field, you'll need to instead
configure a [Custom JWT](/auth/advanced/custom-jwt.mdx). If you're not sure if
your token is an OIDC ID token, check
[the spec](https://openid.net/specs/openid-connect-core-1_0-final.html#rfc.section.2)
for a list of all required fields.

OIDC requires the routes `${domain}/.well-known/jwks.json` and
`${domain}/.well-known/openid-configuration`. `domain` may include a path like
`https://your.issuer.url.com/api/auth`. This isn't common for third party auth
providers but may be useful if you're implementing OIDC on your own server.

## Client-side integration

### Integrating a new identity provider

The [`ConvexProviderWithAuth`](/api/modules/react#convexproviderwithauth)
component provides a convenient abstraction for building an auth integration
similar to the ones Convex provides for [Clerk](/auth/clerk.mdx) and
[Auth0](/auth/auth0.mdx).

In the following example we build an integration with an imaginary "ProviderX",
whose React integration includes `AuthProviderXReactProvider` and
`useProviderXAuth` hook.

First we replace `ConvexProvider` with `AuthProviderXReactProvider` wrapping
`ConvexProviderWithAuth` at the root of our app:

```jsx title="src/index.js"
import { AuthProviderXReactProvider } from "providerX";
import { ConvexProviderWithAuth } from "convex/react";

root.render(
  <StrictMode>
    <AuthProviderXReactProvider>
      <ConvexProviderWithAuth client={convex} useAuth={useAuthFromProviderX}>
        <App />
      </ConvexProviderWithAuth>
    </AuthProviderXReactProvider>
  </StrictMode>,
);
```

All we really need is to implement the `useAuthFromProviderX` hook which gets
passed to the `ConvexProviderWithAuth` component.

This `useAuthFromProviderX` hook provides a translation between the auth
provider API and the [`ConvexReactClient`](/api/classes/react.ConvexReactClient)
API, which is ultimately responsible for making sure that the ID token is passed
down to your Convex backend.

```jsx title="src/ConvexProviderWithProviderX.js"
function useAuthFromProviderX() {
  const { isLoading, isAuthenticated, getToken } = useProviderXAuth();
  const fetchAccessToken = useCallback(
    async ({ forceRefreshToken }) => {
      // Here you can do whatever transformation to get the ID Token
      // or null
      // Make sure to fetch a new token when `forceRefreshToken` is true
      return await getToken({ ignoreCache: forceRefreshToken });
    },
    // If `getToken` isn't correctly memoized
    // remove it from this dependency array
    [getToken],
  );
  return useMemo(
    () => ({
      // Whether the auth provider is in a loading state
      isLoading: isLoading,
      // Whether the auth provider has the user signed in
      isAuthenticated: isAuthenticated ?? false,
      // The async function to fetch the ID token
      fetchAccessToken,
    }),
    [isLoading, isAuthenticated, fetchAccessToken],
  );
}
```

### Using the new provider

If you successfully follow the steps above you can now use the standard Convex
utilities for checking the authentication state: the
[`useConvexAuth()`](/api/modules/react#useconvexauth) hook and the
[`Authenticated`](/api/modules/react#authenticated),
[`Unauthenticated`](/api/modules/react#authenticated) and
[`AuthLoading`](/api/modules/react#authloading) helper components.

### Debugging

See [Debugging Authentication](/auth/debug.mdx).

<StackPosts query="authentication" />


---

# custom-jwt.mdx

<!-- Source: auth/advanced/custom-jwt.mdx -->

---
title: "Custom JWT Provider"
sidebar_label: "Custom JWT Provider"
sidebar_position: 4
---

**Note: This is an advanced feature!** We recommend sticking with the
[supported third-party authentication providers](/auth.mdx).

If your custom auth provider implements the OIDC protocol, it's easiest to
configure it as a [Custom OIDC Provider](/auth/advanced/custom-auth). However,
some auth providers only issue JWTs and don't participate in the full OIDC
protocol. For example, [OpenAuth](https://openauth.js.org/) implements the OAuth
2.0 spec but not OIDC, so to use it with Convex you'll need to set it up as a
Custom JWT provider.

## Server-side integration

Use `type: "customJwt"` to configure a Custom JWT auth provider:

```js noDialect title="convex/auth.config.js"
export default {
  providers: [
    {
      type: "customJwt",
      applicationID: "your-application-id",
      issuer: "https://your.issuer.url.com",
      jwks: "https://your.issuer.url.com/.well-known/jwks.json",
      algorithm: "RS256",
    },
  ],
};
```

- `applicationID` (optional): If provided, Convex will verify that JWTs have
  this value in the `aud` claim.
- `issuer`: The issuer URL of the JWT.
- `jwks`: The URL for fetching the JWKS (JSON Web Key Set) from the auth
  provider.
- `algorithm`: The algorithm used to sign the JWT. Only RS256 and ES256 are
  currently supported. See
  [RFC 7518](https://datatracker.ietf.org/doc/html/rfc7518#section-3.1) for more
  details.

The `issuer` property must exactly match the `iss` field of the JWT used, and if
specified the `applicationID` property must exactly match the `aud` field. If
your JWT doesn't match, use a tool like [jwt.io](https://jwt.io/) to view an JWT
and confirm these fields match exactly.

## Client-side integration

See the instructions for
[Custom OIDC Providers](/auth/advanced/custom-auth#client-side-integration).


---

# auth0.mdx

<!-- Source: auth/auth0.mdx -->

---
title: "Convex & Auth0"
sidebar_label: "Auth0"
sidebar_position: 20
---

import LogoutButtonTSX from "!!raw-loader!@site/../demos/users-and-auth/src/LogoutButton.tsx";
import UnderTheHood from "@site/docs/auth/_under_the_hood.mdx";
import ConfigTS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite-ts/src/_mainAuth0.tsx";
import ConfigJS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite/src/_mainAuth0.jsx";
import ConfigEnvTS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite-ts/src/_mainAuth0Env.tsx";
import ConfigEnvJS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite/src/_mainAuth0Env.jsx";

[Auth0](https://auth0.com) is an authentication platform providing login via
passwords, social identity providers, one-time email or SMS access codes,
multi-factor authentication, and single sign on and basic user management.

**Example:**
[Convex Authentication with Auth0](https://github.com/get-convex/convex-demos/tree/main/users-and-auth)

If you're using Next.js see the
[Next.js setup guide](https://docs.convex.dev/client/react/nextjs).

## Get started

This guide assumes you already have a working React app with Convex. If not
follow the [Convex React Quickstart](/quickstart/react.mdx) first. Then:

<StepByStep>
  <Step title="Follow the Auth0 React quickstart">
    Follow the [Auth0 React Quickstart](https://auth0.com/docs/quickstart/spa/react/interactive).

    Sign up for a free Auth0 account.

    Configure your application, using `http://localhost:3000, http://localhost:5173` for Callback
    and Logout URLs and Allowed Web Origins.

    Come back when you finish the _Install the Auth0 React SDK_ step.

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/auth0-signup.png" alt="Sign up to Auth0" width={300} />
    </p>

  </Step>
  <Step title="Create the auth config">
    In the `convex` folder create a new file <JSDialectFileName name="auth.config.ts" /> with
    the server-side configuration for validating access tokens.

    Paste in the `domain` and `clientId` values shown in
    _Install the Auth0 React SDK_ step of the Auth0 quickstart or
    in your Auth0 application's Settings dashboard.

    ```ts title="convex/auth.config.ts"
    export default {
      providers: [
        {
          domain: "your-domain.us.auth0.com",
          applicationID: "yourclientid",
        },
      ]
    };
    ```

  </Step>
  <Step title="Deploy your changes">
    Run `npx convex dev` to automatically sync your configuration to your backend.

    ```sh
    npx convex dev
    ```

  </Step>
  <Step title="Configure ConvexProviderWithAuth0">
    Now replace your `ConvexProvider` with an `Auth0Provider` wrapping `ConvexProviderWithAuth0`.
    Add the `domain` and `clientId` as props to the `Auth0Provider`.

    Paste in the `domain` and `clientId` values shown in
    _Install the Auth0 React SDK_ step of the Auth0 quickstart or
    in your Auth0 application's Settings dashboard as props to `Auth0Provider`.

    <TSAndJSSnippet
      title="src/main.tsx"
      sourceTS={ConfigTS}
      sourceJS={ConfigJS}
      highlightPatterns={[
        "Auth0Provider",
        "ConvexProviderWithAuth0",
        "domain=",
        "clientId=",
        "authorizationParams=",
          "redirect_uri: ",
        "}}",
        "useRefreshTokens=",
        "cacheLocation=",
        "  >",
      ]}
    />

  </Step>
</StepByStep>

## Login and logout flows

Now that you have everything set up, you can use the
[`useAuth0()`](https://auth0.github.io/auth0-react/functions/useAuth0.html) hook
to create login and logout buttons for your app.

The login button will redirect the user to the Auth0 universal login page. For
details see
[Add Login to Your Application](https://auth0.com/docs/quickstart/spa/react/interactive#add-login-to-your-application)
in the Auth0 React Quickstart.

```tsx title="src/login.ts"
import { useAuth0 } from "@auth0/auth0-react";

export default function LoginButton() {
  const { loginWithRedirect } = useAuth0();
  return <button onClick={loginWithRedirect}>Log in</button>;
}
```

The logout button will redirect the user to the Auth0 logout endpoint. For
details see
[Add Logout to your Application](https://auth0.com/docs/quickstart/spa/react/interactive#add-logout-to-your-application)
in the Auth0 React Quickstart.

<TSAndJSSnippet
  title="src/logout.ts"
  sourceTS={LogoutButtonTSX}
  sourceJS={LogoutButtonTSX}
/>

## Logged-in and logged-out views

Use the [`useConvexAuth()`](/api/modules/react#useconvexauth) hook instead of
the `useAuth0` hook when you need to check whether the user is logged in or not.
The `useConvex` hook makes sure that the browser has fetched the auth token
needed to make authenticated requests to your Convex backend:

```tsx title="src/App.ts"
import { useConvexAuth } from "convex/react";

function App() {
  const { isLoading, isAuthenticated } = useConvexAuth();

  return (
    <div className="App">
      {isAuthenticated ? "Logged in" : "Logged out or still loading"}
    </div>
  );
}
```

You can also use the `Authenticated`, `Unauthenticated` and `AuthLoading` helper
components which use the `useConvexAuth` hook under the hood:

```tsx title="src/App.ts"
import { Authenticated, Unauthenticated, AuthLoading } from "convex/react";

function App() {
  return (
    <div className="App">
      <Authenticated>Logged in</Authenticated>
      <Unauthenticated>Logged out</Unauthenticated>
      <AuthLoading>Still loading</AuthLoading>
    </div>
  );
}
```

## User information in React

You can access information about the authenticated user like their name from the
`useAuth0` hook:

```tsx title="src/badge.ts"
import { useAuth0 } from "@auth0/auth0-react";

export default function Badge() {
  const { user } = useAuth0();
  return <span>Logged in as {user.name}</span>;
}
```

## User information in functions

See [Auth in Functions](/auth/functions-auth.mdx) to learn about how to access
information about the authenticated user in your queries, mutations and actions.

See [Storing Users in the Convex Database](/auth/database-auth.mdx) to learn
about how to store user information in the Convex database.

## Configuring dev and prod tenants

To configure a different Auth0 tenant (environment) between your Convex
development and production deployments you can use environment variables
configured on the Convex dashboard.

### Configuring the backend

First, change your <JSDialectFileName name="auth.config.ts" /> file to use
environment variables:

```ts title="convex/auth.config.ts"
export default {
  providers: [
    {
      domain: process.env.AUTH0_DOMAIN,
      applicationID: process.env.AUTH0_CLIENT_ID,
    },
  ],
};
```

**Development configuration**

Open the Settings for your dev deployment on the Convex
[dashboard](https://dashboard.convex.dev) and add the variables there:

<p style={{ textAlign: "center" }}>
  <img
    src="/screenshots/auth0-convex-dashboard.png"
    alt="Convex dashboard dev deployment settings"
    width={600}
  />
</p>

Now switch to the new configuration by running `npx convex dev`.

**Production configuration**

Similarly on the Convex [dashboard](https://dashboard.convex.dev) switch to your
production deployment in the left side menu and set the values for your
production Auth0 tenant there.

Now switch to the new configuration by running `npx convex deploy`.

### Configuring a React client

To configure your client you can use environment variables as well. The exact
name of the environment variables and the way to refer to them depends on each
client platform (Vite vs Next.js etc.), refer to our corresponding
[Quickstart](/quickstarts.mdx) or the relevant documentation for the platform
you're using.

Change the props to `Auth0Provider` to take in environment variables:

<TSAndJSSnippet
  title="src/main.tsx"
  sourceTS={ConfigEnvTS}
  sourceJS={ConfigEnvJS}
  highlightPatterns={["domain=", "clientId="]}
/>

**Development configuration**

Use the `.env.local` or `.env` file to configure your client when running
locally. The name of the environment variables file depends on each client
platform (Vite vs Next.js etc.), refer to our corresponding
[Quickstart](/quickstarts.mdx) or the relevant documentation for the platform
you're using:

```py title=".env.local"
VITE_AUTH0_DOMAIN="your-domain.us.auth0.com"
VITE_AUTH0_CLIENT_ID="yourclientid"
```

**Production configuration**

Set the environment variables in your production environment depending on your
hosting platform. See [Hosting](/production/hosting/hosting.mdx).

## Debugging authentication

If a user goes through the Auth0 login flow successfully, and after being
redirected back to your page `useConvexAuth` gives `isAuthenticated: false`,
it's possible that your backend isn't correctly configured.

The <JSDialectFileName name="auth.config.ts" /> file in your `convex/` directory
contains a list of configured authentication providers. You must run
`npx convex dev` or `npx convex deploy` after adding a new provider to sync the
configuration to your backend.

For more thorough debugging steps, see
[Debugging Authentication](/auth/debug.mdx).

## Under the hood

<UnderTheHood
  provider="Auth0"
  integrationProvider={<code>ConvexProviderWithAuth0</code>}
  providerProvider={<code>Auth0Provider</code>}
  configProp={
    <>
      the{" "}
      <a
        href="https://auth0.github.io/auth0-react/interfaces/AuthorizationParams.html"
        target="_blank"
      >
        <code>authorizationParams</code>
      </a>{" "}
      prop
    </>
  }
/>


---

# clerk.mdx

<!-- Source: auth/clerk.mdx -->

---
title: "Convex & Clerk"
sidebar_label: "Clerk"
sidebar_position: 10
---

import UnderTheHood from "@site/docs/auth/_under_the_hood.mdx";
import ConfigTS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite-ts/src/_mainClerk.tsx";
import ConfigJS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite/src/_mainClerk.jsx";
import ConfigEnvTS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite-ts/src/_mainClerkEnv.tsx";
import ConfigEnvJS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite/src/_mainClerkEnv.jsx";
import App from "!!raw-loader!@site/../private-demos/snippets/src/clerkApp.tsx";
import Messages from "!!raw-loader!@site/../private-demos/snippets/convex/clerkMessages.ts";

[Clerk](https://clerk.com) is an authentication platform providing login via
passwords, social identity providers, one-time email or SMS access codes, and
multi-factor authentication and basic user management.

## Get started

Convex offers a provider that is specifically for integrating with Clerk called
`<ConvexProviderWithClerk>`. It works with any of Clerk's React-based SDKs, such
as the Next.js and Expo SDKs.

See the following sections for the Clerk SDK that you're using:

- [React](#react) - Use this as a starting point if your SDK is not listed
- [Next.js](#nextjs)
- [Tanstack Start](#tanstack-start)

### React

**Example:**
[React with Convex and Clerk](https://github.com/get-convex/template-react-vite-clerk)

This guide assumes you already have a working React app with Convex. If not
follow the [Convex React Quickstart](/quickstart/react.mdx) first. Then:

<StepByStep>
  <Step title="Sign up for Clerk">
    Sign up for a free Clerk account at [clerk.com/sign-up](https://dashboard.clerk.com/sign-up).

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/clerk-signup.png" alt="Sign up to Clerk" width={200} />
    </p>

  </Step>
  <Step title="Create an application in Clerk">
    Choose how you want your users to sign in.

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/clerk-createapp.png" alt="Create a Clerk application" width={200} />
    </p>

  </Step>
  <Step title="Create a JWT Template">
    In the Clerk Dashboard, navigate to the [JWT templates](https://dashboard.clerk.com/last-active?path=jwt-templates) page.

    Select _New template_ and then from the list of templates, select _Convex_. You'll be redirected to the template's settings page. **Do NOT rename the JWT token. It must be called `convex`.**

    Copy and save the _Issuer_ URL somewhere secure. This URL is the issuer domain for Clerk's JWT templates, which is your Clerk app's _Frontend API URL_. In development, it's format will be `https://verb-noun-00.clerk.accounts.dev`. In production, it's format will be `https://clerk.<your-domain>.com`.

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/clerk-createjwt.png" alt="Create a JWT template" width={400} />
    </p>

  </Step>
  <Step title="Set the Issuer URL in your env vars">
    In your `env` file, add your _Issuer_ URL as the `CLERK_FRONTEND_API_URL` environment variable. If you're using Vite, you'll need to prefix it with `VITE_`.

    ```env title=".env"
    VITE_CLERK_FRONTEND_API_URL=https://verb-noun-00.clerk.accounts.dev
    ```

  </Step>
  <Step title="Configure Convex with the Clerk issuer domain">
    In your app's `convex` folder, create a new file <JSDialectFileName name="auth.config.ts" /> with the following code. This is the server-side configuration for validating access tokens.

    ```ts title="convex/auth.config.ts"
    export default {
      providers: [
        {
          domain: process.env.VITE_CLERK_FRONTEND_API_URL,
          applicationID: "convex",
        },
      ]
    };
    ```

  </Step>
  <Step title="Deploy your changes">
    Run `npx convex dev` to automatically sync your configuration to your backend.

    ```sh
    npx convex dev
    ```

  </Step>
  <Step title="Install clerk">
    In a new terminal window, install the Clerk React SDK:

    ```sh
    npm install @clerk/clerk-react
    ```

  </Step>
  <Step title="Set your Clerk API keys">
    In the Clerk Dashboard, navigate to the [**API keys**](https://dashboard.clerk.com/last-active?path=api-keys) page. In the **Quick Copy** section, copy your Clerk Publishable Key and set it as the `CLERK_PUBLISHABLE_KEY` environment variable. If you're using Vite, you will need to prefix it with `VITE_`.

    ```env title=".env"
    VITE_CLERK_PUBLISHABLE_KEY=YOUR_PUBLISHABLE_KEY
    ```

  </Step>
  <Step title="Configure ConvexProviderWithClerk">
    Both Clerk and Convex have provider components that are required to provide authentication and client context.

    You should already have `<ConvexProvider>` wrapping your app. Replace it with `<ConvexProviderWithClerk>`, and pass Clerk's `useAuth()` hook to it.

    Then, wrap it with `<ClerkProvider>`. `<ClerkProvider>` requires a `publishableKey` prop, which you can set to the `VITE_CLERK_PUBLISHABLE_KEY` environment variable.

    <TSAndJSSnippet
      title="src/main.tsx"
      sourceTS={ConfigTS}
      sourceJS={ConfigJS}
      highlightPatterns={["ClerkProvider", "ConvexProviderWithClerk"]}
    />

  </Step>

  <Step title="Show UI based on authentication state">
    You can control which UI is shown when the user is signed in or signed out using Convex's `<Authenticated>`, `<Unauthenticated>` and `<AuthLoading>` helper components. These should be used instead of Clerk's `<SignedIn>`, `<SignedOut>` and `<ClerkLoading>` components, respectively.

    It's important to use the [`useConvexAuth()`](/api/modules/react#useconvexauth) hook instead of
    Clerk's `useAuth()` hook when you need to check whether the user is logged in or
    not. The `useConvexAuth()` hook makes sure that the browser has fetched the auth
    token needed to make authenticated requests to your Convex backend, and that the
    Convex backend has validated it.

    In the following example, the `<Content />` component is a child of `<Authenticated>`, so its content and any of its child components are guaranteed to have an authenticated user, and Convex queries can require authentication.

    ```tsx title="src/App.tsx"
    import { SignInButton, UserButton } from "@clerk/clerk-react";
    import { Authenticated, Unauthenticated, AuthLoading, useQuery } from "convex/react";
    import { api } from "../convex/_generated/api";

    function App() {
      return (
        <main>
          <Unauthenticated>
            <SignInButton />
          </Unauthenticated>
          <Authenticated>
            <UserButton />
            <Content />
          </Authenticated>
          <AuthLoading>
            <p>Still loading</p>
          </AuthLoading>
        </main>
      );
    }

    function Content() {
      const messages = useQuery(api.messages.getForCurrentUser);
      return <div>Authenticated content: {messages?.length}</div>;
    }

    export default App;
    ```

  </Step>

  <Step title="Use authentication state in your Convex functions">
    If the client is authenticated, you can access the information
    stored in the JWT via `ctx.auth.getUserIdentity`.

    If the client isn't authenticated, `ctx.auth.getUserIdentity` will return `null`.

    **Make sure that the component calling this query is a child of `<Authenticated>` from
    `convex/react`**. Otherwise, it will throw on page load.

    <TSAndJSSnippet
      title="convex/messages.ts"
      sourceTS={Messages}
      sourceJS={Messages}
    />

  </Step>
</StepByStep>

### Next.js

**Example:**
[Next.js with Convex and Clerk](https://github.com/get-convex/template-nextjs-clerk)

This guide assumes you already have a working Next.js app with Convex. If not
follow the [Convex Next.js Quickstart](/quickstart/nextjs.mdx) first. Then:

<StepByStep>
  <Step title="Sign up for Clerk">
    Sign up for a free Clerk account at [clerk.com/sign-up](https://dashboard.clerk.com/sign-up).

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/clerk-signup.png" alt="Sign up to Clerk" width={200} />
    </p>

  </Step>
  <Step title="Create an application in Clerk">
    Choose how you want your users to sign in.

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/clerk-createapp.png" alt="Create a Clerk application" width={200} />
    </p>

  </Step>
  <Step title="Create a JWT Template">
    In the Clerk Dashboard, navigate to the [JWT templates](https://dashboard.clerk.com/last-active?path=jwt-templates) page.

    Select _New template_ and then from the list of templates, select _Convex_. You'll be redirected to the template's settings page. **Do NOT rename the JWT token. It must be called `convex`.**

    Copy and save the _Issuer_ URL somewhere secure. This URL is the issuer domain for Clerk's JWT templates, which is your Clerk app's _Frontend API URL_. In development, it's format will be `https://verb-noun-00.clerk.accounts.dev`. In production, it's format will be `https://clerk.<your-domain>.com`.

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/clerk-createjwt.png" alt="Create a JWT template" width={400} />
    </p>

  </Step>
  <Step title="Set the Issuer URL in your env vars">
    In your `env` file, add your _Issuer_ URL as the `NEXT_PUBLIC_CLERK_FRONTEND_API_URL` environment variable.

    ```env title=".env"
    NEXT_PUBLIC_CLERK_FRONTEND_API_URL=https://verb-noun-00.clerk.accounts.dev
    ```

  </Step>
  <Step title="Configure Convex with the Clerk issuer domain">
    In your app's `convex` folder, create a new file <JSDialectFileName name="auth.config.ts" /> with the following code. This is the server-side configuration for validating access tokens.

    ```ts title="convex/auth.config.ts"
    export default {
      providers: [
        {
          domain: process.env.NEXT_PUBLIC_CLERK_FRONTEND_API_URL,
          applicationID: "convex",
        },
      ]
    };
    ```

  </Step>
  <Step title="Deploy your changes">
    Run `npx convex dev` to automatically sync your configuration to your backend.

    ```sh
    npx convex dev
    ```

  </Step>
  <Step title="Install clerk">
    In a new terminal window, install the Clerk Next.js SDK:

    ```sh
    npm install @clerk/nextjs
    ```

  </Step>
  <Step title="Set your Clerk API keys">
    In the Clerk Dashboard, navigate to the [**API keys**](https://dashboard.clerk.com/last-active?path=api-keys) page. In the **Quick Copy** section, copy your Clerk Publishable and Secret Keys and set them as the `NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY` and `CLERK_SECRET_KEY` environment variables, respectively.

    ```env title=".env"
    NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=YOUR_PUBLISHABLE_KEY
    CLERK_SECRET_KEY=YOUR_SECRET_KEY
    ```

  </Step>
  <Step title="Add Clerk middleware">
    Clerk's `clerkMiddleware()` helper grants you access to user authentication state throughout your app.

    Create a `middleware.ts` file.

    In your `middleware.ts` file, export the `clerkMiddleware()` helper:

    ```tsx {{ filename: 'middleware.ts' }}
    import { clerkMiddleware } from '@clerk/nextjs/server'

    export default clerkMiddleware()

    export const config = {
      matcher: [
        // Skip Next.js internals and all static files, unless found in search params
        '/((?!_next|[^?]*\\.(?:html?|css|js(?!on)|jpe?g|webp|png|gif|svg|ttf|woff2?|ico|csv|docx?|xlsx?|zip|webmanifest)).*)',
        // Always run for API routes
        '/(api|trpc)(.*)',
      ],
    }
    ```

    By default, `clerkMiddleware()` will not protect any routes. All routes are public and you must opt-in to protection for routes.https://clerk.com/docs/references/nextjs/clerk-middleware) to learn how to require authentication for specific routes.

  </Step>
  <Step title="Configure ConvexProviderWithClerk">
    Both Clerk and Convex have provider components that are required to provide authentication and client context.

    Typically, you'd replace `<ConvexProvider>` with `<ConvexProviderWithClerk>`, but with Next.js App Router, things are a bit more complex.

    `<ConvexProviderWithClerk>` calls `ConvexReactClient()` to get Convex's client, so it must be used in a Client Component. Your `app/layout.tsx`, where you would use `<ConvexProviderWithClerk>`, is a Server Component, and a Server Component cannot contain Client Component code. To solve this, you must first create a _wrapper_ Client Component around `<ConvexProviderWithClerk>`.

    ```tsx {{ filename: 'components/ConvexClientProvider.tsx' }}
    'use client'

    import { ReactNode } from 'react'
    import { ConvexReactClient } from 'convex/react'
    import { ConvexProviderWithClerk } from 'convex/react-clerk'
    import { useAuth } from '@clerk/nextjs'

    if (!process.env.NEXT_PUBLIC_CONVEX_URL) {
      throw new Error('Missing NEXT_PUBLIC_CONVEX_URL in your .env file')
    }

    const convex = new ConvexReactClient(process.env.NEXT_PUBLIC_CONVEX_URL)

    export default function ConvexClientProvider({ children }: { children: ReactNode }) {
      return (
        <ConvexProviderWithClerk client={convex} useAuth={useAuth}>
          {children}
        </ConvexProviderWithClerk>
      )
    }
    ```

  </Step>
  <Step title="Wrap your app in Clerk and Convex">
    Now, your Server Component, `app/layout.tsx`, can render `<ConvexClientProvider>` instead of rendering `<ConvexProviderWithClerk>` directly. It's important that `<ClerkProvider>` wraps `<ConvexClientProvider>`, and not the other way around, as Convex needs to be able to access the Clerk context.

    ```tsx {{ filename: 'app/layout.tsx', mark: [5, 31] }}
    import type { Metadata } from 'next'
    import { Geist, Geist_Mono } from 'next/font/google'
    import './globals.css'
    import { ClerkProvider } from '@clerk/nextjs'
    import ConvexClientProvider from '@/components/ConvexClientProvider'

    const geistSans = Geist({
      variable: '--font-geist-sans',
      subsets: ['latin'],
    })

    const geistMono = Geist_Mono({
      variable: '--font-geist-mono',
      subsets: ['latin'],
    })

    export const metadata: Metadata = {
      title: 'Clerk Next.js Quickstart',
      description: 'Generated by create next app',
    }

    export default function RootLayout({
      children,
    }: Readonly<{
      children: React.ReactNode
    }>) {
      return (
        <html lang="en">
          <body className={`${geistSans.variable} ${geistMono.variable} antialiased`}>
            <ClerkProvider>
              <ConvexClientProvider>{children}</ConvexClientProvider>
            </ClerkProvider>
          </body>
        </html>
      )
    }
    ```

  </Step>
  <Step title="Show UI based on authentication state">
    You can control which UI is shown when the user is signed in or signed out using Convex's `<Authenticated>`, `<Unauthenticated>` and `<AuthLoading>` helper components. These should be used instead of Clerk's `<SignedIn>`, `<SignedOut>` and `<ClerkLoading>` components, respectively.

    It's important to use the [`useConvexAuth()`](/api/modules/react#useconvexauth) hook instead of
    Clerk's `useAuth()` hook when you need to check whether the user is logged in or
    not. The `useConvexAuth()` hook makes sure that the browser has fetched the auth
    token needed to make authenticated requests to your Convex backend, and that the
    Convex backend has validated it.

    In the following example, the `<Content />` component is a child of `<Authenticated>`, so its content and any of its child components are guaranteed to have an authenticated user, and Convex queries can require authentication.

    ```tsx title="app/page.tsx"
    "use client";

    import { Authenticated, Unauthenticated } from "convex/react";
    import { SignInButton, UserButton } from "@clerk/nextjs";
    import { useQuery } from "convex/react";
    import { api } from "../convex/_generated/api";

    export default function Home() {
      return (
        <>
          <Authenticated>
            <UserButton />
            <Content />
          </Authenticated>
          <Unauthenticated>
            <SignInButton />
          </Unauthenticated>
        </>
      );
    }

    function Content() {
      const messages = useQuery(api.messages.getForCurrentUser);
      return <div>Authenticated content: {messages?.length}</div>;
    }
    ```

  </Step>

  <Step title="Use authentication state in your Convex functions">
    If the client is authenticated, you can access the information
    stored in the JWT via `ctx.auth.getUserIdentity`.

    If the client isn't authenticated, `ctx.auth.getUserIdentity` will return `null`.

    **Make sure that the component calling this query is a child of `<Authenticated>` from
    `convex/react`**. Otherwise, it will throw on page load.

    <TSAndJSSnippet
      title="convex/messages.ts"
      sourceTS={Messages}
      sourceJS={Messages}
    />

  </Step>
</StepByStep>

### Tanstack Start

**Example:**
[Tanstack Start with Convex and Clerk](https://github.com/get-convex/templates/tree/main/template-tanstack-start)

See the
[Tanstack Start with Clerk guide](/client/react/tanstack-start/clerk.mdx) for
more information.

## Next steps

### Accessing user information in functions

See [Auth in Functions](/auth/functions-auth.mdx) to learn about how to access
information about the authenticated user in your queries, mutations and actions.

See [Storing Users in the Convex Database](/auth/database-auth.mdx) to learn
about how to store user information in the Convex database.

### Accessing user information client-side

To access the authenticated user's information, use Clerk's `User` object, which
can be accessed using Clerk's
[`useUser()`](https://clerk.com/docs/hooks/use-user) hook. For more information
on the `User` object, see the
[Clerk docs](https://clerk.com/docs/references/javascript/user).

```tsx title="components/Badge.tsx"
export default function Badge() {
  const { user } = useUser();

  return <span>Logged in as {user.fullName}</span>;
}
```

## Configuring dev and prod instances

To configure a different Clerk instance between your Convex development and
production deployments, you can use environment variables configured on the
Convex dashboard.

### Configuring the backend

In the Clerk Dashboard, navigate to the
[**API keys**](https://dashboard.clerk.com/last-active?path=api-keys) page. Copy
your Clerk Frontend API URL. This URL is the issuer domain for Clerk's JWT
templates, and is necessary for Convex to validate access tokens. In
development, it's format will be `https://verb-noun-00.clerk.accounts.dev`. In
production, it's format will be `https://clerk.<your-domain>.com`.

Paste your Clerk Frontend API URL into your `.env` file, set it as the
`CLERK_FRONTEND_API_URL` environment variable. If you are using Vite, you will
need to prefix it with `VITE_`. If you are using Next.js, you will need to
prefix it with `NEXT_PUBLIC_`.

```env title=".env"
CLERK_FRONTEND_API_URL=https://verb-noun-00.clerk.accounts.dev
```

Then, update your <JSDialectFileName name="auth.config.ts" /> file to use the
environment variable. Don't forget to use the necessary prefix for your client
platform (e.g. `VITE_` or `NEXT_PUBLIC_`).

```ts title="convex/auth.config.ts"
export default {
  providers: [
    {
      domain: process.env.CLERK_FRONTEND_API_URL,
      applicationID: "convex",
    },
  ],
};
```

**Development configuration**

In the left sidenav of the Convex [dashboard](https://dashboard.convex.dev),
switch to your development deployment and set the values for your development
Clerk instance.

{/* TODO: Update screenshot to use `CLERK_FRONTEND_API_URL`. It should be in the format `https://verb-noun-00.clerk.accounts.dev` */}

<p style={{ textAlign: "center" }}>
  <img
    src="/screenshots/clerk-convex-dashboard.png"
    alt="Convex dashboard dev deployment settings"
    width={600}
  />
</p>

Then, to switch your deployment to the new configuration, run `npx convex dev`.

**Production configuration**

In the left sidenav of the Convex [dashboard](https://dashboard.convex.dev),
switch to your production deployment and set the values for your production
Clerk instance.

{/* TODO: Add screenshot of production configuration in Convex dashboard. The `CLERK_FRONTEND_API_URL` should be in the format `https://clerk.<your-domain>.com` */}

Then, to switch your deployment to the new configuration, run
`npx convex deploy`.

### Configuring Clerk's API keys

Clerk's API keys differ depending on whether they are for development or
production. Don't forget to update the environment variables in your `.env` file
as well as your hosting platform, such as Vercel or Netlify.

**Development configuration**

Clerk's Publishable Key for development follows the format `pk_test_...`.

```py title=".env.local"
VITE_CLERK_PUBLISHABLE_KEY="pk_test_..."
```

**Production configuration**

Clerk's Publishable Key for production follows the format `pk_live_...`.

```py title=".env"
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY="pk_live_..."
```

## Debugging authentication

If a user goes through the Clerk login flow successfully, and after being
redirected back to your page, `useConvexAuth()` returns
`isAuthenticated: false`, it's possible that your backend isn't correctly
configured.

The <JSDialectFileName name="auth.config.ts" /> file contains a list of
configured authentication providers. You must run `npx convex dev` or
`npx convex deploy` after adding a new provider to sync the configuration to
your backend.

For more thorough debugging steps, see
[Debugging Authentication](/auth/debug.mdx).

## Under the hood

<UnderTheHood
  provider="Clerk"
  integrationProvider={<code>ConvexProviderWithClerk</code>}
  providerProvider={<code>ClerkProvider</code>}
  configProp={
    <>
      the{" "}
      <a
        href="https://clerk.com/docs/authentication/sign-in#override-ur-ls"
        target="_blank"
      >
        <code>afterSignIn</code>
      </a>{" "}
      prop
    </>
  }
/>


---

# convex-auth.mdx

<!-- Source: auth/convex-auth.mdx -->

---
title: "Convex Auth"
sidebar_label: "Convex Auth"
sidebar_position: 1
---

[Convex Auth](https://labs.convex.dev/auth) is a library for implementing
authentication directly within your Convex backend. This allows you to
authenticate users without needing an authentication service or even a hosting
server. Convex Auth currently supports client-side React web apps served from a
CDN and React Native mobile apps.

**Example:** [Live Demo](https://labs.convex.dev/auth-example)
([Source](https://github.com/get-convex/convex-auth-example))

<BetaAdmonition feature="Convex Auth" verb="is" />

Support for
[authentication in Next.js](https://labs.convex.dev/auth/authz/nextjs) server
components, API routes, middleware, SSR etc. is under active development. If
you'd like to help test this experimental support please
[let us know how it goes in Discord](https://convex.dev/community).

## Get Started

To start a new project from scratch with Convex and Convex Auth, run:

```sh
npm create convex@latest
```

and choose `React (Vite)` and `Convex Auth`.

---

To add Convex Auth to an existing project, follow the full
[setup guide](https://labs.convex.dev/auth/setup).

## Overview

Convex Auth enables you to implement the following authentication methods:

1. Magic Links & OTPs - send a link or code via email
2. OAuth - sign in with GitHub / Google / Apple etc.
3. Passwords - including password reset flow and optional email verification

The library doesn't come with UI components, but you can copy code from the docs
and example repo to quickly build a UI in React.

Learn more in the [Convex Auth docs](https://labs.convex.dev/auth).


---

# database-auth.mdx

<!-- Source: auth/database-auth.mdx -->

---
title: "Storing Users in the Convex Database"
sidebar_label: "Database"
sidebar_position: 50
---

import Schema from "!!raw-loader!@site/../demos/users-and-clerk/convex/schema.ts";
import useStoreUserEffectTS from "!!raw-loader!@site/../demos/users-and-clerk/src/useStoreUserEffect.ts";
import useStoreUserEffectJS from "!!raw-loader!@site/../private-demos/snippets/users-and-clerk/useStoreUserEffect.js";
import MessagesTS from "!!raw-loader!@site/../demos/users-and-clerk/convex/messages.ts";
import UsersTS from "!!raw-loader!@site/../demos/users-and-clerk/convex/users.ts";
import App from "!!raw-loader!@site/../private-demos/snippets/src/clerkStoreUserApp.tsx";
import WebhooksSchema from "!!raw-loader!@site/../demos/users-and-clerk-webhooks/convex/schema.ts";
import WebhookMutations from "!!raw-loader!@site/../demos/users-and-clerk-webhooks/convex/users.ts";
import WebhookEndpoint from "!!raw-loader!@site/../demos/users-and-clerk-webhooks/convex/http.ts";
import WebhookMessages from "!!raw-loader!@site/../demos/users-and-clerk-webhooks/convex/messages.ts";
import WebhookHook from "!!raw-loader!@site/../demos/users-and-clerk-webhooks/src/useCurrentUser.ts";
import WebhookClient from "!!raw-loader!@site/../demos/users-and-clerk-webhooks/src/App.tsx";

_If you're using [Convex Auth](/auth/convex-auth.mdx) the user information is
already stored in your database. There's nothing else you need to implement._

You might want to store user information directly in your Convex database, for
the following reasons:

- Your functions need information about other users, not just about the
  currently logged-in user
- Your functions need access to information other than the fields available in
  the [Open ID Connect JWT](/auth/functions-auth.mdx)

There are two ways you can choose from for storing user information in your
database (but only the second one allows storing information not contained in
the JWT):

1. Have your app's [client call a mutation](#call-a-mutation-from-the-client)
   that stores the information from the JWT available on
   [`ctx.auth`](/api/interfaces/server.Auth)
2. [Implement a webhook](#set-up-webhooks) and have your identity provider call
   it whenever user information changes

## Call a mutation from the client

**Example:**
[Convex Authentication with Clerk](https://github.com/get-convex/convex-demos/tree/main/users-and-clerk)

### (optional) Users table schema

You can define a `"users"` table, optionally with an
[index](/database/reading-data/indexes/indexes.md) for efficient looking up the
users in the database.

In the examples below we will use the `tokenIdentifier` from the
`ctx.auth.getUserIdentity()` to identify the user, but you could use the
`subject` field (which is usually set to the unique user ID from your auth
provider) or even `email`, if your authentication provider provides email
verification and you have it enabled.

Which field you use will determine how multiple providers interact, and how hard
it will be to migrate to a different provider.

<Snippet source={Schema} snippet="user" title="convex/schema.ts" />

### Mutation for storing current user

This is an example of a mutation that stores the user's `name` and
`tokenIdentifier`:

<TSAndJSSnippet sourceTS={UsersTS} sourceJS={UsersTS} title="convex/users.js" />

### Calling the store user mutation from React

You can call this mutation when the user logs in from a `useEffect` hook. After
the mutation succeeds you can update local state to reflect that the user has
been stored.

This helper hook that does the job:

<TSAndJSSnippet
  sourceTS={useStoreUserEffectTS}
  sourceJS={useStoreUserEffectJS}
  title="src/useStoreUserEffect.ts"
/>

You can use this hook in your top-level component. If your queries need the user
document to be present, make sure that you only render the components that call
them after the user has been stored:

<TSAndJSSnippet sourceTS={App} sourceJS={App} title="src/App.tsx" />

In this way the `useStoreUserEffect` hook replaces the `useConvexAuth` hook.

### Using the current user's document ID

Similarly to the store user mutation, you can retrieve the current user's ID, or
throw an error if the user hasn't been stored.

Now that you have users stored as documents in your Convex database, you can use
their IDs as foreign keys in other documents:

<TSAndJSSnippet
  sourceTS={MessagesTS}
  sourceJS={MessagesTS}
  snippet="load-user"
  title="convex/messages.ts"
  suffix={`    // do something with \`user\`...
  }
});`}
/>

### Loading users by their ID

The information about other users can be retrieved via their IDs:

<TSAndJSSnippet
  sourceTS={MessagesTS}
  sourceJS={MessagesTS}
  snippet="use-users"
  title="convex/messages.ts"
  prefix={`import { query } from "./_generated/server";
`}
/>

## Set up webhooks

This guide will use Clerk, but Auth0 can be set up similarly via
[Auth0 Actions](https://auth0.com/docs/customize/actions/actions-overview).

With this implementation Clerk will call your Convex backend via an HTTP
endpoint any time a user signs up, updates or deletes their account.

**Example:**
[Convex Authentication with Clerk and Webhooks](https://github.com/get-convex/convex-demos/tree/main/users-and-clerk-webhooks)

### Configure the webhook endpoint in Clerk

On your Clerk dashboard, go to _Webhooks_, click on _+ Add Endpoint_.

Set _Endpoint URL_ to
`https://<your deployment name>.convex.site/clerk-users-webhook` (note the
domain ends in **`.site`**, not `.cloud`). You can see your deployment name in
the `.env.local` file in your project directory, or on your Convex dashboard as
part of the [Deployment URL](/dashboard/deployments/settings.md). For example,
the endpoint URL could be:
`https://happy-horse-123.convex.site/clerk-users-webhook`.

In _Message Filtering_, select **user** for all user events (scroll down or use
the search input).

Click on _Create_.

After the endpoint is saved, copy the _Signing Secret_ (on the right side of the
UI), it should start with `whsec_`. Set it as the value of the
`CLERK_WEBHOOK_SECRET` environment variable in your Convex
[dashboard](https://dashboard.convex.dev).

### (optional) Users table schema

You can define a `"users"` table, optionally with an
[index](/database/reading-data/indexes/indexes.md) for efficient looking up the
users in the database.

In the examples below we will use the `subject` from the
`ctx.auth.getUserIdentity()` to identify the user, which should be set to the
Clerk user ID.

<Snippet source={WebhooksSchema} snippet="table" title="convex/schema.ts" />

### Mutations for upserting and deleting users

This is an example of mutations that handle the updates received via the
webhook:

<TSAndJSSnippet
  sourceTS={WebhookMutations}
  sourceJS={WebhookMutations}
  title="convex/users.ts"
/>

There are also a few helpers in this file:

- `current` exposes the user information to the client, which will helps the
  client determine whether the webhook already succeeded
- `upsertFromClerk` will be called when a user signs up or when they update
  their account
- `deleteFromClerk` will be called when a user deletes their account via Clerk
  UI from your app
- `getCurrentUserOrThrow` retrieves the currently logged-in user or throws an
  error
- `getCurrentUser` retrieves the currently logged-in user or returns null
- `userByExternalId` retrieves a user given the Clerk ID, and is used only for
  retrieving the current user or when updating an existing user via the webhook

### Webhook endpoint implementation

This how the actual HTTP endpoint can be implemented:

<TSAndJSSnippet
  sourceTS={WebhookEndpoint}
  sourceJS={WebhookEndpoint}
  title="convex/http.ts"
/>

If you deploy your code now and sign in, you should see the user being created
in your Convex database.

### Using the current user's document

You can use the helpers defined before to retrieve the current user's document.

Now that you have users stored as documents in your Convex database, you can use
their IDs as foreign keys in other documents:

<TSAndJSSnippet
  sourceTS={WebhookMessages}
  sourceJS={WebhookMessages}
  snippet="current-user"
  title="convex/messages.ts"
/>

### Loading users by their ID

The information about other users can be retrieved via their IDs:

<TSAndJSSnippet
  sourceTS={MessagesTS}
  sourceJS={MessagesTS}
  snippet="use-users"
  title="convex/messages.ts"
/>

### Waiting for current user to be stored

If you want to use the current user's document in a query, make sure that the
user has already been stored. You can do this by explicitly checking for this
condition before rendering the components that call the query, or before
redirecting to the authenticated portion of your app.

For example you can define a hook that determines the current authentication
state of the client, taking into account whether the current user has been
stored:

<TSAndJSSnippet
  sourceTS={WebhookHook}
  sourceJS={WebhookHook}
  title="src/useCurrentUser.ts"
/>

And then you can use it to render the appropriate components:

<TSAndJSSnippet
  sourceTS={WebhookClient}
  sourceJS={WebhookClient}
  snippet="client-blocking"
  title="src/App.tsx"
/>


---

# debug.mdx

<!-- Source: auth/debug.mdx -->

---
title: "Debugging Authentication"
sidebar_label: "Debugging"
sidebar_position: 60
---

# Debugging Authentication

You have followed one of our authentication guides but something is not working.
You have double checked that you followed all the steps, and that you used the
correct secrets, but you are still stuck.

## Frequently encountered issues

### `ctx.auth.getUserIdentity()` returns `null` in a query

This often happens when subscribing to queries via `useQuery` in React, without
waiting for the client to be authenticated. Even if the user has been logged-in
previously, it takes some time for the client to authenticate with the Convex
backend. Therefore on page load, `ctx.auth.getUserIdentity()` called within a
query returns `null`.

To handle this, you can either:

1. Use the `Authenticated` component from `convex/react` to wrap the component
   that includes the `useQuery` call (see the last two steps in the
   [Clerk guide](/auth/clerk.mdx#get-started))
2. Or return `null` or some other "sentinel" value from the query and handle it
   on the client

If you are using `fetchQuery` for
[Next.js Server Rendering](/client/react/nextjs/nextjs-server-rendering.mdx),
make sure you are explicitly passing in a JWT token as documented
[here](/client/react/nextjs/nextjs-server-rendering.mdx#server-side-authentication).

If this hasn't helped, follow the steps below to resolve your issue.

## Step 1: Check whether authentication works on the backend

1. Add the following code to the _beginning_ of your function (query, mutation,
   action or http action):

```ts
console.log("server identity", await ctx.auth.getUserIdentity());
```

2. Then call this function from whichever client you're using to talk to Convex.

3. Open the
   [logs page on your dashboard](https://dashboard.convex.dev/deployment/logs).

4. What do you see on the logs page?

   **Answer: I don't see anything**:

   - Potential cause: You don't have the right dashboard open. Confirm that the
     Deployment URL on _Settings_ > _URL and Deploy Key_ page matches how your
     client is configured.
   - Potential cause: Your client is not connected to Convex. Check your client
     logs (browser logs) for errors. Reload the page / restart the client.
   - Potential cause: The code has not been pushed. For dev deployments make
     sure you have `npx convex dev` running. For prod deployments make sure you
     successfully pushed via `npx convex deploy`. Go to the _Functions_ page on
     the dashboard and check that the code shown there includes the
     `console.log` line you added.

   When you resolved the cause you should see the log appear.

   **Answer: I see a log with `'server identity' null`**:

   - Potential cause: The client is not supplying an auth token.
   - Potential cause: Your deployment is misconfigured.
   - Potential cause: Your client is misconfigured.

   Proceed to
   [step 2](#step-2-check-whether-authentication-works-on-the-frontend).

   **Answer: I see a log with `'server identity' { tokenIdentifier: '... } `**

   Great, you are all set!

## Step 2: Check whether authentication works on the frontend

No matter which client you use, it must pass a JWT token to your backend for
authentication to work.

The most bullet-proof way of ensuring your client is passing the token to the
backend, is to inspect the traffic between them.

1. If you're using a client from the web browser, open the _Network_ tab in your
   browser's developer tools.

2. Check the token

   - For Websocket-based clients (`ConvexReactClient` and `ConvexClient`),
     filter for the `sync` name and select `WS` as the type of traffic. Check
     the `sync` items. After the client is initialized (commonly after loading
     the page), it will send a message (check the _Messages_ tab) with
     `type: "Authenticate"`, and `value` will be the authentication token.

     <p style={{ textAlign: "center" }}>
       <img
         src="/screenshots/auth-ws.png"
         alt="Network tab inspecting Websocket messages"
         width={500}
       />
     </p>

   - For HTTP based clients (`ConvexHTTPClient` and the
     [HTTP API](/http-api/index.md)), select `Fetch/XHR` as the type of traffic.
     You should see an individual network request for each function call, with
     an `Authorization` header with value `Bearer ` followed by the
     authentication token.

     <p style={{ textAlign: "center" }}>
       <img
         src="/screenshots/auth-http.png"
         alt="Network tab inspecting HTTP headers"
         width={480}
       />
     </p>

3. Do you see the authentication token in the traffic?

   **Answer: No**:

   - Potential cause: The Convex client is not configured to get/fetch a JWT
     token. You're not using
     `ConvexProviderWithClerk`/`ConvexProviderWithAuth0`/`ConvexProviderWithAuth`
     with the `ConvexReactClient` or you forgot to call `setAuth` on
     `ConvexHTTPClient` or `ConvexClient`.
   - Potential cause: You are not signed in, so the token is `null` or
     `undefined` and the `ConvexReactClient` skipped authentication altogether.
     Verify that you are signed in via `console.log`ing the token from whichever
     auth provider you are using:

     - Clerk:

       ```tsx
       // import { useAuth } from "@clerk/nextjs"; // for Next.js
       import { useAuth } from "@clerk/clerk-react";

       const { getToken } = useAuth();
       console.log(getToken({ template: "convex" }));
       ```

     - Auth0:

       ```tsx
       import { useAuth0 } from "@auth0/auth0-react";

       const { getAccessTokenSilently } = useAuth0();
       const response = await getAccessTokenSilently({
         detailedResponse: true,
       });
       const token = response.id_token;
       console.log(token);
       ```

     - Custom: However you implemented `useAuthFromProviderX`

     If you don't see a long string that looks like a token, check the browser
     logs for errors from your auth provider. If there are none, check the
     Network tab to see whether requests to your provider are failing. Perhaps
     the auth provider is misconfigured. Double check the auth provider
     configuration (in the corresponding React provider or however your auth
     provider is configured for the client). Try clearing your cookies in the
     browser (in dev tools _Application_ > _Cookies_ > _Clear all cookies_
     button).

   **Answer: Yes, I see a long string that looks like a JWT**:

   Great, copy the whole token (there can be `.`s in it, so make sure you're not
   copying just a portion of it).

4. Open https://jwt.io/, scroll down and paste the token in the Encoded textarea
   on the left of the page. On the right you should see:

   - In _HEADER_, `"typ": "JWT"`
   - in _PAYLOAD_, a valid JSON with at least `"aud"`, `"iss"` and `"sub"`
     fields. If you see gibberish in the payload you probably didn't copy the
     token correctly or it's not a valid JWT token.

   If you see a valid JWT token, repeat
   [step 1](#step-1-check-whether-authentication-works-on-the-backend). If you
   still don't see correct identity, proceed to step 3.

## Step 3: Check that backend configuration matches frontend configuration

You have a valid JWT token on the frontend, and you know that it is being passed
to the backend, but the backend is not validating it.

1. Open the _Settings_ > _Authentication_ on your dashboard. What do you see?

   **Answer: I see
   `This deployment has no configured authentication providers`**:

   - Cause: You do not have an `auth.config.ts` (or `auth.config.js`) file in
     your `convex` directory, or you haven't pushed your code. Follow the
     authentication guide to create a valid auth config file. For dev
     deployments make sure you have `npx convex dev` running. For prod
     deployments make sure you successfully pushed via `npx convex deploy`.

   \*\*Answer: I see one or more _Domain_ and _Application ID_ pairs.

Great, let's check they match the JWT token.

2. Look at the `iss` field in the JWT token payload at https://jwt.io/. Does it
   match a _Domain_ on the _Authentication_ page?

   **Answer: No, I don't see the `iss` URL on the Convex dashboard**:

   - Potential cause: You copied the wrong value into your
     <JSDialectFileName name="auth.config.ts" />
     's `domain`, or into the environment variable that is used there. Go back
     to the authentication guide and make sure you have the right URL from your
     auth provider.
   - Potential cause: Your client is misconfigured:

     - Clerk: You have the wrong `publishableKey` configured. The key must
       belong to the Clerk instance that you used to configure your

       <JSDialectFileName name="auth.config.ts" />.

       - Also make sure that the JWT token in Clerk is called `convex`, as
         that's the name `ConvexProviderWithClerk` uses to fetch the token!

     - Auth0: You have the wrong `domain` configured (on the client!). The
       domain must belong to the Auth0 instance that you used to configure your
       <JSDialectFileName name="auth.config.ts" />.
     - Custom: Make sure that your client is correctly configured to match your
       <JSDialectFileName name="auth.config.ts" />.

   **Answer: Yes, I do see the `iss` URL**:

   Great, let's move one.

3. Look at the `aud` field in the JWT token payload at https://jwt.io/. Does it
   match the _Application ID_ under the correct _Domain_ on the _Authentication_
   page?

   **Answer: No, I don't see the `aud` value in the _Application ID_ field**:

   - Potential cause: You copied the wrong value into your
     <JSDialectFileName name="auth.config.ts" />
     's `applicationID`, or into the environment variable that is used there. Go
     back to the authentication guide and make sure you have the right value
     from your auth provider.
   - Potential cause: Your client is misconfigured:
     - Clerk: You have the wrong `publishableKey` configured.The key must belong
       to the Clerk instance that you used to configure your
       <JSDialectFileName name="auth.config.ts" />.
     - Auth0: You have the wrong `clientId` configured. Make sure you're using
       the right `clientId` for the Auth0 instance that you used to configure
       your <JSDialectFileName name="auth.config.ts" />.
     - Custom: Make sure that your client is correctly configured to match your
       <JSDialectFileName name="auth.config.ts" />.

   **Answer: Yes, I do see the `aud` value in the _Application ID_ field**:

   Great, repeat
   [step 1](#step-1-check-whether-authentication-works-on-the-backend) and you
   should be all set!


---

# functions-auth.mdx

<!-- Source: auth/functions-auth.mdx -->

---
title: "Auth in Functions"
sidebar_label: "Functions"
sidebar_position: 40
---

import Example from "!!raw-loader!@site/../private-demos/snippets/convex/authFunctions.ts";
import FieldsTS from "!!raw-loader!@site/../private-demos/snippets/convex/authFunctionsFields.ts";
import FieldsJS from "!!raw-loader!@site/../private-demos/snippets/convex/authFunctionsFieldsJS.js";
import Fetch from "!!raw-loader!@site/../private-demos/snippets/src/httpAuthCall.ts";

_If you're using Convex Auth, see the
[authorization doc](https://labs.convex.dev/auth/authz#use-authentication-state-in-backend-functions)._

Within a Convex [function](/functions.mdx), you can access information about the
currently logged-in user by using the [`auth`](/api/interfaces/server.Auth)
property of the [`QueryCtx`](/generated-api/server#queryctx),
[`MutationCtx`](/generated-api/server#mutationctx), or
[`ActionCtx`](/generated-api/server#actionctx) object:

<TSAndJSSnippet
  sourceTS={Example}
  sourceJS={Example}
  title="convex/myFunctions.ts"
/>

## User identity fields

The [UserIdentity](/api/interfaces/server.UserIdentity) object returned by
`getUserIdentity` is guaranteed to have `tokenIdentifier`, `subject` and
`issuer` fields. Which other fields it will include depends on the identity
provider used and the configuration of JWT tokens and
[OpenID scopes](https://openid.net/specs/openid-connect-core-1_0.html#StandardClaims).

`tokenIdentifier` is a combination of `subject` and `issuer` to ensure
uniqueness even when multiple providers are used.

If you followed one of our integrations with Clerk or Auth0 at least the
following fields will be present: `familyName`, `givenName`, `nickname`,
`pictureUrl`, `updatedAt`, `email`, `emailVerified`. See their corresponding
standard definition in the
[OpenID docs](https://openid.net/specs/openid-connect-core-1_0.html#StandardClaims).

<TSAndJSSnippet
  sourceTS={FieldsTS}
  sourceJS={FieldsJS}
  title="convex/myFunctions.ts"
/>

### Clerk claims configuration

If you're using Clerk, the fields returned by `getUserIdentity` are determined
by your JWT template's _Claims_ config. If you've set custom claims, they will
be returned by `getUserIdentity` as well.

## HTTP Actions

You can also access the user identity from an HTTP action
[`ctx.auth.getUserIdentity()`](/api/interfaces/server.Auth#getuseridentity), by
calling your endpoint with an `Authorization` header including a JWT token:

<TSAndJSSnippet sourceTS={Fetch} sourceJS={Fetch} title="myPage.ts" />

<StackPosts query="authentication functions" />


---

# auth.mdx

<!-- Source: auth.mdx -->

---
title: Authentication
sidebar_position: 30
description: Add authentication to your Convex app.
hide_table_of_contents: true
pagination_prev: file-storage
---

Authentication allows you to identify users and restrict what data they can see
and edit.

Convex is compatible with most authentication providers because it uses OpenID
Connect (based on OAuth) ID tokens in the form of JWTs to authenticate WebSocket
connections or RPCs. These JWTs can be provided by any service implementing the
appropriate OAuth endpoints to verify them, including your own Convex backend.

## Third-party authentication platforms

Leveraging a Convex integration with a third-party auth provider provides the
most comprehensive authentication solutions. Integrating another service
provides a ton of functionality like passkeys, two-factor auth, spam protection,
and more on top of the authentication basics.

- [Clerk](/auth/clerk.mdx) is newer and has better Next.js and React Native
  support
- [Auth0](/auth/auth0.mdx) is more established with more bells and whistles
- [Custom Auth Integration](/auth/advanced/custom-auth.mdx) allow any OpenID
  Connect-compatible identity provider to be used for authentication

After you integrate one of these, learn more about accessing authentication
information in [Functions](/auth/functions-auth.mdx) and storing user
information in the [Database](/auth/database-auth.mdx).

## Convex Auth

For client-side React and React Native mobile apps you can implement auth
directly in Convex with the [Convex Auth](/auth/convex-auth.mdx) library. This
[npm package](https://github.com/get-convex/convex-auth) runs on your Convex
deployment and helps you build a custom sign-up/sign-in flow via social identity
providers, one-time email or SMS access codes, or via passwords.

Convex Auth is in beta (it isn't complete and may change in
backward-incompatible ways) and doesn't provide as many features as third party
auth integrations. Since it doesn't require signing up for another service it's
the quickest way to get auth up and running.

<BetaAdmonition feature="Convex Auth" verb="is" />

Support for Next.js is under active development. If you'd like to help test this
experimental support please [give it a try](https://labs.convex.dev/auth)!

## Debugging

If you run into issues consult the [Debugging](/auth/debug.mdx) guide.

## Service Authentication

Servers you control or third party services can call Convex functions but may
not be able to obtain OpenID JWTs and often do not represent the actions of a
specific user.

Say you're running some inference on a [Modal](https://modal.com/) server
written in Python. When that server subscribes to a Convex query it doesn't do
so with credentials of a particular end-user, rather it's looking for relevant
tasks for any users that need that inference task, say summarizing and
translating a conversation, completed.

To provide access to Convex queries, mutations, and actions to an external
service you can write public functions accessible to the internet that check a
shared secret, for example from an environment variable, before doing anything
else.

## Authorization

Convex enables a traditional three tier application structure. You have your
client/UI for your app, and a backend server that handles user requests, and a
database that the backend queries. This architecture let's you check every
public request against any authorization rules you can define in code.

Thus Convex does not need an opinionated authorization framework like RLS, which
is required in client oriented databases like Firebase or Supabase. This
flexibility lets you build and use an
[authorization framework](https://en.wikipedia.org/wiki/Authorization) for your
needs.

That said, the most common way is to simply write code that checks if the user
is logged in and if they are allowed to do the requested action at the beginning
of your public function.

For example, the following function enforces that only the currently
authenticated user can remove their own user image:

```typescript
export const removeUserImage = mutation({
  args: {},
  handler: async (ctx) => {
    // highlight-next-line
    const userId = await getAuthUserId(ctx);
    // highlight-next-line
    if (!userId) {
      // highlight-next-line
      return;
      // highlight-next-line
    }
    ctx.db.patch(userId, { imageId: undefined, image: undefined });
  },
});
```

<StackPosts query="authentication" />


---

# local-deployments-for-dev.mdx

<!-- Source: cli/local-deployments-for-dev.mdx -->

---
title: "Local Deployments for Development"
slug: "local-deployments"
sidebar_label: "Local Deployments"
---

Instead of syncing code to a Convex dev deployment hosted in the cloud, you can
develop against a deployment running on your own computer. You can even use the
Convex dashboard with local deployments!

## Background on deployments in Convex

Each Convex deployment contains its own data, functions, scheduled functions,
etc. A project has one production deployment, up to one cloud deployment for
development per team member, and potentially many transient
[preview deployments](/production/hosting/preview-deployments.mdx).

You can also develop with Convex using a deployment running on your own machine.
Since the deployment is running locally, code sync is faster and means resources
like functions calls and database bandwidth don't count against
[the quotas for your Convex plan](https://www.convex.dev/pricing).

You can use local deployments with an existing Convex project, and view your
deployment in the Convex dashboard under your project. You can also use local
deployments without a Convex account and debug and inspect them with a locally
running version of the Convex dashboard.

## Using local deployments

<BetaAdmonition feature="Local deployments" verb="are" />

While using local deployments, the local Convex backend runs as a subprocess of
the `npx convex dev` command and exits when that command is stopped. This means
a `convex dev` command must be running in order to run other commands like
`npx convex run` against this local deployment or for your frontend to connect
to this deployment.

State for local backends is stored the `~/.convex/` directory.

### Anonymous development

You can use local deployments to develop with Convex without having to create an
account. Whenever you want to create an account to deploy your app to production
or to use more Convex features, you can use `npx convex login` to link your
local deployments with your account.

### Local deployments for an existing project

To use a local deployment for an existing project, run:

```sh
npx convex dev --local --once
```

You'll also always be given the option for a local deployment if you run
`npx convex dev --configure`. Other flows may assume you want a cloud deployment
in some situations, for example when connecting to a project for which you
already have a cloud development deployment.

## Local deployments vs. production

Local deployments are not recommended for production use: they're development
deployments, i.e. logs for function results and full stack traces for error
responses are sent to connected clients.

For running a production application, you can use a production deployment hosted
on the Convex cloud. Learn more about deploying to production
[here](/production.mdx).

Alternatively, you can self-host a production deployment using the
[open source convex-backend repo](https://github.com/get-convex/convex-backend).

### Disabling

To stop using local developments for a project, run the following:

```sh
npx convex disable-local-deployments
```

Remember your cloud dev deployment and each local dev deployment are completely
separate, so contain different data. When switching between deployments you may
wish to [export and re-import](/database/import-export/import-export.mdx) the
data to keep using it.

## Limitations

- **No Public URL** - Cloud deployments have public URL to receive incoming HTTP
  requests from services like Twilio, but local deployments listen for HTTP
  requests on your own computer. Similarly, you can't power websites with Convex
  WebSocket connections unless your users browsers know how to reach your
  computer. Set up a proxy like ngrok or use a cloud deployment for these uses
  cases.

- **Node actions require specific Node.js versions** - Running Node.js actions
  (actions defined in files with `"use node;"`) requires having Node.js 18
  installed, since this is the version of Node.js used in production when
  Node.js actions run in AWS Lambda functions. To resolve this you can install
  and set up [nvm](https://github.com/nvm-sh/nvm) and then install Node.js
  version 18. You don't need to use Node.js 18 for the rest of your project.

- **Node.js actions run directly on your computer** - Like a normal Node.js
  server, code running in Node.js actions has unrestricted filesystem access.
  Queries, mutations, and Convex runtime actions still run in isolated
  environments.

- Logs get cleared out every time a `npx convex dev` command is restarted.


---

# cli.md

<!-- Source: cli.md -->

---
title: "CLI"
sidebar_position: 110
slug: "cli"
---

The Convex command-line interface (CLI) is your interface for managing Convex
projects and Convex functions.

To install the CLI, run:

```sh
npm install convex
```

You can view the full list of commands with:

```sh
npx convex
```

## Configure

### Create a new project

The first time you run

```sh
npx convex dev
```

it will ask you to log in your device and create a new Convex project. It will
then create:

1. The `convex/` directory: This is the home for your query and mutation
   functions.
2. `.env.local` with `CONVEX_DEPLOYMENT` variable: This is the main
   configuration for your Convex project. It is the name of your development
   deployment.

### Recreate project configuration

Run

```sh
npx convex dev
```

in a project directory without a set `CONVEX_DEPLOYMENT` to configure a new or
existing project.

### Log out

```sh
npx convex logout
```

Remove the existing Convex credentials from your device, so subsequent commands
like `npx convex dev` can use a different Convex account.

## Develop

### Run the Convex dev server

```sh
npx convex dev
```

Watches the local filesystem. When you change a [function](/functions.mdx) or
the [schema](/database/schemas.mdx), the new versions are pushed to your dev
deployment and the [generated types](/generated-api/) in `convex/_generated` are
updated. By default, logs from your dev deployment are displayed in the
terminal.

It's also possible to
[run a Convex deployment locally](/cli/local-deployments-for-dev.mdx) for
development.

### Open the dashboard

```sh
npx convex dashboard
```

Open the [Convex dashboard](./dashboard).

### Open the docs

```sh
npx convex docs
```

Get back to these docs!

### Run Convex functions

```sh
npx convex run <functionName> [args]
```

Run a public or internal Convex query, mutation, or action on your development
deployment.

Arguments are specified as a JSON object.

```sh
npx convex run messages:send '{"body": "hello", "author": "me"}'
```

Add `--watch` to live update the results of a query. Add `--push` to push local
code to the deployment before running the function.

Use `--prod` to run functions in the production deployment for a project.

### Tail deployment logs

You can choose how to pipe logs from your dev deployment to your console:

```sh
# Show all logs continuously
npx convex dev --tail-logs always

# Pause logs during deploys to see sync issues (default)
npx convex dev

# Don't display logs while developing
npx convex dev --tail-logs disable

# Tail logs without deploying
npx convex logs
```

Use `--prod` with `npx convex logs` to tail the prod deployment logs instead.

### Import data from a file

```sh
npx convex import --table <tableName> <path>
npx convex import <path>.zip
```

See description and use-cases:
[data import](/database/import-export/import.mdx).

### Export data to a file

```sh
npx convex export --path <directoryPath>
npx convex export --path <filePath>.zip
npx convex export --include-file-storage --path <path>
```

See description and use-cases:
[data export](/database/import-export/export.mdx).

### Display data from tables

```sh
npx convex data  # lists tables
npx convex data <table>
```

Display a simple view of the
[dashboard data page](/dashboard/deployments/data.md) in the command line.

The command supports `--limit` and `--order` flags to change data displayed. For
more complex filters, use the dashboard data page or write a
[query](/database/reading-data/reading-data.mdx).

The `npx convex data <table>` command works with
[system tables](/database/advanced/system-tables.mdx), such as `_storage`, in
addition to your own tables.

### Read and write environment variables

```sh
npx convex env list
npx convex env get <name>
npx convex env set <name> <value>
npx convex env remove <name>
```

See and update the deployment environment variables which you can otherwise
manage on the dashboard
[environment variables settings page](/dashboard/deployments/settings.md#environment-variables).

## Deploy

### Deploy Convex functions to production

```sh
npx convex deploy
```

The target deployment to push to is determined like this:

1. If the `CONVEX_DEPLOY_KEY` environment variable is set (typical in CI), then
   it is the deployment associated with that key.
2. If the `CONVEX_DEPLOYMENT` environment variable is set (typical during local
   development), then the target deployment is the production deployment of the
   project that the deployment specified by `CONVEX_DEPLOYMENT` belongs to. This
   allows you to deploy to your prod deployment while developing against your
   dev deployment.

This command will:

1. Run a command if specified with `--cmd`. The command will have CONVEX_URL (or
   similar) environment variable available:
   ```sh
   npx convex deploy --cmd "npm run build"
   ```
   You can customize the URL environment variable name with
   `--cmd-url-env-var-name`:
   ```sh
   npx convex deploy --cmd 'npm run build' --cmd-url-env-var-name CUSTOM_CONVEX_URL
   ```
1. Typecheck your Convex functions.
1. Regenerate the [generated code](/generated-api/) in the `convex/_generated`
   directory.
1. Bundle your Convex functions and their dependencies.
1. Push your functions, [indexes](/database/reading-data/indexes/indexes.md),
   and [schema](/database/schemas.mdx) to production.

Once this command succeeds the new functions will be available immediately.

### Deploy Convex functions to a [preview deployment](/production/hosting/preview-deployments.mdx)

```sh
npx convex deploy
```

When run with the `CONVEX_DEPLOY_KEY` environment variable containing a Preview
Deploy Key, this command will:

1. Create a deployment with the specified name. `npx convex deploy` will infer
   the Git branch name for Vercel, Netlify, GitHub, and GitLab environments, but
   the `--preview-create` option can be used to customize the name associated
   with the newly created deployment.
   ```
   npx convex deploy --preview-create my-branch-name
   ```
1. Run a command if specified with `--cmd`. The command will have CONVEX_URL (or
   similar) environment variable available:

   ```sh
   npx convex deploy --cmd "npm run build"
   ```

   You can customize the URL environment variable name with
   `--cmd-url-env-var-name`:

   ```sh
   npx convex deploy --cmd 'npm run build' --cmd-url-env-var-name CUSTOM_CONVEX_URL
   ```

1. Typecheck your Convex functions.
1. Regenerate the [generated code](/generated-api/) in the `convex/_generated`
   directory.
1. Bundle your Convex functions and their dependencies.
1. Push your functions, [indexes](/database/reading-data/indexes/indexes.md),
   and [schema](/database/schemas.mdx) to the deployment.
1. Run a function specified by `--preview-run` (similar to the `--run` option
   for `npx convex dev`).

   ```sh
   npx convex deploy --preview-run myFunction
   ```

See the [Vercel](/production/hosting/vercel.mdx#preview-deployments) or
[Netlify](/production/hosting/netlify.mdx#deploy-previews) hosting guide for
setting up frontend and backend previews together.

### Update generated code

```sh
npx convex codegen
```

Update the [generated code](/generated-api/) in `convex/_generated` without
pushing. This can be useful for orchestrating build steps in CI.


---

# data-types.md

<!-- Source: client/android/data-types.md -->

---
title: "Kotlin and Convex type conversion"
sidebar_label: "Data Types"
hidden: false
sidebar_position: 5
description:
  "Customizing and converting types between the Kotlin app and Convex"
---

## Custom data types

When receiving values from Convex, you aren't limited to primitive values. You
can create custom `@Serializable` classes that will be automatically decoded
from response data.

Consider a Convex query function that returns results like this JavaScript
object:

```jsx
{
	name: "Guardians",
	uniformColors: ["blue", "white", "red"],
	wins: 80n,
	losses: 60n
}
```

That can be represented in Kotlin using:

```kotlin
@Serializable
data class BaseballTeam(
    val name: String,
    val uniformColors: List<String>,
    val wins: @ConvexNum Int,
    val losses: @ConvexNum Int)
```

Then you can pass it as the type argument in your `subscribe` call:

```kotlin
convex.subscribe<Team>("mlb:first_place_team", args = mapOf("division" to "AL Central"))
```

The data from the remote function will be deserialized to your custom class.

## Numerical types

Your Convex backend code is written in JavaScript, which has two relatively
common types for numerical data: `number` and `BigInt`.

`number` is used whenever a value is assigned a literal numeric value, whether
`42` or `3.14`. `BigInt` can be used by adding a trailing `n`, like `42n`.
Despite the two types, is very common to use `number` for holding either integer
or floating point values in JavaScript.

Because of this, Convex takes extra care to encode values so they won't lose
precision. Since technically the `number` type is an IEEE 754 floating point
value, anytime you get a plain `number` from Convex it will be represented as
floating point in Kotlin. You can choose to use `Double` or `Float`, depending
on your needs but be aware that `Float` might lose precision from the original.

It also means that Kotlin's `Long` type (64 bit) can't be safely stored in a
`number` (only 53 bits are available to encode integers) and requires a
`BigInt`.

That's a long lead up to explain that in order to represent numerical values in
responses from Convex, you need to hint to Kotlin that they should use custom
decoding.

You can do this in three ways. Use whichever seems most useful to your project.

1. Annotate the plain Kotlin type (`Int`, `Long`, `Float`, `Double`) with
   `@ConvexNum`
2. Use a provided type alias for those types (`Int32`, `Int64`, `Float32`,
   `Float64`)
3. Include a special annotation at the top of any file that defines
   `@Serializable` classes and just use the plain types with no annotation

   ```kotlin
   @file:UseSerializers(
       Int64ToIntDecoder::class,
       Int64ToLongDecoder::class,
       Float64ToFloatDecoder::class,
       Float64ToDoubleDecoder::class
   )

   package com.example.convexapp

   import kotlinx.serialization.UseSerializers

   // @Serializable classes and things.
   ```

In the example, JavaScript's `BigInt` type is used by adding a trailing `n` to
the `wins` and `losses` values which lets the Kotlin code use `Int`. If instead
the code used regular JavaScript `number` types, on the Kotlin side those would
be received as floating point values and deserialization would fail.

If you have a situation like that where `number` is used but by convention only
contains integer values, you can handle that in your `@Serializable` class.

```kotlin
@Serializable
data class BaseballTeam(
    val name: String,
    val uniformColors: List<String>,
    @SerialName("wins") private val internalWins: Double,
    @SerialName("losses") private val internalLosses: Double) {

    // Expose the JavaScript number values as Ints.
    val wins get() = internalWins.toInt()
    val losses get() = internalLosses.toInt()
}
```

The pattern is to store the `Double` values privately and with different names
that the value from the backend. Then add accessors to provide the `Int` values.

## Field name conversion

This pattern was used above, but it bears describing on its own. Sometimes a
value will be produced on the backend with a key that matches a Kotlin keyword
(`{fun: true}`) or doesn't conform to Kotlin naming conventions (e.g. starts
with an underscore). You can use `@SerialName` to handle those cases.

For example, here's how you can ingest the Convex
[document ID](https://docs.convex.dev/database/document-ids) from a backend
response and convert it to a field name that won't trigger Kotlin lint warnings:

```kotlin
@Serializable
data class ConvexDocument(@SerialName("_id") val id: String)
```


---

# android.md

<!-- Source: client/android.md -->

---
title: "Android Kotlin"
sidebar_label: "Android Kotlin"
sidebar_position: 600
---

Convex Android client library enables your Android application to interact with
your Convex backend. It allows your frontend code to:

1. Call
   your [queries](/functions/query-functions.mdx), [mutations](/functions/mutation-functions.mdx) and [actions](/functions/actions.mdx)
2. Authenticate users using [Auth0](/auth/auth0.mdx)

The library is open source and
[available on GitHub](https://github.com/get-convex/convex-mobile/tree/main/android).

Follow the [Android Quickstart](/quickstart/android.mdx) to get started.

## Installation

You'll need to make the following changes to your app's `build.gradle[.kts]`
file.

```kotlin
plugins {
    // ... existing plugins
    kotlin("plugin.serialization") version "1.9.0"
}

dependencies {
    // ... existing dependencies
    implementation("dev.convex:android-convexmobile:0.4.1@aar") {
        isTransitive = true
    }
    implementation("org.jetbrains.kotlinx:kotlinx-serialization-json:1.6.3")
}
```

After that, sync Gradle to pick up those changes. Your app will now have access
to the Convex for Android library as well as Kotlin's JSON serialization which
is used to communicate between your code and the Convex backend.

## Connecting to a backend

The `ConvexClient` is used to establish and maintain a connect between your
application and the Convex backend. First you need to create an instance of the
client by giving it your backend deployment URL:

```kotlin
package com.example.convexapp

import dev.convex.android.ConvexClient

val convex = ConvexClient("https://<your domain here>.convex.cloud")
```

You should create and use one instance of the `ConvexClient` for the lifetime of
your application process. It can be convenient to create a custom Android
[`Application`](https://developer.android.com/reference/android/app/Application)
subclass and initialize it there:

```kotlin
package com.example.convexapp

import android.app.Application
import dev.convex.android.ConvexClient

class MyApplication : Application() {
    lateinit var convex: ConvexClient

    override fun onCreate() {
        super.onCreate()
        convex = ConvexClient("https://<your domain here>.convex.cloud")
    }
}
```

Once you've done that, you can access the client from a Jetpack Compose
`@Composable` function like this:

```kotlin
val convex = (application as MyApplication).convex
```

## Fetching data

Convex for Android gives you access to the Convex
[reactor](https://docs.convex.dev/tutorial/reactor), which enables real-time
_subscriptions_ to query results. You subscribe to queries with the `subscribe`
method on `ConvexClient` which returns a `Flow`. The contents of the `Flow` will
change over time as the underlying data backing the query changes.

All methods on `ConvexClient` suspend, and need to be called from a
`CoroutineScope` or another `suspend` function. A simple way to consume a query
that returns a list of strings from a `@Composable` is to use a combination of
mutable state containing a list and `LaunchedEffect`:

```kotlin
var workouts: List<String> by remember { mutableStateOf(listOf()) }
LaunchedEffect("onLaunch") {
    client.subscribe<List<String>>("workouts:get").collect { result ->
        result.onSuccess { receivedWorkouts ->
            workouts = receivedWorkouts
        }
    }
}
```

Any time the data that powers the backend `"workouts:get"` query changes, a new
`Result<List<String>>` will be emitted into the `Flow` and the `workouts` list
will refresh with the new data. Any UI that uses `workouts` will then rebuild,
giving you a fully reactive UI.

Note: you may prefer to put the subscription logic wrapped a Repository as
described in the
[Android architecture patterns](https://developer.android.com/topic/architecture/data-layer).

### Query arguments

You can pass arguments to `subscribe` and they will be supplied to the
associated backend `query` function. The arguments are typed as
`Map<String, Any?>`. The values in the map must be primitive values or other
maps and lists.

```kotlin
val favoriteColors = mapOf("favoriteColors" to listOf("blue", "red"))
client.subscribe<List<String>>("users:list", args = favoriteColors)
```

Assuming a backend query that accepts a `favoriteColors` argument, the value can
be received and used to perform logic in the query function.

<Admonition type="tip">
Use serializable [Kotlin Data classes](/client/android/data-types.md#custom-data-types)
to automatically convert Convex objects to Kotlin model classes.
</Admonition>

<Admonition type="caution">
* There are important gotchas when
  [sending and receiving numbers](/client/android/data-types.md#numerical-types)
  between Kotlin and Convex.
* `_` is a used to signify private fields in Kotlin. If you want to use a
  `_creationTime` and `_id` Convex fields directly without warnings you'll have
  to
  [convert the field name in Kotlin](/client/android/data-types.md#field-name-conversion).
* Depending on your backend functions, you may need to deal with
  [reserved Kotlin keywords](/client/android/data-types.md#field-name-conversion).
</Admonition>

### Subscription lifetime

The `Flow` returned from `subscribe` will persist as long as something is
waiting to consume results from it. When a `@Composable` or `ViewModel` with a
subscription goes out of scope, the underlying query subscription to Convex will
be canceled.

## Editing data

You can use the `mutation` method on `ConvexClient` to trigger a backend
[mutation](https://docs.convex.dev/functions/mutation-functions).

You'll need to use it in another `suspend` function or a `CoroutineScope`.
Mutations can return a value or not. If you expect a type in the response,
indicate it in the call signature.

Mutations can also receive arguments, just like queries. Here's an example of
returning a type from a mutation with arguments:

```kotlin
val recordsDeleted = convex.mutation<@ConvexNum Int>(
  "messages:cleanup",
  args = mapOf("keepLatest" to 100)
)
```

If an error occurs during a call to `mutation`, it will throw an exception.
Typically you may want to catch
[`ConvexError`](https://docs.convex.dev/functions/error-handling/application-errors)
and `ServerError` and handle them however is appropriate in your application.
See documentation on
[error handling](https://docs.convex.dev/functions/error-handling/) for more
details.

## Calling third-party APIs

You can use the `action` method on `ConvexClient` to trigger a backend
[action](https://docs.convex.dev/functions/actions).

Calls to `action` can accept arguments, return values and throw exceptions just
like calls to `mutation`.

Even though you can call actions from Android, it's not always the right choice.
See the action docs for tips on
[calling actions from clients](https://docs.convex.dev/functions/actions#calling-actions-from-clients).

## Authentication with Auth0

You can use `ConvexClientWithAuth` in place of `ConvexClient` to configure
authentication with [Auth0](https://auth0.com/). You'll need the
`convex-android-auth0` library to do that, as well as an Auth0 account and
application configuration.

See the
[README](https://github.com/get-convex/convex-android-auth0/blob/main/README.md)
in the `convex-android-auth0` repo for more detailed setup instructions, and the
[Workout example app](https://github.com/get-convex/android-convex-workout)
which is configured for Auth0. The overall
[Convex authentication docs](https://docs.convex.dev/auth) are a good resource
as well.

It should also be possible to integrate other similar OpenID Connect
authentication providers. See the
[`AuthProvider`](https://github.com/get-convex/convex-mobile/blob/5babd583631a7ff6d739e1a2ab542039fd532548/android/convexmobile/src/main/java/dev/convex/android/ConvexClient.kt#L291)
interface in the `convex-mobile` repo for more info.

## Production and dev deployments

When you're ready to move toward
[production](https://docs.convex.dev/production) for your app, you can setup
your Android build system to point different builds or flavors of your
application to different Convex deployments. One fairly simple way to do it is
by passing different values (e.g. deployment URL) to different build targets or
flavors.

Here's a simple example that shows using different deployment URLs for release
and debug builds:

```kotlin
// In the android section of build.gradle.kts:
buildTypes {
    release {
        // Snip various other config like ProGuard ...
        resValue("string", "convex_url", "YOUR_PROD.convex.cloud")
    }

    debug {
        resValue("string", "convex_url", "YOUR_DEV.convex.cloud")
    }
}
```

Then you can build your `ConvexClient` using a single resource in code, and it
will get the right value at compile time.

```kotlin
val convex = ConvexClient(context.getString(R.string.convex_url))
```

<Admonition type="tip">
You may not want these urls checked into your repository. One pattern is to 
create a custom `my_app.properties` file that is configured to be ignored in
your `.gitignore` file. You can then read this file in your `build.gradle.kts` 
file. You can see this pattern in use in the
[workout sample app](https://github.com/get-convex/android-convex-workout?tab=readme-ov-file#configuration).
</Admonition>

## Structuring your application

The examples shown in this guide are intended to be brief, and don't provide
guidance on how to structure a whole application.

The official
[Android application architecture](https://developer.android.com/topic/architecture/intro)
docs cover best practices for building applications, and Convex also has a
[sample open source application](https://github.com/get-convex/android-convex-workout/tree/main)
that attempts to demonstrate what a small multi-screen application might look
like.

In general, do the following:

1. Embrace Flows and
   [unidirectional data flow](https://developer.android.com/develop/ui/compose/architecture#udf)
2. Have a clear
   [data layer](https://developer.android.com/topic/architecture/data-layer)
   (use Repository classes with `ConvexClient` as your data source)
3. Hold UI state in a
   [ViewModel](https://developer.android.com/topic/architecture/recommendations#viewmodel)

## Testing

`ConvexClient` is an `open` class so it can be mocked or faked in unit tests. If
you want to use more of the real client, you can pass a fake
`MobileConvexClientInterface` in to the `ConvexClient` constructor. Just be
aware that you'll need to provide JSON in Convex's undocumented
[JSON format](https://github.com/get-convex/convex-mobile/blob/5babd583631a7ff6d739e1a2ab542039fd532548/android/convexmobile/src/main/java/dev/convex/android/jsonhelpers.kt#L47).

You can also use the full `ConvexClient` in Android instrumentation tests. You
can setup a special backend instance for testing or run a local Convex server
and run full integration tests.

## Under the hood

Convex for Android is built on top of the official
[Convex Rust client](https://docs.convex.dev/client/rust). It handles
maintaining a WebSocket connection with the Convex backend and implements the
full Convex protocol.

All method calls on `ConvexClient` are handled via a Tokio async runtime on the
Rust side and are safe to call from the application's main thread.

`ConvexClient` also makes heavy use of
[Kotlin's serialization framework](https://github.com/Kotlin/kotlinx.serialization/blob/master/docs/serialization-guide.md),
and most of the functionality in that framework is available for you to use in
your applications. Internally, `ConvexClient` enables the JSON
[`ignoreUnknownKeys`](https://github.com/Kotlin/kotlinx.serialization/blob/master/docs/json.md#ignoring-unknown-keys)
and
[`allowSpecialFloatingPointValues`](https://github.com/Kotlin/kotlinx.serialization/blob/master/docs/json.md#allowing-special-floating-point-values)
features.


---

# bun.mdx

<!-- Source: client/javascript/bun.mdx -->

---
title: "Bun"
hidden: false
sidebar_position: 200
---

[Bun](https://bun.sh/) can be used to run scripts and servers that use Convex
clients and can even run the Convex CLI.

Convex supports point-in-time queries, mutations and actions (see
[HTTP client](/api/classes/browser.ConvexHttpClient)) and those plus query
subscriptions (see [ConvexClient](/api/classes/browser.ConvexClient)) in Bun.

```js
import { ConvexHttpClient, ConvexClient } from "convex/browser";
import { api } from "./convex/_generated/api.js";

// HTTP client
const httpClient = new ConvexHttpClient(process.env.CONVEX_URL);
httpClient.query(api.messages.list).then((messages) => {
  console.log(messages);
});

// Subscription client
const client = new ConvexClient(process.env.CONVEX_URL);
const unsubscribe = client.onUpdate(api.messages.list, {}, (messages) =>
  console.log(messages),
);
await Bun.sleep(1000);
client.mutate(api.messages.send, {}, { body: "hello!", author: "me" });
await Bun.sleep(1000);
```

## Using Convex with Bun without codegen

You can always use the `anyApi` object or strings if you don't have the Convex
functions and api file handy. An api reference like `api.folder.file.exportName`
becomes `anyApi.folder.file.exportName` or `"folder/file:exportName"`.


---

# node.mdx

<!-- Source: client/javascript/node.mdx -->

---
title: "Node.js"
hidden: false
sidebar_position: 100
---

Convex supports point-in-time queries (see
[HTTP client](/api/classes/browser.ConvexHttpClient)) and query subscriptions
(see [ConvexClient](/api/classes/browser.ConvexClient)) in Node.js.

If your JavaScript code uses import/export syntax, calling Convex functions
works just like in a browser.

```js
import { ConvexHttpClient, ConvexClient } from "convex/browser";
import { api } from "./convex/_generated/api.js";

// HTTP client
const httpClient = new ConvexHttpClient(CONVEX_URL_GOES_HERE);
httpClient.query(api.messages.list).then(console.log);

// Subscription client
const client = new ConvexClient(CONVEX_URL_GOES_HERE);
client.onUpdate(api.messages.list, {}, (messages) => console.log(messages));
```

## TypeScript

Just like bundling for the browser, bundling TypeScript code for Node.js with
webpack, esbuild, rollup, vite, and others usually allow you import from code
that uses import/export syntax with no extra setup.

If you use TypeScript to _compile_ your code (this is rare for web projects but
more common with Node.js), add `"allowJs": true` to `tsconfig.json` compiler
options so that TypeScript will compile the `api.js` file as well.

## TypeScript without a compile step

If you want to run your TypeScript script directly without a compile step,
installing [ts-node-esm](https://www.npmjs.com/package/ts-node) and running your
script with ts-node-esm should work if you use `"type": "module"` in your
`package.json`.

## JavaScript with CommonJS (`require()` syntax)

If you don't use `"type": "module"` in the `package.json` of your project you'll
need to use `require()` syntax and Node.js will not be able to import the
`convex/_generated/api.js` file directly.

In the same directory as your `package.json`, create or edit
[`convex.json`](/production/project-configuration.mdx#convexjson):

```json title=convex.json
{
  "generateCommonJSApi": true
}
```

When the `convex dev` command generates files in `convex/_generated/` a new
`api_cjs.cjs` file will be created which can be imported from CommonJS code.

```js
const { ConvexHttpClient, ConvexClient } = require("convex/browser");
const { api } = require("./convex/_generated/api_cjs.cjs");
const httpClient = new ConvexHttpClient(CONVEX_URL_GOES_HERE);
```

## TypeScript with CommonJS without a compile step

Follow the steps above for CommonJS and use
[`ts-node`](https://www.npmjs.com/package/ts-node) to run you code. Be sure your
`tsconfig.json` is configured for CommonJS output.

## Using Convex with Node.js without codegen

You can always use the `anyApi` object or strings if you don't have the Convex
functions and api file handy. An api reference like `api.folder.file.exportName`
becomes `anyApi.folder.file.exportName` or `"folder/file:exportName"`.


---

# script-tag.mdx

<!-- Source: client/javascript/script-tag.mdx -->

---
title: "Script Tag"
sidebar_position: 100
---

Sometimes you just want to get your data on a web page: no installing packages,
no build steps, no TypeScript. Subscribing to queries deployed to an existing
Convex deployment from a script tag is simple.

import simpleHtml from "!!raw-loader!@site/../demos/html/simple.html";
import typedHtml from "!!raw-loader!@site/../demos/html/typed-example.html";
import script from "!!raw-loader!@site/../demos/html/script.js";

<Snippet
  source={simpleHtml}
  title="index.html"
  replacements={[[/https?:\/\/localhost:8000/g, "CONVEX_URL_GOES_HERE"]]}
/>

VS Code doesn't support TypeScript autocompletion in HTML files so for types and
better autocompletion you can split your code out into a script file:

<Snippet
  source={typedHtml}
  title="index.html"
  replacements={[[/https?:\/\/localhost:8000/g, "CONVEX_URL_GOES_HERE"]]}
/>
<Snippet
  source={script}
  title="script.js"
  replacements={[[/https?:\/\/localhost:8000/g, "CONVEX_URL_GOES_HERE"]]}
/>

See the [Script Tag Quickstart](/quickstart/script-tag.mdx) for instructions for
setting up a new Convex project.


---

# javascript.mdx

<!-- Source: client/javascript.mdx -->

---
title: "JavaScript"
sidebar_label: "JavaScript"
sidebar_position: 350
---

import Http from "!!raw-loader!@site/../private-demos/snippets/src/vanilla.ts";

# Convex JavaScript Clients

Convex applications can be accessed from Node.js or any JavaScript runtime that
implements [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/fetch) or
[`WebSocket`](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket). The
reactive [Convex Client](/api/classes/browser.ConvexClient) allows web
applications and long-running Node.js servers to subscribe to updates on Convex
queries, while the [Convex HTTP client](/api/classes/browser.ConvexHttpClient)
is typically used for server-side rendering, migrations, administrative scripts,
and serverless functions to run queries at a single point in time.

If you're using React, see the dedicated
[`ConvexReactClient`](/api/classes/browser.ConvexClient) described in
[React](/client/react.mdx).

## Convex Client

The [`ConvexClient`](/api/classes/browser.ConvexClient) provides subscriptions
to queries in Node.js and any JavaScript environment that supports WebSockets.

import VanillaTS from "!!raw-loader!@site/../private-demos/snippets/src/vanilla.ts";
import VanillaJS from "!!raw-loader!@site/../private-demos/snippets/src/vanilla.js";

<TSAndJSSnippet title="script.ts" sourceTS={VanillaTS} sourceJS={VanillaJS} />

The Convex client is open source and available on
[GitHub](https://github.com/get-convex/convex-js).

See the [Script Tag Quickstart](/quickstart/script-tag.mdx) to get started.

## HTTP client

import Example from "!!raw-loader!@site/../private-demos/snippets/nodeExample.ts";

The [`ConvexHttpClient`](/api/classes/browser.ConvexHttpClient) works in the
browser, Node.js, and any JavaScript environment with `fetch`.

See the [Node.js Quickstart](/quickstart/nodejs.mdx).

<TSAndJSSnippet title="script.ts" sourceTS={Example} sourceJS={Example} />

## Using Convex without generated `convex/_generated/api.js`

If the source code for your Convex function isn't located in the same project or
in the same monorepos you can use the untyped `api` object called `anyApi`.

import StringsTS from "!!raw-loader!@site/../private-demos/snippets/src/strings.ts";
import StringsJS from "!!raw-loader!@site/../private-demos/snippets/src/strings.js";

<TSAndJSSnippet title="script.ts" sourceTS={StringsTS} sourceJS={StringsJS} />


---

# open-api.mdx

<!-- Source: client/open-api.mdx -->

---
title: "OpenAPI & Other Languages"
sidebar_label: "OpenAPI"
sidebar_position: 325
---

import Load from "!!raw-loader!@site/../private-demos/snippets/convex/goClientExample.ts";
import Go from "!!raw-loader!@site/../private-demos/snippets/goExample.txt";

Convex doesn’t have explicit support for many languages including Go, Java, and
C++. However, you can generate [OpenAPI](https://swagger.io/specification/)
specifications from your Convex deployment to create type-safe clients for
languages that aren't currently supported. Under the hood, this uses our
[HTTP API](/http-api). This means that your queries will not be
reactive/real-time.

<BetaAdmonition feature="OAS generation" verb="is" />

## Setup

<StepByStep>
  <Step title="Install the Convex Helpers npm package">
    Install the `convex-helpers` package, which contains a CLI command to generate an Open API specification.

    ```sh
    npm install convex-helpers
    ```

  </Step>
  <Step title="Run a command to generate an OpenAPI specification">
    Running this command will call into your configured Convex deployment and generate an `convex-spec.yaml` file based
    on it. You can see additional flags by passing `--help` to the command.

    ```sh
    npx convex-helpers open-api-spec
    ```

  </Step>
  <Step title="Generate a type-safe client">
    You can use a separate tools to generate a client from the `convex-spec.yaml` file. Some popular options are [OpenAPI Tools](https://github.com/OpenAPITools/openapi-generator) and [Swagger](https://swagger.io/tools/swagger-codegen/).
    ```yaml
    # convex-spec.yaml
    openapi: 3.0.3
    info:
      title: Convex App - OpenAPI 3.0
      version: 0.0.0
      servers:
        - url: "{hostUrl}"
      description: Convex App API
      ...
    ```
  </Step>
</StepByStep>

## Example

Below are code snippets of what this workflow looks like in action. These
snippets include two different files:

- `convex/load.ts` - contains Convex function definitions
- `convex.go` - contains `Go` code that uses a generated, type-safe `HTTP`
  client. This client was generated by installing the
  [OpenAPI Tools](https://github.com/OpenAPITools/openapi-generator) package and
  running the command
  `npx openapi-generator-cli generate -i convex-spec.yaml -g go -o convex_client`

<TSAndJSSnippet title="convex/load.ts" sourceTS={Load} sourceJS={Load} />

<Snippet source={Go} title="convex.go" />

## Limits

- Argument and return value validators are not required, but they will enrich
  the types of your OpenAPI spec. Where validators aren't defined, we default to
  `v.any()` as the validator.
- You cannot call internal functions from outside of your Convex deployment.
- We currently do not support `bigints` or `bytes`.


---

# python.md

<!-- Source: client/python.md -->

---
title: "Python"
sidebar_position: 400
---

See the [Python Quickstart](/quickstart/python.mdx) and the
<a href="https://pypi.org/project/convex/" target="_blank">convex PyPI package
docs</a>. The Python client is open source and available on
[GitHub](https://github.com/get-convex/convex-py).


---

# nextjs-server-rendering.mdx

<!-- Source: client/react/nextjs/nextjs-server-rendering.mdx -->

---
title: "Next.js Server Rendering"
slug: "server-rendering"
sidebar_label: "Server Rendering"
sidebar_position: 10
---

import PreloadQuery from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/TasksWrapper.tsx";
import AuthedPreloadQuery from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/AuthedTasksWrapper.tsx";
import UsePreloadedQueryTS from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/Tasks.tsx";
import UsePreloadedQueryJS from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/TasksJS.jsx";
import FetchQuery from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/StaticTasks.tsx";
import ServerActionTS from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/example/page.tsx";
import ServerActionJS from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/exampleJS/page.jsx";
import RouteHandlerTS from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/api/route.ts";
import RouteHandlerJS from "!!raw-loader!@site/../private-demos/nextjs-app-router-snippets/app/apiJS/route.js";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

Next.js automatically renders both Client and Server Components on the server
during the initial page load.

By default Client Components will not wait for Convex data to be loaded, and
your UI will render in a "loading" state. Read on to learn how to preload data
during server rendering and how to interact with the Convex deployment from
Next.js server-side.

**Example:**
[Next.js App Router](https://github.com/get-convex/convex-demos/tree/main/nextjs-app-router)

This pages covers the App Router variant of Next.js.

<BetaAdmonition feature="Next.js Server Rendering support" verb="is" />

## Preloading data for Client Components

If you want to preload data from Convex and leverage Next.js
[server rendering](https://nextjs.org/docs/app/building-your-application/rendering/server-components#server-rendering-strategies),
but still retain reactivity after the initial page load, use
[`preloadQuery`](/api/modules/nextjs#preloadquery) from
[`convex/nextjs`](/api/modules/nextjs).

In a
[Server Component](https://nextjs.org/docs/app/building-your-application/rendering/server-components)
call `preloadQuery`:

<TSAndJSSnippet
  title="app/TasksWrapper.tsx"
  sourceTS={PreloadQuery}
  sourceJS={PreloadQuery}
/>

In a
[Client Component](https://nextjs.org/docs/app/building-your-application/rendering/client-components)
call [`usePreloadedQuery`](/api/modules/react#usepreloadedquery):

<TSAndJSSnippet
  title="app/TasksWrapper.tsx"
  sourceTS={UsePreloadedQueryTS}
  sourceJS={UsePreloadedQueryJS}
/>

[`preloadQuery`](/api/modules/nextjs#preloadquery) takes three arguments:

1. The query reference
2. Optionally the arguments object passed to the query
3. Optionally a [NextjsOptions](/api/modules/nextjs#nextjsoptions) object

`preloadQuery` uses the
[`cache: 'no-store'` policy](https://nextjs.org/docs/app/building-your-application/data-fetching/fetching-caching-and-revalidating#opting-out-of-data-caching)
so any Server Components using it will not be eligible for
[static rendering](https://nextjs.org/docs/app/building-your-application/rendering/server-components#server-rendering-strategies).

### Using the query result

[`preloadQuery`](/api/modules/nextjs#preloadquery) returns an opaque `Preloaded`
payload that should be passed through to `usePreloadedQuery`. If you want to use
the return value of the query, perhaps to decide whether to even render the
Client Component, you can pass the `Preloaded` payload to the
[`preloadedQueryResult`](/api/modules/nextjs#preloadedqueryresult) function.

## Using Convex to render Server Components

If you need Convex data on the server, you can load data from Convex in your
[Server Components](https://nextjs.org/docs/app/building-your-application/data-fetching/fetching),
but it will be non-reactive. To do this, use the
[`fetchQuery`](/api/modules/nextjs#fetchquery) function from `convex/nextjs`:

<TSAndJSSnippet
  title="app/StaticTasks.tsx"
  sourceTS={FetchQuery}
  sourceJS={FetchQuery}
/>

## Server Actions and Route Handlers

Next.js supports building HTTP request handling routes, similar to Convex
[HTTP Actions](/functions/http-actions.mdx). You can use Convex from a
[Server Action](https://nextjs.org/docs/app/building-your-application/data-fetching/server-actions-and-mutations)
or a
[Route Handler](https://nextjs.org/docs/app/building-your-application/routing/route-handlers)
as you would any other database service.

To load and edit Convex data in your Server Action or Route Handler, you can use
the `fetchQuery`, `fetchMutation` and `fetchAction` functions.

Here's an example inline Server Action calling a Convex mutation:

<TSAndJSSnippet
  title="app/example/page.tsx"
  sourceTS={ServerActionTS}
  sourceJS={ServerActionJS}
/>

Here's an example Route Handler calling a Convex mutation:

<TSAndJSSnippet
  title="app/api/route.ts"
  sourceTS={RouteHandlerTS}
  sourceJS={RouteHandlerJS}
/>

## Server-side authentication

To make authenticated requests to Convex during server rendering, pass a JWT
token to [`preloadQuery`](/api/modules/nextjs#preloadquery) or
[`fetchQuery`](/api/modules/nextjs#fetchquery) in the third options argument:

<TSAndJSSnippet
  title="app/TasksWrapper.tsx"
  sourceTS={AuthedPreloadQuery}
  sourceJS={AuthedPreloadQuery}
  snippet="example"
/>

The implementation of `getAuthToken` depends on your authentication provider.

<Tabs>
<TabItem value="clerk" label="Clerk">
```ts title="app/auth.ts"
import { auth } from "@clerk/nextjs/server";

export async function getAuthToken() {
  return (await (await auth()).getToken({ template: "convex" })) ?? undefined;
}
```
</TabItem>
<TabItem value="auth0" label="Auth0">
```ts title="app/auth.ts"
// You'll need v4.3 or later of @auth0/nextjs-auth0
import { getSession } from '@auth0/nextjs-auth0';

export async function getAuthToken() {
  const session = await getSession();
  const idToken = session.tokenSet.idToken;
  return idToken;
}
```
</TabItem>
</Tabs>

## Configuring Convex deployment URL

Convex hooks used by Client Components are configured via the
`ConvexReactClient` constructor, as shown in the
[Next.js Quickstart](/quickstart/nextjs.mdx).

To use `preloadQuery`, `fetchQuery`, `fetchMutation` and `fetchAction` in Server
Components, Server Actions and Route Handlers you must either:

1. have `NEXT_PUBLIC_CONVEX_URL` environment variable set to the Convex
   deployment URL
2. or pass the [`url` option](/api/modules/nextjs#nextjsoptions) in the third
   argument to `preloadQuery`, `fetchQuery`, `fetchMutation` or `fetchAction`

## Consistency

[`preloadQuery`](/api/modules/nextjs#preloadquery) and
[`fetchQuery`](/api/modules/nextjs#fetchquery) use the `ConvexHTTPClient` under
the hood. This client is stateless. This means that two calls to `preloadQuery`
are not guaranteed to return consistent data based on the same database state.
This is similar to more traditional databases, but is different from the
[guaranteed consistency](/client/react.mdx#consistency) provided by the
`ConvexReactClient`.

To prevent rendering an inconsistent UI avoid using multiple `preloadQuery`
calls on the same page.


---

# nextjs.mdx

<!-- Source: client/react/nextjs/nextjs.mdx -->

---
title: "Next.js"
sidebar_label: "Next.js App Router"
sidebar_position: 200
description: "How Convex works in a Next.js app"
---

import Config from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir-14/app/_ConvexClientProviderAuth.tsx";

[Next.js](https://nextjs.org/) is a React web development framework. When used
with Convex, Next.js provides:

- File-system based routing
- Fast refresh in development
- Font and image optimization

and more!

This page covers the App Router variant of Next.js. Alternatively see the
[Pages Router](/client/react/nextjs-pages-router/nextjs-pages-router.mdx)
version of this page.

## Getting started

Follow the [Next.js Quickstart](/quickstart/nextjs.mdx) to add Convex to a new
or existing Next.js project.

## Adding authentication

### Client-side only

The simplest way to add user authentication to your Next.js app is to follow our
React-based authentication guides for [Clerk](/auth/clerk.mdx) or
[Auth0](/auth/auth0.mdx), inside your `app/ConvexClientProvider.tsx` file. For
example this is what the file would look like for Auth0:

<TSAndJSSnippet
  title="app/ConvexClientProvider.tsx"
  sourceTS={Config}
  sourceJS={Config}
/>

Custom loading and logged out views can be built with the helper
`Authenticated`, `Unauthenticated` and `AuthLoading` components from
`convex/react`, see the
[Convex Next.js demo](https://github.com/get-convex/convex-demos/tree/main/nextjs-pages-router/pages/_app.tsx)
for an example.

If only some routes of your app require login, the same helpers can be used
directly in page components that do require login instead of being shared
between all pages from `app/ConvexClientProvider.tsx`. Share a single
[ConvexReactClient](/api/classes/react.ConvexReactClient) instance between pages
to avoid needing to reconnect to Convex on client-side page navigation.

### Server and client side

To access user information or load Convex data requiring `ctx.auth` from Server
Components, Server Actions, or Route Handlers you need to use the Next.js
specific SDKs provided by Clerk and Auth0.

Additional `.env.local` configuration is needed for these hybrid SDKs.

#### Clerk

For an example of using Convex and with Next.js 15, run

<p>
  <b>
    <CodeWithCopyButton text="npm create convex@latest -- -t nextjs-clerk" />
  </b>
</p>

Otherwise, follow the
[Clerk Next.js quickstart](https://clerk.com/docs/quickstarts/nextjs), a guide
from Clerk that includes steps for adding `NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY`
and `CLERK_SECRET_KEY` to the .env.local file. In Next.js 15, the
`<ClerkProvider>` component imported from the `@clerk/nextjs` v6 package
functions as both a client and a server context provider so you probably won't
need the `ClerkProvider` from `@clerk/clerk-react`.

#### Auth0

See the
[Auth0 Next.js](https://auth0.com/docs/quickstart/webapp/nextjs/01-login) guide.

#### Other providers

Convex uses JWT identity tokens on the client for live query subscriptions and
running mutations and actions, and on the Next.js backend for running queries,
mutations, and actions in server components and API routes.

Obtain the appropriate OpenID Identity JWT in both locations and you should be
able to use any auth provider. See
[Custom Auth](https://docs.convex.dev/auth/advanced/custom-auth) for more.

## Server rendering (SSR)

Next.js automatically renders both Client and Server Components on the server
during the initial page load.

To keep your UI
[automatically reactive](/functions/query-functions.mdx#caching--reactivity--consistency)
to changes in your Convex database it needs to use Client Components. The
`ConvexReactClient` will maintain a connection to your deployment and will get
updates as data changes and that must happen on the client.

See the dedicated
[Server Rendering](/client/react/nextjs/nextjs-server-rendering.mdx) page for
more details about preloading data for Client Components, fetching data and
authentication in Server Components, and implementing Route Handlers.


---

# nextjs-pages-router.mdx

<!-- Source: client/react/nextjs-pages-router/nextjs-pages-router.mdx -->

---
title: "Next.js Pages Router"
slug: "nextjs-pages-router"
sidebar_position: 250
sidebar_label: "Next.js Pages Router"
---

import simpleAuthedAppTSX from "!!raw-loader!@site/../demos/nextjs-pages-router/pages/_simpleAuthedApp.tsx";
import apiTS from "!!raw-loader!@site/../demos/nextjs-pages-router/pages/api/clicks.ts";

This pages covers the Pages Router variant of Next.js. Alternatively see the
[App Router](/client/react/nextjs/nextjs.mdx) version of this page.

## Getting started

Follow the
[Next.js Pages Router Quickstart](/client/react/nextjs-pages-router/quickstart-nextjs-pages-router.mdx)
to add Convex to a new or existing Next.js project.

## Adding client-side authentication

The simplest approach to authentication in Next.js is to keep it client-side.

For example Auth0 describes this approach in
[Next.js Authentication with Auth0 guide](https://auth0.com/blog/ultimate-guide-nextjs-authentication-auth0),
describing it in
"[Next.js Static Site Approach](https://auth0.com/blog/ultimate-guide-nextjs-authentication-auth0/#Next-js-Static-Site-Approach)"
and "Serverless with the user on the frontend".

To require login on every page of your application you can add logic to
`_app.jsx` to conditionally render page content, blocking it until the user is
logged in.

If you're using Auth0, the helper component `ConvexProviderWithAuth0` can be
imported from `convex/react-auth0`.

<Snippet
  title="pages/_app.jsx"
  snippet="simpleAuthedApp"
  source={simpleAuthedAppTSX}
/>

Custom loading and logged out views can be built with the helper
`Authenticated`, `Unauthenticated` and `AuthLoading` components from
`convex/react`, see the
[Convex Next.js demo](https://github.com/get-convex/convex-demos/tree/main/nextjs-pages-router/pages/_app.jsx)
for an example.

If only some routes of your app require login, the same helpers can be used
directly in page components that do require login instead of being shared
between all pages from `pages/_app.jsx`. Share a single
[ConvexReactClient](/api/classes/react.ConvexReactClient) instance between pages
to avoid needing to reconnect to Convex on client-side page navigation.

Read more about authenticating users with Convex in [Authentication](/auth.mdx).

## API routes

Next.js supports building HTTP request handling routes, similar to Convex
[HTTP Actions](/functions/http-actions.mdx). Using Next.js routes might be
helpful if you need to use a dependency not supported by the Convex default
runtime.

To build an [API route](https://nextjs.org/docs/api-routes/introduction) add a
file to the `pages/api` directory.

To load and edit Convex data in your endpoints, use the
[`fetchQuery`](/api/modules/nextjs#fetchquery) function from `convex/nextjs`:

<Snippet title="pages/api/clicks.js" source={apiTS} />

## Server-side rendering

**Consider client-side rendering Convex data when using Next.js.** Data from
Convex is
[fully reactive](/functions/query-functions.mdx#caching--reactivity--consistency)
so Convex needs a connection from your deployment to the browser in order to
push updates as data changes.

You can of course load data from Convex in
[`getStaticProps`](https://nextjs.org/docs/basic-features/data-fetching/get-static-props)
or
[`getServerSideProps`](https://nextjs.org/docs/basic-features/data-fetching/get-server-side-props),
but it will be non-reactive. To do this, use the
[`fetchQuery`](/api/modules/nextjs#fetchquery) function to call query functions
just like you would in [API routes](#api-routes).

To make authenticated requests to Convex during server-side rendering, you need
authentication info present server-side. Auth0 describes this approach in
[Serverless with the user on the backend](https://auth0.com/blog/ultimate-guide-nextjs-authentication-auth0/#Serverless-with-the-user-on-the-backend).
When server-side rendering, pass the authentication token as `token` to the
third argument of `fetchQuery`.

To preload data on server side before rendering a reactive query on the client
side use [`preloadQuery`](/api/modules/nextjs#preloadquery). Check out the
[App Router version of these docs](/client/react/nextjs/nextjs-server-rendering.mdx)
for more details.


---

# quickstart-nextjs-pages-router.mdx

<!-- Source: client/react/nextjs-pages-router/quickstart-nextjs-pages-router.mdx -->

---
title: Next.js Pages Quickstart
sidebar_label: Quickstart
hide_table_of_contents: true
slug: "quickstart"
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/nextjs/sampleData.jsonl";
import tasksJs from "!!raw-loader!@site/../private-demos/quickstarts/nextjs/convex/tasks.js";
import app from "!!raw-loader!@site/../private-demos/quickstarts/nextjs/pages/_app.js";
import index from "!!raw-loader!@site/../private-demos/quickstarts/nextjs/pages/index.js";

Learn how to query data from Convex in a Next.js app using the Pages Router.

Alternatively see the [App Router](/quickstart/nextjs.mdx) version of this
quickstart.

<StepByStep>
  <Step title="Create a React app">
    Create a Next.js app using the `npx create-next-app` command.

    Choose the default option for every prompt (hit Enter).


    ```sh
    npx create-next-app@latest my-app --no-app --js
    ```

  </Step>
  <Step title="Install the Convex client and server library">
    To get started, install the `convex`
    package which provides a convenient interface for working
    with Convex from a React app.

    Navigate to your app and install `convex`.


    ```sh
    cd my-app && npm install convex
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.js` in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasksJs}
      title="convex/tasks.js"
    />

  </Step>

  <Step title="Connect the app to your backend">
    In `pages/_app.js`, create a `ConvexReactClient` and pass it to a `ConvexProvider`
    wrapping your app.

    <Snippet
      source={app}
      title="pages/_app.js"
      highlightPatterns={[ "Convex", ]}
    />

  </Step>

  <Step title="Display the data in your app">
    In `pages/index.js`, use the `useQuery` hook to fetch from your `api.tasks.get`
    API function.

    <Snippet
      source={index}
      title="pages/index.js"
      highlightPatterns={[ "useQuery", "tasks", "text", "\\)\\)\\}" ]}
    />

  </Step>

  <Step title="Start the app">
    Start the app, open [http://localhost:3000](http://localhost:3000) in a browser,
    and see the list of tasks.

    ```sh
    npm run dev
    ```

  </Step>

</StepByStep>


---

# optimistic-updates.mdx

<!-- Source: client/react/optimistic-updates.mdx -->

---
title: "Optimistic Updates"
slug: "optimistic-updates"
hidden: false
sidebar_position: 90
---

import Simple from "!!raw-loader!@site/../private-demos/snippets/src/optimisticUpdatesSimple.tsx";
import ComplexTS from "!!raw-loader!@site/../private-demos/snippets/src/optimisticUpdatesComplex.tsx";
import ComplexJS from "!!raw-loader!@site/../private-demos/snippets/src/optimisticUpdatesComplexJS.jsx";

Even though Convex queries are completely reactive, sometimes you'll want to
update your UI before the mutation changes propagate back to the client. To
accomplish this, you can configure an _optimistic update_ to execute as part of
your mutation.

Optimistic updates are temporary, local changes to your query results which are
used to make your app more responsive. These updates are made by functions
registered on a mutation invocation with the
[`.withOptimisticUpdate`](/api/interfaces/react.ReactMutation#withoptimisticupdate)
configuration option.

Optimistic updates are run when a mutation is initiated, rerun if the local
query results change, and rolled back when a mutation completes.

## Simple example

Here is how an optimistic update could be added to an `increment` mutation in a
simple counter app:

<TSAndJSSnippet
  title="src/IncrementCounter.tsx"
  sourceTS={Simple}
  sourceJS={Simple}
/>

Optimistic updates receive a
[`localStore`](/api/interfaces/browser.OptimisticLocalStore), a view of the
Convex client's internal state, followed by the arguments to the mutation.

This optimistic update updates the `api.counter.get` query to be `increment`
higher if it's loaded.

## Complex example

If we want to add an optimistic update to a multi-channel chat app, that might
look like:

<TSAndJSSnippet
  title="src/MessageSender.tsx"
  sourceTS={ComplexTS}
  sourceJS={ComplexJS}
/>

This optimistic update changes the `api.messages.list` query for the current
channel to include a new message. The newly created message object should match
the structure of the real messages generated by the `api.messages.list` query on
the server.

Because this message includes the client's current time (not the server's), it
will inevitably not match the `api.messages.list` query after the mutation runs.
That's okay! The Convex client will handle rolling back this update after the
mutation completes and the queries are updated. If there are small mistakes in
optimistic updates, the UI will always eventually render the correct values.

Similarly, the update creates a temporary `Id` with
`new Id("messages", crypto.randomUUID())`. This will also be rolled back and
replaced with the true ID once the server assigns it.

Lastly, note that this update creates a new array of messages instead of using
`existingMessages.push(newMessage)`. This is important! Mutating objects inside
of optimistic updates will corrupt the client's internal state and lead to
surprising results. Always create new objects inside of optimistic updates.

## Learning more

To learn more, check out our API documentation:

- [`.withOptimisticUpdate`](/api/interfaces/react.ReactMutation#withoptimisticupdate)
- [`OptimisticUpdate`](/api/modules/browser#optimisticupdate)
- [`OptimisticLocalStore`](/api/interfaces/browser.OptimisticLocalStore)

If you'd like some hands on experience, try adding optimistic updates to the
[tutorial app](https://github.com/get-convex/convex-tutorial)! If you do, you
should notice the app feels snappier — just a little, Convex is pretty fast
already! — but otherwise works the same.

To explore even further, try inserting a mistake into this update! You should
see a flicker as the optimistic update is applied and then rolled back.


---

# project-setup.md

<!-- Source: client/react/project-setup.md -->

---
title: "Configuring Deployment URL"
slug: "deployment-urls"
sidebar_label: "Deployment URLs"
hidden: false
sidebar_position: 5
description: "Configuring your project to run with Convex"
---

When [connecting to your backend](/client/react.mdx#connecting-to-a-backend)
it's important to correctly configure the deployment URL.

### Create a Convex project

The first time you run

```sh
npx convex dev
```

in your project directory you will create a new Convex project.

Your new project includes two deployments: _production_ and _development_. The
_development_ deployment's URL will be saved in `.env.local` or `.env` file,
depending on the frontend framework or bundler you're using.

You can find the URLs of all deployments in a project by visiting the
[deployment settings](/dashboard/deployments/settings.md) on your Convex
[dashboard](https://dashboard.convex.dev).

### Configure the client

Construct a Convex React client by passing in the URL of the Convex deployment.
There should generally be a single Convex client in a frontend application.

```jsx title="src/index.js"
import { ConvexProvider, ConvexReactClient } from "convex/react";

const deploymentURL = import.meta.env.VITE_CONVEX_URL;

const convex = new ConvexReactClient(deploymentURL);
```

While this URL can be hardcoded, it's convenient to use an environment variable
to determine which deployment the client should connect to.

Use an environment variable name accessible from your client code according to
the frontend framework or bundler you're using.

### Choosing environment variable names

To avoid unintentionally exposing secret environment variables in frontend code,
many bundlers require environment variables referenced in frontend code to use a
specific prefix.

[Vite](https://vitejs.dev/guide/env-and-mode.html) requires environment
variables used in frontend code start with `VITE_`, so `VITE_CONVEX_URL` is a
good name.

[Create React App](https://create-react-app.dev/docs/adding-custom-environment-variables/)
requires environment variables used in frontend code to begin with `REACT_APP_`,
so the code above uses `REACT_APP_CONVEX_URL`.

[Next.js](https://nextjs.org/docs/basic-features/environment-variables#exposing-environment-variables-to-the-browser)
requires them to begin with `NEXT_PUBLIC_`, so `NEXT_PUBLIC_CONVEX_URL` is a
good name.

Bundlers provide different ways to access these variables too: while
[Vite uses `import.meta.env.VARIABLE_NAME`](https://vitejs.dev/guide/env-and-mode.html),
many other tools like Next.js use the Node.js-like
[`process.env.VARIABLE_NAME`](https://nextjs.org/docs/basic-features/environment-variables)

```jsx
import { ConvexProvider, ConvexReactClient } from "convex/react";

const convex = new ConvexReactClient(process.env.NEXT_PUBLIC_CONVEX_URL);
```

[`.env` files](https://www.npmjs.com/package/dotenv) are a common way to wire up
different environment variable values in development and production
environments. `npx convex dev` will save the deployment URL to the corresponding
`.env` file, while trying to infer which bundler your project uses.

```shell title=".env.local"
NEXT_PUBLIC_CONVEX_URL=https://guiltless-dog-960.convex.cloud

# examples of other environment variables that might be passed to the frontend
NEXT_PUBLIC_SENTRY_DSN=https://123abc@o123.ingest.sentry.io/1234
NEXT_PUBLIC_LAUNCHDARKLY_SDK_CLIENT_SIDE_ID=01234567890abcdef
```

Your backend functions can use
[environment variables](/production/environment-variables.mdx) configured on
your dashboard. They do not source values from `.env` files.


---

# quickstart-react-cra.mdx

<!-- Source: client/react/quickstart-react-cra.mdx -->

---
title: Create-React-App Quickstart
sidebar_label: Create React App
description: "Add Convex to a Create React App project"
slug: "quickstart-create-react-app"
hide_table_of_contents: true
sidebar_position: 1000
---

Learn how to query data from Convex in a React app using Create React App.

Alternatively check out the [React Quickstart](/quickstart/react.mdx) using
Vite.

<StepByStep>
  <Step title="Create a React app">
    Create a React app using the `create-react-app` command.

    ```sh
    npx create-react-app my-app
    ```

  </Step>
  <Step title="Install the Convex client and server library">
    To get started, install the `convex`
    package which provides a convenient interface for working
    with Convex from a React app.

    Navigate to your app directory and install `convex`.


    ```sh
    cd my-app && npm install convex
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `src/convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    ```csv title="sampleData.jsonl"
    {"text": "Buy groceries", "isCompleted": true}
    {"text": "Go for a swim", "isCompleted": true}
    {"text": "Integrate Convex", "isCompleted": false}
    ```

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.js` in the `src/convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    ```js title="src/convex/tasks.js"
    import { query } from "./_generated/server";

    export const get = query({
      args: {},
      handler: async (ctx) => {
        return await ctx.db.query("tasks").collect();
      },
    });
    ```

  </Step>

  <Step title="Connect the app to your backend">
    In `index.js`, create a `ConvexReactClient` and pass it to a `ConvexProvider`
    wrapping your app.

    ```js title="src/index.js"
    import { ConvexProvider, ConvexReactClient } from "convex/react";

    const convex = new ConvexReactClient(process.env.REACT_APP_CONVEX_URL);
    root.render(
      <React.StrictMode>
        <ConvexProvider client={convex}>
          <App />
        </ConvexProvider>
      </React.StrictMode>
    );
    ```

  </Step>

  <Step title="Display the data in your app">
      In `App.js`, use the `useQuery` hook to fetch from your `api.tasks.get`
      API function.

      ```js title="src/App.js"
      import { useQuery } from "convex/react";
      import { api } from "./convex/_generated/api";

      function App() {
        const tasks = useQuery(api.tasks.get);
        return (
          <div className="App">
            {JSON.stringify(tasks, null, 2)}
          </div>
        );
      }
      ```

  </Step>

  <Step title="Start the app">
      Start the app, go to [http://localhost:3000](http://localhost:3000) in a browser,
      and see the serialized list of tasks at the top of the page.

      ```sh
      npm start
      ```

  </Step>

</StepByStep>


---

# clerk.mdx

<!-- Source: client/react/tanstack-start/clerk.mdx -->

---
title: "TanStack Start with Clerk"
slug: "tanstack-start-with-clerk"
sidebar_label: With Clerk
sidebar_position: 10
---

import appRouter from "!!raw-loader!@site/../private-demos/tanstack-start-clerk/app/router.tsx";
import appRoutesRoot from "!!raw-loader!@site/../private-demos/tanstack-start-clerk/app/routes/__root.tsx";

Using Clerk with Convex looks like following the
[Clerk TanStack Quickstart](https://clerk.com/docs/quickstarts/tanstack-start)
and adding Convex like the
[Convex TanStack Quickstart](/quickstart/tanstack-start.mdx) shows. Then to make
Clerk identity tokens available everywhere you might make authenticated calls to
Convex in TanStack Start, you'll want to

1. Get an ID token from Clerk in addition to the `getAuth()` call with
   `const token = await auth.getToken({ template: "convex" })`.
2. Set the token in beforeLoad with
   `ctx.context.convexQueryClient.serverHttpClient?.setAuth(token)` so the token
   will be available in loaders.
3. Add `<ConvexProviderWithClerk>` to the root component to keep refreshing
   Clerk tokens while the app is in use.

Making these changes looks like modifying `app/router.tsx` like this:

<Snippet
  source={appRouter}
  title="app/router.tsx"
  highlightPatterns={["context: "]}
/>

and modifying `app/routes/__root.tsx` like this:

<Snippet
  source={appRoutesRoot}
  title="app/routes/__root.tsx"
  highlightPatterns={[
    "getAuth\\(get",
    "getToken",
    "token,",
    "ConvexReactClient",
    "ConvexQueryClient",
    "userId, token",
    "ConvexProviderWithClerk",
    "if \\(token",
    "ctx.context.convexQuery",
  ]}
/>

Now all queries, mutations and action made with
[TanStack Query](/client/tanstack-query.mdx) will be authenticated by a Clerk
identity token.


---

# tanstack-start.mdx

<!-- Source: client/react/tanstack-start/tanstack-start.mdx -->

---
title: "TanStack Start"
sidebar_label: "TanStack Start"
sidebar_position: 180
description: "How Convex works with TanStack Start"
---

[TanStack Start](https://tanstack.com/start/latest) is a new React web framework
with best-in-class typesafe routing.

When used with Convex, TanStack Start provides

- Live-updating queries with React Query (the React client for TanStack Query)
- Subscription session resumption, from SSR to live on the client
- Loader-based preloading and prefetching
- Consistent logical query timestamp during SSR
- Opt-in component-local SSR

and more!

This page describes the recommended way to use Convex with TanStack Start, via
React Query. The standard Convex React hooks work also with TanStack Start
without React Query, as do the [React Query hooks](/client/tanstack-query.mdx)
without TanStack Start! But using all three is a sweet spot.

<Admonition type="caution" title="TanStack Start is in Beta">
  TanStack Start is a new React framework currently in beta. You can use it
  today but there may be breaking changes made to it before a stable release.
</Admonition>

## Getting started

Follow the [TanStack Start Quickstart](/quickstart/tanstack-start.mdx) to add
Convex to a new TanStack Start project.

## Using Convex with React Query

You can read more about [React Query hooks](/client/tanstack-query.mdx), but a
few highlights relevant to TanStack Start.

### Staying subscribed to queries

Convex queries in React Query continue to receive updates after the last
component subscribed to the query unmounts. The default for this behavior is 5
minutes and this value is configured with
[`gcTime`](https://tanstack.com/query/latest/docs/framework/react/guides/caching).

This is useful to know when debugging why a query result is already loaded: for
client side navigations, whether a subscription is already active can depend on
what pages were previously visited in a session.

### Using Convex React hooks

[Convex React](/client/react.mdx) hooks like
[`usePaginatedQuery`](/api/modules/react#usepaginatedquery) can be used
alongside TanStack hooks. These hooks reference the same Convex Client so
there's still just one set of consistent query results in your app when these
are combined.

## Server-side Rendering

Using TanStack Start and Query with Convex makes it particularly easy to
live-update Convex queries on the client while also
[server-rendering](https://tanstack.com/query/v5/docs/framework/react/guides/ssr)
them.
[`useSuspenseQuery()`](https://tanstack.com/query/latest/docs/framework/react/reference/useSuspenseQuery)
is the simplest way to do this:

```ts
const { data } = useSuspenseQuery(convexQuery(api.messages.list, {}));
```

### Consistent client views

In the browser all Convex query subscriptions present a consistent,
at-the-same-logical-timestamp view of the database: if one query result reflects
a given mutation transaction, every other query result will too.

Server-side rendering is usually a special case: instead of a stateful WebSocket
session, on the server it's simpler to fetch query results ad-hoc. This can lead
to inconsistencies analogous to one REST endpoint returning results before a
mutation ran and another endpoint returning results after that change.

In TanStack Start, this issue is avoided by sending in a timestamp along with
each query: Convex uses the same timestamp for all queries.

### Loaders

To make client-side navigations faster you can add a
[loader](https://tanstack.com/router/latest/docs/framework/react/guide/external-data-loading#using-loaders-to-ensure-data-is-loaded)
to a route. By default, loaders will run when mousing over a link to that page.

```ts
export const Route = createFileRoute('/posts')({
  loader: async (opts) => {
    await opts.context.queryClient.ensureQueryData(
      convexQuery(api.messages.list, {}),
    );
  };
  component: () => {
    const { data } = useSuspenseQuery(convexQuery(api.messages.list, {}));
    return (
      <div>
	{data.map((message) => (
	  <Message key={message.id} post={message} />
	))}
      </div>
    );
  },
})
```

## Authentication

Client-side authentication in Start works the way
[client-side authentication with Convex](https://docs.convex.dev/auth) generally
works in React because TanStack Start works well as a client-side framework.

To use Clerk auth to make authenticated Convex calls on the server as well see
the [TanStack Start + Clerk guide](/client/react/tanstack-start/clerk.mdx).

Clerk is an official partner of TanStack, see our setup guide.


---

# react-native.mdx

<!-- Source: client/react-native.mdx -->

---
title: "Convex React Native"
sidebar_label: "React Native"
slug: "react-native"
sidebar_position: 300
description: "How Convex works in a React Native app"
---

To use Convex in [React Native](https://reactnative.dev/) use the
[Convex React client library](/client/react.mdx).

Follow the [React Native Quickstart](/quickstart/react-native.mdx) for the
different configuration needed specifically for React Native.

You can also clone a working
[Convex React Native demo](https://github.com/get-convex/convex-demos/tree/main/react-native).


---

# react.mdx

<!-- Source: client/react.mdx -->

---
title: "Convex React"
sidebar_label: "React"
sidebar_position: 4
---

import SkipBad from "!!raw-loader!@site/../private-demos/snippets/src/reactSkipBad.tsx";
import SkipGood from "!!raw-loader!@site/../private-demos/snippets/src/reactSkipGood.tsx";

Convex React is the client library enabling your React application to interact
with your Convex backend. It allows your frontend code to:

1. Call your [queries](/functions/query-functions.mdx),
   [mutations](/functions/mutation-functions.mdx) and
   [actions](/functions/actions.mdx)
2. Upload and display files from [File Storage](/file-storage.mdx)
3. Authenticate users using [Authentication](/auth.mdx)
4. Implement full text [Search](/search.mdx) over your data

The Convex React client is open source and available on
[GitHub](https://github.com/get-convex/convex-js).

Follow the [React Quickstart](/quickstart/react.mdx) to get started with React
using [Vite](https://vitejs.dev/).

## Installation

Convex React is part of the `convex` npm package:

```
npm install convex
```

## Connecting to a backend

The [`ConvexReactClient`](/api/classes/react.ConvexReactClient) maintains a
connection to your Convex backend, and is used by the React hooks described
below to call your functions.

First you need to create an instance of the client by giving it your backend
deployment URL. See [Configuring Deployment URL](/client/react/project-setup.md)
on how to pass in the right value:

```jsx
import { ConvexProvider, ConvexReactClient } from "convex/react";

const convex = new ConvexReactClient("https://<your domain here>.convex.cloud");
```

And then you make the client available to your app by passing it in to a
[`ConvexProvider`](/api/modules/react#convexprovider) wrapping your component
tree:

```jsx
reactDOMRoot.render(
  <React.StrictMode>
    <ConvexProvider client={convex}>
      <App />
    </ConvexProvider>
  </React.StrictMode>,
);
```

## Fetching data

Your React app fetches data using the [`useQuery`](/api/modules/react#usequery)
React hook by calling your [queries](/functions/query-functions.mdx) via an
[`api`](/generated-api/api.md#api) object.

The `npx convex dev` command generates this api object for you in the
`convex/_generated/api.js` module to provide better autocompletion in JavaScript
and end-to-end type safety in
[TypeScript](/understanding/best-practices/typescript.mdx):

```tsx title="src/App.tsx"
import { useQuery } from "convex/react";
import { api } from "../convex/_generated/api";

export function App() {
  const data = useQuery(api.functions.myQuery);
  return data ?? "Loading...";
}
```

The `useQuery` hook returns `undefined` while the data is first loading and
afterwards the return value of your query.

### Query arguments

Arguments to your query follow the query name:

```tsx title="src/App.tsx"
export function App() {
  const a = "Hello world";
  const b = 4;
  const data = useQuery(api.functions.myQuery, { a, b });
  //...
}
```

### Reactivity

The `useQuery` hook makes your app automatically reactive: when the underlying
data changes in your database, your component rerenders with the new query
result.

The first time the hook is used it creates a subscription to your backend for a
given query and any arguments you pass in. When your component unmounts, the
subscription is canceled.

### Consistency

Convex React ensures that your application always renders a consistent view of
the query results based on a single state of the underlying database.

Imagine a mutation changes some data in the database, and that 2 different
`useQuery` call sites rely on this data. Your app will never render in an
inconsistent state where only one of the `useQuery` call sites reflects the new
data.

### Paginating queries

See
[Paginating within React Components](/database/pagination.mdx#paginating-within-react-components).

### Skipping queries

<Details summary="Advanced: Loading a query conditionally">

With React it can be tricky to dynamically invoke a hook, because hooks cannot
be placed inside conditionals or after early returns:

<TSAndJSSnippet
  title="src/App.tsx"
  sourceTS={SkipBad}
  sourceJS={SkipBad}
  snippet="example"
  highlightPatterns={["useQuery"]}
/>

For this reason `useQuery` can be "disabled" by passing in `"skip"` instead of
its arguments:

<TSAndJSSnippet
  title="src/App.tsx"
  sourceTS={SkipGood}
  sourceJS={SkipGood}
  highlightPatterns={["skip"]}
/>

When `"skip"` is used the `useQuery` doesn't talk to your backend at all and
returns `undefined`.

</Details>

### One-off queries

<Details summary="Advanced: Fetching a query from a callback">

Sometimes you might want to read state from the database in response to a user
action, for example to validate given input, without making any changes to the
database. In this case you can use a one-off
[`query`](/api/classes/react.ConvexReactClient#query) call, similarly to calling
mutations and actions.

The async method `query` is exposed on the `ConvexReactClient`, which you can
reference in your components via the
[`useConvex()`](/api/modules/react#useconvex) hook.

```tsx title="src/App.tsx"
import { useConvex } from "convex/react";
import { api } from "../convex/_generated/api";

export function App() {
  const convex = useConvex();
  return (
    <button
      onClick={async () => {
        console.log(await convex.query(api.functions.myQuery));
      }}
    >
      Check
    </button>
  );
}
```

</Details>

## Editing data

Your React app edits data using the
[`useMutation`](/api/modules/react#usemutation) React hook by calling your
[mutations](/functions/mutation-functions.mdx).

The `convex dev` command generates this api object for you in the
`convex/_generated/api.js` module to provide better autocompletion in JavaScript
and end-to-end type safety in
[TypeScript](/understanding/best-practices/typescript.mdx):

```tsx title="src/App.tsx"
import { useMutation } from "convex/react";
import { api } from "../convex/_generated/api";

export function App() {
  const doSomething = useMutation(api.functions.doSomething);
  return <button onClick={() => doSomething()}>Click me</button>;
}
```

The hook returns an `async` function which performs the call to the mutation.

### Mutation arguments

Arguments to your mutation are passed to the `async` function returned from
`useMutation`:

```tsx title="src/App.tsx"
export function App() {
  const a = "Hello world";
  const b = 4;
  const doSomething = useMutation(api.functions.doSomething);
  return <button onClick={() => doSomething({ a, b })}>Click me</button>;
}
```

### Mutation response and error handling

The mutation can optionally return a value or throw errors, which you can
[`await`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/await):

```tsx title="src/App.tsx"
export function App() {
  const doSomething = useMutation(api.functions.doSomething);
  const onClick = () => {
    async function callBackend() {
      try {
        const result = await doSomething();
      } catch (error) {
        console.error(error);
      }
      console.log(result);
    }
    void callBackend();
  };
  return <button onClick={onClick}>Click me</button>;
}
```

Or handle as a
[`Promise`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise):

```tsx title="src/App.tsx"
export function App() {
  const doSomething = useMutation(api.functions.doSomething);
  const onClick = () => {
    doSomething()
      .catch((error) => {
        console.error(error);
      })
      .then((result) => {
        console.log(result);
      });
  };
  return <button onClick={onClick}>Click me</button>;
}
```

Learn more about [Error Handling](/functions/error-handling/error-handling.mdx)
in functions.

### Retries

Convex React automatically retries mutations until they are confirmed to have
been written to the database. The Convex backend ensures that despite multiple
retries, every mutation call only executes once.

Additionally, Convex React will warn users if they try to close their browser
tab while there are outstanding mutations. This means that when you call a
Convex mutation, you can be sure that the user's edits won't be lost.

### Optimistic updates

Convex queries are fully reactive, so all query results will be automatically
updated after a mutation. Sometimes you may want to update the UI before the
mutation changes propagate back to the client. To accomplish this, you can
configure an _optimistic update_ to execute as part of your mutation.

Optimistic updates are temporary, local changes to your query results which are
used to make your app more responsive.

See [Optimistic Updates](/client/react/optimistic-updates.mdx) on how to
configure them.

## Calling third-party APIs

Your React app can read data, call third-party services, and write data with a
single backend call using the [`useAction`](/api/modules/react#useaction) React
hook by calling your [actions](/functions/actions.mdx).

Like `useQuery` and `useMutation`, this hook is used with the `api` object
generated for you in the `convex/_generated/api.js` module to provide better
autocompletion in JavaScript and end-to-end type safety in
[TypeScript](/understanding/best-practices/typescript.mdx):

```tsx title="src/App.tsx"
import { useAction } from "convex/react";
import { api } from "../convex/_generated/api";

export function App() {
  const doSomeAction = useAction(api.functions.doSomeAction);
  return <button onClick={() => doSomeAction()}>Click me</button>;
}
```

The hook returns an `async` function which performs the call to the action.

### Action arguments

Action arguments work exactly the same as
[mutation arguments](#mutation-arguments).

### Action response and error handling

Action response and error handling work exactly the same as
[mutation response and error handling](#mutation-response-and-error-handling).

Actions do not support automatic retries or optimistic updates.

## Under the hood

The [`ConvexReactClient`](/api/classes/react.ConvexReactClient) connects to your
Convex deployment by creating a
[`WebSocket`](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket). The
WebSocket provides a 2-way communication channel over TCP. This allows Convex to
push new query results reactively to the client without the client needing to
poll for updates.

If the internet connection drops, the client will handle reconnecting and
re-establishing the Convex session automatically.


---

# rust.md

<!-- Source: client/rust.md -->

---
title: "Rust"
sidebar_position: 500
---

See the [Rust Quickstart](/quickstart/rust.mdx) and
<a href="https://docs.rs/convex/latest/convex/" target="_blank">`convex` on
docs.rs docs</a>. The Rust client is open source and available on
[GitHub](https://github.com/get-convex/convex-rs).


---

# svelte.md

<!-- Source: client/svelte.md -->

---
title: "Svelte"
sidebar_position: 250
---

Convex is a great fit for reactive UI frameworks like Svelte. The
[convex-svelte npm package](https://www.npmjs.com/package/convex-svelte)
enhances the [ConvexClient](/api/classes/browser.ConvexClient) with declarative
subscriptions in Svelte 5.

See the [Svelte Quickstart](/quickstart/svelte.mdx) to get started. The Svelte
client is open source and available on
[GitHub](https://github.com/get-convex/convex-svelte).


---

# data-types.md

<!-- Source: client/swift/data-types.md -->

---
title: "Swift and Convex type conversion"
sidebar_label: "Data Types"
hidden: false
sidebar_position: 5
description: "Customizing and converting types between the Swift app and Convex"
---

## Custom data types

Convex lets you easily express your data in the backend as TypeScript objects,
and can return those objects from queries, mutations and actions. To handle
objects on the Swift side, create `struct` definitions that conform to the
`Decodable` protocol. Usually that’s fairly trivial to do, as any `struct` with
all `Decodable` members can automatically conform.

Consider a Convex query function that returns results like this JavaScript
object:

```tsx
{
  name: "Guardians",
  uniformColors: ["blue", "white", "red"],
  wins: 80n,
  losses: 60n
}
```

That can be represented in Swift using:

```swift
struct BaseballTeam: Decodable {
  let name: String
  let uniformColors: [String]
  @ConvexInt
  var wins: Int
  @ConvexInt
  var losses: Int
}
```

Then you can pass that type as the yielding argument in your subscribe call:

```swift
convex.subscribe(to: "mlb:first_place_team",
               with: ["division": "AL Central"],
           yielding: BaseballTeam.self)
```

The data from the remote function will be deserialized to your custom struct.
Often your use of the type can be inferred from the calling context, and you can
skip the yielding argument.

## Numerical types

Numeric types like `Int` and `Double` are encoded in a special format to ensure
proper interoperation with your TypeScript backend functions. To safely use them
on the Swift side, ensure that you use one of the following property wrappers.

| Type                           | Wrapper                |
| ------------------------------ | ---------------------- |
| `Float` or `Double`            | `@ConvexFloat`         |
| `Float?` or `Double?`          | `@OptionalConvexFloat` |
| `Int` or `Int32` or `Int64`    | `@ConvexInt`           |
| `Int?` or `Int32?` or `Int64?` | `@OptionalConvexInt`   |

Note that `struct` properties with wrappers must be declared as `var`.

## Field name conversion

If your code receives objects with names that you need to or want to translate
to different names, you can use a `CodingKeys` `enum` to specify a mapping of
remote names to names on your struct. For example, imagine a backend function or
API that returns log entries like the following representing when someone came
in and went out:

```tsx
{name: "Bob", in: "2024-10-03 08:00:00", out: "2024-10-03 11:00:00"}
```

That data can’t decode directly into a `struct` because `in` is a keyword in
Swift. We can use `CodingKeys` to give it an alternate name while still
ingesting the data from the original name.

```swift
struct Log: Decodable {
  let name: String
  let inTime: String
  let outTime: String

  enum CodingKeys: String, CodingKey {
    case name
    case inTime = "in"
    case outTime = "out"
  }
}
```

## Putting it all together

In the custom data type example above, JavaScript's `BigInt` type is used in the
backend data by adding a trailing `n` to the `wins` and `losses` values which
lets the Swift code use `Int`. If instead the code used regular
JavaScript `number` types, on the Swift side those would be received as floating
point values and deserialization to `Int` would fail.

If you have a situation like that where `number` is used but by convention it
only contains integer values, you can handle that in your `struct` by using
field name conversion and custom properties to hide the floating point
representation.

```swift
struct BaseballTeam: Decodable {
  let name: String
  let uniformColors: [String]
  @ConvexFloat
  private var internalWins: Double
  @ConvexFloat
  private var internalLosses: Double

  enum CodingKeys: String, CodingKey {
    case name
    case uniformColors
    case internalWins = "wins"
    case internalLosses = "losses"
  }

  // Expose the Double values as Ints
  var wins: Int { Int(internalWins) }
  var losses: Int { Int(internalLosses) }
}
```

The pattern is to store the `Double` values privately and with different names
than the value from the backend. Then add custom properties to provide
the `Int` values.


---

# swift.md

<!-- Source: client/swift.md -->

---
title: "iOS & macOS Swift"
sidebar_label: "Swift"
sidebar_position: 700
---

The Convex Swift client library enables your iOS or macOS application to
interact with your Convex backend. It allows your frontend code to:

1. Call
   your [queries](/functions/query-functions.mdx), [mutations](/functions/mutation-functions.mdx) and [actions](/functions/actions.mdx)
2. Authenticate users using [Auth0](/auth/auth0.mdx)

The library is open source
and [available on GitHub](https://github.com/get-convex/convex-swift).

Follow the [Swift Quickstart](/quickstart/swift.mdx) to get started.

## Installation

For an iOS or macOS project in Xcode, you’ll need to perform the following steps
to add a dependency on the `ConvexMobile` library.

1. Click on the top-level app container in the project navigator on the left
2. Click on the app name under the PROJECT heading
3. Click the _Package Dependencies_ tab
4. Click the + button

   ![Screenshot 2024-10-02 at 2.33.43 PM.png](/screenshots/swift_qs_step_2.png)

5. Paste
   [`https://github.com/get-convex/convex-swift`](https://github.com/get-convex/convex-swift)
   into the search box and press Enter
6. When the `convex-swift` package loads, click the Add Package button
7. In the _Package Products_ dialog, select your product name in the _Add to
   Target_ dropdown
8. Click _Add Package_

## Connecting to a backend

The `ConvexClient` is used to establish and maintain a connection between your
application and the Convex backend. First you need to create an instance of the
client by giving it your backend deployment URL:

```swift
import ConvexMobile

let convex = ConvexClient(deploymentUrl: "https://<your domain here>.convex.cloud")
```

You should create and use one instance of the `ConvexClient` for the lifetime of
your application process. You can store the client in a global constant like
shown above. An actual connection to the Convex backend won’t be initiated until
you call a method on the `ConvexClient`. After that it will maintain the
connection and re-establish it if it gets dropped.

## Fetching data

The Swift Convex library gives you access to the Convex sync engine, which
enables real-time *subscriptions* to query results. You subscribe to queries
with the `subscribe` method on `ConvexClient` which returns
a [`Publisher`](https://developer.apple.com/documentation/combine). The data
available via the `Publisher` will change over time as the underlying data
backing the query changes.

You can call methods on the `Publisher` to transform and consume the data it
provides.

A simple way to consume a query that returns a list of strings in a `View` is to
use a combination of a `@State` containing a list and the `.task` modifier with
code that loops over the query results as an `AsyncSequence`:

```swift
struct ColorList: View {
  @State private var colors: [String] = []

  var body: some View {
    List {
      ForEach(colors, id: \.self) { color in
        Text(color)
      }
    }.task {
      let latestColors = convex.subscribe(to: "colors:get", yielding: [String].self)
        .replaceError(with: [])
        .values
      for await colors in latestColors {
        self.colors = colors
      }
    }
  }
}
```

Any time the data that powers the backend `"colors:get"` query changes, a
new array of `String` values will appear in the `AsyncSequence` and the
`View`'s `colors` list gets assigned the new data. The UI will then rebuild
reactively to reflect the changed data.

### Query arguments

You can pass arguments to `subscribe` and they will be supplied to the
associated backend `query` function. The arguments must be a Dictionary keyed
with strings and the values should generally be primitive types, Arrays and
other Dictionaries.

```swift
let publisher = convex.subscribe(to: "colors:get",
                               with:["onlyFavorites": true],
                           yielding:[String].self)
```

Assuming the `colors:get` query accepts an `onlyFavorites` argument, the value
can be received and used to perform logic in the query function.

<Admonition type="tip">
Use [Decodable structs](/client/swift/data-types.md#custom-data-types)
to automatically convert Convex objects to Swift structs.
</Admonition>

<Admonition type="caution">
* There are important gotchas when
  [sending and receiving numbers](/client/swift/data-types.md#numerical-types)
  between Swift and Convex.
* Depending on your backend functions, you may need to deal with
  [reserved Swift keywords](/client/swift/data-types.md#field-name-conversion).
</Admonition>

### Subscription lifetime

The `Publisher` returned from `subscribe` will persist as long as the associated
`View` or `ObservableObject`. When either is no longer part of the UI, the
underlying query subscription to Convex will be canceled.

## Editing Data

You can use the `mutation` method on `ConvexClient` to trigger a
backend [mutation](/functions/mutation-functions.mdx).

`mutation` is an `async` method so you'll need to call it within a `Task`.
Mutations can return a value or not.

Mutations can also receive arguments, just like queries. Here's an example of
calling a mutation with arguments that returns a value:

```swift
let isColorAdded: Bool = try await convex.mutation("colors:put", with: ["color": newColor])
```

### Handling errors

If an error occurs during a call to `mutation`, it will throw. Typically you may
want to
catch [`ConvexError`](/functions/error-handling/application-errors.mdx) and `ServerError` and
handle them however is appropriate in your application.

Here’s a small example of how you might handle an error from `colors:put` if it
threw a `ConvexError` with an error message if a color already existed.

```swift
do {
  try await convex.mutation("colors:put", with: ["color": newColor])
} catch ClientError.ConvexError(let data) {
  errorMessage = try! JSONDecoder().decode(String.self, from: Data(data.utf8))
  colorNotAdded = true
}
```

See documentation on [error handling](/functions/error-handling/) for more
details.

## Calling third-party APIs

You can use the `action` method on `ConvexClient` to trigger a
backend [action](/functions/actions.mdx).

Calls to `action` can accept arguments, return values and throw exceptions just
like calls to `mutation`.

Even though you can call actions from your client code, it's not always the
right choice. See the action docs for tips
on [calling actions from clients](/functions/actions.mdx#calling-actions-from-clients).

## Authentication with Auth0

You can use `ConvexClientWithAuth` in place of `ConvexClient` to configure
authentication with [Auth0](https://auth0.com/). You'll need
the `convex-swift-auth0` library to do that, as well as an Auth0 account and
application configuration.

See
the [README](https://github.com/get-convex/convex-swift-auth0/blob/main/README.md) in
the `convex-swift-auth0` repo for more detailed setup instructions, and
the [Workout example app](https://github.com/get-convex/ios-convex-workout) which
is configured for Auth0. The overall [Convex authentication docs](/auth.mdx) are
a good resource as well.

It should also be possible to integrate other similar OpenID Connect
authentication providers. See
the [`AuthProvider`](https://github.com/get-convex/convex-swift/blob/c47aea414c92db2ccf3a0fa4f9db8caf2029b032/Sources/ConvexMobile/ConvexMobile.swift#L188) protocol
in the `convex-swift` repo for more info.

## Production and dev deployments

When you're ready to move toward [production](/production.mdx) for your app, you
can setup your Xcode build system to point different build targets to different
Convex deployments. Build environment configuration is highly specialized, and
it’s possible that you or your team have different conventions, but this is one
way to approach the problem.

1. Create “Dev” and “Prod” folders in your project sources.
2. Add an `Env.swift` file in each one with contents like:

```swift
let deploymentUrl = "https://$DEV_OR_PROD.convex.cloud"
```

3. Put your dev URL in `Dev/Env.swift` and your prod URL in `Prod/Env.swift`.
   Don’t worry if Xcode complains that `deploymentUrl` is defined multiple
   times.
4. Click on your top-level project in the explorer view on the left.
5. Select your build target from the **TARGETS** list.
6. Change the target’s name so it ends in “dev”.
7. Right/Ctrl-click it and duplicate it, giving it a name that ends in “prod”.
8. With the “dev” target selected, click the **Build Phases** tab.
9. Expand the **Compile Sources** section.
10. Select `Prod/Env.swift` and remove it with the - button.
11. Likewise, open the “prod” target and remove `Dev/Env.swift` from its
    sources.

![Screenshot 2024-10-03 at 1.34.34 PM.png](/screenshots/swift_env_setup.png)

Now you can refer to `deploymentUrl` wherever you create your `ConvexClient` and
depending on the target that you build, it will use your dev or prod URL.

## Structuring your application

The examples shown in this guide are intended to be brief, and don't provide
guidance on how to structure a whole application.

If you want a more robust and layered approach, put your code that interacts
with `ConvexClient`in a class that conforms to `ObservableObject`. Then your
`View` can observe that object as a `@StateObject` and will rebuild whenever it
changes.

For example, if we adapt the `colors:get` example from above to a
`ViewModel: ObservableObject` class, the `View` no longer plays a direct part in
fetching the data - it only knows that the list of `colors` is provided by the
`ViewModel`.

```swift
import SwiftUI

class ViewModel: ObservableObject {
  @Published var colors: [String] = []

  init() {
    convex.subscribe(to: "colors:get")
      .replaceError(with: [])
      .receive(on: DispatchQueue.main)
      .assign(to: &$colors)
  }
}

struct ContentView: View {
  @StateObject var viewModel = ViewModel()

  var body: some View {
    List {
      ForEach(viewModel.colors, id: \.self) { color in
        Text(color)
      }
    }
  }
}
```

Depending on your needs and the scale of your app, it might make sense to give
it even more formal structure as demonstrated in something like
https://github.com/nalexn/clean-architecture-swiftui.

## Under the hood

The Swift Convex library is built on top of the
official [Convex Rust client](/client/rust.md). It handles maintaining a
WebSocket connection with the Convex backend and implements the full Convex
protocol.

All method calls on `ConvexClient` are handled via a Tokio async runtime on the
Rust side and are safe to call from the application's main actor.


---

# tanstack-query.mdx

<!-- Source: client/tanstack-query.mdx -->

---
title: "Convex with TanStack Query"
sidebar_label: "TanStack Query"
sidebar_position: 325
---

import Setup from "!!raw-loader!@site/../demos/react-query/src/main.tsx";
import App from "!!raw-loader!@site/../demos/react-query/src/App.tsx";

[TanStack Query](https://tanstack.com/query/latest) is an excellent, popular
library for managing requests to a server.

The
[`@convex-dev/react-query`](https://www.npmjs.com/package/@convex-dev/react-query)
library provides
[Query Option](https://tanstack.com/query/latest/docs/framework/react/guides/query-options)
functions for use with TanStack Query.

Not all features of the standard [Convex React client](/client/react) are
available through the TanStack Query APIs but you can use the two alongside each
other, dropping into the standard Convex React hooks as necessary.

<BetaAdmonition feature="The TanStack Query adapter" verb="is" />

This makes subscribing to a Convex query function using the TanStack Query
`useQuery` hook look like this:

```ts
const { data, isPending, error } = useQuery(convexQuery(api.messages.list, {}));
```

Instead of the typical polling pattern for API endpoints used with TanStack
Query, the code above receives updates for this `api.messages.list` query from
the Convex server reactively. New results for all relevant subscriptions are
pushed to the client where they update at the same time so data is never stale
and there's no need to manually invalidate queries.

<Admonition type="note" title="Support for other frameworks">
  Currently only [React
  Query](https://tanstack.com/query/latest/docs/framework/react/overview) is
  supported via
  [`@convex-dev/react-query`](https://www.npmjs.com/package/@convex-dev/react-query).
  [Let us know](https://convex.dev/community) if you would find support for
  vue-query, svelte-query, solid-query, or angular-query helpful.
</Admonition>

## Setup

To get live updates in TanStack Query create a `ConvexQueryClient` and connect
it to the TanStack Query
[QueryClient](https://tanstack.com/query/latest/docs/reference/QueryClient).
After installing the adapter library with

```
npm i @convex-dev/react-query
```

wire up Convex to TanStack Query like this:

<Snippet
  title="src/main.tsx"
  source={Setup}
  highlightPatterns={["QueryClient", "convexQuery"]}
/>

Note that when your create your React tree you should both:

- wrap your app in the TanStack Query
  [`QueryClientProvider`](https://tanstack.com/query/latest/docs/framework/react/reference/QueryClientProvider)
  so you can use
  [TanStack Query hooks](https://tanstack.com/query/latest/docs/framework/react/reference/useQuery)
  and
- wrap your app in the [`ConvexProvider`](/api/modules/react#convexprovider) so
  you can also use normal [Convex React](/client/react) hooks

## Queries

A live-updating subscription to a Convex [query](/functions/query-functions.mdx)
is as simple as calling TanStack
[`useQuery`](https://tanstack.com/query/latest/docs/framework/react/reference/useQuery)
with `convexQuery`:

```ts
import { useQuery } from "@tanstack/react-query";
import { convexQuery } from "@convex-dev/react-query";
import { api } from "../convex/_generated/api";

export function App() {
  const { data, isPending, error } = useQuery(
    convexQuery(api.functions.myQuery, { id: 123 }),
  );
  return isPending ? "Loading..." : data;
}
```

You can spread the object returned by `convexQuery` into an object specifying
additional
[arguments of `useQuery`](https://tanstack.com/query/latest/docs/framework/react/reference/useQuery).

```ts
const { data, isPending, error } = useQuery({
  ...convexQuery(api.functions.myQuery, { id: 123 }),
  initialData: [], // use an empty list if no data is available yet
  gcTime: 10000, // stay subscribed for 10 seconds after this component unmounts
});
```

## Mutations

Your app can call Convex [mutations](/functions/mutation-functions.mdx) by using
the TanStack
[`useMutation`](https://tanstack.com/query/latest/docs/framework/react/reference/useMutation)
hook, and setting the `mutationFn` property to the result of calling
`useConvexMutation`:

```ts
import { useMutation } from "@tanstack/react-query";
import { useConvexMutation } from "@convex-dev/react-query";
import { api } from "../convex/_generated/api";

export function App() {
  const { mutate, isPending } = useMutation({
    mutationFn: useConvexMutation(api.functions.doSomething),
  });
  return <button onClick={() => mutate({a: "Hello"})}>Click me</button>;
}
```

`useConvexMutation` is just a re-export of the
[`useMutation`](/client/react#editing-data) hook from
[Convex React](/client/react).

## Differences from using `fetch` with TanStack Query

Convex provides stronger guarantees than other methods of fetching data with
React Query, so some options and return value properties are no longer
necessary.

Subscriptions to Convex queries will remain active after the last component
using `useQuery` for a given function unmounts for `gcTime` milliseconds. This
value is 5 minutes by default; if this results in unwanted function activity use
a smaller value.

Data provided by Convex is never stale, so the `isStale` property of the return
value of `useQuery` will always be false. `retry`-related options are ignored,
since Convex provides its own retry mechanism over its WebSocket protocol.
`refetch`-related options are similarly ignored since Convex queries are always
up to date.


---

# vue.md

<!-- Source: client/vue.md -->

---
title: "Vue"
sidebar_position: 250
---

The community-maintained
[`@convex-vue/core` npm package](https://www.npmjs.com/package/@convex-vue/core)
provides deep integration of Convex with the Vue ecosystem.

See the [Vue Quickstart](/quickstart/vue.mdx) to get started or the
[convex-vue GitHub page](https://github.com/Darialyphia/convex-vue/tree/master/packages/convex-vue)
for more documentation.

<Admonition type="info">

The [`@convex-vue/core` library](https://www.npmjs.com/package/@convex-vue/core)
is community-maintained. Thank you to the maintainer
[Daria](https://github.com/Darialyphia) for his work on this project!

You're welcome to ask questions about the library on the
[Convex Discord](https://convex.dev/community) but opening a
[convex-vue GitHub](https://github.com/Darialyphia/convex-vue/tree/master/packages/convex-vue)
issue is a better way to request a new feature or report a bug.

</Admonition>


---

# using.mdx

<!-- Source: components/using.mdx -->

---
title: "Using Components"
slug: "using-components"
sidebar_position: 10
description: "Using existing components"
---

Convex components add new features to your backend in their own sandbox with
their own functions, schema and data, scheduled functions and all other
fundamental Convex features.

You can see the full list of components in the
[directory](https://convex.dev/components). Each component README provides full
instructions on how to install and use them.

This doc will go through common patterns on how to install and use Components.

## Installing Components

We'll use the
[Sharded Counter](https://www.npmjs.com/package/@convex-dev/sharded-counter)
component as an example.

<StepByStep>
  <Step title="Install from `npm`">
  Install the relevant package from npm

```bash
npm i @convex-dev/sharded-counter
```

  </Step>
  <Step title="Add the component to your app">
  Create or update the `convex.config.ts` file in your app's `convex/` folder and install the component by calling `use`:

```ts
// convex/convex.config.ts
import { defineApp } from "convex/server";
import shardedCounter from "@convex-dev/sharded-counter/convex.config";

const app = defineApp();

// highlight-next-line
app.use(shardedCounter);
//... Add other components here

export default app;
```

  </Step>
  <Step title="Run convex dev">
  Make sure the convex dev cli is running to ensure the component is registered with your backend and the necessary code is generated.

```bash
npx convex dev
```

  </Step>
  <Step title="Use the provided component API">
    Each component has its own API. Check out each component's README file for more details on its usage.
  </Step>

</StepByStep>

## Component functions

Though components may expose higher level TypeScript APIs, under the hood they
are called via normal Convex functions over the component sandbox boundary.

Queries, mutations, and action rules still apply - queries can only call
component queries, mutations can also call component mutations, and actions can
also call component actions. As a result, queries into components are reactive
by default, and mutations have the same transaction guarantees.

## Transactions

Remember that mutation functions in Convex are
[transactions](/functions/mutation-functions.mdx#transactions). Either all the
changes in the mutation get written at once or none are written at all.

All writes for a top-level mutation call, including writes performed by calls
into other components' mutations, are committed at the same time. If the
top-level mutation throws an error, all of the writes are rolled back, and the
mutation doesn't change the database at all.

However, if a component mutation call throws an exception, only its writes are
rolled back. Then, if the caller catches the exception, it can continue, perform
more writes, and return successfully. If the caller doesn't catch the exception,
then it's treated as failed and all the writes associated with the caller
mutation are rolled back. This means your code can choose a different code path
depending on the semantics of your component.

As an example, take the
[Rate Limiter](https://www.npmjs.com/package/@convex-dev/ratelimiter) component.
One API of the Rate Limiter throws an error if a rate limit is hit:

```ts
// Automatically throw an error if the rate limit is hit.
await rateLimiter.limit(ctx, "failedLogins", { key: userId, throws: true });
```

If the call to `rateLimiter.limit` throws an exception, we're over the rate
limit. Then, if the calling mutation doesn't catch this exception, the whole
transaction is rolled back.

The calling mutation, on the other hand, could also decide to ignore the rate
limit by catching the exception and proceeding. For example, an app may want to
ignore rate limits if there is a development environment override. In this case,
only the component mutation will be rolled back, and the rest of the mutation
will continue.

## Dashboard

You can see your component’s data, functions, files, and other info using the
dropdown in the Dashboard.

<p style={{ textAlign: "center" }}>
  <img
    src="/screenshots/component_dropdown.png"
    alt="Screenshot of the component dropdown"
    width={414}
  />
</p>


---

# components.mdx

<!-- Source: components.mdx -->

---
title: "Components"
description: "Self contained building blocks of your app"
pagination_prev: search
---

import { ComponentCardList } from "@site/src/ComponentCardList.tsx";

<span className="convex-hero">
  Convex Components package up code and data in a sandbox that allows you to
  confidently and quickly add new features to your backend.
</span>

Convex Components are like mini self-contained Convex backends, and installing
them is always safe. They can't read your app's tables or call your app's
functions unless you pass them in explicitly.

You can read about the full vision in
[Convex: The Software-Defined Database](https://stack.convex.dev/the-software-defined-database#introducing-convex-components)

The Convex team has built a few components that add new features to your
backend. You'll eventually be able to author your own components to use within
your project and to share with the community, but we haven't stabilized and
documented the authoring APIs yet.

Each component is installed as its own independent library from NPM. Check out
the component's README for installation and usage instructions. You can see the
full directory on the [Convex website](https://convex.dev/components).

<CardLink
  className="convex-hero-card"
  item={{
    href: "https://convex.dev/components",
    label: "Full Components Directory",
  }}
/>

## Durable Functions

<ComponentCardList
  items={[
    {
      type: "link",
      href: "https://www.convex.dev/components/workflow",
      label: "Workflow",
      description: "Async code flow as durable functions.",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/workpool",
      label: "Workpool",
      description: "Async durable function queue.",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/crons",
      label: "Crons",
      description: "Dynamic runtime cron management",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/retrier",
      label: "Action Retrier",
      description: "Retry failed external calls automatically",
    },
  ]}
/>

## Database

<ComponentCardList
  items={[
    {
      type: "link",
      href: "https://www.convex.dev/components/sharded-counter",
      label: "Sharded Counter",
      description: "High-throughput counter operations",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/migrations",
      label: "Migrations",
      description: "Define and run migrations",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/aggregate",
      label: "Aggregate",
      description: "Efficient sums and counts",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/geospatial",
      label: "Geospatial (Beta)",
      description: "Store and search locations",
    },
  ]}
/>

## Integrations

<ComponentCardList
  items={[
    {
      type: "link",
      href: "https://www.convex.dev/components/cloudflare-r2",
      label: "Cloudflare R2",
      description: "Store and serve files",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/prosemirror-sync",
      label: "Collaborative Text Editor Sync",
      description: "Real-time collaborative text editing",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/push-notifications",
      label: "Expo Push Notifications",
      description: "Send mobile push notifications",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/twilio",
      label: "Twilio SMS",
      description: "Send and receive SMS messages",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/launchdarkly",
      label: "LaunchDarkly Feature Flags",
      description: "Sync feature flags with backend",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/polar",
      label: "Polar",
      description: "Add subscriptions and billing",
    },
  ]}
/>

## Backend

<ComponentCardList
  items={[
    {
      type: "link",
      href: "https://www.convex.dev/components/agent",
      label: "AI Agent",
      description: "Define agents with tools and memory",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/persistent-text-streaming",
      label: "Persistent Text Streaming",
      description: "Stream and store text data",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/rate-limiter",
      label: "Rate Limiter",
      description: "Control resource usage rates",
    },
    {
      type: "link",
      href: "https://www.convex.dev/components/action-cache",
      label: "Action Cache",
      description: "Cache expensive external calls",
    },
  ]}
/>

<Admonition type="caution" title="The component authoring APIs are in Beta">
  The underlying authoring APIs for components are still in flux. The Convex
  team authored components listed below will be kept up to date as the APIs
  change.
</Admonition>

## Understanding Components

Components can be thought of as a combination of concepts from frontend
components, third party APIs, and both monolith and service-oriented
architectures.

### Data

Similar to frontend components, Convex Components encapsulate state and behavior
and allow exposing a clean interface. However, instead of just storing state in
memory, these can have internal state machines that can persist between user
sessions, span users, and change in response to external inputs, such as
webhooks. Components can store data in a few ways:

- Database tables with their own schema validation definitions. Since Convex is
  realtime by default, data reads are automatically reactive, and writes commit
  transactionally.
- File storage, independent of the main app's file storage.
- Durable functions via the built-in function scheduler. Components can reliably
  schedule functions to run in the future and pass along state.

Typically, libraries require configuring a third party service to add stateful
off-the-shelf functionality, which lack the transactional guarantees that come
from storing state in the same database.

### Isolation

Similar to regular npm libraries, Convex Components include functions, type
safety, and are called from your code. However, they also provide extra
guarantees.

- Similar to a third-party API, components can't read data for which you don't
  provide access. This includes database tables, file storage, environment
  variables, scheduled functions, etc.
- Similar to service-oriented architecture, functions in components are run in
  an isolated environment, so they can't read or write global variables or patch
  system behavior.
- Similar to a monolith architecture, data changes commit transactionally across
  calls to components, without having to reason about complicated distributed
  commit protocols or data inconsistencies. You'll never have a component commit
  data but have the calling code roll back.
- In addition, each mutation call to a component is a sub-mutation isolated from
  other calls, allowing you to safely catch errors thrown by components. It also
  allows component authors to easily reason about state changes without races,
  and trust that a thrown exception will always roll back the Component's
  sub-mutation. [Read more](/components/using.mdx#transactions).

### Encapsulation

Being able to reason about your code is essential to scaling a codebase.
Components allow you to reason about API boundaries and abstractions.

- The transactional guarantees discussed above allows authors and users of
  components to reason locally about data changes.
- Components expose an explicit API, not direct database table access. Data
  invariants can be enforced in code, within the abstraction boundary. For
  example, the [aggregate component](https://convex.dev/components/aggregate)
  can internally denormalize data, the
  [rate limiter](https://convex.dev/components/rate-limiter) component can shard
  its data, and the
  [push notification](https://convex.dev/components/push-notifications)
  component can internally batch API requests, while maintaining simple
  interfaces.
- Runtime validation ensures all data that cross a component boundary are
  validated: both arguments and return values. As with normal Convex functions,
  the validators also specify the TypeScript types, providing end-to-end typing
  with runtime guarantees.


---

# data.md

<!-- Source: dashboard/deployments/data.md -->

---
title: "Data"
slug: "data"
sidebar_position: 5
---

![Data Dashboard Page](/screenshots/data.png)

The [data page](https://dashboard.convex.dev/deployment/data) allows you to view
and manage all of your tables and documents.

On the left side of the page is a list of your tables. Clicking on a table will
allows you to create, view, update, and delete documents in that table.

You may drag-and-drop the column headers in each table to visually re-order the
data.

A readonly view of the data page is available in the
[command line](/cli.md#display-data-from-tables).

```sh
npx convex data [table]
```

## Filtering documents

You may filters documents on the data page by clicking the "Filter" button on
the top of the page.

![Data filters](/screenshots/data_filters.png)

All fields in a document are filterable by the operations supported in Convex
query syntax. [Equality](/database/reading-data/filters.mdx#equality-conditions)
and [comparisons](/database/reading-data/filters.mdx#comparisons) share the same
rules when filtering in the dashboard as a query using the Convex client. You
may also filter based on the type of the field.

To add a filter, click the `+` next to an existing filter. If you add more than
one condition, they will be evaluated using the `and` operation.

For each filter, you must select a field to filter by, operation, and comparison
value. In the third input box (selecting a value), you may enter a valid Convex
value, such as `"a string"`, `123`, or even a complex object, such as
`{ a: { b: 2 } }`

<Admonition type="note">

When filtering by `_creationTime`, a date picker will be displayed instead of
the normal JavaScript syntax input box. Comparisons for `_creationTime` are made
at the nanosecond granularity, so if you'd like to filter to an exact time, try
adding two filter conditions for `creationTime >= $time` and
`creationTime <= $time + 1 minute`.

</Admonition>

## Writing custom queries

You can write a [query](/database/reading-data/reading-data.mdx) directly in the
dashboard. This allows you to perform arbitrary filtering and transformation of
the data, including sorting, joins, grouping and aggregations.

In the `⋮` overflow menu at the top of the data page click on the “Custom query”
option.

<img
    src="/screenshots/data_custom_query.png"
    alt="Custom query button"
    width={250}
/>

This opens the same UI used for
[running your deployed functions](/dashboard/deployments/functions.md#running-functions),
but with the “Custom test query” option selected, which lets you edit the source
code for the query. This source code will be sent to your deployment and
executed when you click on the “Run Custom Query“ button.

![Running a custom test query](/screenshots/data_custom_query_runner.png)

If you're not on the data page, you can still open this UI via the persistent
_fn_ button shown on the bottom right of all deployment pages. The keyboard
shortcut to open the function runner is Ctrl + ` (backtick).

## Creating tables

You may create a table from the dashboard by clicking the "Create Table" button
and entering a new name for the table.

## Creating documents

You may add individual documents to the table using the “Add Documents” button
located in the data table's toolbar.

Once you click “Add Documents” a side panel will open, allowing you to add new
documents to your table using JavaScript syntax. To add more than one document
add a time, add new objects to the array in the editor.

![Add document](/screenshots/data_add_document.png)

## Quick actions (context menu)

You can right-click on a document or value to open a context menu with quick
actions, like copying values, quickly filtering by the selected value, and
deleting documents.

![Quick actions context menu](/screenshots/data_context_menu.png)

## Editing a cell

To edit a cell's value, double-click on the cell in the data table, or press the
Enter key while it’s selected. You can change the selected cell by using the
arrow keys.

You can change the value by editing inline, and pressing enter to save.

<Admonition type="note">

You can even edit the type of your value here, as long as it satisfies your
[schema](/database/schemas.mdx) — try replacing a string with an object!

</Admonition>

![Inline value editor](/screenshots/data_edit_inline.png)

## Editing a document

To edit multiple fields in a document at the same time, hover over the document
and right-click to open the context menu. From there you can click on "Edit
Document".

![Edit entire document](/screenshots/data_edit_document.png)

## Adding references to other documents

To reference another document, use the string ID of the document you want to
reference.

You can copy the ID by clicking on its cell and pressing CTRL/CMD+C.

## Bulk editing documents

You can edit multiple or all documents at once. To select all documents click on
the checkbox in the table header row. To select individual documents hover over
the left-most cell and click the checkbox that appears. To select multiple
adjacent documents at once, press the Shift key when clicking on the checkbox.

When at least one document is selected, the “(Bulk) Edit Document(s)” button
will be visible in the table toolbar. Click the button and an editor will appear
on the right hand side.

![Bulk edit documents](/screenshots/data_bulk_edit.png)

## Deleting documents

When at least one document is selected (see above), the “Delete Document(s)”
button will be visible in the table toolbar. Click the button to delete
documents. If you're editing data in a production deployment a confirmation
dialog will appear before the documents are deleted.

## Clear a table

You can also delete all documents by clicking on the `⋮` overflow menu at the
top of the data page and clicking "Clear Table". This action will delete all
documents in the table, without deleting the table itself.

In production environments, the Convex dashboard will have you type in the name
of the table before deletion.

## Delete a table

<Admonition type="caution" title="This is a permanent action">

Deleting a table is irreversible. In production environments, the Convex
dashboard will have you type in the name of the table before deletion.

</Admonition>

The "Delete table" button can be found by clicking on the `⋮` overflow menu at
the top of the data page. This action will delete all documents this table, and
remove the table from your list of tables. If this table had indexes, you will
need to redeploy your convex functions (by running `npx convex deploy` or
`npx convex dev` for production or development, respectively) to recreate the
indexes.

## Generating a schema

At the bottom-left of the page is a "Generate Schema" button which you can click
to have Convex generate a [schema](/database/schemas.mdx) of all your documents
within this table.

![Generate Schema button](/screenshots/data_generate_schema.png)

## Table Schema and Indexes

The "Schema and Indexes" button can be found by clicking on the `⋮` overflow
menu at the top of the data page.

This button will open a panel showing the saved [schema](/database/schemas.mdx)
and [indexes](/database/reading-data/indexes/indexes.md) associated with the
selected table.

Indexes that have not completed backfilling will be accompanied by a loading
spinner next to their name.

![Table indexes](/screenshots/data_indexes.png)


---

# deployments.md

<!-- Source: dashboard/deployments/deployments.md -->

---
title: "Deployments"
id: "deployments"
sidebar_position: 20
---

Each project in Convex has a main production deployment, and each developer on
your team can also set up their own personal development deployment.
Additionally, there are
[preview deployments](/production/hosting/preview-deployments.mdx) used to test
backend changes before they're deployed to production.

While on a [deployment page](https://dashboard.convex.dev/deployment), you may
switch between production, your development deployment, and any preview
deployments by using the dropdown menu on the top-left of the page.

![Deployment switcher](/screenshots/deployment_menu.png)


---

# files.md

<!-- Source: dashboard/deployments/files.md -->

---
title: "File Storage"
sidebar_label: "Files"
slug: "file-storage"
sidebar_position: 20
---

The [file storage page](https://dashboard.convex.dev/deployment/files) displays
[files stored in your deployment](/file-storage.mdx). The page also shows the
files' storage IDs, size, and content type. You can upload new files and
download or delete existing files.

Storage IDs might be referenced by documents in your database.

<Admonition type="tip">

When new files are uploaded, the UI will reference the name of the recently
uploaded file. However, these names are not persisted and will no longer appear
when the page is reloaded.

</Admonition>

![File Storage button](/screenshots/file_storage.png)


---

# functions.md

<!-- Source: dashboard/deployments/functions.md -->

---
title: "Functions"
slug: "functions"
sidebar_position: 10
---

![Functions Dashboard View](/screenshots/functions.png)

The [functions page](https://dashboard.convex.dev/deployment/functions) shows
all currently deployed Convex functions.

For dev deployments, these are updated continuously by
[`npx convex dev`](/cli.md#run-the-convex-dev-server). The functions for
production deployments are registered with
[`npx convex deploy`](/cli.md#deploy-convex-functions-to-production).

## Running functions

To run a Convex function in the dashboard, select a function from the list on
the left-hand side of the page, and click the "Run Function" button that appears
next to the function's name.

If you're not on the functions page, you can still open this UI via the
persistent _fn_ button shown on the bottom right of all deployment pages. The
keyboard shortcut to open the function runner is Ctrl + ` (backtick).

This view allows you to fill out the arguments for your function and run it.

Query results will update automatically as you modify function arguments and
data changes.

Mutation and action results will be visible once you click the "Run" button.

Note that these results will show the logs and value returned from the function.
To see what changed when you ran your function, see the
[data page](/dashboard/deployments/data.md).

![Running a function](/screenshots/run_function.png)

You can also
[write a custom query function](/dashboard/deployments/data.md#writing-custom-queries)
by choosing the “Custom test query“ option instead of one of your deployed
functions.

### Querying a paginated function

When querying a paginated function in the dashboard, the UI will expect the
arguments to include
[`PaginationOptions`](/api/interfaces/server.PaginationOptions) -- i.e. an
object containing the `numItems` field, and optionally the `cursor` field. The
name of this argument should be the same as the name defined in your query
function.

- `numItems` should be the number of items to include in a page
- `cursor` can be left blank to begin pagination. Once you receive results, you
  may set `cursor` to the result's `continueCursor` field to proceed to the next
  page.

### Assuming a user identity

<Admonition type="tip">

Assuming a user identity in the Convex dashboard does not give you access to a
real user identity. Instead, this concept can be thought of as "mocking" a user
identity into your function.

</Admonition>

If you're building an authenticated application, you may want to run a Convex
function while acting as an authenticated user identity.

To do so, check the "Act as a user" box.

From there, you can type in the box that appears to fill out the user identity
object.

![Acting as a user](/screenshots/acting_as_a_user.png)

The valid user attributes are:

| Attribute           | Type                                     |
| ------------------- | ---------------------------------------- |
| subject\*           | string                                   |
| issuer\*            | string                                   |
| name                | string                                   |
| givenName           | string                                   |
| familyName          | string                                   |
| nickname            | string                                   |
| preferredUsername   | string                                   |
| profileUrl          | string                                   |
| email               | string                                   |
| emailVerified       | boolean                                  |
| gender              | string                                   |
| birthday            | string                                   |
| timezone            | string                                   |
| language            | string                                   |
| phoneNumber         | string                                   |
| phoneNumberVerified | boolean                                  |
| address             | string                                   |
| updatedAt           | string (in the form of an RFC 3339 date) |
| customClaims        | object                                   |

\*These attributes are required.

## Metrics

There are four basic charts for each function. For overall team usage metrics,
see [team settings](/dashboard/teams.md#usage).

### Invocations

This chart plots the number of times your function was called per minute. As
your app's usage increases, you should see this chart trend upward as well.

### Errors

A plot of any exceptions that occur while running your function. Want to know
what's going wrong? Check out the logs page, detailed below.

### Cache Hit Rate

<Admonition type="tip">
Cache hit rate only applies to query functions
</Admonition>

A percentage rate of how often this function is simply reusing a cached value
vs. being rerun. Your application will run best and your response times will be
fastest with high cache hit rates.

### Execution Time

How long, in milliseconds, this function is taking to run.

There are four individual lines plotted on this chart, p50, p90, p95, and p99.
Each of these lines represents the response time for that percentile in the
distribution of hits over time. So, only 1% of requests took longer to run than
the time shown by the p99 line. Typically, keeping an eye on these _tail
latencies_ is a good way to make sure your application is getting data services
quickly.

Consider the relationship of the execution time to the cache hit rate. As a
rule, a cache hit takes well under 1 ms, so the higher your cache hit rate, the
better your response times will be.

Clicking on any of the charts will give you a larger, detailed view where you
can customize the time ranges you're inspecting.


---

# health.md

<!-- Source: dashboard/deployments/health.md -->

---
title: "Health"
slug: "health"
sidebar_position: 0
---

The [health page](https://dashboard.convex.dev/deployment/) is the landing page
for your deployment. On this page, you can see some important information about
the health of your deployment.

## Failure Rate

![Failure Rate Card](/screenshots/health_failure_rate.png)

The failure rate card shows the percentage of failed request by minute ove the
last hour. The failure rate is calculated as the number of failed requests
divided by the total number of requests.

## Cache Hit Rate

![Cache Hit Rate Card](/screenshots/health_cache_hit_rate.png)

The cache hit rate card shows the percentage of cache hits by minute over the
last hour. The cache hit rate is calculated as the number of cache hits divided
by the total number of requests.

Cache hit rate only applies to query functions.

## Scheduler Status

![Scheduler Status Card](/screenshots/scheduler_overdue.png)

The scheduler status card shows the status of the
[scheduler](/scheduling/scheduled-functions). If the scheduler falls behind due
to too many scheduled tasks, the status will show as "Overdue", displaying the
lag time in minutes.

You may click the button in the top right corner of the card to view a chart
showing the scheduler status over the last hour.

![Scheduler Status Chart](/screenshots/scheduler_status.png)

## Last Deployed

![Last Deployed Card](/screenshots/health_last_deployed.png)

The last deployed card shows the time of the last time your functions were
deployed.

## Integrations

<Admonition type="info">

Integrations are only available for paid teams.

</Admonition>

![Last Deployed Card](/screenshots/health_integrations.png)

The integrations card shows the status of your
[Exception Reporting](/production/integrations/exception-reporting) and
[Log Streams](/production/integrations/log-streams) integrations, with quick
links to view and configure your integrations.

## Insights

![Insights Card](/screenshots/insights.png)

The Health page also surfaces insights about your deployment, with suggestions
on how to improve performance and reliability.

Each Insight contains a description of the issue, the impact on your deployment
(via a chart and event log), and a link to learn more about the issue and how to
resolve it.

Clicking on an Insight will open a breakdown of the issue, including a larger
chart and a list of events that triggered the Insight.

![Insight Breakdown](/screenshots/insights_breakdown.png)

Available insights include:

- Functions that are
  [reading too many bytes](/production/state/limits#transactions) in a single
  transaction.
- Functions that are
  [reading too many documents](/production/state/limits#transactions) in a
  single transaction.
- Functions that are experiencing [write conflicts](/error#1).


---

# history.md

<!-- Source: dashboard/deployments/history.md -->

---
title: "History"
slug: "history"
sidebar_position: 50
---

![History Dashboard Page](/screenshots/history.png)

<Admonition type="info">

The history page is only available for paid teams.

</Admonition>

This [history page](https://dashboard.convex.dev/deployment/history) is an audit
log of configuration-related events that have occurred in the selected
deployment, such as function deployments, changes to indexes, and changes to
environment variables.

You may also view an audit log of team-related events in the
[team audit log](/dashboard/teams.md#audit-log).


---

# logs.md

<!-- Source: dashboard/deployments/logs.md -->

---
title: "Logs"
slug: "logs"
sidebar_position: 40
---

![Logs Dashboard Page](/screenshots/logs.png)

The [logs page](https://dashboard.convex.dev/deployment/logs) is a realtime view
of all activity that occurs within your deployment.

The logs page provides a short history of recent function logs, and will display
new logs as they are generated. To store a longer history of logs, you may
configure a [log stream](/production/integrations/log-streams/log-streams.mdx).

Function activity includes:

- The time of function execution.
- The request ID of the function execution.
- The outcome of the function execution (success or failure).
- The name of the invoked function.
- The output of the function, including any log lines logged by the function (ex
  `console.log`) and exceptions.
- The duration of function execution, in milliseconds (does not include network
  latency).

In addition to function activity,
[deployment events](/dashboard/deployments/history.md) describing configuration
changes will be present here.

Clicking on log will open a view for all logs associated with the same Request
ID as the selected log. This can be useful for debugging errors and
understanding the context of a function execution.

![Request ID Logs](/screenshots/request_logs.png)

You can use controls on the top of this page to filter logs by text, function
name, execution status, and log severity.

### Filter logs

Use the "Filter logs..." text box on the top of the page to filter log text.

You can use the “Functions” drop-down list to include or exclude functions from
the results.

You can also find logs for a particular error using "Filter logs" and the
[Convex request id](/functions/error-handling/error-handling.mdx#debugging-errors).
For example if you see this `Error` in your browser console:

![Browser Error](/screenshots/console_error_requestid.png)

You can view the logs for that function in your dashboard by pasting that
Request ID into the 'Search logs...' search bar on the
[Logs](/dashboard/deployments/logs.md) page of your Convex dashboard. Note that
because this page is not a complete historical view of logs, you may not find
logs for older requests.

Most error reporting services and log sinks should also be searchable by Request
ID.

### Log Types

Logs can also be filtered by type. Types include function outcomes (success or
failure) and severity levels (info, warn, debug, error).

All failed executions will include a reason, which will usually be a JavaScript
exception.


---

# schedules.md

<!-- Source: dashboard/deployments/schedules.md -->

---
title: "Schedules"
slug: "schedules"
sidebar_position: 30
---

The [schedules page](https://dashboard.convex.dev/deployment/schedules) displays
all [scheduled functions](docs/scheduling/scheduled-functions.mdx) and
[cron jobs](/scheduling/cron-jobs.mdx) in your deployment. Use the tabs at the
top of this page to switch between scheduled functions and cron jobs.

## Scheduled functions UI

The scheduled functions UI shows a list of all upcoming function invocation.
From here, you can filter to scheduled runs for a specific function, and cancel
scheduled functions runs.

![Scheduled functions](/screenshots/scheduled_functions.png)

## Cron jobs UI

The cron jobs UI lists all of your cron jobs, including their run frequency and
scheduled run time.

![Cron jobs](/screenshots/cron_jobs.png)

Expanding a specific cron job will open the execution history for the selected
job.

![Cron job history](/screenshots/cron_job_history.png)


---

# settings.md

<!-- Source: dashboard/deployments/settings.md -->

---
title: "Settings"
slug: "deployment-settings"
sidebar_position: 60
---

The [deployment settings page](https://dashboard.convex.dev/deployment/settings)
gives you access to information and configuration options related to a specific
deployment (**production**, your personal **development** deployment, or a
**preview** deployment).

## URL and Deploy Key

The [URL and deploy key page](https://dashboard.convex.dev/deployment/settings)
shows:

- The URL this deployment is hosted at. Some Convex integrations may require the
  deployment URL for configuration.
- The URL that HTTP Actions for this deployment should be sent to.
- The deployment's deploy key, used to
  [integrate with build tools such as Netlify and Vercel](/production/hosting/hosting.mdx)
  and
  [syncing data with Fivetran and Airbyte](/production/integrations/streaming-import-export.md).

![Deployment Settings Dashboard Page](/screenshots/deployment_settings.png)

## Environment Variables

The
[environment variables page](https://dashboard.convex.dev/deployment/settings/environment-variables)
lets you add, change, remove and copy the deployment's
[environment variables](/production/environment-variables.mdx).

![deployment settings environment variables page](/screenshots/deployment_settings_env_vars.png)

## Authentication

The
[authentication page](https://dashboard.convex.dev/deployment/settings/authentication)
shows the values configured in your `auth.config.js` for user
[authentication](/auth.mdx) implementation.

## Backup & Restore

The
[backup & restore page](https://dashboard.convex.dev/deployment/settings/backups)
lets you [backup](/database/backup-restore.mdx) the data stored in your
deployment's database and file storage. On this page, you can schedule periodic
backups.

![deployment settings export page](/screenshots/backups.png)

## Integrations

The integrations page allows you to configure
[log streaming](/production/integrations/integrations.mdx),
[exception reporting](/production/integrations/integrations.mdx), and
[streaming export](/production/integrations/streaming-import-export.md)
integrations.

## Pause Deployment

On the
[pause deployment page](https://dashboard.convex.dev/deployment/settings/pause-deployment)
you can [pause your deployment](/production/pause-deployment.mdx) with the pause
button.

![deployment settings pause deployment page](/screenshots/deployment_settings_pause.png)


---

# projects.md

<!-- Source: dashboard/projects.md -->

---
title: "Projects"
slug: "projects"
sidebar_position: 10
---

![Project settings](/screenshots/projects.png)

A project corresponds to a codebase that uses Convex, which contains a
production deployment and one personal deployment for each team member.

Clicking on a project in the [landing page](https://dashboard.convex.dev) will
redirect you to project details.

## Creating a project

Projects can be created from the dashboard or from the
[CLI](/cli.md#create-a-new-project). To create a project from the dashboard
click on the Create Project button.

## Project Settings

You can access project-level settings by clicking on the triple-dot `⋮` button
on each Project card on the Projects page.

![Project card menu](/screenshots/project_menu.png)

On the [Project Settings page](https://dashboard.convex.dev/project/settings),
you can:

- Update your project's name and slug.
- Manage the project's Admins. See
  [Roles and Permissions](/dashboard/teams.md#roles-and-permissions) for more
  details.
- View the amount of [usage metrics](/dashboard/teams.md#usage) your project has
  consumed.
- Add [custom domains](/production/hosting/custom.mdx#custom-domains) for your
  production deployment
- Generate deploy keys for your production and preview deployments.
- Create and edit
  [default environment variables](/production/environment-variables.mdx#project-environment-variable-defaults).
- View instructions to regain access to your project, should you lose track of
  your `CONVEX_DEPLOYMENT` config.
- Permanently delete the project.

![Project settings](/screenshots/project_settings.png)

## Deleting projects

To delete a project, click on the triple-dot `⋮` button on the Project card and
select "Delete". You may also delete your project from the Project Settings
page.

Once a project is deleted, it cannot be recovered. All deployments and data
associated with the project will be permanently removed. When deleting a project
from the dashboard, you will be asked to confirm the deletion. Projects with
activity in the production deployment will have additional confirmation steps to
prevent accidental deletion.

![Delete project](/screenshots/project_delete.png)


---

# teams.md

<!-- Source: dashboard/teams.md -->

---
title: "Teams"
slug: "teams"
sidebar_position: 0
---

In Convex, your projects are organized by team. Teams are used to share access
to your projects with other people. You may switch between teams or create a new
team by clicking on the name of your team located on the top of the Convex
dashboard. This will open the project selector, where you can switch teams by
clicking on the team name once again.

![Team switcher](/screenshots/team_selector.png)

You may change the name of a team or invite new members to a team by clicking on
the "Team Settings" button located on the top of the project list page.

## General

The [general page](https://dashboard.convex.dev/team/settings) allows changing
the team name and slug.

You may also delete the team from this page. You can only delete a team after
deleting all of it's projects, and removing all other team members from your
team. Deleting your team will automatically cancel your Convex subscription.

![General team settings page](/screenshots/teams_general.png)

## Team Members

Use the
[members settings page](https://dashboard.convex.dev/team/settings/members) to
invite or remove members from your team.

![Team members page](/screenshots/teams_members.png)

### Roles and permissions

Convex has two levels of control for managing access to your team, projects, and
deployments. Team-level roles control what a user can do within the team, while
project-level permissions control what a user can do within a specific project.

#### Team roles

Your team members can have one of the following roles:

- Admin
- Developer

The creator of the team is automatically assigned the Admin role. When inviting
new team members, you may select a role for them. You may also change the role
of a team member at any time.

Developers can:

- Create new projects and deployments. When a new project is created, the
  creator of the project is automatically granted the
  [Project Admin](#project-admins) role for that project.
- View existing projects, and create development and preview deployments for
  these projects. Developers may read data from production deployments, but
  cannot write to them.
- View the team's usage and billing status (such as previous and upcoming
  invoices)

Admins can do everything developers can, as well as:

- Invite new team members
- Remove members from the team
- Change the role of other team members
- Manage the team's Convex subscription and billing details.
- Change the team name and slug
- Team Admins are also implicitly granted project admin access to all projects
  within the team. See [Project Admins](#project-admins) for more information.

#### Project Admins

In addition to team roles, you may also grant admin access to individual
projects by granting team members the "Project Admin" role.

If you are a Project Admin for a given project, you may:

- Update the project name and slug
- Update the project's default environment variables
- Delete the project
- Write to production deployments

You may assign and remove the Project Admin role for multiple projects at the
same time on the member settings page. To assign or remove the Project Admin
role for multiple members at the same time, visit the
[Project Settings](/dashboard/projects.md#project-settings) page instead.

## Billing

Use the [billing page](https://dashboard.convex.dev/team/settings/billing) to
upgrade your Convex subscription to a higher tier, or manage your existing
subscription.

On paid plans, you can also update your billing contact details, payment method,
and view your invoices.

[Learn more about Convex pricing](https://www.convex.dev/pricing).

![Team billing page](/screenshots/teams_billing.png)

### Spending limits

When you have an active Convex subscription, you can set the spending limits for
your team on the
[billing page](https://dashboard.convex.dev/team/settings/billing):

- The **warning threshold** is only a soft limit: if it is exceeded, the team
  will be notified by email, but no other action will be taken.
- The **disable threshold** is a hard limit: if it is exceeded, all projects in
  the team will be disabled. This will cause errors to be thrown when attempting
  to run functions in your projects. You can re-enable projects by increasing or
  removing the limit.

Spending limits only apply to the resources used by your team’s projects beyond
the amounts included in your plan. The seat fees (the amount paid for each
developer in your team) are not counted towards the limits. For instance, if you
send the spending limit to $0/month, you will be billed for the seat fees only
and the projects will be disabled if you exceed the built-in resources included
in your plan.

![The team billing page with some spending limits set.](/screenshots/teams_billing_spending_limits.png)

## Usage

On the [usage page](https://dashboard.convex.dev/team/settings/usage) you can
see all the resources consumed by your team, and how you're tracking against
your plan's limits.

[Learn more about Convex pricing](https://www.convex.dev/pricing).

![Team usage page](/screenshots/teams_usage.png)

All metrics are available in daily breakdowns:

![Team usage page graphs](/screenshots/teams_usage_2.png)

## Audit Log

<Admonition type="info">

The Audit Log is only available for paid teams.

</Admonition>

The [audit log page](https://dashboard.convex.dev/team/settings/audit-log) shows
all the actions taken by members within the team. This includes creating and
managing projects and deployments, inviting and removing team members, and more.

![Team audit log page](/screenshots/teams_audit_log.png)

You may also view a history of deployment-related events on the
[deployment history page](/dashboard/deployments/history.md).


---

# dashboard.md

<!-- Source: dashboard.md -->

---
title: "Dashboard"
id: "dashboard"
---

![Dashboard Projects View](/screenshots/projects.png)

[The dashboard](https://dashboard.convex.dev/) is the central hub for managing
your Convex projects. Here you can create and manage your Convex teams,
projects, and deployments.


---

# occ.md

<!-- Source: database/advanced/occ.md -->

---
title: "OCC and Atomicity"
slug: "occ"
hidden: false
sidebar_position: 500
todo: Push under mutations, or inline, or kill (move to Stack)
---

In [Queries](/functions/query-functions.mdx), we mentioned that determinism as
important in the way optimistic concurrency control (OCC) was used within
Convex. In this section, we'll dive much deeper into _why_.

## Convex Financial, Inc.

Imagine that you're building a banking app, and therefore your databases stores
accounts with balances. You want your users to be able to give each other money,
so you write a mutation function that transfers funds from one user's account to
another.

One run of that transaction might read Alice's account balance, and then Bob's.
You then propose to deduct $5 from Alice's account and increase Bob's balance by
the same $5.

Here's our pseudocode:

```
$14 <- READ Alice
$11 <- READ Bob
WRITE Alice $9
WRITE Bob $16
```

This ledger balance transfer is a classic database scenario that requires a
guarantee that these write operations will only apply together. It is a really
bad thing if only one operation succeeds!

```
$14 <- READ Alice
$11 <- READ Bob
WRITE Alice $9
*crash* // $5 lost from your bank
```

You need a guarantee that this can never happen. You require transaction
atomicity, and Convex provides it.

The problem of data correctness is much deeper. Concurrent transactions that
read and edit the same records can create _data races_.

In the case of our app it's entirely possible that someone deducts Alice's
balance right after we read it. Maybe she bought a Coke Zero at the airport with
her debit card for $3.

```
$5 Transfer                           $3 Debit Card Charge
----------------------------------------------------------
$14 <- READ Alice
$11 <- READ Bob
                                        $14 <- READ Alice
                                        WRITE Alice $11
WRITE Alice $9 // Free coke!
WRITE Bob $16
```

Clearly, we need to prevent these types of data races from happening. We need a
way to handle these concurrent conflicts. Generally, there are two common
approaches.

Most traditional databases choose a _pessimistic locking_ strategy. (Pessimism
in this case means the strategy assumes conflict will happen ahead of time so
seeks to prevent it.) With pessimistic locking, you first need to acquire a lock
on Alice's record, and then acquire a lock on Bob's record. Then you can proceed
to conduct your transaction, knowing that any other transaction that needed to
touch those records will wait until you are done and all your writes are
committed.

After decades of experience, the drawbacks of pessimistic locking are well
understood and undeniable. The biggest limitation arises from real-life networks
and computers being inherently unreliable. If the lock holder goes missing for
whatever reason half way through its transaction, everyone else that wants to
modify any of those records is waiting indefinitely. Not good!

Optimistic concurrency control is, as the name states, optimistic. It assumes
the transaction will succeed and doesn't worry about locking anything ahead of
time. Very brash! How can it be so sure?

It does this by treating the transaction as a _declarative proposal_ to write
records on the basis of any read record versions (the "read set"). At the end of
the transaction, the writes all commit if every version in the read set is still
the latest version of that record. This means no concurrent conflict occurred.

Now using our version read set, let's see how OCC would have prevented the
soda-catastrophe above:

```
$5 Transfer                           $3 Debit Card Charge
----------------------------------------------------------
(v1, $14) <- READ Alice
(v7, $11) <- READ Bob
                                        (v1, $14) <- READ Alice
                                        WRITE Alice $11
                                        IF Alice.v = v1

WRITE Alice = $9, Bob = $16
    IF Alice.v = v1, Bob.v = v7 // Fails! Alice is = v2
```

This is akin to being unable to push your Git repository because you're not at
HEAD. We all know in that circumstance, we need to pull, and rebase or merge,
etc.

## When OCC loses, determinism wins

A naive optimistic concurrency control solution would be to solve this the same
way that Git does: require the user/application to resolve the conflict and
determine if it is safe to retry.

In Convex, however, we don't need to do that. We know the transaction is
deterministic. It didn't charge money to Stripe, it didn't write a permanent
value out to the filesystem. It had no effect at all other than proposing some
atomic changes to Convex tables that were not applied.

The determinism means that we can simply re-run the transaction; you never need
to worry about temporary data races. We can run several retries if necessary
until we succeed to execute the transaction without any conflicts.

<Admonition type="tip">

In fact, the Git analogy stays very apt. An OCC conflict means we cannot push
because our HEAD is out of date, so we need to rebase our changes and try again.
And determinism is what guarantees there is never a "merge conflict", so (unlike
with Git) this rebase operation will always eventually succeed without developer
intervention.

</Admonition>

## Snapshot Isolation vs Serializability

It is common for optimistic multi-version concurrency control databases to
provide a guarantee of
[snapshot isolation](https://en.wikipedia.org/wiki/Snapshot_isolation). This
[isolation level](<https://en.wikipedia.org/wiki/Isolation_(database_systems)>)
provides the illusion that all transactions execute on an atomic snapshot of the
data but it is vulnerable to
[anomalies](https://en.wikipedia.org/wiki/Snapshot_isolation#Definition) where
certain combinations of concurrent transactions can yield incorrect results. The
implementation of optimistic concurrency control in Convex instead provides true
[serializability](https://en.wikipedia.org/wiki/Serializability) and will yield
correct results regardless of what transactions are issued concurrently.

## No need to think about this

The beauty of this approach is that you can simply write your mutation functions
as if they will _always succeed_, and always be guaranteed to be atomic.

Aside from sheer curiosity about how Convex works, day to day there's no need to
worry about conflicts, locking, or atomicity when you make changes to your
tables and documents. The "obvious way" to write your mutation functions will
just work.


---

# schema-philosophy.md

<!-- Source: database/advanced/schema-philosophy.md -->

---
title: Schema Philosophy
sidebar_position: 450
---

With Convex there is no need to write any `CREATE TABLE` statements, or think
through your stored table structure ahead of time so you can name your field and
types. You simply put your objects into Convex and keep building your app!

However, moving fast early can be problematic later. "Was that field a number or
a string? I think I changed it when I fixed that one bug?"

Storage systems which are too permissive can sometimes become liabilities as
your system matures and you want to be able to reason assuredly about exactly
what data is in your system.

The good news is Convex is always typed. It's just implicitly typed! When you
submit a document to Convex, tracks all the types of all the fields in your
document. You can go to your [dashboard](/dashboard.md) and view the inferred
schema of any table to understand what you've ended up with.

"What about that field I changed from a string to a number?" Convex can handle
this too. Convex will track those changes, in this case the field is a union
like `v.union(v.number(), v.string())`. That way even when you change your mind
about your documents fields and types, Convex has your back.

Once you are ready to formalize your schema, you can define it using our
[schema builder](/database/schemas.mdx) to enable schema validation and generate
types based on it.


---

# system-tables.mdx

<!-- Source: database/advanced/system-tables.mdx -->

---
title: "System Tables"
sidebar_position: 1
---

System tables enable read-only access to metadata for built-in Convex features.
Currently there are two system tables exposed:

- `"_scheduled_functions"` table contains metadata for
  [scheduled functions](/scheduling/scheduled-functions.mdx#retrieving-scheduled-function-status)
- `"_storage"` table contains metadata for
  [stored files](/file-storage/file-metadata.mdx)

You can read data from system tables using the `db.system.get` and
`db.system.query` methods, which work the same as the standard `db.get` and
`db.query` methods. Queries reading from system tables are reactive and realtime
just like queries reading from all other tables, and pagination can be used to
enumerate all documents even when there are too many to read in a single query.


---

# backup-restore.mdx

<!-- Source: database/backup-restore.mdx -->

---
title: "Backup & Restore"
sidebar_position: 85
---

Convex supports Backup & Restore of data via the
[dashboard](https://dashboard.convex.dev/deployment/settings/backups).

![Backups Page](/screenshots/backups.png)

# Backups

A backup is a consistent snapshot of your table data and file storage made at
the time of your request.

Take a manual backup by pressing the "Backup Now" button. This may take a few
seconds to a few hours, depending on how much data is in your deployment.

Manual backups are stored for 7 days. You can download or delete backups via
this page.

Deployment configuration and other data (code, environment variables, scheduled
functions, etc.) will not be included.

### Periodic Backups

Schedule a periodic daily or weekly backup by checking the "Backup
automatically" box. You can select what time of day / day of week to have the
backup occur.

Daily backups are stored for 7 days. Weekly backups are stored for 14 days.

<ProFeatureUpsell feature="Periodic backups" verb="require" />

### Restoring from backup

Restore from a backup by selecting "Restore" from the submenu of an individual
backup. You can restore from backups in the same deployment or from other
deployments on the same team by using the deployment selector on the backups
page. Restores may take a few seconds to a few hours depending on how much data
is in your backup.

Note that restoring is a destructive operation that wipes your existing data and
replaces it with that from the backup. It's recommended that you generate an
additional backup before doing a restore.

### Restoring in an emergency

If your production deployment ends up in a bad state, you may want to consider
doing a restore to return to a good state. Note that getting your data to a good
state may not be enough. Consider whether you may need each of the following
actions. Depending on the nature of your emergency, these may be required.

- Take an additional backup prior to restore, since restores are destructive
- Do a restore from a good backup - to restore data
- Use `npx convex dev` to push a known version of good code.
- Use `npx convex env` or the dashboard to restore to a good set of env vars
- Use the dashboard to make any manual fixes to the database for your app.
- Write mutations to make required (more programmatic) manual fixes to the
  database for your app.

# Downloading a backup

You can download your manual and periodic backups from the dashboard via the
download button in the menu.

Alternatively, you can generate an export in the same format with the
[command line](/cli.md#export-data-to-a-file):

```sh
npx convex export --path ~/Downloads
```

The backup comes as a generated a ZIP file with all documents in all Convex
tables in your deployment.

The ZIP file's name has the format `snapshot_{ts}.zip` where `ts` is a UNIX
timestamp of the snapshot in nanoseconds. The export ZIP file contains documents
for each table at `<table_name>/documents.jsonl`, with one document per line.

Exported ZIP files also contain data from [file storage](/file-storage) in a
`_storage` folder, with metadata like IDs and checksums in
`_storage/documents.jsonl` and each file as `_storage/<id>`.

### Using the downloaded backup.

Downloaded ZIP files can be imported into the same deployment or a different
deployment
[with the CLI](/database/import-export/import.mdx#restore-data-from-a-backup-zip-file).

## FAQ

### Are there any limitations?

Each backup is accessible for up to 7 days.

On the Starter plan, up to two backups can stored per deployment at a time. Paid
plan deployments can have many backups with standard usage based pricing.

### How are they priced?

Backups uses database bandwidth to read all documents, and file bandwidth to
include user files. The generation and storage of the backup itself is billed
with the same bandwidth and storage pricing as user file storage. You can
observe this bandwidth and storage cost in the
[usage dashboard](https://dashboard.convex.dev/team/settings/usage). Check the
[limits docs](/production/state/limits#database) for pricing details.

### What does the backup not contain?

The backup only contains the documents for your tables and files in file
storage. In particular it lacks:

1. Your deployment's code and configuration. Convex functions, crons.ts,
   auth.config.js, schema.ts, etc. are configured in your source code.
2. Pending scheduled functions. You can access pending scheduled functions in
   the [`_scheduled_functions`](/database/advanced/system-tables.mdx) system
   table.
3. Environment variables. Environment variables can be copied from Settings in
   the Convex dashboard.


---

# document-ids.mdx

<!-- Source: database/document-ids.mdx -->

---
title: "Document IDs"
sidebar_position: 10
description: "Create complex, relational data models using IDs."
---

import SerializeExample from "!!raw-loader!@site/../private-demos/snippets/convex/tasks.ts";
import SerializeCall from "!!raw-loader!@site/../private-demos/snippets/src/documentIdsSerializeCall.tsx";

**Example:**
[Relational Data Modeling](https://github.com/get-convex/convex-demos/tree/main/relational-data-modeling)

Every document in convex has a globally unique string _document ID_ that is
automatically generated by the system.

```ts
const userId = await ctx.db.insert("users", { name: "Michael Jordan" });
```

You can use this ID to efficiently read a single document using the `get`
method:

```ts
const retrievedUser = await ctx.db.get(userId);
```

You can access the ID of a document in the
[`_id` field](/database/types.md#system-fields):

```ts
const userId = retrievedUser._id;
```

Also, this same ID can be used to update that document in place:

```ts
await ctx.db.patch(userId, { name: "Steph Curry" });
```

Convex generates an [`Id`](/generated-api/data-model#id) TypeScript type based
on your [schema](/database/schemas.mdx) that is parameterized over your table
names:

```typescript
import { Id } from "./_generated/dataModel";

const userId: Id<"users"> = user._id;
```

IDs are strings at runtime, but the [`Id`](/generated-api/data-model#id) type
can be used to distinguish IDs from other strings at compile time.

## References and relationships

In Convex, you can reference a document simply by embedding its `Id` in another
document:

```ts
await ctx.db.insert("books", {
  title,
  ownerId: user._id,
});
```

You can follow references with `ctx.db.get`:

```ts
const user = await ctx.db.get(book.ownerId);
```

And [query for documents](/database/reading-data/reading-data.mdx) with a
reference:

```ts
const myBooks = await ctx.db
  .query("books")
  .filter((q) => q.eq(q.field("ownerId"), user._id))
  .collect();
```

Using `Id`s as references can allow you to build a complex data model.

## Trading off deeply nested documents vs. relationships

While it's useful that Convex supports nested objects and arrays, you should
keep documents relatively small in size. In practice, we recommend limiting
Arrays to no more than 5-10 elements and avoiding deeply nested Objects.

Instead, leverage separate tables, documents, and references to structure your
data. This will lead to better maintainability and performance as your project
grows.

## Serializing IDs

IDs are strings, which can be easily inserted into URLs or stored outside of
Convex.

You can pass an ID string from an external source (like a URL) into a Convex
function and get the corresponding object. If you're using TypeScript on the
client you can cast a string to the `Id` type:

<Snippet
  title="src/App.tsx"
  source={SerializeCall}
  highlightPatterns={[" as "]}
/>

Since this ID is coming from an external source, use an argument validator or
[`ctx.db.normalizeId`](/api/interfaces/server.GenericDatabaseReader#normalizeid)
to confirm that the ID belongs to the expected table before returning the
object.

<TSAndJSSnippet
  title="convex/tasks.ts"
  sourceTS={SerializeExample}
  sourceJS={SerializeExample}
  highlightPatterns={["v.id"]}
/>

<StackPosts query="document IDs" />


---

# export.mdx

<!-- Source: database/import-export/export.mdx -->

---
title: "Data Export"
sidebar_label: "Data Export"
description: "Export your data out of Convex"
sidebar_position: 168
---

You can export your data from Convex by
[taking a backup](/database/backup-restore) and downloading it as a zip file.

Alternatively, you can export the same data with the
[command line](/cli.md#export-data-to-a-file):

```sh
npx convex export --path ~/Downloads
```


---

# import-export.mdx

<!-- Source: database/import-export/import-export.mdx -->

---
title: "Data Import & Export"
sidebar_position: 90
---

If you're bootstrapping your app from existing data, Convex provides three ways
to get the data in:

- Import from csv/json into a single table via the
  [CLI](/database/import-export/import.mdx#single-table-import).
- Restore from a backup via the [dashboard](/database/backup-restore) or
  [CLI](/database/import-export/import.mdx#restore-data-from-a-backup-zip-file).
- [Streaming import](/production/integrations/streaming-import-export.md) from
  any existing database via Airbyte destination connector.

You can export data from Convex in two ways.

- Download a backup as a zip from the [dashboard](/database/backup-restore).
- Set up [streaming export](/production/integrations/streaming-import-export.md)
  to any external database via Fivetran or Airbyte. Great for connecting to a
  custom BI setup (eg [Snowflake](https://www.snowflake.com/),
  [Databricks](https://www.databricks.com), or
  [BigQuery](https://cloud.google.com/bigquery)):

<BetaAdmonition feature="Data Import & Export" verb="is" />


---

# import.mdx

<!-- Source: database/import-export/import.mdx -->

---
title: "Data Import"
sidebar_label: "Data Import"
description: "Import data into Convex"
sidebar_position: 169
---

You can import data into Convex from a local file using the command line.

```sh
npx convex import
```

<BetaAdmonition feature="Data import" verb="is" />

Use `--help` to see all options. The most common flows are described here.

## Single table import

```sh
npx convex import --table <tableName> <path>
```

Import a CSV, JSON, or JSONLines file into a Convex table.

- `.csv` files must have a header, and each row's entries are interpreted either
  as a (floating point) number or a string.
- `.jsonl` files must have a JSON object per line.
- `.json` files must be an array of JSON objects.
  - JSON arrays have a size limit of 8MiB. To import more data, use CSV or
    JSONLines. You can convert json to jsonl with a command like
    `jq -c '.[]' data.json > data.jsonl`

Imports into a table with existing data will fail by default, but you can
specify `--append` to append the imported rows to the table or `--replace` to
replace existing data in the table with your import.

The default is to import into your dev deployment. Use `--prod` to import to
your production deployment or `--preview-name` to import into a preview
deployment.

## Restore data from a backup ZIP file

```sh
npx convex import <path>.zip
```

Import from a [Backup](/database/backup-restore) into a Convex deployment, where
the backup is a ZIP file that has been downloaded on the dashboard. Documents
will retain their `_id` and `_creationTime` fields so references between tables
are maintained.

Imports where tables have existing data will fail by default, but you can
specify `--replace` to replace existing data in tables mentioned in the ZIP
file.

## Use cases

1. Seed dev deployments with sample data.

```sh
# full backup - exported from prod or another dev deployment.
npx convex import seed_data.zip

# Import single table from jsonl/csv
npx convex import --table <table name> data.jsonl
```

2. Restore a deployment from a [backup](/database/backup-restore)
   programmatically. Download a backup, and restore from this backup if needed.

```sh
npx convex import --prod --replace backup.zip
```

3. Seed preview deployments with sample data, exported from prod, dev, or
   another preview deployment. Example for Vercel, seeding data from
   `seed_data.zip` committed in the root of the repo.

```sh
npx convex deploy --cmd 'npm run build' &&
if [ "$VERCEL_ENV" == "preview" ]; then
npx convex import --preview-name "$VERCEL_GIT_COMMIT_REF" seed_data.zip;
fi
```

4. Clear a table efficiently with an empty import.

```sh
touch empty_file.jsonl
npx convex import --replace --table <tableNameToClear> empty_file.jsonl
```

## Features

- Data import is the only way to create documents with pre-existing `_id` and
  `_creationTime` fields.
  - The `_id` field must match Convex's ID format.
  - If `_id` or `_creationTime` are not provided, new values are chosen during
    import.
- Data import creates and replaces tables atomically (except when using
  `--append`).
  - Queries and mutations will not view intermediate states where partial data
    is imported.
  - Indexes and schemas will work on the new data without needing time for
    re-backfilling or re-validating.
- Data import only affects tables that are mentioned in the import, either by
  `--table` or as entries in the ZIP file.
- While JSON and JSONLines can import arbitrary JSON values, ZIP imports can
  additionally import other Convex values: Int64, Bytes, etc. Types are
  preserved in the ZIP file through the `generated_schema.jsonl` file.
- Data import of ZIP files that include [file storage](/file-storage) import the
  files and preserve [`_storage`](/database/advanced/system-tables.mdx)
  documents, including their `_id`, `_creationTime`, and `contentType` fields.

## Warnings

- [Streaming Export](/production/integrations/streaming-import-export.md)
  (Fivetran or Airbyte) does not handle data imports or backup restorations,
  similar to table deletion and creation and some schema changes. We recommend
  resetting streaming export sync after a restore or a data import.
- Avoid changing the ZIP file between downloading it from Data Export and
  importing it with `npx convex import`. Some manual changes of the ZIP file may
  be possible, but remain undocumented. Please share your use case and check
  with the Convex team in [Discord](https://convex.dev/community).
- Data import is not always supported when importing into a deployment that was
  created before Convex version 1.7.
  - The import may work, especially when importing a ZIP backup from a
    deployment created around the same time as the target deployment. As a
    special case, you can always restore from backups from its own deployment.
  - Reach out in [Discord](https://convex.dev/community) if you encounter
    issues, as there may be a workaround.

Data import uses database bandwidth to write all documents, and file bandwidth
if the export includes file storage. You can observe this bandwidth in the
[usage dashboard](https://dashboard.convex.dev/team/settings/usage) as function
name `_cli/import` and associated cost in the
[limits docs](/production/state/limits#database).


---

# pagination.mdx

<!-- Source: database/pagination.mdx -->

---
title: "Paginated Queries"
slug: "pagination"
sidebar_position: 60
description: "Load paginated queries."
---

import Messages from "!!raw-loader!@site/../demos/pagination/convex/messages.ts";
import Download from "!!raw-loader!@site/../demos/pagination/src/download.ts";
import SimpleCall from "!!raw-loader!@site/../demos/pagination/src/_simpleListing.tsx";
import CallWithArgs from "!!raw-loader!@site/../demos/pagination/src/_listingWithArgument.tsx";

Paginated queries are [queries](/functions/query-functions.mdx) that return a
list of results in incremental pages.

This can be used to build components with "Load More" buttons or "infinite
scroll" UIs where more results are loaded as the user scrolls.

**Example:**
[Paginated Messaging App](https://github.com/get-convex/convex-demos/tree/main/pagination)

Using pagination in Convex is as simple as:

1. Writing a paginated query function that calls
   [`.paginate(paginationOpts)`](/api/interfaces/server.OrderedQuery#paginate).
2. Using the [`usePaginatedQuery`](/api/modules/react#usepaginatedquery) React
   hook.

Like other Convex queries, paginated queries are completely reactive.

## Writing paginated query functions

Convex uses cursor-based pagination. This means that paginated queries return a
string called a [`Cursor`](/api/modules/server#cursor) that represents the point
in the results that the current page ended. To load more results, you simply
call the query function again, passing in the cursor.

To build this in Convex, define a query function that:

1. Takes in a single arguments object with a `paginationOpts` property of type
   [`PaginationOptions`](/api/interfaces/server.PaginationOptions).
   - `PaginationOptions` is an object with `numItems` and `cursor` fields.
   - Use `paginationOptsValidator` exported from `"convex/server"` to
     [validate](/functions/validation.mdx) this argument
   - The arguments object may include properties as well.
2. Calls
   [`.paginate(paginationOpts)`](/api/interfaces/server.OrderedQuery#paginate)
   on a [database query](/database/reading-data/reading-data.mdx), passing in
   the `PaginationOptions` and returning its result.
   - The returned `page` in the
     [`PaginationResult`](/api/interfaces/server.PaginationResult) is an array
     of documents. You may
     [`map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map)
     or
     [`filter`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/filter)
     it before returning it.

<TSAndJSSnippet
  sourceTS={Messages}
  sourceJS={Messages}
  title="convex/messages.ts"
  highlightPatterns={["paginationOpts"]}
  snippet="list"
/>

### Additional arguments

You can define paginated query functions that take arguments in addition to
`paginationOpts`:

<TSAndJSSnippet
  sourceTS={Messages}
  sourceJS={Messages}
  snippet="listWithExtraArg"
  title="convex/messages.ts"
/>

### Transforming results

You can apply arbitrary
[transformations](/database/reading-data/reading-data.mdx#more-complex-queries)
to the `page` property of the object returned by `paginate`, which contains the
array of documents:

<TSAndJSSnippet
  sourceTS={Messages}
  sourceJS={Messages}
  snippet="listWithTransformation"
  title="convex/messages.ts"
/>

## Paginating within React Components

To paginate within a React component, use the
[`usePaginatedQuery`](/api/modules/react#usepaginatedquery) hook. This hook
gives you a simple interface for rendering the current items and requesting
more. Internally, this hook manages the continuation cursors.

The arguments to this hook are:

- The name of the paginated query function.
- The arguments object to pass to the query function, excluding the
  `paginationOpts` (that's injected by the hook).
- An options object with the `initialNumItems` to load on the first page.

The hook returns an object with:

- `results`: An array of the currently loaded results.
- `isLoading` - Whether the hook is currently loading results.
- `status`: The status of the pagination. The possible statuses are:
  - `"LoadingFirstPage"`: The hook is loading the first page of results.
  - `"CanLoadMore"`: This query may have more items to fetch. Call `loadMore` to
    fetch another page.
  - `"LoadingMore"`: We're currently loading another page of results.
  - `"Exhausted"`: We've paginated to the end of the list.
- `loadMore(n)`: A callback to fetch more results. This will only fetch more
  results if the status is `"CanLoadMore"`.

<TSAndJSSnippet
  sourceTS={SimpleCall}
  sourceJS={SimpleCall}
  snippet="example"
  title="src/App.tsx"
  highlightPatterns={["usePaginatedQuery\\(", "api.", "{}", "initialNumItems"]}
/>

You can also pass additional arguments in the arguments object if your function
expects them:

<TSAndJSSnippet
  sourceTS={CallWithArgs}
  sourceJS={CallWithArgs}
  snippet="example"
  title="src/App.tsx"
  highlightPatterns={["author:"]}
/>

### Reactivity

Like any other Convex query functions, paginated queries are **completely
reactive**. Your React components will automatically rerender if items in your
paginated list are added, removed or changed.

One consequence of this is that **page sizes in Convex may change!** If you
request a page of 10 items and then one item is removed, this page may "shrink"
to only have 9 items. Similarly if new items are added, a page may "grow" beyond
its initial size.

## Paginating manually

If you're paginating outside of React, you can manually call your paginated
function multiple times to collect the items:

<TSAndJSSnippet title="download.ts" sourceTS={Download} sourceJS={Download} />


---

# filters.mdx

<!-- Source: database/reading-data/filters.mdx -->

---
title: "Filters"
sidebar_position: 200
---

# Filtering

The [`filter`](/api/interfaces/server.Query#filter) method allows you to
restrict the documents that your document query returns. This method takes a
filter constructed by [`FilterBuilder`](/api/interfaces/server.FilterBuilder)
and will only select documents that match.

The examples below demonstrate some of the common uses of `filter`. You can see
the full list of available filtering methods
[in the reference docs](/api/interfaces/server.FilterBuilder).

If you need to filter to documents containing some keywords, use a
[search query](/search/search.mdx).

<Admonition type="caution" title="Use indexes instead">
  Filters effectively loop over your table looking for documents that match.
  This can be slow or cause your function to hit a
  [limit](/production/state/limits.mdx) when your table has thousands of rows.
  For faster more database efficient queries use [indexes
  instead](/database/reading-data/indexes/indexes.md).
</Admonition>

### Equality conditions

This document query finds documents in the `users` table where
`doc.name === "Alex"`:

```ts
// Get all users named "Alex".
const usersNamedAlex = await ctx.db
  .query("users")
  .filter((q) => q.eq(q.field("name"), "Alex"))
  .collect();
```

Here `q` is the [`FilterBuilder`](/api/interfaces/server.FilterBuilder) utility
object. It contains methods for all of our supported filter operators.

This filter will run on all documents in the table. For each document,
`q.field("name")` evaluates to the `name` property. Then `q.eq` checks if this
property is equal to `"Alex"`.

If your query references a field that is missing from a given document then that
field will be considered to have the value `undefined`.

### Comparisons

Filters can also be used to compare fields against values. This document query
finds documents where `doc.age >= 18`:

```ts
// Get all users with an age of 18 or higher.
const adults = await ctx.db
  .query("users")
  .filter((q) => q.gte(q.field("age"), 18))
  .collect();
```

Here the `q.gte` operator checks if the first argument (`doc.age`) is greater
than or equal to the second (`18`).

Here's the full list of comparisons:

| Operator      | Equivalent TypeScript |
| ------------- | --------------------- |
| `q.eq(l, r)`  | `l === r`             |
| `q.neq(l, r)` | `l !== r`             |
| `q.lt(l, r)`  | `l < r`               |
| `q.lte(l, r)` | `l <= r`              |
| `q.gt(l, r)`  | `l > r`               |
| `q.gte(l, r)` | `l >= r`              |

### Arithmetic

You can also include basic arithmetic in your queries. This document query finds
documents in the `carpets` table where `doc.height * doc.width > 100`:

```ts
// Get all carpets that have an area of over 100.
const largeCarpets = await ctx.db
  .query("carpets")
  .filter((q) => q.gt(q.mul(q.field("height"), q.field("width")), 100))
  .collect();
```

Here's the full list of arithmetic operators:

| Operator      | Equivalent TypeScript |
| ------------- | --------------------- |
| `q.add(l, r)` | `l + r`               |
| `q.sub(l, r)` | `l - r`               |
| `q.mul(l, r)` | `l * r`               |
| `q.div(l, r)` | `l / r`               |
| `q.mod(l, r)` | `l % r`               |
| `q.neg(x)`    | `-x`                  |

### Combining operators

You can construct more complex filters using methods like `q.and`, `q.or`, and
`q.not`. This document query finds documents where
`doc.name === "Alex" && doc.age >= 18`:

```ts
// Get all users named "Alex" whose age is at least 18.
const adultAlexes = await ctx.db
  .query("users")
  .filter((q) =>
    q.and(q.eq(q.field("name"), "Alex"), q.gte(q.field("age"), 18)),
  )
  .collect();
```

Here is a query that finds all users where
`doc.name === "Alex" || doc.name === "Emma"`:

```ts
// Get all users named "Alex" or "Emma".
const usersNamedAlexOrEmma = await ctx.db
  .query("users")
  .filter((q) =>
    q.or(q.eq(q.field("name"), "Alex"), q.eq(q.field("name"), "Emma")),
  )
  .collect();
```

## Advanced filtering techniques

Sometimes the filter syntax is is not expressive enough. For example you may
want to collect all posts that have a tag. Your schema for the posts looks like
this:

```ts
export default defineSchema({
  posts: defineTable({
    body: v.string(),
    tags: v.array(v.string()),
  }),
});
```

One way to solve is by applying the filter on the result of the `collect()`
call. This is just filtering a JavaScript array:

```ts
export const postsWithTag = query({
  args: { tag: v.string() },
  handler: async (ctx, args) => {
    const allPosts = await ctx.db.query("posts").collect();
    return allPosts.filter((post) => post.tags.includes(args.tag));
  },
});
```

But this requires reading the whole table first. If you want to just get the
first result that matches, reading the whole table could be very inefficient.
Instead you may want to use the JavaScript
[`for await...of`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of)
syntax to loop through the table one document at a time:

```ts
export const firstPostWithTag = query({
  args: { tag: v.string() },
  handler: (ctx, args) => {
    for await (const post of db.query("posts")) {
      if (post.tags.includes(args.tag)) {
        return post;
      }
    }
  },
});
```

This works because Convex queries are
[JavaScript iterables](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols).

Even with this optimization you are still just looping over the table to find
the first post that matches and may hit your function limits. Using indexes is
still the way to go. You can read a
[detailed discussion of how to handle tags with indexes](https://stack.convex.dev/complex-filters-in-convex#optimize-with-indexes).

## Querying performance and limits

Most of the example document queries above can lead to a _full table scan_. That
is, for the document query to return the requested results, it might need to
walk over every single document in the table.

Take this simple example:

```ts
const tasks = await ctx.db.query("tasks").take(5);
```

This document query will not scan more than 5 documents.

On the other hand, this document query:

```ts
const tasks = await ctx.db
  .query("tasks")
  .filter((q) => q.eq(q.field("isCompleted"), true))
  .first();
```

might need to walk over every single document in the `"tasks"` table just to
find the first one with `isCompleted: true`.

If a table has more than a few thousand documents, you should use
[indexes](/database/reading-data/indexes/indexes.md) to improve your document
query performance. Otherwise, you may run into our enforced limits, detailed in
[Read/write limit errors](/functions/error-handling/error-handling.mdx#readwrite-limit-errors).

For information on other limits, see [Limits](/production/state/limits.mdx).


---

# indexes-and-query-perf.md

<!-- Source: database/reading-data/indexes/indexes-and-query-perf.md -->

---
sidebar_label: "Indexes and Query Performance"
title: "Introduction to Indexes and Query Performance"
sidebar_position: 100
---

How do I ensure my Convex
[database queries](/database/reading-data/reading-data.mdx) are fast and
efficient? When should I define an
[index](/database/reading-data/indexes/indexes.md)? What is an index?

This document explains how you should think about query performance in Convex by
describing a simplified model of how queries and indexes function.

If you already have a strong understanding of database queries and indexes you
can jump straight to the reference documentation instead:

- [Reading Data](/database/reading-data/reading-data.mdx)
- [Indexes](/database/reading-data/indexes/indexes.md)

## A Library of Documents

You can imagine that Convex is a physical library storing documents as physical
books. In this world, every time you add a document to Convex with
[`db.insert("books", {...})`](/api/interfaces/server.GenericDatabaseWriter#insert)
a librarian places the book on a shelf.

By default, Convex organizes your documents in the order they were inserted. You
can imagine the librarian inserting documents left to right on a shelf.

If you run a query to find the first book like:

```ts
const firstBook = await ctx.db.query("books").first();
```

then the librarian could start at the left edge of the shelf and find the first
book. This is an extremely fast query because the librarian only has to look at
a single book to get the result.

Similarly, if we want to retrieve the last book that was inserted we could
instead do:

```ts
const lastBook = await ctx.db.query("books").order("desc").first();
```

This is the same query but we've swapped the order to descending. In the
library, this means that the librarian will start on the right edge of the shelf
and scan right-to-left. The librarian still only needs to look at a single book
to determine the result so this query is also extremely fast.

## Full Table Scans

Now imagine that someone shows up at the library and asks "what books do you
have by Jane Austen?"

This could be expressed as:

```ts
const books = await ctx.db
  .query("books")
  .filter((q) => q.eq(q.field("author"), "Jane Austen"))
  .collect();
```

This query is saying "look through all of the books, left-to-right, and collect
the ones where the `author` field is Jane Austen." To do this the librarian will
need to look through the entire shelf and check the author of every book.

This query is a _full table scan_ because it requires Convex to look at every
document in the table. The performance of this query is based on the number of
books in the library.

If your Convex table has a small number of documents, this is fine! Full table
scans should still be fast if there are a few hundred documents, but if the
table has many thousands of documents these queries will become slow.

In the library analogy, this kind of query is fine if the library has a single
shelf. As the library expands into a bookcase with many shelves or many
bookcases, this approach becomes infeasible.

## Card Catalogs

How can we more efficiently find books given an author?

One option is to re-sort the entire library by `author`. This will solve our
immediate problem but now our original queries for `firstBook` and `lastBook`
would become full table scans because we'd need to examine every book to see
which was inserted first/last.

Another option is to duplicate the entire library. We could purchase 2 copies of
every book and put them on 2 separate shelves: one shelf sorted by insertion
time and another sorted by author. This would work, but it's expensive. We now
need twice as much space for our library.

A better option is to build an _index_ on `author`. In the library, we could use
an old-school [card catalog](https://en.wikipedia.org/wiki/Library_catalog) to
organize the books by author. The idea here is that the librarian will write an
index card for each book that contains:

- The book's author
- The location of the book on the shelves

These index cards will be sorted by author and live in a separate organizer from
the shelves that hold the books. The card catalog should stay small because it
only has an index card per book (not the entire text of the book).

![Card Catalog](/img/card-catalog.jpg)

When a patron asks for "books by Jane Austen", the librarian can now:

1. Go to the card catalog and quickly find all of the cards for "Jane Austen".
2. For each card, go and find the book on the shelf.

This is quite fast because the librarian can quickly find the index cards for
Jane Austen. It's still a little bit of work to find the book for each card but
the number of index cards is small so this is quite fast.

## Indexes

Database indexes work based on the same concept! With Convex you can define an
_index_ with:

```ts noDialect title="convex/schema.ts"
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  books: defineTable({
    author: v.string(),
    title: v.string(),
    text: v.string(),
  }).index("by_author", ["author"]),
});
```

then Convex will create a new index called `by_author` on `author`. This means
that your `books` table will now have an additional data structure that is
sorted by the `author` field.

You can query this index with:

```ts
const austenBooks = await ctx.db
  .query("books")
  .withIndex("by_author", (q) => q.eq("author", "Jane Austen"))
  .collect();
```

This query instructs Convex to go to the `by_author` index and find all the
entries where `doc.author === "Jane Austen"`. Because the index is sorted by
`author`, this is a very efficient operation. This means that Convex can execute
this query in the same manner that the librarian can:

1. Find the range of the index with entries for Jane Austen.
2. For each entry in that range, get the corresponding document.

The performance of this query is based on the number of documents where
`doc.author === "Jane Austen"` which should be quite small. We've dramatically
sped up the query!

## Backfilling and Maintaining Indexes

One interesting detail to think about is the work needed to create this new
structure. In the library, the librarian must go through every book on the shelf
and put a new index card for each one in the card catalog sorted by author. Only
after that can the librarian trust that the card catalog will give it correct
results.

The same is true for Convex indexes! When you define a new index, the first time
you run `npx convex deploy` Convex will need to loop through all of your
documents and index each one. This is why the first deploy after the creation of
a new index will be slightly slower than normal; Convex has to do a bit of work
for each document in your table.

Similarly, even after an index is defined, Convex will have to do a bit of extra
work to keep this index up to date as the data changes. Every time a document is
inserted, updated, or deleted in an indexed table, Convex will also update its
index entry. This is analogous to a librarian creating new index cards for new
books as they add them to the library.

If you are defining a few indexes there is no need to worry about the
maintenance cost. As you define more indexes, the cost to maintain them grows
because every `insert` needs to update every index. This is why Convex has a
limit of 32 indexes per table. In practice most applications define a handful of
indexes per table to make their important queries efficient.

## Indexing Multiple Fields

Now imagine that a patron shows up at the library and would like to check out
_Foundation_ by Isaac Asimov. Given our index on `author`, we can write a query
that uses the index to find all the books by Isaac Asimov and then examines the
title of each book to see if it's _Foundation_.

```ts
const foundation = await ctx.db
  .query("books")
  .withIndex("by_author", (q) => q.eq("author", "Isaac Asimov"))
  .filter((q) => q.eq(q.field("title"), "Foundation"))
  .unique();
```

This query describes how a librarian might execute the query. The librarian will
use the card catalog to find all of the index cards for Isaac Asimov's books.
The cards themselves don't have the title of the book so the librarian will need
to find every Asimov book on the shelves and look at its title to find the one
named _Foundation_. Lastly, this query ends with
[`.unique`](/api/interfaces/server.Query#unique) because we expect there to be
at most one result.

This query demonstrates the difference between filtering using
[`withIndex`](/api/interfaces/server.QueryInitializer#withindex) and
[`filter`](/api/interfaces/server.Query#filter). `withIndex` only allows you to
restrict your query based on the index. You can only do operations that the
index can do efficiently like finding all documents with a given author.

`filter` on the other hand allows you to write arbitrary, complex expressions
but it won't be run using the index. Instead, `filter` expressions will be
evaluated on every document in the range.

Given all of this, we can conclude that **the performance of indexed queries is
based on how many documents are in the index range**. In this case, the
performance is based on the number of Isaac Asimov books because the librarian
will need to look at each one to examine its title.

Unfortunately, Isaac Asimov wrote
[a lot of books](<https://en.wikipedia.org/wiki/Isaac_Asimov_bibliography_(alphabetical)>).
Realistically even with 500+ books, this will be fast enough on Convex with the
existing index, but let's consider how we could improve it anyway.

One approach is to build a separate `by_title` index on `title`. This could let
us swap the work we do in `.filter` and `.withIndex` to instead be:

```ts
const foundation = await ctx.db
  .query("books")
  .withIndex("by_title", (q) => q.eq("title", "Foundation"))
  .filter((q) => q.eq(q.field("author"), "Isaac Asimov"))
  .unique();
```

In this query, we're efficiently using the index to find all the books called
_Foundation_ and then filtering through to find the one by Isaac Asimov.

This is okay, but we're still at risk of having a slow query because too many
books have a title of _Foundation_. An even better approach could be to build a
_compound_ index that indexes both `author` and `title`. Compound indexes are
indexes on an ordered list of fields.

```ts noDialect title="convex/schema.ts"
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  books: defineTable({
    author: v.string(),
    title: v.string(),
    text: v.string(),
  }).index("by_author_title", ["author", "title"]),
});
```

In this index, books are sorted first by the author and then within each author
by title. This means that a librarian can use the index to jump to the Isaac
Asimov section and quickly find _Foundation_ within it.

Expressing this as a Convex query this looks like:

```ts
const foundation = await ctx.db
  .query("books")
  .withIndex("by_author_title", (q) =>
    q.eq("author", "Isaac Asimov").eq("title", "Foundation"),
  )
  .unique();
```

Here the index range expression tells Convex to only consider documents where
the author is Isaac Asimov and the title is _Foundation_. This is only a single
document so this query will be quite fast!

Because this index sorts by `author` and then by `title`, it also efficiently
supports queries like "All books by Isaac Asimov that start with F." We could
express this as:

```ts
const asimovBooksStartingWithF = await ctx.db
  .query("books")
  .withIndex("by_author_title", (q) =>
    q.eq("author", "Isaac Asimov").gte("title", "F").lt("title", "G"),
  )
  .collect();
```

This query uses the index to find books where
`author === "Isaac Asimov" && "F" <= title < "G"`. Once again, the performance
of this query is based on how many documents are in the index range. In this
case, that's just the Asimov books that begin with "F" which is quite small.

Also note that this index also supports our original query for "books by Jane
Austen." It's okay to only use the `author` field in an index range expression
and not restrict by title at all.

Lastly, imagine that a library patron asks for the book _The Three-Body Problem_
but they don't know the author's name. Our `by_author_title` index won't help us
here because it's sorted first by `author`, and then by `title`. The title, _The
Three-Body Problem_, could appear anywhere in the index!

The Convex TypeScript types in the `withIndex` make this clear because they
require that you compare index fields in order. Because the index is defined on
`["author", "title"]`, you must first compare the `author` with `.eq` before the
`title`.

In this case, the best option is probably to create the separate `by_title`
index to facilitate this query.

## Conclusions

Congrats! You now understand how queries and indexes work within Convex!

Here are the main points we've covered:

1. By default Convex queries are _full table scans_. This is appropriate for
   prototyping and querying small tables.
2. As your tables grow larger, you can improve your query performance by adding
   _indexes_. Indexes are separate data structures that order your documents for
   fast querying.
3. In Convex, queries use the _`withIndex`_ method to express the portion of the
   query that uses the index. The performance of a query is based on how many
   documents are in the index range expression.
4. Convex also supports _compound indexes_ that index multiple fields.

To learn more about queries and indexes, check out our reference documentation:

- [Reading Data](/database/reading-data/reading-data.mdx)
- [Indexes](/database/reading-data/indexes/indexes.md)


---

# indexes.md

<!-- Source: database/reading-data/indexes/indexes.md -->

---
title: "Indexes"
sidebar_position: 100
---

Indexes are a data structure that allow you to speed up your
[document queries](/database/reading-data/reading-data.mdx#querying-documents)
by telling Convex how to organize your documents. Indexes also allow you to
change the order of documents in query results.

For a more in-depth introduction to indexing see
[Indexes and Query Performance](/database/reading-data/indexes/indexes-and-query-perf.md).

## Defining indexes

Indexes are defined as part of your Convex [schema](/database/schemas.mdx). Each
index consists of:

1. A name.
   - Must be unique per table.
2. An ordered list of fields to index.
   - To specify a field on a nested document, use a dot-separated path like
     `properties.name`.

To add an index onto a table, use the
[`index`](/api/classes/server.TableDefinition#index) method on your table's
schema:

```ts noDialect title="convex/schema.ts"
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

// Define a messages table with two indexes.
export default defineSchema({
  messages: defineTable({
    channel: v.id("channels"),
    body: v.string(),
    user: v.id("users"),
  })
    .index("by_channel", ["channel"])
    .index("by_channel_user", ["channel", "user"]),
});
```

The `by_channel` index is ordered by the `channel` field defined in the schema.
For messages in the same channel, they are ordered by the
[system-generated `_creationTime` field](/database/types.md#system-fields) which
is added to all indexes automatically.

By contrast, the `by_channel_user` index orders messages in the same `channel`
by the `user` who sent them, and only then by `_creationTime`.

Indexes are created in [`npx convex dev`](/cli.md#run-the-convex-dev-server) and
[`npx convex deploy`](/cli.md#deploy-convex-functions-to-production).

You may notice that the first deploy that defines an index is a bit slower than
normal. This is because Convex needs to _backfill_ your index. The more data in
your table, the longer it will take Convex to organize it in index order. If
this is problematic for your workflow, [contact us](/production/contact.md).

You can feel free to query an index in the same deploy that defines it. Convex
will ensure that the index is backfilled before the new query and mutation
functions are registered.

<Admonition type="caution" title="Be careful when removing indexes">

In addition to adding new indexes, `npx convex deploy` will delete indexes that
are no longer present in your schema. Make sure that your indexes are completely
unused before removing them from your schema!

</Admonition>

## Querying documents using indexes

A query for "messages in `channel` created 1-2 minutes ago" over the
`by_channel` index would look like:

```ts
const messages = await ctx.db
  .query("messages")
  .withIndex("by_channel", (q) =>
    q
      .eq("channel", channel)
      .gt("_creationTime", Date.now() - 2 * 60000)
      .lt("_creationTime", Date.now() - 60000),
  )
  .collect();
```

The [`.withIndex`](/api/interfaces/server.QueryInitializer#withindex) method
defines which index to query and how Convex will use that index to select
documents. The first argument is the name of the index and the second is an
_index range expression_. An index range expression is a description of which
documents Convex should consider when running the query.

The choice of index both affects how you write the index range expression and
what order the results are returned in. For instance, by making both a
`by_channel` and `by_channel_user` index, we can get results within a channel
ordered by `_creationTime` or by `user`, respectively. If you were to use the
`by_channel_user` index like this:

```ts
const messages = await ctx.db
  .query("messages")
  .withIndex("by_channel_user", (q) => q.eq("channel", channel))
  .collect();
```

The results would be all of the messages in a `channel` ordered by `user`, then
by `_creationTime`. If you were to use `by_channel_user` like this:

```ts
const messages = await ctx.db
  .query("messages")
  .withIndex("by_channel_user", (q) =>
    q.eq("channel", channel).eq("user", user),
  )
  .collect();
```

The results would be the messages in the given `channel` sent by `user`, ordered
by `_creationTime`.

An index range expression is always a chained list of:

1. 0 or more equality expressions defined with
   [`.eq`](/api/interfaces/server.IndexRangeBuilder#eq).
2. [Optionally] A lower bound expression defined with
   [`.gt`](/api/interfaces/server.IndexRangeBuilder#gt) or
   [`.gte`](/api/interfaces/server.IndexRangeBuilder#gte).
3. [Optionally] An upper bound expression defined with
   [`.lt`](/api/interfaces/server.IndexRangeBuilder#lt) or
   [`.lte`](/api/interfaces/server.IndexRangeBuilder#lte).

**You must step through fields in index order.**

Each equality expression must compare a different index field, starting from the
beginning and in order. The upper and lower bounds must follow the equality
expressions and compare the next field.

For example, it is not possible to write a query like:

```ts
// DOES NOT COMPILE!
const messages = await ctx.db
  .query("messages")
  .withIndex("by_channel", (q) =>
    q
      .gt("_creationTime", Date.now() - 2 * 60000)
      .lt("_creationTime", Date.now() - 60000),
  )
  .collect();
```

This query is invalid because the `by_channel` index is ordered by
`(channel, _creationTime)` and this query range has a comparison on
`_creationTime` without first restricting the range to a single `channel`.
Because the index is sorted first by `channel` and then by `_creationTime`, it
isn't a useful index for finding messages in all channels created 1-2 minutes
ago. The TypeScript types within `withIndex` will guide you through this.

To better understand what queries can be run over which indexes, see
[Introduction to Indexes and Query Performance](/database/reading-data/indexes/indexes-and-query-perf.md).

**The performance of your query is based on the specificity of the range.**

For example, if the query is

```ts
const messages = await ctx.db
  .query("messages")
  .withIndex("by_channel", (q) =>
    q
      .eq("channel", channel)
      .gt("_creationTime", Date.now() - 2 * 60000)
      .lt("_creationTime", Date.now() - 60000),
  )
  .collect();
```

then query's performance would be based on the number of messages in `channel`
created 1-2 minutes ago.

If the index range is not specified, all documents in the index will be
considered in the query.

<Admonition type="tip" title="Picking a good index range">

For performance, define index ranges that are as specific as possible! If you
are querying a large table and you're unable to add any equality conditions with
`.eq`, you should consider defining a new index.

</Admonition>

`.withIndex` is designed to only allow you to specify ranges that Convex can
efficiently use your index to find. For all other filtering you can use the
[`.filter`](/api/interfaces/server.Query#filter) method.

For example to query for "messages in `channel` **not** created by me" you could
do:

```ts
const messages = await ctx.db
  .query("messages")
  .withIndex("by_channel", q => q.eq("channel", channel))
  .filter(q => q.neq(q.field("user"), myUserId)
  .collect();
```

In this case the performance of this query will be based on how many messages
are in the channel. Convex will consider each message in the channel and only
return the messages where the `user` field matches `myUserId`.

## Sorting with indexes

Queries that use `withIndex` are ordered by the columns specified in the index.

The order of the columns in the index dictates the priority for sorting. The
values of the columns listed first in the index are compared first. Subsequent
columns are only compared as tie breakers only if all earlier columns match.

Since Convex automatically includes `_creationTime` as the last column in all
indexes, `_creationTime` will always be the final tie breaker if all other
columns in the index are equal.

For example, `by_channel_user` includes `channel`, `user`, and `\_creationTime`.
So queries on `messages` that use `.withIndex("by_channel_user")` will be sorted
first by channel, then by user within each channel, and finally by the creation
time.

Sorting with indexes allows you to satisfy use cases like displaying the top `N`
scoring users, the most recent `N` transactions, or the most `N` liked messages.

For example, to get the top 10 highest scoring players in your game, you might
define an index on the player's highest score:

```ts
export default defineSchema({
  players: defineTable({
    username: v.string(),
    highestScore: v.number(),
  }).index("by_highest_score", ["highestScore"]),
});
```

You can then efficiently find the top 10 highest scoring players using your
index and [`take(10)`](/api/interfaces/server.Query#take):

```ts
const topScoringPlayers = await ctx.db
  .query("users")
  .withIndex("by_highest_score")
  .order("desc")
  .take(10);
```

In this example, the range expression is omitted because we're looking for the
highest scoring players of all time. This particular query is reasonably
efficient for large data sets only because we're using `take()`.

If you use an index without a range expression, you should always use one of the
following in conjunction with `withIndex`:

1. [`.first()`](/api/interfaces/server.Query#first)
2. [`.unique()`](/api/interfaces/server.Query#unique)
3. [`.take(n)`](/api/interfaces/server.Query#take)
4. [`.paginate(ops)`](/database/pagination.mdx)

These APIs allow you to efficiently limit your query to a reasonable size
without performing a full table scan.

<Admonition type="caution" title="Full Table Scans">

When your query fetches documents from the database, it will scan the rows in
the range you specify. If you are using `.collect()`, for instance, it will scan
all of the rows in the range. So if you use `withIndex` without a range
expression, you will be
[scanning the whole table](https://docs.convex.dev/database/indexes/indexes-and-query-perf#full-table-scans),
which can be slow when your table has thousands of rows. `.filter()` doesn't
affect which documents are scanned. Using `.first()` or `.unique()` or
`.take(n)` will only scan rows until it has enough documents.

</Admonition>

You can include a range expression to satisfy more targeted queries. For
example, to get the top scoring players in Canada, you might use both `take()`
and a range expression:

```ts
// query the top 10 highest scoring players in Canada.
const topScoringPlayers = await ctx.db
  .query("users")
  .withIndex("by_country_highest_score", (q) => q.eq("country", "CA"))
  .order("desc")
  .take(10);
```

## Limits

Convex supports indexes containing up to 16 fields. You can define 32 indexes on
each table. Indexes can't contain duplicate fields.

No reserved fields (starting with `_`) are allowed in indexes. The
`_creationTime` field is automatically added to the end of every index to ensure
a stable ordering. It should not be added explicitly in the index definition,
and it's counted towards the index fields limit.

The `by_creation_time` index is created automatically (and is what is used in
database queries that don't specify an index). The `by_id` index is reserved.


---

# reading-data.mdx

<!-- Source: database/reading-data/reading-data.mdx -->

---
title: "Reading Data"
sidebar_position: 3
---

import getExample from "!!raw-loader!@site/../private-demos/snippets/convex/readingDataDbGet.ts";
import queryExample from "!!raw-loader!@site/../private-demos/snippets/convex/readingDataDbQuery.ts";
import averageExample from "!!raw-loader!@site/../private-demos/snippets/convex/readingDataAverage.ts";
import groupByExampleTS from "!!raw-loader!@site/../private-demos/snippets/convex/readingDataGroupByTS.ts";
import groupByExampleJS from "!!raw-loader!@site/../private-demos/snippets/convex/readingDataGroupByJS.js";
import joinExample from "!!raw-loader!@site/../private-demos/snippets/convex/readingDataJoin.ts";

[Query](/functions/query-functions.mdx) and
[mutation](/functions/mutation-functions.mdx) functions can read data from
database tables using _document ids_ and _document queries_.

## Reading a single document

Given a single document's id you can read its data with the
[`db.get`](/api/interfaces/server.GenericDatabaseReader#get) method:

<TSAndJSSnippet
  title="convex/tasks.ts"
  sourceTS={getExample}
  sourceJS={getExample}
  highlightPatterns={["db.get"]}
/>

**Note**: You should use the `v.id` validator like in the example above to make
sure you are not exposing data from tables other than the ones you intended.

## Querying documents

Document queries always begin by choosing the table to query with the
[`db.query`](/api/interfaces/server.GenericDatabaseReader#query) method:

<TSAndJSSnippet
  title="convex/tasks.ts"
  sourceTS={queryExample}
  sourceJS={queryExample}
  highlightPatterns={["db.query"]}
/>

Then you can:

1. filter
2. order
3. and `await` the results

We'll see how this works in the examples below.

## Filtering your query

The best way to filter in Convex is to use indexes. Indexes build a special
internal structure in your database to speed up lookups.

There are two steps to using indexes:

1. Define the index in your `convex/schema.ts` file.
2. Query via the `withIndex()` syntax.

### 1. Define the index

If you aren't familiar with how to create a Convex schema, read the
[schema doc](/database/schemas.mdx).

Let’s assume you’re building a chat app and want to get all messages in a
particular channel. You can define a new index called `by_channel` on the
`messages` table by using the `.index()` method in your schema.

```ts noDialect title="convex/schema.ts"
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

// Define a messages table with an index.
export default defineSchema({
  messages: defineTable({
    channel: v.id("channels"),
    body: v.string(),
    user: v.id("users"),
    // highlight-next-line
  }).index("by_channel", ["channel"]),
});
```

### 2. Filter a query with an index

In your query function, you can now filter your `messages` table by using the
`by_channel` index.

```ts
const messages = await ctx.db
  .query("messages")
  // highlight-next-line
  .withIndex("by_channel", (q) => q.eq("channel", channel))
  .collect();
```

In Convex, you must explicitly use the `withIndex()` syntax to ensure your
database uses the index. This differs from a more traditional SQL database,
where the database implicitly chooses to use an index based on heuristics. The
Convex approach leads to fewer surprises in the long run.

You can create an index across multiple fields at once, query a specific range
of data, and change the order of your query result.
[Read the complete index documentation](/database/reading-data/indexes/indexes.md)
to learn more.

Convex also supports a slower filtering mechanism that effectively loops through
the table to match the filter. This can be useful if you know your table will be
small (low thousands of rows), you're prototyping, or you want to filter an
index query further. You can read more about filters
[here](/database/reading-data/filters.mdx).

## Ordering

By default Convex always returns documents ordered by
[`_creationTime`](/database/types.md#system-fields).

You can use [`.order("asc" | "desc")`](/api/interfaces/server.Query#order) to
pick whether the order is ascending or descending. If the order isn't specified,
it defaults to ascending.

```ts
// Get all messages, oldest to newest.
const messages = await ctx.db.query("messages").order("asc").collect();
```

```ts
// Get all messages, newest to oldest.
const messages = await ctx.db.query("messages").order("desc").collect();
```

If you need to sort on a field other than `_creationTime` and your document
query returns a small number of documents (on the order of hundreds rather than
thousands of documents), consider sorting in Javascript:

```ts
// Get top 10 most liked messages, assuming messages is a fairly small table:
const messages = await ctx.db.query("messages").collect();
const topTenMostLikedMessages = recentMessages
  .sort((a, b) => b.likes - a.likes)
  .slice(0, 10);
```

For document queries that return larger numbers of documents, you'll want to use
an [index](/database/reading-data/indexes/indexes.md) to improve the
performance. Document queries that use indexes will be
[ordered based on the columns in the index](/database/reading-data/indexes/indexes.md#sorting-with-indexes)
and can avoid slow table scans.

```ts
// Get the top 20 most liked messages of all time, using the "by_likes" index.
const messages = await ctx.db
  .query("messages")
  .withIndex("by_likes")
  .order("desc")
  .take(20);
```

See [Limits](/database/reading-data/indexes/indexes.md#limits) for details.

### Ordering of different types of values

A single field can have values of any [Convex type](/database/types.md). When
there are values of different types in an indexed field, their ascending order
is as follows:

No value set&nbsp;(`undefined`) < Null&nbsp;(`null`) < Int64&nbsp;(`bigint`) <
Float64 (`number`) < Boolean&nbsp;(`boolean`) < String&nbsp;(`string`) <
Bytes&nbsp;(`ArrayBuffer`) < Array&nbsp;(`Array`) < Object&nbsp;(`Object`)

The same ordering is used by the filtering comparison operators `q.lt()`,
`q.lte()`, `q.gt()` and `q.gte()`.

## Retrieving results

Most of our previous examples have ended the document query with the
[`.collect()`](/api/interfaces/server.Query#collect) method, which returns all
the documents that match your filters. Here are the other options for retrieving
results.

### Taking `n` results

[`.take(n)`](/api/interfaces/server.Query#take) selects only the first `n`
results that match your query.

```ts
const users = await ctx.db.query("users").take(5);
```

### Finding the first result

[`.first()`](/api/interfaces/server.Query#first) selects the first document that
matches your query and returns `null` if no documents were found.

```ts
// We expect only one user with that email address.
const userOrNull = await ctx.db
  .query("users")
  .withIndex("by_email", (q) => q.eq("email", "test@example.com"))
  .first();
```

### Using a unique result

[`.unique()`](/api/interfaces/server.Query#unique) selects the single document
from your query or returns `null` if no documents were found. If there are
multiple results it will throw an exception.

```ts
// Our counter table only has one document.
const counterOrNull = await ctx.db.query("counter").unique();
```

### Loading a page of results

[`.paginate(opts)`](/api/interfaces/server.OrderedQuery#paginate) loads a page
of results and returns a [`Cursor`](/api/modules/server#cursor) for loading
additional results.

See [Paginated Queries](/database/pagination.mdx) to learn more.

## More complex queries

Convex prefers to have a few, simple ways to walk through and select documents
from tables. In Convex, there is no specific query language for complex logic
like a join, an aggregation, or a group by.

Instead, you can write the complex logic in Javascript! Convex guarantees that
the results will be consistent.

### Join

Table join might look like:

<TSAndJSSnippet
  title="convex/events.ts"
  sourceTS={joinExample}
  sourceJS={joinExample}
/>

### Aggregation

Here's an example of computing an average:

<TSAndJSSnippet
  title="convex/purchases.ts"
  sourceTS={averageExample}
  sourceJS={averageExample}
/>

> If you need more scalable aggregate options (for example to handle frequent
> updates or large tables), consider using the
> [Sharded Counter](https://www.convex.dev/components/sharded-counter) or
> [Aggregate](https://www.convex.dev/components/aggregate) components. These
> components can help you handle high-throughput counters, sums, or computations
> without looping through the whole table.

### Group by

Here's an example of grouping and counting:

<TSAndJSSnippet
  title="convex/purchases.ts"
  sourceTS={groupByExampleTS}
  sourceJS={groupByExampleJS}
/>

## Explore the syntax on the dashboard

You can try out the syntax described above directly from the dashboard by
[writing a custom test query](/dashboard/deployments/data.md#writing-custom-queries).


---

# schemas.mdx

<!-- Source: database/schemas.mdx -->

---
title: "Schemas"
sidebar_position: 5
description:
  "Schema validation keeps your Convex data neat and tidy. It also gives you
  end-to-end TypeScript type safety!"
toc_max_heading_level: 4
---

import SchemaTS from "!!raw-loader!@site/../demos/users-and-auth/convex/schema.ts";
import circularExample from "!!raw-loader!@site/../private-demos/snippets/convex/schemasCircular.ts";

A schema is a description of

1. the tables in your Convex project
2. the type of documents within your tables

While it is possible to use Convex _without_ defining a schema, adding a
`schema.ts` file will ensure that the documents in your tables are the correct
type. If you're using
[TypeScript](/understanding/best-practices/typescript.mdx), adding a schema will
also give you end-to-end type safety throughout your app.

We recommend beginning your project without a schema for rapid prototyping and
then adding a schema once you've solidified your plan. To learn more see our
[Schema Philosophy](/database/advanced/schema-philosophy.md).

**Example:**
[TypeScript and Schemas](https://github.com/get-convex/convex-demos/tree/main/typescript)

## Writing schemas

Schemas are defined in a `schema.ts` file in your `convex/` directory and look
like:

<Snippet source={SchemaTS} title="convex/schema.ts" />

This schema (which is based on our
[users and auth example](https://github.com/get-convex/convex-demos/tree/main/users-and-auth)),
has 2 tables: messages and users. Each table is defined using the
[`defineTable`](/api/modules/server#definetable) function. Within each table,
the document type is defined using the validator builder,
[`v`](/api/modules/values#v). In addition to the fields listed, Convex will also
automatically add `_id` and `_creationTime` fields. To learn more, see
[System Fields](/database/types.md#system-fields).

<Admonition type="tip" title="Generating a Schema">

While writing your schema, it can be helpful to consult the
[Convex Dashboard](/dashboard/deployments/data.md#generating-a-schema). The
"Generate Schema" button in the "Data" view suggests a schema declaration based
on the data in your tables.

</Admonition>

### Validators

The validator builder, [`v`](/api/modules/values#v) is used to define the type
of documents in each table. It has methods for each of
[Convex's types](/database/types):

```ts noDialect title="convex/schema.ts"
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  documents: defineTable({
    id: v.id("documents"),
    string: v.string(),
    number: v.number(),
    boolean: v.boolean(),
    nestedObject: v.object({
      property: v.string(),
    }),
  }),
});
```

It additionally allows you to define unions, optional property, string literals,
and more. [Argument validation](/functions/validation.mdx) and schemas both use
the same validator builder, `v`.

#### Optional fields

You can describe optional fields by wrapping their type with `v.optional(...)`:

```typescript
defineTable({
  optionalString: v.optional(v.string()),
  optionalNumber: v.optional(v.number()),
});
```

This corresponds to marking fields as optional with `?` in TypeScript.

#### Unions

You can describe fields that could be one of multiple types using `v.union`:

```typescript
defineTable({
  stringOrNumber: v.union(v.string(), v.number()),
});
```

If your table stores multiple different types of documents, you can use
`v.union` at the top level:

```typescript
defineTable(
  v.union(
    v.object({
      kind: v.literal("StringDocument"),
      value: v.string(),
    }),
    v.object({
      kind: v.literal("NumberDocument"),
      value: v.number(),
    }),
  ),
);
```

In this schema, documents either have a `kind` of `"StringDocument"` and a
string for their `value`:

```json
{
  "kind": "StringDocument",
  "value": "abc"
}
```

or they have a `kind` of `"NumberDocument"` and a number for their `value`:

```json
{
  "kind": "NumberDocument",
  "value": 123
}
```

#### Literals

Fields that are a constant can be expressed with `v.literal`:

```typescript
defineTable({
  oneTwoOrThree: v.union(
    v.literal("one"),
    v.literal("two"),
    v.literal("three"),
  ),
});
```

#### Record objects

You can describe objects that map arbitrary keys to values with `v.record`:

```typescript
defineTable({
  simpleMapping: v.record(v.string(), v.boolean()),
});
```

You can use other types of string validators for the keys:

```typescript
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export default mutation({
  args: {
    userIdToValue: v.record(v.id("users"), v.boolean()),
  },
  handler: async ({ db }, { userIdToValue }) => {
    //...
  },
});
```

Notes:

- This type corresponds to the
  [Record\<K,V\>](https://www.typescriptlang.org/docs/handbook/utility-types.html#recordkeys-type)
  type in TypeScript
- You cannot use string literals as a `record` key
- Using `v.string()` as a `record` key validator will only allow ASCII
  characters

#### Any

Fields or documents that could take on any value can be represented with
`v.any()`:

```typescript
defineTable({
  anyValue: v.any(),
});
```

This corresponds to the `any` type in TypeScript.

### Options

These options are passed as part of the
[options](/api/interfaces/server.DefineSchemaOptions) argument to
[`defineSchema`](/api/modules/server#defineschema).

#### `schemaValidation: boolean`

Whether Convex should validate at runtime that your documents match your schema.

By default, Convex will enforce that all new and existing documents match your
schema.

You can disable `schemaValidation` by passing in `schemaValidation: false`:

```typescript
defineSchema(
  {
    // Define tables here.
  },
  {
    schemaValidation: false,
  },
);
```

When `schemaValidation` is disabled, Convex will not validate that new or
existing documents match your schema. You'll still get schema-specific
TypeScript types, but there will be no validation at runtime that your documents
match those types.

#### `strictTableNameTypes: boolean`

Whether the TypeScript types should allow accessing tables not in the schema.

By default, the TypeScript table name types produced by your schema are strict.
That means that they will be a union of strings (ex. `"messages" | "users"`) and
only support accessing tables explicitly listed in your schema.

Sometimes it's useful to only define part of your schema. For example, if you
are rapidly prototyping, it could be useful to try out a new table before adding
it your `schema.ts` file.

You can disable `strictTableNameTypes` by passing in
`strictTableNameTypes: false`:

```typescript
defineSchema(
  {
    // Define tables here.
  },
  {
    strictTableNameTypes: false,
  },
);
```

When `strictTableNameTypes` is disabled, the TypeScript types will allow access
to tables not listed in the schema and their document type will be `any`.

Regardless of the value of `strictTableNameTypes`, your schema will only
validate documents in the tables listed in the schema. You can still create and
modify documents in other tables in JavaScript or on the dashboard (they just
won't be validated).

## Schema validation

Schemas are pushed automatically in
[`npx convex dev`](/cli.md#run-the-convex-dev-server) and
[`npx convex deploy`](/cli.md#deploy-convex-functions-to-production).

The first push after a schema is added or modified will validate that all
existing documents match the schema. If there are documents that fail
validation, the push will fail.

After the schema is pushed, Convex will validate that all future document
inserts and updates match the schema.

Schema validation is skipped if [`schemaValidation`](#schemavalidation-boolean)
is set to `false`.

Note that schemas only validate documents in the tables listed in the schema.
You can still create and modify documents in other tables (they just won't be
validated).

### Circular references

You might want to define a schema with circular ID references like:

```typescript title="convex/schema.ts"
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  users: defineTable({
    preferencesId: v.id("preferences"),
  }),
  preferences: defineTable({
    userId: v.id("users"),
  }),
});
```

In this schema, documents in the `users` table contain a reference to documents
in `preferences` and vice versa.

Because schema validation enforces your schema on every `db.insert`,
`db.replace`, and `db.patch` call, creating circular references like this is not
possible.

The easiest way around this is to make one of the references nullable:

```typescript title="convex/schema.ts"
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  users: defineTable({
    preferencesId: v.id("preferences"),
  }),
  preferences: defineTable({
    userId: v.union(v.id("users"), v.null()),
  }),
});
```

This way you can create a preferences document first, then create a user
document, then set the reference on the preferences document:

<TSAndJSSnippet
  title="convex/users.ts"
  sourceTS={circularExample}
  sourceJS={circularExample}
/>

[Let us know](/production/contact.md) if you need better support for circular
references.

## TypeScript types

Once you've defined a schema,
[`npx convex dev`](/cli.md#run-the-convex-dev-server) will produce new versions
of [`dataModel.d.ts`](/generated-api/data-model) and
[`server.d.ts`](/generated-api/server) with types based on your schema.

### `Doc<TableName>`

The [`Doc`](/generated-api/data-model#doc) TypeScript type from
[`dataModel.d.ts`](/generated-api/data-model) provides document types for all of
your tables. You can use these both when writing Convex functions and in your
React components:

```tsx noDialect title="MessageView.tsx"
import { Doc } from "../convex/_generated/dataModel";

function MessageView(props: { message: Doc<"messages"> }) {
  ...
}
```

If you need the type for a portion of a document, use the
[`Infer` type helper](/functions/validation#extracting-typescript-types).

### `query` and `mutation`

The [`query`](/generated-api/server#query) and
[`mutation`](/generated-api/server#mutation) functions in
[`server.js`](/generated-api/server) have the same API as before but now provide
a `db` with more precise types. Functions like
[`db.insert(table, document)`](/api/interfaces/server.GenericDatabaseWriter#insert)
now understand your schema. Additionally
[database queries](/database/reading-data/reading-data.mdx) will now return the
correct document type (not `any`).

<StackPosts query="schemas" />


---

# types.md

<!-- Source: database/types.md -->

---
title: "Data Types"
sidebar_position: 40
---

import ConvexValues from "@site/docs/\_convexValues.mdx";

All Convex documents are defined as Javascript objects. These objects can have
field values of any of the types below.

You can codify the shape of documents within your tables by
[defining a schema](/database/schemas.mdx).

## Convex values

<ConvexValues />

## System fields

Every document in Convex has two automatically-generated system fields:

- `_id`: The [document ID](/database/document-ids.mdx) of the document.
- `_creationTime`: The time this document was created, in milliseconds since the
  Unix epoch.

## Limits

Convex values must be less than 1MB in total size. This is an approximate limit
for now, but if you're running into these limits and would like a more precise
method to calculate a document's size,
[reach out to us](https://convex.dev/community). Documents can have nested
values, either objects or arrays that contain other Convex types. Convex types
can have at most 16 levels of nesting, and the cumulative size of a nested tree
of values must be under the 1MB limit.

Table names may contain alphanumeric characters ("a" to "z", "A" to "Z", and "0"
to "9") and underscores ("\_"), and they cannot start with an underscore.

For information on other limits, see [here](/production/state/limits.mdx).

If any of these limits don't work for you,
[let us know](https://convex.dev/community)!

## Working with `undefined`

The TypeScript value `undefined` is not a valid Convex value, so it cannot be
used in Convex function arguments or return values, or in stored documents.

1. Objects/records with `undefined` values are the same as if the field were
   missing: `{a: undefined}` is transformed into `{}` when passed to a function
   or stored in the database. You can think of Convex function calls and the
   Convex database as serializing the data with `JSON.stringify`, which
   similarly removes `undefined` values.
2. Validators for object fields can use `v.optional(...)` to indicate that the
   field might not be present.
   - If an object's field "a" is missing, i.e. `const obj = {};`, then
     `obj.a === undefined`. This is a property of TypeScript/JavaScript, not
     specific to Convex.
3. You can use `undefined` in filters and index queries, and it will match
   documents that do not have the field. i.e.
   `.withIndex("by_a", q=>q.eq("a", undefined))` matches document `{}` and
   `{b: 1}`, but not `{a: 1}` or `{a: null, b: 1}`.
   - In Convex's ordering scheme, `undefined < null < all other values`, so you
     can match documents that _have_ a field via `q.gte("a", null as any)`.
4. There is exactly one case where `{a: undefined}` is different from `{}`: when
   passed to `ctx.db.patch`. Passing `{a: undefined}` removes the field "a" from
   the document, while passing `{}` does not change the field "a". See
   [Updating existing documents](/database/writing-data.mdx#updating-existing-documents).
5. Since `undefined` gets stripped from function arguments but has meaning in
   `ctx.db.patch`, there are some tricks to pass patch's argument from the
   client.
   - If the client passing `args={}` (or `args={a: undefined}` which is
     equivalent) should leave the field "a" unchanged, use
     `ctx.db.patch(id, args)`.
   - If the client passing `args={}` should remove the field "a", use
     `ctx.db.patch(id, {a: undefined, ...args})`.
   - If the client passing `args={}` should leave the field "a" unchanged and
     `args={a: null}` should remove it, you could do
     ```ts
     if (args.a === null) {
       args.a = undefined;
     }
     await ctx.db.patch(id, args);
     ```
6. Functions that return a plain `undefined`/`void` are treated as if they
   returned `null`.
7. Arrays containing `undefined` values, like `[undefined]`, throw an error when
   used as Convex values.

If you would prefer to avoid the special behaviors of `undefined`, you can use
`null` instead, which _is_ a valid Convex value.

## Working with dates and times

Convex does not have a special data type for working with dates and times. How
you store dates depends on the needs of your application:

1. If you only care about a point in time, you can store a
   [UTC timestamp](https://en.wikipedia.org/wiki/Unix_time). We recommend
   following the `_creationTime` field example, which stores the timestamp as a
   `number` in milliseconds. In your functions and on the client you can create
   a JavaScript `Date` by passing the timestamp to its constructor:
   `new Date(timeInMsSinceEpoch)`. You can then print the date and time in the
   desired time zone (such as your user's machine's configured time zone).
   - To get the current UTC timestamp in your function and store it in the
     database, use `Date.now()`
2. If you care about a calendar date or a specific clock time, such as when
   implementing a booking app, you should store the actual date and/or time as a
   string. If your app supports multiple timezones you should store the timezone
   as well. [ISO8601](https://en.wikipedia.org/wiki/ISO_8601) is a common format
   for storing dates and times together in a single string like
   `"2024-03-21T14:37:15Z"`. If your users can choose a specific time zone you
   should probably store it in a separate `string` field, usually using the
   [IANA time zone name](https://en.wikipedia.org/wiki/Tz_database#Names_of_time_zones)
   (although you could concatenate the two fields with unique character like
   `"|"`).

For more sophisticated printing (formatting) and manipulation of dates and times
use one of the popular JavaScript libraries: [date-fns](https://date-fns.org/),
[Day.js](https://day.js.org/), [Luxon](https://moment.github.io/luxon/) or
[Moment.js](https://momentjs.com/).


---

# writing-data.mdx

<!-- Source: database/writing-data.mdx -->

---
title: "Writing Data"
sidebar_position: 4
---

import insertExample from "!!raw-loader!@site/../private-demos/snippets/convex/writingDataInsert.ts";
import patchExample from "!!raw-loader!@site/../private-demos/snippets/convex/writingDataPatch.ts";
import replaceExample from "!!raw-loader!@site/../private-demos/snippets/convex/writingDataReplace.ts";
import deleteExample from "!!raw-loader!@site/../private-demos/snippets/convex/writingDataDelete.ts";
import { ComponentCardList } from "@site/src/components/ComponentCard";

[Mutations](/functions/mutation-functions.mdx) can insert, update, and remove
data from database tables.

## Inserting new documents

You can create new documents in the database with the
[`db.insert`](/api/interfaces/server.GenericDatabaseWriter#insert) method:

<TSAndJSSnippet
  title="convex/tasks.ts"
  sourceTS={insertExample}
  sourceJS={insertExample}
  highlightPatterns={["db.insert"]}
/>

The second argument to `db.insert` is a JavaScript object with data for the new
document.

The same types of values that can be passed into and returned from
[queries](/functions/query-functions.mdx) and
[mutations](/functions/mutation-functions.mdx) can be written into the database.
See [Data Types](/database/types.md) for the full list of supported types.

The `insert` method returns a globally unique ID for the newly inserted
document.

## Updating existing documents

Given an existing document ID the document can be updated using the following
methods:

1. The [`db.patch`](/api/interfaces/server.GenericDatabaseWriter#patch) method
   will patch an existing document, shallow merging it with the given partial
   document. New fields are added. Existing fields are overwritten. Fields set
   to `undefined` are removed.

<TSAndJSSnippet
  title="convex/tasks.ts"
  sourceTS={patchExample}
  sourceJS={patchExample}
  highlightPatterns={["db.patch"]}
/>

2. The [`db.replace`](/api/interfaces/server.GenericDatabaseWriter#replace)
   method will replace the existing document entirely, potentially removing
   existing fields:

<TSAndJSSnippet
  title="convex/tasks.ts"
  sourceTS={replaceExample}
  sourceJS={replaceExample}
  highlightPatterns={["db.replace"]}
/>

## Deleting documents

Given an existing document ID the document can be removed from the table with
the [`db.delete`](/api/interfaces/server.GenericDatabaseWriter#delete) method.

<TSAndJSSnippet
  title="convex/tasks.ts"
  sourceTS={deleteExample}
  sourceJS={deleteExample}
  highlightPatterns={["db.delete"]}
/>

## Bulk inserts or updates

If you are used to SQL you might be looking for some sort of bulk insert or bulk
update statement. In Convex the entire `mutation` function is automatically a
single transaction.

You can just insert or update in a loop in the mutation function. Convex queues
up all database changes in the function and executes them all in a single
transaction when the function ends, leading to a single efficient change to the
database.

````typescript
/**
 * Bulk insert multiple products into the database.
 *
 * Equivalent to the SQL:
 * ```sql
 * INSERT INTO products (product_id, product_name, category, price, in_stock)
 * VALUES
 *     ('Laptop Pro', 'Electronics', 1299.99, true),
 *     ('Wireless Mouse', 'Electronics', 24.95, true),
 *     ('Ergonomic Keyboard', 'Electronics', 89.50, true),
 *     ('Ultra HD Monitor', 'Electronics', 349.99, false),
 *     ('Wireless Headphones', 'Audio', 179.99, true);
 * ```
 */
export const bulkInsertProducts = mutation({
  args: {
    products: v.array(
      v.object({
        product_name: v.string(),
        category: v.string(),
        price: v.number(),
        in_stock: v.boolean(),
      }),
    ),
  },
  handler: async (ctx, args) => {
    const { products } = args;

    // Insert in a loop. This is efficient because Convex queues all the changes
    // to be executed in a single transaction when the mutation ends.
    for (const product of products) {
      const id = await ctx.db.insert("products", {
        product_name: product.product_name,
        category: product.category,
        price: product.price,
        in_stock: product.in_stock,
      });
    }
  },
});
````

## Migrations

Database migrations are done through the migration component. The component is
designed to run online migrations to safely evolve your database schema over
time. It allows you to resume from failures, and validate changes with dry runs.

<ComponentCardList
  items={[
    {
      title: "Migrations",
      description: "Framework for long running data migrations of live data.",
      href: "https://www.convex.dev/components/migrations",
    },
  ]}
/>

## Write performance and limits

To prevent accidental writes of large amounts of records, queries and mutations
enforce limits detailed [here](/production/state/limits.mdx#transactions).


---

# database.mdx

<!-- Source: database.mdx -->

---
title: "Database"
description: "Store JSON-like documents with a relational data model."
hide_table_of_contents: true
pagination_prev: functions
---

The Convex database provides a relational data model, stores JSON-like
documents, and can be used with or without a schema. It "just works," giving you
predictable query performance in an easy-to-use interface.

Query and mutation [functions](/functions.mdx) read and write data through a
lightweight JavaScript API. There is nothing to set up and no need to write any
SQL. Just use JavaScript to express your app's needs.

Start by learning about the basics of [tables](#tables), [documents](#documents)
and [schemas](#schemas) below, then move on to
[Reading Data](/database/reading-data/reading-data.mdx) and
[Writing Data](/database/writing-data.mdx).

As your app grows more complex you'll need more from your database:

- Relational data modeling with [Document IDs](/database/document-ids.mdx)
- Fast querying with [Indexes](/database/reading-data/indexes/indexes.md)
- Exposing large datasets with [Paginated Queries](/database/pagination.mdx)
- Type safety by [Defining a Schema](/database/schemas.mdx)
- Interoperability with data
  [Import & Export](docs/database/import-export/import-export.mdx)

## Tables

Your Convex deployment contains tables that hold your app's data. Initially,
your deployment contains no tables or documents.

Each table springs into existence as soon as you add the first document to it.

```javascript
// `friends` table doesn't exist.
await ctx.db.insert("friends", { name: "Jamie" });
// Now it does, and it has one document.
```

You do not have to specify a schema upfront or create tables explicitly.

## Documents

Tables contain documents. Documents are very similar to JavaScript objects. They
have fields and values, and you can nest arrays or objects within them.

These are all valid Convex documents:

```json
{}
{"name": "Jamie"}
{"name": {"first": "Ari", "second": "Cole"}, "age": 60}
```

They can also contain references to other documents in other tables. See
[Data Types](/database/types.md) to learn more about the types supported in
Convex and [Document IDs](/database/document-ids.mdx) to learn about how to use
those types to model your data.

## Schemas

Though optional, schemas ensure that your data looks exactly how you want. For a
simple chat app, the schema will look like this:

```typescript
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

// @snippet start schema
export default defineSchema({
  messages: defineTable({
    author: v.id("users"),
    body: v.string(),
  }),
});
```

You can choose to be as flexible as you want by using types such as `v.any()` or
as specific as you want by precisely describing a `v.object()`.

See [the schema documentation](/database/schemas.mdx) to learn more about
schemas.

<CardLink
  className="convex-hero-card"
  item={{
    href: "/database/reading-data",
    docId: "database/reading-data/reading-data",
    label: "Next: Reading Data",
  }}
/>

<StackPosts query="database" />


---

# error.mdx

<!-- Source: error.mdx -->

# Errors and Warnings

This page explains specific errors thrown by Convex.

See [Error Handling](/functions/error-handling/error-handling.mdx) to learn
about handling errors in general.

<div id="occ-failure"></div>

## Write conflict: Optimistic concurrency control \{#1}

This system error is thrown when a mutation repeatedly fails due to conflicting
changes from parallel mutation executions.

### Example A

A mutation `updateCounter` always updates the same document:

```ts
export const updateCounter = mutation({
  args: {},
  handler: async (ctx) => {
    const doc = await ctx.db.get(process.env.COUNTER_ID);
    await ctx.db.patch(doc._id, { value: doc.value + 1 });
  },
});
```

If this mutation is called many times per second, many of its executions will
conflict with each other. Convex internally does several retries to mitigate
this concern, but if the mutation is called more rapidly than Convex can execute
it, some of the invocations will eventually throw this error:

<ErrorExample name="updateCounter">
  Documents read from or written to the table "counters" changed while this
  mutation was being run and on every subsequent retry. Another call to this
  mutation changed the document with ID "123456789101112".
</ErrorExample>

The error message will note the table name, which mutation caused the conflict
(in this example its another call to the same mutation), and one document ID
which was part of the conflicting change.

### Example B

Mutation `writeCount` depends on the entire `tasks` table:

```ts
export const writeCount = mutation({
  args: {
    target: v.id("counts"),
  },
  handler: async (ctx, args) => {
    const tasks = await ctx.db.query("tasks").collect();
    await ctx.db.patch(args.target, { value: tasks });
  },
});

export const addTask = mutation({
  args: {
    text: v.string(),
  },
  handler: async (ctx, args) => {
    await ctx.db.insert("tasks", { text: args.text });
  },
});
```

If the mutation `writeCount` is called at the same time as many calls to
`addTask` are made, either of the mutations can fail with this error. This is
because any change to the `"tasks"` table will conflict with the `writeCount`
mutation:

<ErrorExample name="writeCount">
  Documents read from or written to the table "tasks" changed while this
  mutation was being run and on every subsequent retry. A call to "addTask"
  changed the document with ID "123456789101112".
</ErrorExample>

### Remediation

To fix this issue:

1. Make sure that your mutations only read the data they need. Consider reducing
   the amount of data read by using indexed queries with
   [selective index range expressions](https://docs.convex.dev/database/indexes/).
2. Make sure you are not calling a mutation an unexpected number of times,
   perhaps from an action inside a loop.
3. Design your data model such that it doesn't require making many writes to the
   same document.

### Resources

- Learn more about [optimistic concurrency control](/database/advanced/occ.md).
- See this [Stack post](https://stack.convex.dev/waitlist) for an example of
  designing an app to avoid mutation conflicts.


---

# eslint.mdx

<!-- Source: eslint.mdx -->

---
title: ESLint rules
sidebar_position: 30
description: ESLint rules for Convex
---

ESLint rules for Convex functions enforce best practices. Let us know if there's
a rule you would find helpful!

<BetaAdmonition feature="Convex ESLint rules" verb="are" />

## Setup

### ESLint 8 (.eslintrc.js)

For ESLint 8, install these two libraries

```bash
npm i @typescript-eslint/eslint-plugin @convex-dev/eslint-plugin
```

and in .eslintrc.js:

```js
module.exports = {
  extends: [
    // Other configurations
    "plugin:@typescript-eslint/recommended",
    "plugin:@convex-dev/recommended",
  ],
  ignorePatterns: ["node_modules/", "dist/", "build/"],
};
```

### ESLint 9 (eslint.config.js)

For ESLint 9 (flat config), install just this library

```bash
npm i @convex-dev/eslint-plugin
```

and in eslint.config.js:

```bash
import convexPlugin from "@convex-dev/eslint-plugin";

export default [
  // Other configurations
  ...convexPlugin.configs.recommended
];
```

## Rules

### no-old-registered-function-syntax

Prefer object syntax for registered functions.

Convex queries, mutations, and actions can be defined with a single function or
with an object containing a handler property. Using the objects makes it
possible to add argument and return value validators, so is always preferable.

```ts
// Allowed by this rule:
export const list = query({
  handler: async (ctx) => {
    const data = await ctx.db.query("messages").collect();
    ...
  },
});

// Not allowed by this rule:
export const list = query(async (ctx) => {
  const data = await ctx.db.query("messages").collect();
  ...
});
```

### no-missing-args-validator

Use argument validators.

Convex queries, mutations, and actions can validate their arguments before
beginning to run the handler function. Besides being a concise way to validate,
the types of arguments, using argument validators enables generating more
descriptive function specs and therefore OpenAPI bindings.

```ts
// Allowed by this rule:
export const list = query({
  args: {},
  handler: async (ctx) => {
    ...
  },
});

// Allowed by this rule:
export const list = query({
  args: { channel: v.id('channel') },
  handler: async (ctx, { channel }) => {
    ...
  },
});

// Not allowed by this rule:
export const list = query({
  handler: async (ctx, { channel }: { channel: Id<"channel">}) => {
    ...
  },
});
```


---

# delete-files.mdx

<!-- Source: file-storage/delete-files.mdx -->

---
title: "Deleting Files"
sidebar_label: "Delete"
sidebar_position: 4
---

import DeleteImage from "!!raw-loader!@site/../private-demos/snippets/convex/deletingFiles.ts";

Files stored in Convex can be deleted from
[mutations](/functions/mutation-functions.mdx),
[actions](/functions/actions.mdx), and
[HTTP actions](/functions/http-actions.mdx) via the
[`storage.delete()`](/api/interfaces/server.StorageWriter#delete) function,
which accepts a storage ID.

Storage IDs correspond to documents in the `"_storage"` system table (see
[Metadata](/file-storage/file-metadata.mdx)), so they can be validated using the
`v.id("_storage")`.

<TSAndJSSnippet
  title="convex/images.ts"
  sourceTS={DeleteImage}
  sourceJS={DeleteImage}
  highlightPatterns={["delete\\("]}
/>


---

# file-metadata.mdx

<!-- Source: file-storage/file-metadata.mdx -->

---
title: "Accessing File Metadata"
sidebar_label: "Metadata"
sidebar_position: 5
---

import FileMetadata from "!!raw-loader!@site/../private-demos/snippets/convex/imagesMetadata.ts";
import FileMetadataDeprecated from "!!raw-loader!@site/../private-demos/snippets/convex/fileMetadata.ts";

Every stored file is reflected as a document in the `"_storage"` system table.
File metadata of a file can be accessed from
[queries](/functions/query-functions.mdx) and
[mutations](/functions/mutation-functions.mdx) via `db.system.get` and
`db.system.query`:

<TSAndJSSnippet
  title="convex/images.ts"
  sourceTS={FileMetadata}
  sourceJS={FileMetadata}
  highlightPatterns={["db.system.get\\(", "db.system.query\\("]}
/>

This is an example of the returned document:

```json
{
  "_creationTime": 1700697415295.742,
  "_id": "3k7ty84apk2zy00ay4st1n5p9kh7tf8",
  "contentType": "image/jpeg",
  "sha256": "cb58f529b2ed5a1b8b6681d91126265e919ac61fff6a367b8341c0f46b06a5bd",
  "size": 125338
}
```

The returned document has the following fields:

- `sha256`: a base16 encoded sha256 checksum of the file contents
- `size`: the size of the file in bytes
- `contentType`: the `ContentType` of the file if it was provided on upload

You can check the metadata manually on your
[dashboard](/dashboard/deployments/files.md).

## Accessing metadata from actions (deprecated)

Alternatively, a
[`storage.getMetadata()`](/api/interfaces/server.StorageReader#getmetadata)
function is available to access individual file metadata from
[actions](/functions/actions.mdx) and
[HTTP actions](/functions/http-actions.mdx):

<TSAndJSSnippet
  title="convex/images.ts"
  sourceTS={FileMetadataDeprecated}
  sourceJS={FileMetadataDeprecated}
  highlightPatterns={["getMetadata\\("]}
/>

Note that
[`storage.getMetadata()`](/api/interfaces/server.StorageReader#getmetadata)
returns a [`FileMetadata`](/api/modules/server#filemetadata), which has a
slightly different shape than the result from `db.system.get`.


---

# serve-files.mdx

<!-- Source: file-storage/serve-files.mdx -->

---
title: "Serving Files"
sidebar_label: "Serve"
sidebar_position: 3
---

import Messages from "!!raw-loader!@site/../demos/file-storage/convex/messages.ts";
import AppTS from "!!raw-loader!@site/../demos/file-storage/src/App.tsx";
import AppJS from "!!raw-loader!@site/../private-demos/snippets/src/fileStorageApp.jsx";
import Http from "!!raw-loader!@site/../demos/file-storage-with-http/convex/http.ts";
import HttpAppTS from "!!raw-loader!@site/../demos/file-storage-with-http/src/App.tsx";
import HttpAppJS from "!!raw-loader!@site/../private-demos/snippets/src/fileStorageWithHttpImage.jsx";

Files stored in Convex can be served to your users by generating a URL pointing
to a given file.

## Generating file URLs in queries

The simplest way to serve files is to return URLs along with other data required
by your app from [queries](/functions/query-functions.mdx) and
[mutations](/functions/mutation-functions.mdx).

A file URL can be generated from a storage ID by the
[`storage.getUrl`](/api/interfaces/server.StorageReader#geturl) function of the
[`QueryCtx`](/api/interfaces/server.GenericQueryCtx),
[`MutationCtx`](/api/interfaces/server.GenericMutationCtx), or
[`ActionCtx`](/api/interfaces/server.GenericActionCtx) object:

<TSAndJSSnippet
  title="convex/listMessages.ts"
  sourceTS={Messages}
  sourceJS={Messages}
  snippet="query"
  highlightPatterns={["storage.getUrl"]}
/>

File URLs can be used in `img` elements to render images:

<TSAndJSSnippet
  title="src/App.tsx"
  sourceTS={AppTS}
  sourceJS={AppJS}
  snippet="imageComponent"
/>

In your query you can control who gets access to a file when the URL is
generated. If you need to control access when the file is _served_, you can
define your own file serving HTTP actions instead.

## Serving files from HTTP actions

You can serve files directly from [HTTP actions](/functions/http-actions.mdx).
An HTTP action will need to take some parameter(s) that can be mapped to a
storage ID, or a storage ID itself.

This enables access control at the time the file is served, such as when an
image is displayed on a website. But note that the HTTP actions response size is
[currently limited](/functions/http-actions.mdx#limits) to 20MB. For larger
files you need to use file URLs as described
[above](#generating-file-urls-in-queries).

A file [`Blob`](https://developer.mozilla.org/en-US/docs/Web/API/Blob) object
can be generated from a storage ID by the
[`storage.get`](/api/interfaces/server.StorageActionWriter#get) function of the
[`ActionCtx`](/api/interfaces/server.GenericActionCtx) object, which can be
returned in a `Response`:

<TSAndJSSnippet title="convex/http.ts" sourceTS={Http} sourceJS={Http} snippet="getImage"
highlightPatterns={["storage.get"]} prefix={
    `import { httpRouter } from "convex/server";
import { httpAction } from "./\_generated/server";
import { Id } from "./\_generated/dataModel";

const http = httpRouter();\

`} suffix={"\nexport default http;"} />

The URL of such an action can be used directly in `img` elements to render
images:

<TSAndJSSnippet
  title="src/App.tsx"
  sourceTS={HttpAppTS}
  sourceJS={HttpAppJS}
  snippet="getImage"
/>


---

# store-files.mdx

<!-- Source: file-storage/store-files.mdx -->

---
title: "Storing Generated Files"
sidebar_label: "Store"
sidebar_position: 2
---

import StoreImageTS from "!!raw-loader!@site/../private-demos/snippets/convex/images.ts";
import StoreImageJS from "!!raw-loader!@site/../private-demos/snippets/convex/imagesJS.js";

Files can be uploaded to Convex from a client and stored directly, see
[Upload](/file-storage/upload-files.mdx).

Alternatively files can also be stored after they've been fetched or generated
in [actions](/functions/actions.mdx) and
[HTTP actions](/functions/http-actions.mdx). For example you might call a
third-party API to generate an image based on a user prompt and then store that
image in Convex.

**Example:**
[Dall-E Storage & Action](https://github.com/get-convex/convex-demos/tree/main/dall-e-storage-action)

## Storing files in actions

Storing files in actions is similar to
[uploading a file via an HTTP action](/file-storage/upload-files.mdx#uploading-files-via-an-http-action).

The action takes these steps:

1. Fetch or generate an image.
2. Store the image using
   [`storage.store()`](/api/interfaces/server.StorageActionWriter#store) and
   receive a storage ID.
3. Save the storage ID into your data model via a mutation.

Storage IDs correspond to documents in the `"_storage"` system table (see
[Metadata](/file-storage/file-metadata.mdx)), so they can be validated using the
`v.id("_storage")` validator and typed as `Id<"_storage">` in TypeScript.

<TSAndJSSnippet
  title="convex/images.ts"
  sourceTS={StoreImageTS}
  sourceJS={StoreImageJS}
  highlightPatterns={["fetch", "storage.store", "runMutation\\("]}
/>


---

# upload-files.mdx

<!-- Source: file-storage/upload-files.mdx -->

---
title: "Uploading and Storing Files"
sidebar_label: "Upload"
sidebar_position: 1
---

import Messages from "!!raw-loader!@site/../demos/file-storage/convex/messages.ts";
import URLUploadTS from "!!raw-loader!@site/../demos/file-storage/src/_simpleApp.tsx";
import URLUploadJS from "!!raw-loader!@site/../private-demos/snippets/src/fileStorageApp.jsx";
import HttpAction from "!!raw-loader!@site/../demos/file-storage-with-http/convex/http.ts";
import HttpUploadTS from "!!raw-loader!@site/../demos/file-storage-with-http/src/_simpleApp.tsx";
import HttpUploadJS from "!!raw-loader!@site/../private-demos/snippets/src/fileStorageWithHttpApp.jsx";

Upload files to Convex by
[generated upload urls](#uploading-files-via-upload-urls), or via an
[custom HTTP Action](#uploading-files-via-an-http-action).

## Uploading files via upload URLs

Arbitrarily large files can be uploaded directly to your backend using a
generated upload URL. This requires the client to make 3 requests:

1. Generate an upload URL using a mutation that calls
   [`storage.generateUploadUrl()`](/api/interfaces/server.StorageWriter#generateuploadurl).
2. Send a POST request with the file contents to the upload URL and receive a
   storage ID.
3. Save the storage ID into your data model via another mutation.

In the first mutation that generates the upload URL you can control who can
upload files to your Convex storage.

**Example**:
[File Storage with Queries and Mutations](https://github.com/get-convex/convex-demos/tree/main/file-storage)

### Calling the upload APIs from a web page

Here's an example of uploading an image via a form submission handler to an
upload URL generated by a mutation:

<TSAndJSSnippet
  title="src/App.jsx"
  sourceTS={URLUploadTS}
  sourceJS={URLUploadJS}
  snippet="fileUpload"
  highlightPatterns={[
    "generateUploadUrl\\(",
    "sendImage\\(",
    "await fetch",
    "method:",
    "headers:",
    "body:",
    "}\\);",
  ]}
/>

### Generating the upload URL

An upload URL can be generated by the
[`storage.generateUploadUrl`](/api/interfaces/server.StorageWriter#generateuploadurl)
function of the [`MutationCtx`](/api/interfaces/server.GenericMutationCtx)
object:

<TSAndJSSnippet
  title="convex/messages.js"
  sourceTS={Messages}
  sourceJS={Messages}
  snippet="generateUploadUrl"
  highlightPatterns={["storage.generateUploadUrl"]}
/>

This mutation can control who is allowed to upload files.

The upload URL expires in 1 hour and so should be fetched shortly before the
upload is made.

### Writing the new storage ID to the database

Since the storage ID is returned to the client it is likely you will want to
persist it in the database via another mutation:

<TSAndJSSnippet
  title="convex/messages.ts"
  sourceTS={Messages}
  sourceJS={Messages}
  prefix={`import { mutation } from "./_generated/server";\n`}
  snippet="saveStorageId"
  highlightPatterns={["storage.generateUploadUrl"]}
/>

### Limits

The file size is not limited, but upload POST request has a 2 minute timeout.

## Uploading files via an HTTP action

The file upload process can be more tightly controlled by leveraging
[HTTP action](/functions/http-actions.mdx)s, performing the whole upload flow
using a single request, but requiring correct CORS headers configuration.

The custom upload HTTP action can control who can upload files to your Convex
storage. But note that the HTTP action request size is
[currently limited](/functions/http-actions.mdx#limits) to 20MB. For larger
files you need to use upload URLs as described
[above](#uploading-files-via-upload-urls).

**Example:**
[File Storage with HTTP Actions](https://github.com/get-convex/convex-demos/tree/main/file-storage-with-http)

### Calling the upload HTTP action from a web page

Here's an example of uploading an image via a form submission handler to the
`sendImage` HTTP action defined next.

The highlighted lines make the actual request to the HTTP action:

<TSAndJSSnippet
  title="src/App.tsx"
  sourceTS={HttpUploadTS}
  sourceJS={HttpUploadJS}
  snippet="httpFileUpload"
  highlightPatterns={["fetch", "method:", "headers:", "body:", "}\\);"]}
/>

### Defining the upload HTTP action

A file sent in the HTTP request body can be stored using the
[`storage.store`](/api/interfaces/server.StorageActionWriter#store) function of
the [`ActionCtx`](/api/interfaces/server.GenericActionCtx) object. This function
returns an `Id<"_storage">` of the stored file.

From the HTTP action you can call a mutation to write the storage ID to a
document in your database.

To confirm success back to your hosted website, you will need to set the right
[CORS headers](/functions/http-actions.mdx#cors):

<TSAndJSSnippet
  title="convex/http.js"
  sourceTS={HttpAction}
  sourceJS={HttpAction}
  snippet="sendImageStore"
  highlightPatterns={["storage.store"]}
/>

You also need to handle the pre-flight `OPTIONS` request:

<TSAndJSSnippet
  title="convex/http.js"
  sourceTS={HttpAction}
  sourceJS={HttpAction}
  snippet="preflight"
  highlightPatterns={["storage.store"]}
/>


---

# file-storage.mdx

<!-- Source: file-storage.mdx -->

---
title: "File Storage"
description: "Store and serve files of any type."
sidebar_position: 160
pagination_prev: database
---

File Storage makes it easy to implement file upload in your app, store files
from and send files to third-party APIs, and to serve dynamic files to your
users. All file types are supported.

- [Upload](/file-storage/upload-files.mdx) files to store them in Convex and
  reference them in your database documents
- [Store](/file-storage/store-files.mdx) files generated or fetched from
  third-party APIs
- [Serve](/file-storage/serve-files.mdx) files via URL
- [Delete](/file-storage/delete-files.mdx) files stored in Convex
- Access file [metadata](/file-storage/file-metadata.mdx)

You can manage your stored files on the
[dashboard](/dashboard/deployments/files.md).

**Examples:**
[File Storage with HTTP Actions](https://github.com/get-convex/convex-demos/tree/main/file-storage-with-http),
[File Storage with Queries and Mutations](https://github.com/get-convex/convex-demos/tree/main/file-storage)


---

# actions.mdx

<!-- Source: functions/actions.mdx -->

---
title: Actions
sidebar_position: 30
---

import Constructor from "!!raw-loader!@site/../private-demos/snippets/convex/actionsConstructor.ts";
import ArgsWithValidation from "!!raw-loader!@site/../private-demos/snippets/convex/actionsArgsWithValidation.ts";
import Context from "!!raw-loader!@site/../private-demos/snippets/convex/actionsContext.ts";
import ContextRunQuery from "!!raw-loader!@site/../private-demos/snippets/convex/myFunctions.ts";
import ContextRunMutation from "!!raw-loader!@site/../private-demos/snippets/convex/actionsContextRunMutation.ts";
import CircularError from "!!raw-loader!@site/../private-demos/snippets/convex/actionsCircularError.ts";
import CircularErrorFixedResults from "!!raw-loader!@site/../private-demos/snippets/convex/actionsCircularErrorFixedResults.ts";
import CircularErrorFixedReturn from "!!raw-loader!@site/../private-demos/snippets/convex/actionsCircularErrorFixedReturn.ts";
import NPM from "!!raw-loader!@site/../private-demos/snippets/convex/actionsNPM.ts";
import Node from "!!raw-loader!@site/../private-demos/snippets/convex/actionsNode.ts";
import Call from "!!raw-loader!@site/../private-demos/snippets/src/actionsCall.tsx";
import ScheduleFromMutation from "!!raw-loader!@site/../private-demos/snippets/convex/actionsScheduleFromMutation.ts";

Actions can call third party services to do things such as processing a payment
with [Stripe](https://stripe.com). They can be run in Convex's JavaScript
environment or in Node.js. They can interact with the database indirectly by
calling [queries](/functions/query-functions.mdx) and
[mutations](/functions/mutation-functions.mdx).

**Example:**
[GIPHY Action](https://github.com/get-convex/convex-demos/tree/main/giphy-action)

## Action names

Actions follow the same naming rules as queries, see
[Query names](/functions/query-functions.mdx#query-names).

## The `action` constructor

To declare an action in Convex you use the action constructor function. Pass it
an object with a `handler` function, which performs the action:

<TSAndJSSnippet
  sourceTS={Constructor}
  sourceJS={Constructor}
  title="convex/myFunctions.ts"
/>

Unlike a query, an action can but does not have to return a value.

### Action arguments and responses

Action arguments and responses follow the same rules as
[mutations](/functions/mutation-functions.mdx#mutation-arguments):

<TSAndJSSnippet
  sourceTS={ArgsWithValidation}
  sourceJS={ArgsWithValidation}
  title="convex/myFunctions.ts"
/>

The first argument to the handler function is reserved for the action context.

### Action context

The `action` constructor enables interacting with the database, and other Convex
features by passing an [ActionCtx](/api/interfaces/server.GenericActionCtx)
object to the handler function as the first argument:

<TSAndJSSnippet
  sourceTS={Context}
  sourceJS={Context}
  title="convex/myFunctions.ts"
/>

Which part of that action context is used depends on what your action needs to
do:

- To read data from the database use the `runQuery` field, and call a query that
  performs the read:

  <TSAndJSSnippet
    sourceTS={ContextRunQuery}
    sourceJS={ContextRunQuery}
    snippet="action"
    title="convex/myFunctions.ts"
  />

  Here `readData` is an [internal query](/functions/internal-functions.mdx)
  because we don't want to expose it to the client directly. Actions, mutations
  and queries can be defined in the same file.

- To write data to the database use the `runMutation` field, and call a mutation
  that performs the write:

  <TSAndJSSnippet
    sourceTS={ContextRunMutation}
    sourceJS={ContextRunMutation}
    title="convex/myFunctions.ts"
  />

  Use an [internal mutation](/functions/internal-functions.mdx) when you want to
  prevent users from calling the mutation directly.

  As with queries, it's often convenient to define actions and mutations in the
  same file.

- To generate upload URLs for storing files use the `storage` field. Read on
  about [File Storage](/file-storage.mdx).
- To check user authentication use the `auth` field. Auth is propagated
  automatically when calling queries and mutations from the action. Read on
  about [Authentication](/auth.mdx).
- To schedule functions to run in the future, use the `scheduler` field. Read on
  about [Scheduled Functions](/scheduling/scheduled-functions.mdx).
- To search a vector index, use the `vectorSearch` field. Read on about
  [Vector Search](/search/vector-search.mdx).

### Dealing with circular type inference

<Details summary={<>
Working around the TypeScript error: some action <code>implicitly has
type 'any' because it does not have a type annotation and is
referenced directly or indirectly in its own initializer.</code>
</>}>

When the return value of an action depends on the result of calling
`ctx.runQuery` or `ctx.runMutation`, TypeScript will complain that it cannot
infer the return type of the action. This is a minimal example of the issue:

<Snippet
  title="convex/myFunctions.ts"
  source={CircularError}
  snippet="tsError"
/>

To work around this, there are two options:

1. Type the return value of the handler function explicitly:
   <Snippet
     title="convex/myFunctions.ts"
     source={CircularErrorFixedReturn}
     snippet="fixed"
     highlightPatterns={["null"]}
   />
2. Type the the result of the `ctx.runQuery` or `ctx.runMutation` call
   explicitly:
   <Snippet
     title="convex/myFunctions.ts"
     source={CircularErrorFixedResults}
     snippet="fixed"
     highlightPatterns={["null"]}
   />

TypeScript will check that the type annotation matches what the called query or
mutation returns, so you don't lose any type safety.

In this trivial example the return type of the query was `null`. See the
[TypeScript](/understanding/best-practices/typescript.mdx#type-annotating-server-side-helpers)
page for other types which might be helpful when annotating the result.

</Details>

## Choosing the runtime ("use node")

Actions can run in Convex's custom JavaScript environment or in Node.js.

By default, actions run in Convex's environment. This environment supports
`fetch`, so actions that simply want to call a third-party API using `fetch` can
be run in this environment:

<TSAndJSSnippet sourceTS={NPM} sourceJS={NPM} title="convex/myFunctions.ts" />

Actions running in Convex's environment are faster compared to Node.js, since
they don't require extra time to start up before running your action (cold
starts). They can also be defined in the same file as other Convex functions.
Like queries and mutations they can import NPM packages, but not all are
supported.

Actions needing unsupported NPM packages or Node.js APIs can be configured to
run in Node.js by adding the `"use node"` directive at the top of the file. Note
that other Convex functions cannot be defined in files with the `"use node";`
directive.

<TSAndJSSnippet
  sourceTS={Node}
  sourceJS={Node}
  highlightPatterns={["use node"]}
  title="convex/myAction.ts"
/>

Learn more about the two [Convex Runtimes](/functions/runtimes.mdx).

## Splitting up action code via helpers

<>
  {/* Fragment for Prettier */}
  Just like with [queries](/functions/query-functions.mdx#splitting-up-query-code-via-helpers)
  and [mutations](/functions/mutation-functions.mdx#splitting-up-mutation-code-via-helpers)
  you can define and call helper
  <LanguageSelector verbose /> functions to split up the code in your actions or
  reuse logic across multiple Convex functions.

But note that the [ActionCtx](/api/interfaces/server.GenericActionCtx) only has
the `auth` field in common with [QueryCtx](/generated-api/server.md#queryctx)
and [MutationCtx](/generated-api/server.md#mutationctx).

</>

## Calling actions from clients

To call an action from [React](/client/react.mdx) use the
[`useAction`](/api/modules/react#useaction) hook along with the generated
[`api`](/generated-api/api) object.

<TSAndJSSnippet sourceTS={Call} sourceJS={Call} title="src/myApp.tsx" />

Unlike
[mutations](/functions/mutation-functions.mdx#calling-mutations-from-clients),
actions from a single client are parallelized. Each action will be executed as
soon as it reaches the server (even if other actions and mutations from the same
client are running). If your app relies on actions running after other actions
or mutations, make sure to only trigger the action after the relevant previous
function completes.

**Note:** In most cases calling an action directly from a client **is an
anti-pattern**. Instead, have the client call a
[mutation](/functions/mutation-functions.mdx) which captures the user intent by
writing into the database and then
[schedules](/scheduling/scheduled-functions.mdx) an action:

<TSAndJSSnippet
  sourceTS={ScheduleFromMutation}
  sourceJS={ScheduleFromMutation}
  title="convex/myFunctions.ts"
/>

This way the mutation can enforce invariants, such as preventing the user from
executing the same action twice.

## Limits

Actions time out after 10 minutes.
[Node.js](/functions/runtimes.mdx#nodejs-runtime) and
[Convex runtime](/functions/runtimes.mdx#default-convex-runtime) have 512MB and
64MB memory limit respectively. Please [contact us](/production/contact.md) if
you have a use case that requires configuring higher limits.

Actions can do up to 1000 concurrent operations, such as executing queries,
mutations or performing fetch requests.

For information on other limits, see [here](/production/state/limits.mdx).

## Error handling

Unlike queries and mutations, actions may have side-effects and therefore can't
be automatically retried by Convex when errors occur. For example, say your
action calls Stripe to send a customer invoice. If the HTTP request fails,
Convex has no way of knowing if the invoice was already sent. Like in normal
backend code, it is the responsibility of the caller to handle errors raised by
actions and retry the action call if appropriate.

## Dangling promises

Make sure to await all promises created within an action. Async tasks still
running when the function returns might or might not complete. In addition,
since the Node.js execution environment might be reused between action calls,
dangling promises might result in errors in subsequent action invocations.

## Best practices

### `await ctx.runAction` should only be used for crossing JS runtimes

**Why?** `await ctx.runAction` incurs to overhead of another Convex server
function. It counts as an extra function call, it allocates its own system
resources, and while you're awaiting this call the parent action call is frozen
holding all it's resources. If you pile enough of these calls on top of each
other, your app may slow down significantly.

**Fix:** The reason this api exists is to let you run code in the
[Node.js environment](/functions/runtimes.mdx). If you want to call an action
from another action that's in the same runtime, which is the normal case, the
best way to do this is to pull the code you want to call into a TypeScript
[helper function](/understanding/best-practices/best-practices.mdx#use-helper-functions-to-write-shared-code)
and call the helper instead.

### Avoid `await ctx.runMutation` / `await ctx.runQuery`

```ts
// ❌
const foo = await ctx.runQuery(...)
const bar = await ctx.runQuery(...)

// ✅
const fooAndBar = await ctx.runQuery(...)
```

**Why?** Multiple runQuery / runMutations execute in separate transactions and
aren’t guaranteed to be consistent with each other (e.g. foo and bar could read
the same document and return two different results), while a single runQuery /
runMutation will always be consistent. Additionally, you’re paying for multiple
function calls when you don’t have to.

**Fix:** Make a new internal query / mutation that does both things. Refactoring
the code for the two functions into helpers will make it easy to create a new
internal function that does both things while still keeping around the original
functions. Potentially try and refactor your action code to “batch” all the
database access.

Caveats: Separate runQuery / runMutation calls are valid when intentionally
trying to process more data than fits in a single transaction (e.g. running a
migration, doing a live aggregate).


---

# bundling.mdx

<!-- Source: functions/bundling.mdx -->

---
title: "Bundling"
sidebar_position: 90
---

Bundling is the process of gathering, optimizing and transpiling the JS/TS
source code of [functions](/functions.mdx) and their dependencies. During
development and when deploying, the code is transformed to a format that Convex
[runtimes](/functions/runtimes.mdx) can directly and efficiently execute.

Convex currently bundles all dependencies automatically, but for the Node.js
runtime you can disable bundling certain packages via the
[external packages](#external-packages) config.

## Bundling for Convex

When you push code either via `npx convex dev` or `npx convex deploy`, the
Convex CLI uses [esbuild](https://esbuild.github.io/) to traverse your `convex/`
folder and bundle your functions and all of their used dependencies into a
source code bundle. This bundle is then sent to the server.

Thanks to bundling you can write your code using both modern ECMAScript Modules
(ESM) or the older CommonJS (CJS) syntax.

<Details summary="ESM vs. CJS">
    ESM
    - Is the standard for browser Javascript
    - Uses static imports via the `import` and `export` **keywords** (not functions)
    at the global scope
    - Also supports dynamic imports via the asynchronous `import` function

    CJS
    - Was previously the standard module system for Node.js
    - Relies on dynamic imports via the `require` and asynchronous `import`
    functions for fetching external modules
    - Uses the `module.exports` object for exports

</Details>

## Bundling limitations

The nature of bundling comes with a few limitations.

### Code size limits

The total size of your bundled function code in your `convex/` folder is
**limited to 32MiB (~33.55MB)**. Other platform limits can be found
[here](/production/state/limits.mdx).

While this limit in itself is quite high for just source code, certain
dependencies can quickly make your bundle size cross over this limit,
particularly if they are not effectively
[tree-shakeable](https://webpack.js.org/guides/tree-shaking/) (such as
[aws-sdk](https://www.npmjs.com/package/aws-sdk) or
[snowflake-sdk](https://www.npmjs.com/package/snowflake-sdk))

You can follow these steps to debug bundle size:

<StepByStep>
  <Step title="Make sure you're using the most recent version of convex">
    ```sh
    npm install convex@latest
    ```
  </Step>
  <Step title="Generate the bundle">
   Note that this will not push code, and just generated a bundle for debugging purposes.

    ```sh
    npx convex dev --once --debug-bundle-path /tmp/myBundle
    ```

  </Step>
  <Step title="Visualize the bundle">
  Use
   [source-map-explorer](https://github.com/danvk/source-map-explorer/tree/master)
   to visualize your bundle.

    ```sh
    npx source-map-explorer /tmp/myBundle/**/*.js
    ```

  </Step>
</StepByStep>

Code bundled for the Convex runtime will be in the `isolate` directory while
code bundled for node actions will be in the `node` directory.

Large node dependencies can be eliminated from the bundle by marking them as
[external packages](/functions/bundling.mdx#external-packages).

### Dynamic dependencies

Some libraries rely on dynamic imports (via `import`/`require` calls) to avoid
always including their dependencies. These imports are not supported by the
[default Convex runtime](/functions/runtimes.mdx#default-convex-runtime) and
will throw an error at runtime.

Additionally, some libraries rely on local files, which cannot be bundled by
esbuild. If bundling is used, irrespective of the choice of runtime, these
imports will always fail in Convex.

<Details summary="Examples of libraries with dynamic dependencies">

Consider the following examples of packages relying on dynamic dependencies:

- [langchain](https://www.npmjs.com/package/langchain) relying on the presence
  of peer dependencies that it can dynamically import. These dependencies are
  not statically `import`ed so will not be bundled by `esbuild`.
- [sharp](https://www.npmjs.com/package/sharp) relying on the presence of
  `libvips` binaries for image-processing operations
- [pdf-parse](https://www.npmjs.com/package/pdf-parse) relies on being
  dynamically imported with `require()` in order to detect if it is being run in
  test mode. Bundling can eliminate these `require()` calls, making `pdf-parse`
  assume it is running in test mode.
- [tiktoken](https://www.npmjs.com/package/tiktoken) relying on local WASM files

</Details>

## External packages

As a workaround for the bundling limitations above, Convex provides an escape
hatch: **external packages**. This feature is currently exclusive to Convex's
[Node.js runtime](/functions/runtimes.mdx#nodejs-runtime).

External packages use
[`esbuild`'s facility for marking a dependency as external](https://esbuild.github.io/api/#external).
This tells `esbuild` to not bundle the external dependency at all and to leave
the import as a dynamic runtime import using `require()` or `import()`. Thus,
your Convex modules will rely on the underlying system having that dependency
made available at execution-time.

### Package installation on the server

Packages marked as external are installed from [npm](https://www.npmjs.com/) the
first time you push code that uses them. The version installed matches the
version installed in the `node_modules` folder on your local machine.

While this comes with a latency penalty the first time you push external
packages, your packages are cached and this install step only ever needs to
rerun if your external packages change. Once cached, pushes can actually be
faster due to smaller source code bundles being sent to the server during
pushes!

### Specifying external packages

Create a [`convex.json`](/production/project-configuration.mdx#convexjson) file
in the same directory as your `package.json` if it does not exist already. Set
the `node.externalPackages` field to `["*"]` to mark all dependencies used
within your Node actions as external:

```json
{
  "node": {
    "externalPackages": ["*"]
  }
}
```

Alternatively, you can explicitly specify which packages to mark as external:

```json
{
  "node": {
    "externalPackages": ["aws-sdk", "sharp"]
  }
}
```

The package identifiers should match the string used in `import`/`require` in
your [Node.js action](/functions/actions.mdx#choosing-the-runtime-use-node).

### Troubleshooting external packages

#### Incorrect package versions

The Convex CLI searches for external packages within your local `node_modules`
directory. Thus, changing version of a package in the `package.json` will not
affect the version used on the server until you've updated the package version
installed in your local `node_modules` folder (e.g. running `npm install`).

#### Import errors

Marking a dependency as external may result in errors like this:

> The requested module "some-module" is a CommonJs module, which may not support
> all module.exports as named exports. CommonJs modules can always be imported
> via the default export

This requires rewriting any imports for this module as follows:

```ts
// ❌ old
import { Foo } from "some-module";

// ✅ new
import SomeModule from "some-module";
const { Foo } = SomeModule;
```

### Limitations

The total size of your source code bundle and external packages cannot exceed
the following:

- 45MB zipped
- 240MB unzipped

Packages that are known not to work at this time:

- [Puppeteer](https://www.npmjs.com/package/puppeteer) - browser binary
  installation exceeds the size limit
- [@ffmpeg.wasm](https://www.npmjs.com/package/@ffmpeg/ffmpeg) - since 0.12.0,
  [no longer supports Node environments](https://ffmpegwasm.netlify.app/docs/faq#why-ffmpegwasm-doesnt-support-nodejs)

If there is a package that you would like working in your Convex functions,
[let us know](https://convex.dev/community).


---

# debugging.mdx

<!-- Source: functions/debugging.mdx -->

---
title: Debugging
sidebar_position: 100
---

Debugging is the process of figuring out why your code isn't behaving as you
expect.

## Debugging during development

During development the built-in `console` API allows you to understand what's
going on inside your functions:

```ts title="convex/myFunctions.ts"
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export const mutateSomething = mutation({
  args: { a: v.number(), b: v.number() },
  handler: (_, args) => {
    console.log("Received args", args);
    // ...
  },
});
```

The following methods are available in the
[default Convex runtime](/functions/runtimes.mdx#default-convex-runtime):

- Logging values, with a specified severity level:
  - `console.log`
  - `console.info`
  - `console.warn`
  - `console.error`
  - `console.debug`
- Logging with a stack trace:
  - [`console.trace`](https://developer.mozilla.org/en-US/docs/Web/API/console/trace_static)
- Measuring execution time:
  - [`console.time`](https://developer.mozilla.org/en-US/docs/Web/API/console/time_static)
  - [`console.timeLog`](https://developer.mozilla.org/en-US/docs/Web/API/console/timelog_static)
  - [`console.timeEnd`](https://developer.mozilla.org/en-US/docs/Web/API/console/timeend_static)

The Convex backend also automatically logs all successful function executions
and all errors thrown by your functions.

You can view these logs:

1. When using the [`ConvexReactClient`](/client/react.mdx), in your browser
   developer tools console pane. The logs are sent from your dev deployment to
   your client, and the client logs them to the browser. Production deployments
   [**do not** send logs to the client](/functions/error-handling/error-handling.mdx#differences-in-error-reporting-between-dev-and-prod).
2. In your Convex dashboard on the [Logs page](/dashboard/deployments/logs.md).
3. In your terminal with [`npx convex dev`](/cli.md#tail-deployment-logs) during
   development or [`npx convex logs`](/cli.md#tail-deployment-logs), which only
   prints logs.

### Using a debugger

You can exercise your functions from tests, in which case you can add
`debugger;` statements and step through your code. See
[Testing](/testing/convex-test.mdx#debugging-tests).

## Debugging in production

When debugging an issue in production your options are:

1. Leverage existing logging
2. Add more logging and deploy a new version of your backend to production

Convex backend currently only preserves a limited number of logs, and logs can
be erased at any time when the Convex team performs internal maintenance and
upgrades. You should therefore set up
[log streaming and error reporting](/production/integrations/integrations.mdx)
integrations to enable your team easy access to historical logs and additional
information logged by your client.

## Finding relevant logs by Request ID

To find the appropriate logs for an error you or your users experience, Convex
includes a Request ID in all exception messages in both dev and prod in this
format: `[Request ID: <request_id>]`.

You can copy and paste a Request ID into your Convex dashboard to view the logs
for functions started by that request. See the
[Dashboard logs page](/dashboard/deployments/logs.md#filter-logs) for details.

{/* TODO: Document how to filter by Request ID in Datadog/Axiom */}


---

# application-errors.mdx

<!-- Source: functions/error-handling/application-errors.mdx -->

---
title: "Application Errors"
sidebar_label: "Application Errors"
---

import Server from "!!raw-loader!@site/../private-demos/snippets/convex/applicationErrors.ts";
import ClientTS from "!!raw-loader!@site/../private-demos/snippets/src/applicationErrors.tsx";
import ClientJS from "!!raw-loader!@site/../private-demos/snippets/src/applicationErrorsJS.jsx";

If you have expected ways your functions might fail, you can either return
different values or throw `ConvexError`s.

## Returning different values

If you're using TypeScript different return types can enforce that you're
handling error scenarios.

For example, a `createUser` mutation could return

```ts
Id<"users"> | { error: "EMAIL_ADDRESS_IN_USE" };
```

to express that either the mutation succeeded or the email address was already
taken.

This ensures that you remember to handle these cases in your UI.

## Throwing application errors

You might prefer to throw errors for the following reasons:

- You can use the exception bubbling mechanism to throw from a deeply nested
  function call, instead of manually propagating error results up the call
  stack. This will work for `runQuery`, `runMutation` and `runAction` calls in
  [actions](/functions/actions.mdx) too.
- In [mutations](/functions/mutation-functions.mdx), throwing an error will
  prevent the mutation transaction from committing
- On the client, it might be simpler to handle all kinds of errors, both
  expected and unexpected, uniformly

Convex provides an error subclass,
[`ConvexError`](/api/classes/values.ConvexError), which can be used to carry
information from the backend to the client:

<TSAndJSSnippet
  title="convex/myFunctions.ts"
  sourceTS={Server}
  sourceJS={Server}
  snippet="example"
  highlightPatterns={["ConvexError"]}
/>

### Application error `data` payload

You can pass the same [data types](/database/types.md) supported by function
arguments, return types and the database, to the `ConvexError` constructor. This
data will be stored on the `data` property of the error:

```ts
// error.data === "My fancy error message"
throw new ConvexError("My fancy error message");

// error.data === {message: "My fancy error message", code: 123, severity: "high"}
throw new ConvexError({
  message: "My fancy error message",
  code: 123,
  severity: "high",
});

// error.data === {code: 123, severity: "high"}
throw new ConvexError({
  code: 123,
  severity: "high",
});
```

Error payloads more complicated than a simple `string` are helpful for more
structured error logging, or for handling sets of errors differently on the
client.

## Handling application errors on the client

On the client, application errors also use the `ConvexError` class, and the data
they carry can be accessed via the `data` property:

<TSAndJSSnippet
  title="src/App.tsx"
  sourceTS={ClientTS}
  sourceJS={ClientJS}
  highlightPatterns={["ConvexError", ".data"]}
/>


---

# error-handling.mdx

<!-- Source: functions/error-handling/error-handling.mdx -->

---
title: "Error Handling"
sidebar_position: 70
---

There are four reasons why your Convex [queries](/functions/query-functions.mdx)
and [mutations](/functions/mutation-functions.mdx) may hit errors:

1. [Application Errors](#application-errors-expected-failures): The function
   code hits a logical condition that should stop further processing, and your
   code throws a `ConvexError`
1. Developer Errors: There is a bug in the function (like calling `db.get(null)`
   instead of `db.get(id)`).
1. [Read/Write Limit Errors](#readwrite-limit-errors): The function is
   retrieving or writing too much data.
1. Internal Convex Errors: There is a problem within Convex (like a network
   blip).

Convex will automatically handle internal Convex errors. If there are problems
on our end, we'll automatically retry your queries and mutations until the
problem is resolved and your queries and mutations succeed.

On the other hand, you must decide how to handle application, developer and
read/write limit errors. When one of these errors happens, the best practices
are to:

1. Show the user some appropriate UI.
2. Send the error to an exception reporting service using the
   [Exception Reporting Integration](/production/integrations/exception-reporting).
3. Log the incident using `console.*` and set up reporting with
   [Log Streaming](/production/integrations/log-streams/log-streams.mdx). This
   can be done in addition to the above options, and doesn't require an
   exception to be thrown.

Additionally, you might also want to send client-side errors to a service like
[Sentry](https://sentry.io) to capture additional information for debugging and
observability.

## Errors in queries

If your query function hits an error, the error will be sent to the client and
thrown from your `useQuery` call site. **The best way to handle these errors is
with a React
[error boundary component](https://reactjs.org/docs/error-boundaries.html).**

Error boundaries allow you to catch errors thrown in their child component tree,
render fallback UI, and send information about the error to your exception
handling service. Adding error boundaries to your app is a great way to handle
errors in Convex query functions as well as other errors in your React
components. If you are using Sentry, you can use their
[`Sentry.ErrorBoundary`](https://docs.sentry.io/platforms/javascript/guides/react/components/errorboundary/)
component.

With error boundaries, you can decide how granular you'd like your fallback UI
to be. One simple option is to wrap your entire application in a single error
boundary like:

```tsx
<StrictMode>
  <ErrorBoundary>
    <ConvexProvider client={convex}>
      <App />
    </ConvexProvider>
  </ErrorBoundary>
</StrictMode>,
```

Then any error in any of your components will be caught by the boundary and
render the same fallback UI.

On the other hand, if you'd like to enable some portions of your app to continue
functioning even if other parts hit errors, you can instead wrap different parts
of your app in separate error boundaries.

<Admonition type="note" title="Retrying">

Unlike other frameworks, there is no concept of "retrying" if your query
function hits an error. Because Convex functions are
[deterministic](/functions/query-functions.mdx#caching--reactivity--consistency),
if the query function hits an error, retrying will always produce the same
error. There is no point in running the query function with the same arguments
again.

</Admonition>

## Errors in mutations

If a mutation hits an error, this will

1. Cause the promise returned from your mutation call to be rejected.
2. Cause your [optimistic update](/client/react/optimistic-updates.mdx) to be
   rolled back.

If you have an exception service like [Sentry](https://sentry.io/) configured,
it should report "unhandled promise rejections" like this automatically. That
means that with no additional work your mutation errors should be reported.

Note that errors in mutations won't be caught by your error boundaries because
the error doesn't happen as part of rendering your components.

If you would like to render UI specifically in response to a mutation failure,
you can use `.catch` on your mutation call. For example:

```javascript
sendMessage(newMessageText).catch((error) => {
  // Do something with `error` here
});
```

If you're using an `async` handled function you can also use `try...catch`:

```javascript
try {
  await sendMessage(newMessageText);
} catch (error) {
  // Do something with `error` here
}
```

<Admonition type="caution" title="Reporting caught errors">

If you handle your mutation error, it will no longer become an unhandled promise
rejection. You may need to report this error to your exception handling service
manually.

</Admonition>

## Errors in action functions

Unlike queries and mutations, [actions](//docs/functions/actions.mdx) may have
side-effects and therefore can't be automatically retried by Convex when errors
occur. For example, say your action sends a email. If it fails part-way through,
Convex has no way of knowing if the email was already sent and can't safely
retry the action. It is responsibility of the caller to handle errors raised by
actions and retry if appropriate.

## Differences in error reporting between dev and prod

Using a dev deployment any server error thrown on the client will include the
original error message and a server-side stack trace to ease debugging.

Using a production deployment any server error will be redacted to only include
the name of the function and a generic `"Server Error"` message, with no stack
trace. Server
[application errors](/functions/error-handling/application-errors.mdx) will
still include their custom `data`.

Both development and production deployments log full errors with stack traces
which can be found on the [Logs](/dashboard/deployments/logs.md) page of a given
deployment.

## Application errors, expected failures

If you have expected ways your functions might fail, you can either return
different values or throw `ConvexError`s.

See [Application Errors](/functions/error-handling/application-errors.mdx).

## Read/write limit errors

To ensure uptime and guarantee performance, Convex will catch queries and
mutations that try to read or write too much data. These limits are enforced at
the level of a single query or mutation function execution. The limits are:

Queries and mutations error out when:

- More than 16384 documents are scanned
- More than 8MiB worth of data is scanned
- More than 4096 queries calls to `db.get` or `db.query` are made
- The function spends more than 1 second executing Javascript

In addition, mutations error out when:

- More than 8192 documents are written
- More than 8MiB worth of data is written

Documents are "scanned" by the database to figure out which documents should be
returned from `db.query`. So for example `db.query("table").take(5).collect()`
will only need to scan 5 documents, but `db.query("table").filter(...).first()`
might scan up to as many documents as there are in `"table"`, to find the first
one that matches the given filter.

Number of calls to `db.get` and `db.query` has a limit to prevent a single query
from subscribing to too many index ranges.

In general, if you're running into these limits frequently, we recommend
[indexing your queries](/database/reading-data/indexes/indexes.md) to reduce the
number of documents scanned, allowing you to avoid unnecessary reads. Queries
that scan large swaths of your data may look innocent at first, but can easily
blow up at any production scale. If your functions are close to hitting these
limits they will log a warning.

For information on other limits, see [here](/production/state/limits.mdx).

## Debugging Errors

See [Debugging](/functions/debugging.mdx) and specifically
[Finding relevant logs by Request ID](/functions/debugging.mdx#finding-relevant-logs-by-request-id).


---

# http-actions.mdx

<!-- Source: functions/http-actions.mdx -->

---
title: HTTP Actions
sidebar_position: 35
---

import http from "!!raw-loader!@site/../demos/http/convex/http.ts";
import httpFunction from "!!raw-loader!@site/../private-demos/snippets/convex/httpActionExample.ts";
import Constructor from "!!raw-loader!@site/../private-demos/snippets/convex/httpActionConstructor.ts";
import httpStorage from "!!raw-loader!@site/../demos/file-storage-with-http/convex/http.ts";
import Fetch from "!!raw-loader!@site/../private-demos/snippets/src/httpAuthCall.ts";

HTTP actions allow you to build an HTTP API right in Convex!

HTTP actions take in a
[Request](https://developer.mozilla.org/en-US/docs/Web/API/Request) and return a
[Response](https://developer.mozilla.org/en-US/docs/Web/API/Response) following
the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).
HTTP actions can manipulate the request and response directly, and interact with
data in Convex indirectly by running [queries](/functions/query-functions.mdx),
[mutations](/functions/mutation-functions.mdx), and
[actions](/functions/actions.mdx). HTTP actions might be used for receiving
webhooks from external applications or defining a public HTTP API.

HTTP actions are exposed at `https://<your deployment name>.convex.site` (e.g.
`https://happy-animal-123.convex.site`).

**Example:**
[HTTP Actions](https://github.com/get-convex/convex-demos/tree/main/http)

## Defining HTTP actions

HTTP action handlers are defined using the
[`httpAction`](/generated-api/server#httpaction) constructor, similar to the
`action` constructor for normal actions:

<TSAndJSSnippet
  title="convex/myHttpActions.ts"
  sourceTS={Constructor}
  sourceJS={Constructor}
/>

The first argument to the `handler` is an
[`ActionCtx`](/api/interfaces/server.GenericActionCtx) object, which provides
[`auth`](/api/interfaces/server.Auth),
[`storage`](/api/interfaces/server.StorageActionWriter), and
[`scheduler`](/api/interfaces/server.Scheduler), as well as `runQuery`,
`runMutation`, `runAction`.

The second argument contains the
[`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request) data. HTTP
actions do not support argument validation, as the parsing of arguments from the
incoming Request is left entirely to you.

Here's an example:

<TSAndJSSnippet
  title="convex/messages.ts"
  sourceTS={httpFunction}
  sourceJS={httpFunction}
/>

<>
  {/* Wrapped in fragment because Prettier pushes the JSDialectFileName on new line */}
  To expose the HTTP Action, export an instance of
  [`HttpRouter`](/api/classes/server.HttpRouter) from the
  <JSDialectFileName name="convex/http.ts" /> file. To create the instance call
  the `httpRouter` function. On the `HttpRouter` you can expose routes using the
  `route` method:
</>

<TSAndJSSnippet
  title="convex/http.js"
  sourceTS={http}
  sourceJS={http}
  snippet="router"
  highlightPatterns={["handler: postMessage"]}
/>

You can now call this action via HTTP and interact with data stored in the
Convex Database. HTTP actions are exposed on
`https://<your deployment name>.convex.site`.

```bash
export DEPLOYMENT_NAME=... # example: "happy-animal-123"
curl -d '{ "author": "User 123", "body": "Hello world" }' \
    -H 'content-type: application/json' "https://$DEPLOYMENT_NAME.convex.site/postMessage"
```

Like other Convex functions, you can view your HTTP actions in the
[Functions view](/dashboard/deployments/functions.md) of
[your dashboard](https://dashboard.convex.dev/) and view logs produced by them
in the [Logs view](/dashboard/deployments/logs.md).

## Limits

HTTP actions run in the same environment as queries and mutations so also do not
have access to Node.js-specific JavaScript APIs. HTTP actions can call
[actions](/functions/actions.mdx), which can run in Node.js.

Like [actions](/functions/actions.mdx#error-handling), HTTP actions may have
side-effects and will not be automatically retried by Convex when errors occur.
It is a responsibility of the caller to handle errors and retry the request if
appropriate.

Request and response size is limited to 20MB.

HTTP actions support request and response body types of `.text()`, `.json()`,
`.blob()`, and `.arrayBuffer()`.

Note that you don't need to define an HTTP action to call your queries,
mutations and actions over HTTP if you control the caller, since you can use use
the JavaScript [`ConvexHttpClient`](/api/classes/browser.ConvexHttpClient) or
the [Python client](/client/python.md) to call these functions directly.

## Debugging

### Step 1: Check that your HTTP actions were deployed.

Check the [functions page](https://dashboard.convex.dev/deployment/functions) in
the dashboard and make sure there's an entry called `http`.

If not, double check that you've defined your HTTP actions with the `httpRouter`
in a file called `http.js` or `http.ts` (the name of the file must match
exactly), and that `npx convex dev` has no errors.

### Step 2: Check that you can access your endpoint using curl

Get your URL from the dashboard under
[Settings](https://dashboard.convex.dev/deployment/settings) > URL and Deploy
Key.

Make sure this is the URL that ends in **`.convex.site`**, and not
`.convex.cloud`. E.g. `https://happy-animal-123.convex.site`

Run a `curl` command to hit one of your defined endpoints, potentially defining
a new endpoint specifically for testing

```
curl -X GET https://<deployment name>.convex.site/myEndpoint
```

Check the [logs page](https://dashboard.convex.dev/deployment/logs) in the
dashboard to confirm that there's an entry for your HTTP action.

### Step 3: Check the request being made by your browser

If you've determined that your HTTP actions have been deployed and are
accessible via curl, but there are still issues requesting them from your app,
check the exact requests being made by your browser.

Open the _Network_ tab in your browser's developer tools, and trigger your HTTP
requests.

Check that this URL matches what you tested earlier with curl -- it ends in
`.convex.site` and has the right deployment name.

You should be able to see these requests in the dashboard
[logs page](https://dashboard.convex.dev/deployment/logs).

If you see "CORS error" or messages in the browser console like
`Access to fetch at '...' from origin '...' has been blocked by CORS policy`,
you likely need to configure CORS headers and potentially add a handler for the
pre-flight `OPTIONS` request. See
[this section](/functions/http-actions.mdx#cors) below.

## Common patterns

### File Storage

HTTP actions can be used to handle uploading and fetching stored files, see:

- [Uploading files via an HTTP action](/file-storage/upload-files.mdx#uploading-files-via-an-http-action)
- [Serving files from HTTP actions](/file-storage/serve-files.mdx#serving-files-from-http-actions)

### CORS

To make requests to HTTP actions from a website you need to add
[Cross-Origin Resource Sharing (CORS)](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS)
headers to your HTTP actions.

There are existing resources for exactly which CORS headers are required based
on the use case. [This site](https://httptoolkit.com/will-it-cors/) provides an
interactive walkthrough for what CORS headers to add. Here's an example of
adding CORS headers to a Convex HTTP action:

<TSAndJSSnippet
  title="convex/http.ts"
  sourceTS={httpStorage}
  sourceJS={httpStorage}
  snippet={["sendImageStore"]}
  highlightPatterns={["headers: new Headers", "        ", "     \\}\\)"]}
/>

Here's an example of handling a pre-flight `OPTIONS` request:

<TSAndJSSnippet
  title="convex/http.ts"
  sourceTS={httpStorage}
  sourceJS={httpStorage}
  snippet="preflight"
  highlightPatterns={["headers: new Headers", "          ", "       \\}\\)"]}
/>

### Authentication

You can leverage Convex's built-in [authentication](/auth.mdx) integration and
access a user identity from
[`ctx.auth.getUserIdentity()`](/api/interfaces/server.Auth#getuseridentity). To
do this call your endpoint with an `Authorization` header including a JWT token:

<TSAndJSSnippet sourceTS={Fetch} sourceJS={Fetch} title="myPage.ts" />


---

# internal-functions.mdx

<!-- Source: functions/internal-functions.mdx -->

---
title: Internal Functions
sidebar_position: 40
---

import Definition from "!!raw-loader!@site/../private-demos/snippets/convex/plans.ts";
import Call from "!!raw-loader!@site/../private-demos/snippets/convex/internalFunctionsCall.ts";
import DefinitionWithoutValidationTS from "!!raw-loader!@site/../private-demos/snippets/convex/internalFunctionsDefinitionWithoutValidation.ts";
import DefinitionWithoutValidationJS from "!!raw-loader!@site/../private-demos/snippets/convex/internalFunctionsDefinitionWithoutValidationJS.js";

Internal functions can only be called by other [functions](/functions.mdx) and
cannot be called directly from a [Convex client](/client/react.mdx).

By default your Convex functions are public and accessible to clients. Public
functions may be called by malicious users in ways that cause surprising
results. Internal functions help you mitigate this risk. We recommend using
internal functions any time you're writing logic that should not be called from
a client.

While internal functions help mitigate risk by reducing the public surface area
of your application, you can still validate internal invariants using
[argument validation](/functions/validation.mdx) and/or
[authentication](/auth/functions-auth.mdx).

## Use cases for internal functions

Leverage internal functions by:

- Calling them from [actions](/functions/actions.mdx#action-context) via
  `runQuery` and `runMutation`
- Calling them from [HTTP actions](/functions/http-actions.mdx) via `runQuery`,
  `runMutation`, and `runAction`
- [Scheduling](/scheduling/scheduled-functions.mdx) them from other functions to
  run in the future
- Scheduling them to run periodically from
  [cron jobs](/scheduling/cron-jobs.mdx)
- Running them using the
  [Dashboard](/dashboard/deployments/functions.md#running-functions)
- Running them from the [CLI](/cli.md#run-convex-functions)

## Defining internal functions

An internal function is defined using `internalQuery`, `internalMutation`, or
`internalAction`. For example:

<TSAndJSSnippet
  title="convex/plans.ts"
  sourceTS={Definition}
  sourceJS={Definition}
  highlightPatterns={["internalMutation"]}
/>

If you need to pass complicated objects to internal functions you might prefer
to not use argument validation. Note though that if you're using `internalQuery`
or `internalMutation` it's a better idea to pass around document IDs instead of
documents, to ensure the query or mutation is working with the up-to-date state
of the database.

<Details summary="Internal function without argument validation">

<TSAndJSSnippet
  title="convex/plans.ts"
  sourceTS={DefinitionWithoutValidationTS}
  sourceJS={DefinitionWithoutValidationJS}
  highlightPatterns={[": {"]}
/>

</Details>

## Calling internal functions

Internal functions can be called from actions and scheduled from actions and
mutation using the [`internal`](/generated-api/api#internal) object.

For example, consider this public `upgrade` action that calls the internal
`plans.markPlanAsProfessional` mutation we defined above:

<TSAndJSSnippet title="convex/changes.ts" sourceTS={Call} sourceJS={Call} />

In this example a user should not be able to directly call
`internal.plans.markPlanAsProfessional` without going through the `upgrade`
action — if they did, then they would get a free upgrade.

You can define public and internal functions in the same file.


---

# mutation-functions.mdx

<!-- Source: functions/mutation-functions.mdx -->

---
title: Mutations
sidebar_position: 20
---

import Example from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsExample.ts";
import Constructor from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsConstructor.ts";
import ArgsWithoutValidationTS from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsArgsWithoutValidation.ts";
import ArgsWithoutValidationJS from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsArgsWithoutValidationJS.js";
import ArgsWithValidation from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsArgsWithValidation.ts";
import Context from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsContext.ts";
import ContextDB from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsContextDB.ts";
import Helper from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsHelper.ts";
import HelperJS from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsHelperJS.js";
import NPM from "!!raw-loader!@site/../private-demos/snippets/convex/mutationsNPM.ts";
import Call from "!!raw-loader!@site/../private-demos/snippets/src/mutationsCall.tsx";

Mutations insert, update and remove data from the database, check authentication
or perform other business logic, and optionally return a response to the client
application.

This is an example mutation, taking in named arguments, writing data to the
database and returning a result:

<TSAndJSSnippet
  sourceTS={Example}
  sourceJS={Example}
  title="convex/myFunctions.ts"
/>

Read on to understand how to build mutations yourself.

## Mutation names

Mutations follow the same naming rules as queries, see
[Query names](/functions/query-functions.mdx#query-names).

Queries and mutations can be defined in the same file when using named exports.

## The `mutation` constructor

To declare a mutation in Convex use the `mutation` constructor function. Pass it
an object with a `handler` function, which performs the mutation:

<TSAndJSSnippet
  sourceTS={Constructor}
  sourceJS={Constructor}
  title="convex/myFunctions.ts"
/>

Unlike a query, a mutation can but does not have to return a value.

### Mutation arguments

Just like queries, mutations accept named arguments, and the argument values are
accessible as fields of the second parameter of the `handler` function:

<TSAndJSSnippet
  sourceTS={ArgsWithoutValidationTS}
  sourceJS={ArgsWithoutValidationJS}
  title="convex/myFunctions.ts"
/>

Arguments and responses are automatically serialized and deserialized, and you
can pass and return most value-like JavaScript data to and from your mutation.

To both declare the types of arguments and to validate them, add an `args`
object using `v` validators:

<TSAndJSSnippet
  sourceTS={ArgsWithValidation}
  sourceJS={ArgsWithValidation}
  title="convex/myFunctions.ts"
/>

See [argument validation](/functions/validation.mdx) for the full list of
supported types and validators.

The first parameter to the handler function is reserved for the mutation
context.

### Mutation responses

Queries can return values of any supported
[Convex type](/functions/validation.mdx) which will be automatically serialized
and deserialized.

Mutations can also return `undefined`, which is not a valid Convex value. When a
mutation returns `undefined` **it is translated to `null`** on the client.

### Mutation context

The `mutation` constructor enables writing data to the database, and other
Convex features by passing a [MutationCtx](/generated-api/server.md#mutationctx)
object to the handler function as the first parameter:

<TSAndJSSnippet
  sourceTS={Context}
  sourceJS={Context}
  title="convex/myFunctions.ts"
/>

Which part of the mutation context is used depends on what your mutation needs
to do:

- To read from and write to the database use the `db` field. Note that we make
  the handler function an `async` function so we can `await` the promise
  returned by `db.insert()`:

  <TSAndJSSnippet
    sourceTS={ContextDB}
    sourceJS={ContextDB}
    title="convex/myFunctions.ts"
  />

  Read on about [Writing Data](/database/writing-data.mdx).

- To generate upload URLs for storing files use the `storage` field. Read on
  about [File Storage](/file-storage.mdx).
- To check user authentication use the `auth` field. Read on about
  [Authentication](/auth.mdx).
- To schedule functions to run in the future, use the `scheduler` field. Read on
  about [Scheduled Functions](/scheduling/scheduled-functions.mdx).

## Splitting up mutation code via helpers

<>
  {/* Fragment for Prettier */}
  When you want to split up the code in your mutation or reuse logic across
  multiple Convex functions you can define and call helper
  <LanguageSelector verbose /> functions:
</>

<TSAndJSSnippet
  sourceTS={Helper}
  sourceJS={HelperJS}
  title="convex/myFunctions.ts"
/>

Mutations can call helpers that take a
[QueryCtx](/generated-api/server.md#queryctx) as argument, since the mutation
context can do everything query context can.

You can `export` helpers to use them across multiple files. They will not be
callable from outside of your Convex functions.

See
[Type annotating server side helpers](/understanding/best-practices/typescript.mdx#type-annotating-server-side-helpers)
for more guidance on TypeScript types.

## Using NPM packages

Mutations can import NPM packages installed in `node_modules`. Not all NPM
packages are supported, see
[Runtimes](/functions/runtimes.mdx#default-convex-runtime) for more details.

```sh
npm install @faker-js/faker
```

<TSAndJSSnippet sourceTS={NPM} sourceJS={NPM} title="convex/myFunctions.ts" />

## Calling mutations from clients

To call a mutation from [React](/client/react.mdx) use the generated
[`useMutation`](/client/react.mdx#editing-data) hook:

To call a mutation from [React](/client/react.mdx) use the
[`useMutation`](/api/modules/react#usemutation) hook along with the generated
[`api`](/generated-api/api) object.

<TSAndJSSnippet sourceTS={Call} sourceJS={Call} title="src/myApp.tsx" />

See the [React](/client/react.mdx) client documentation for all the ways queries
can be called.

When mutations are called from the [React](/client/react.mdx) or
[Rust](/client/rust.md) clients, they are executed one at a time in a single,
ordered queue. You don't have to worry about mutations editing the database in a
different order than they were triggered.

## Transactions

Mutations run **transactionally**. This means that:

1. All database reads inside the transaction get a consistent view of the data
   in the database. You don't have to worry about a concurrent update changing
   the data in the middle of the execution.
2. All database writes get committed together. If the mutation writes some data
   to the database, but later throws an error, no data is actually written to
   the database.

For this to work, similarly to queries, mutations must be deterministic, and
cannot call third party APIs. To call third party APIs, use
[actions](/functions/actions.mdx).

## Limits

Mutations have a limit to the amount of data they can read and write at once to
guarantee good performance. Learn more in
[Read/write limit errors](/functions/error-handling/error-handling.mdx#readwrite-limit-errors).

For information on other limits, see [Limits](/production/state/limits.mdx).


---

# query-functions.mdx

<!-- Source: functions/query-functions.mdx -->

---
title: Queries
sidebar_position: 10
---

import Example from "!!raw-loader!@site/../private-demos/snippets/convex/queriesExample.ts";
import Constructor from "!!raw-loader!@site/../private-demos/snippets/convex/queriesConstructor.ts";
import ArgsWithoutValidationTS from "!!raw-loader!@site/../private-demos/snippets/convex/queriesArgsWithoutValidation.ts";
import ArgsWithoutValidationJS from "!!raw-loader!@site/../private-demos/snippets/convex/queriesArgsWithoutValidationJS.js";
import ArgsWithValidation from "!!raw-loader!@site/../private-demos/snippets/convex/queriesArgsWithValidation.ts";
import Context from "!!raw-loader!@site/../private-demos/snippets/convex/queriesContext.ts";
import ContextDB from "!!raw-loader!@site/../private-demos/snippets/convex/queriesContextDB.ts";
import Helper from "!!raw-loader!@site/../private-demos/snippets/convex/queriesHelper.ts";
import HelperJS from "!!raw-loader!@site/../private-demos/snippets/convex/queriesHelperJS.js";
import NPM from "!!raw-loader!@site/../private-demos/snippets/convex/queriesNPM.ts";
import Call from "!!raw-loader!@site/../private-demos/snippets/src/queriesCall.tsx";

Queries are the bread and butter of your backend API. They fetch data from the
database, check authentication or perform other business logic, and return data
back to the client application.

This is an example query, taking in named arguments, reading data from the
database and returning a result:

<TSAndJSSnippet
  sourceTS={Example}
  sourceJS={Example}
  title="convex/myFunctions.ts"
/>

Read on to understand how to build queries yourself.

## Query names

Queries are defined in <LanguageSelector verbose /> files inside your `convex/`
directory.

The path and name of the file, as well as the way the function is exported from
the file, determine the name the client will use to call it:

```ts title="convex/myFunctions.ts"
// This function will be referred to as `api.myFunctions.myQuery`.
export const myQuery = …;

// This function will be referred to as `api.myFunctions.sum`.
export const sum = …;
```

To structure your API you can nest directories inside the `convex/` directory:

```ts title="convex/foo/myQueries.ts"
// This function will be referred to as `api.foo.myQueries.listMessages`.
export const listMessages = …;
```

Default exports receive the name `default`.

```ts title="convex/myFunctions.ts"
// This function will be referred to as `api.myFunctions.default`.
export default …;
```

The same rules apply to [mutations](/functions/mutation-functions.mdx) and
[actions](/functions/actions.mdx), while
[HTTP actions](/functions/http-actions.mdx) use a different routing approach.

Client libraries in languages other than JavaScript and TypeScript use strings
instead of API objects:

- `api.myFunctions.myQuery` is `"myFunctions:myQuery"`
- `api.foo.myQueries.myQuery` is `"foo/myQueries:myQuery"`.
- `api.myFunction.default` is `"myFunction:default"` or `"myFunction"`.

## The `query` constructor

To actually declare a query in Convex you use the `query` constructor function.
Pass it an object with a `handler` function, which returns the query result:

<TSAndJSSnippet
  sourceTS={Constructor}
  sourceJS={Constructor}
  title="convex/myFunctions.ts"
/>

### Query arguments

Queries accept named arguments. The argument values are accessible as fields of
the second parameter of the handler function:

<TSAndJSSnippet
  sourceTS={ArgsWithoutValidationTS}
  sourceJS={ArgsWithoutValidationJS}
  title="convex/myFunctions.ts"
/>

Arguments and responses are automatically serialized and deserialized, and you
can pass and return most value-like JavaScript data to and from your query.

To both declare the types of arguments and to validate them, add an `args`
object using `v` validators:

<TSAndJSSnippet
  sourceTS={ArgsWithValidation}
  sourceJS={ArgsWithValidation}
  highlightPatterns={["args:"]}
  title="convex/myFunctions.ts"
/>

See [argument validation](/functions/validation.mdx) for the full list of
supported types and validators.

The first parameter of the handler function contains the query context.

### Query responses

Queries can return values of any supported
[Convex type](/functions/validation.mdx) which will be automatically serialized
and deserialized.

Queries can also return `undefined`, which is not a valid Convex value. When a
query returns `undefined` **it is translated to `null`** on the client.

### Query context

The `query` constructor enables fetching data, and other Convex features by
passing a [QueryCtx](/generated-api/server.md#queryctx) object to the handler
function as the first parameter:

<TSAndJSSnippet
  sourceTS={Context}
  sourceJS={Context}
  title="convex/myFunctions.ts"
/>

Which part of the query context is used depends on what your query needs to do:

- To fetch from the database use the `db` field. Note that we make the handler
  function an `async` function so we can `await` the promise returned by
  `db.get()`:

  <TSAndJSSnippet
    sourceTS={ContextDB}
    sourceJS={ContextDB}
    highlightPatterns={["db."]}
    title="convex/myFunctions.ts"
  />

  Read more about [Reading Data](/database/reading-data/reading-data.mdx).

- To return URLs to stored files use the `storage` field. Read more about
  [File Storage](/file-storage.mdx).
- To check user authentication use the `auth` field. Read more about
  [Authentication](/auth.mdx).

## Splitting up query code via helpers

When you want to split up the code in your query or reuse logic across multiple
Convex functions you can define and call helper <LanguageSelector verbose />
functions:

<TSAndJSSnippet
  sourceTS={Helper}
  sourceJS={HelperJS}
  title="convex/myFunctions.ts"
/>

You can `export` helpers to use them across multiple files. They will not be
callable from outside of your Convex functions.

See
[Type annotating server side helpers](/understanding/best-practices/typescript.mdx#type-annotating-server-side-helpers)
for more guidance on TypeScript types.

## Using NPM packages

Queries can import NPM packages installed in `node_modules`. Not all NPM
packages are supported, see
[Runtimes](/functions/runtimes.mdx#default-convex-runtime) for more details.

```sh
npm install @faker-js/faker
```

<TSAndJSSnippet sourceTS={NPM} sourceJS={NPM} title="convex/myFunctions.ts" />

## Calling queries from clients

To call a query from [React](/client/react.mdx) use the
[`useQuery`](/client/react.mdx#fetching-data) hook along with the generated
[`api`](/generated-api/api) object.

<TSAndJSSnippet sourceTS={Call} sourceJS={Call} title="src/MyApp.tsx" />

See the [React](/client/react.mdx) client documentation for all the ways queries
can be called.

## Caching & reactivity & consistency

Queries have three awesome attributes:

1. **Caching**: Convex caches query results automatically. If many clients
   request the same query, with the same arguments, they will receive a cached
   response.
2. **Reactivity**: clients can subscribe to queries to receive new results when
   the underlying data changes.
3. **Consistency**: All database reads inside a single query call are performed
   at the same logical timestamp. Concurrent writes do not affect the query
   results.

To have these attributes the handler function must be _deterministic_, which
means that given the same arguments (including the query context) it will return
the same response.

For this reason queries cannot `fetch` from third party APIs. To call third
party APIs, use [actions](/functions/actions.mdx).

You might wonder whether you can use non-deterministic language functionality
like `Math.random()` or `Date.now()`. The short answer is that Convex takes care
of implementing these in a way that you don't have to think about the
deterministic constraint.

See [Runtimes](/functions/runtimes.mdx#default-convex-runtime) for more details
on the Convex runtime.

## Limits

Queries have a limit to the amount of data they can read at once to guarantee
good performance. Check out these limits in
[Read/write limit errors](/functions/error-handling/error-handling.mdx#readwrite-limit-errors).

For information on other limits, see [Limits](/production/state/limits.mdx).


---

# runtimes.mdx

<!-- Source: functions/runtimes.mdx -->

---
title: Runtimes
sidebar_position: 80
---

# Runtimes

Convex functions can run in two runtimes:

- Default [Convex runtime](#default-convex-runtime)
- Opt-in [Node.js runtime](#nodejs-runtime)

## Default Convex runtime

All Convex backend functions are written in JavaScript or TypeScript. By default
all functions run in a custom JavaScript runtime very similar to the
[Cloudflare Workers runtime](https://blog.cloudflare.com/cloud-computing-without-containers/)
with access to most
[web standard globals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects).

The default runtime has many advantages including:

- **No cold starts**. The runtime is always up, and ready to handle any function
  at a moments notice.
- **Latest web JavaScript standards**. The runtime is based on V8 that also
  powers Google Chrome. This ensures it provides an interface very similar to
  your frontend code, allowing further simplification to your code.
- **Low overhead access to your data**. The runtime is designed to have low
  overhead access to your data via query & mutation functions, allowing you to
  access your database via a simple
  [JavaScript interface](/database/reading-data/reading-data.mdx).

### Supported APIs

The default runtime supports most npm libraries that work in the browser,
[Deno](https://deno.com/), and
[Cloudflare workers](https://developers.cloudflare.com/workers/). If your
library isn't supported, you can use an action with the
[Node.js runtime](#nodejs-runtime), or reach out in
[Discord](https://convex.dev/community). We are improving support all the time.

#### Network APIs

- [Blob](https://developer.mozilla.org/en-US/docs/Web/API/Blob)
- [Event](https://developer.mozilla.org/en-US/docs/Web/API/Event)
- [EventTarget](https://developer.mozilla.org/en-US/docs/Web/API/EventTarget)
- [fetch](https://developer.mozilla.org/en-US/docs/Web/API/fetch) — in
  [Actions](#actions) only
- [File](https://developer.mozilla.org/en-US/docs/Web/API/File)
- [FormData](https://developer.mozilla.org/en-US/docs/Web/API/FormData)
- [Headers](https://developer.mozilla.org/en-US/docs/Web/API/Headers)
- [Request](https://developer.mozilla.org/en-US/docs/Web/API/Request)
- [Response](https://developer.mozilla.org/en-US/docs/Web/API/Response)

#### Encoding APIs

- [TextDecoder](https://developer.mozilla.org/en-US/docs/Web/API/TextDecoder)
- [TextEncoder](https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder)
- [atob](https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/atob)
- [btoa](https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/btoa)

#### Web Stream APIs

- [ReadableStream](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream)
- [ReadableStreamBYOBReader](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStreamBYOBReader)
- [ReadableStreamDefaultReader](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStreamDefaultReader)
- [TransformStream](https://developer.mozilla.org/en-US/docs/Web/API/TransformStream)
- [WritableStream](https://developer.mozilla.org/en-US/docs/Web/API/WritableStream)
- [WritableStreamDefaultWriter](https://developer.mozilla.org/en-US/docs/Web/API/WritableStreamDefaultWriter)

#### Web Crypto APIs

- [crypto](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API)
- [CryptoKey](https://developer.mozilla.org/en-US/docs/Web/API/CryptoKey)
- [SubtleCrypto](https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto)

### Restrictions on queries and mutations

Query and mutation functions are further **restricted by the runtime to be
[deterministic](https://en.wikipedia.org/wiki/Deterministic_algorithm)**. This
allows Convex to automatically retry them by the system as necessary.

Determinism means that no matter how many times your function is run, as long as
it is given the same arguments, it will have identical side effects and return
the same value.

You don't have to think all that much about maintaining these properties of
determinism when you write your Convex functions. Convex will provide helpful
error messages as you go, so you can't *accidentally* do something forbidden.

#### Using randomness and time in queries and mutations

Convex provides a "seeded" strong pseudo-random number generator
at `Math.random()` so that it can guarantee the determinism of your function.
The random number generator's seed is an implicit parameter to your function.
Multiple calls to `Math.random()` in one function call will return different
random values. Note that Convex does not reevaluate the Javascript modules on
every function run, so a call to `Math.random()` stored in a global variable
will not change between function runs.

To ensure the logic within your function is reproducible, the system time used
globally (outside of any function) is "frozen" at deploy time, while the system
time during Convex function execution is "frozen" when the function
begins. `Date.now()` will return the same result for the entirety of your
function's execution. For example,

```javascript
const globalRand = Math.random(); // `globalRand` does not change between runs.
const globalNow = Date.now(); // `globalNow` is the time when Convex functions were deployed.

export const updateSomething = mutation({
  args: {},
  handler: () => {
    const now1 = Date.now(); // `now1` is the time when the function execution started.
    const rand1 = Math.random(); // `rand1` has a new value for each function run.
    // implementation
    const now2 = Date.now(); // `now2` === `now1`
    const rand2 = Math.random(); // `rand1` !== `rand2`
  },
});
```

### Actions

Actions are unrestricted by the same rules of determinism as query and mutation
functions. Notably actions are allowed to call third-party HTTP endpoints via
the browser-standard
[`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) function.

By default actions also run in Convex’s custom JavaScript runtime with all of
its advantages including no cold starts and a browser-like API environment. They
can also live in the same file as your query and mutation functions.

## Node.js runtime

Some JavaScript and TypeScript libraries use features that are not included in
the default Convex runtime. This is why Convex actions provide an escape hatch
to [Node.js 18](https://nodejs.org/en/about) via the `"use node"` directive at
the top of a file that contains your action.
[Learn more](/functions/actions.mdx#choosing-the-runtime-use-node).

Use of the Node.js environment is restricted to **action functions only**. If
you want to use a library designed for Node.js and interact with the Convex
database, you need to call the Node.js library from an action, and use
[`runQuery`](/functions/actions.mdx#action-context) or
[`runMutation`](/functions/actions.mdx#action-context) helper to call a query or
mutation.

Every `.ts` and `.js` file in the convex directory
[is bundled](/functions/bundling.mdx) either for the default Convex JavaScript
runtime or Node.js, along with any code it imports.

Files with the `"use node"` directive should not contain any Convex queries or
mutations since they cannot be run in the Node.js runtime. Additionally, files
without the `"use node"` directive should not import any files with the
`"use node"` directive. Files that contain no Convex functions, like a
`convex/utils.ts` file, also need the "use node" directive if they use
Node.js-specific libraries.


---

# validation.mdx

<!-- Source: functions/validation.mdx -->

---
title: "Argument and Return Value Validation"
sidebar_label: "Validation"
sidebar_position: 50
---

import ConvexValues from "@site/docs/_convexValues.mdx";

import messagesTS from "!!raw-loader!@site/../demos/args-validation/convex/messages.ts";

Argument and return value validators ensure that
[queries](./query-functions.mdx), [mutations](./mutation-functions.mdx), and
[actions](./actions.mdx) are called with the correct types of arguments and
return the expected types of return values.

**This is important for security!** Without argument validation, a malicious
user can call your public functions with unexpected arguments and cause
surprising results. [TypeScript](/understanding/best-practices/typescript) alone
won't help because TypeScript types aren't present at runtime. We recommend
adding argument validation for all public functions in production apps. For
non-public functions that are not called by clients, we recommend
[internal functions](/functions/internal-functions.mdx) and optionally
validation.

**Example:**
[Argument Validation](https://github.com/get-convex/convex-demos/tree/main/args-validation)

## Adding validators

To add argument validation to your functions, pass an object with `args` and
`handler` properties to the `query`, `mutation` or `action` constructor. To add
return value validation, use the `returns` property in this object:

<TSAndJSSnippet
  title="convex/message.ts"
  sourceTS={messagesTS}
  sourceJS={messagesTS}
  snippet="mutation"
/>

If you define your function with an argument validator, there is no need to
include [TypeScript](/understanding/best-practices/typescript.mdx) type
annotations! The type of your function will be inferred automatically.
Similarly, if you define a return value validator, the return type of your
function will be inferred from the validator, and TypeScript will check that it
matches the inferred return type of the `handler` function.

Unlike TypeScript, validation for an object will throw if the object contains
properties that are not declared in the validator.

If the client supplies arguments not declared in `args`, or if the function
returns a value that does not match the validator declared in `returns`. This is
helpful to prevent bugs caused by mistyped names of arguments or returning more
data than intended to a client.

Even `args: {}` is a helpful use of validators because TypeScript will show an
error on the client if you try to pass any arguments to the function which
doesn't expect them.

## Supported types

All functions, both public and internal, can accept and return the following
data types. Each type has a corresponding validator that can be accessed on the
[`v`](/api/modules/values#v) object imported from `"convex/values"`.

The [database](/database.mdx) can store the exact same set of
[data types](/database/types.md).

Additionally you can also express type unions, literals, `any` types, and
optional fields.

### Convex values

<ConvexValues />

### Unions

You can describe fields that could be one of multiple types using `v.union`:

```typescript
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export default mutation({
  args: {
    stringOrNumber: v.union(v.string(), v.number()),
  },
  handler: async ({ db }, { stringOrNumber }) => {
    //...
  },
});
```

### Literals

Fields that are a constant can be expressed with `v.literal`. This is especially
useful when combined with unions:

```typescript
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export default mutation({
  args: {
    oneTwoOrThree: v.union(
      v.literal("one"),
      v.literal("two"),
      v.literal("three"),
    ),
  },
  handler: async ({ db }, { oneTwoOrThree }) => {
    //...
  },
});
```

### Record objects

You can describe objects that map arbitrary keys to values with `v.record`:

```typescript
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export default mutation({
  args: {
    simpleMapping: v.record(v.string(), v.boolean()),
  },
  handler: async ({ db }, { simpleMapping }) => {
    //...
  },
});
```

You can use other types of string validators for the keys:

```typescript
defineTable({
  userIdToValue: v.record(v.id("users"), v.boolean()),
});
```

Notes:

- This type corresponds to the
  [Record\<K,V\>](https://www.typescriptlang.org/docs/handbook/utility-types.html#recordkeys-type)
  type in TypeScript
- You cannot use string literals as a `record` key
- Using `v.string()` as a `record` key validator will only allow ASCII
  characters

### Any

Fields that could take on any value can be represented with `v.any()`:

```typescript
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export default mutation({
  args: {
    anyValue: v.any(),
  },
  handler: async ({ db }, { anyValue }) => {
    //...
  },
});
```

This corresponds to the `any` type in TypeScript.

### Optional fields

You can describe optional fields by wrapping their type with `v.optional(...)`:

```typescript
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export default mutation({
  args: {
    optionalString: v.optional(v.string()),
    optionalNumber: v.optional(v.number()),
  },
  handler: async ({ db }, { optionalString, optionalNumber }) => {
    //...
  },
});
```

This corresponds to marking fields as optional with `?` in TypeScript.

## Extracting TypeScript types

The [`Infer`](/api/modules/values#infer) type allows you to turn validator calls
into TypeScript types. This can be useful to remove duplication between your
validators and TypeScript types:

```ts
import { mutation } from "./_generated/server";
import { Infer, v } from "convex/values";

const nestedObject = v.object({
  property: v.string(),
});

// Resolves to `{property: string}`.
export type NestedObject = Infer<typeof nestedObject>;

export default mutation({
  args: {
    nested: nestedObject,
  },
  handler: async ({ db }, { nested }) => {
    //...
  },
});
```


---

# functions.mdx

<!-- Source: functions.mdx -->

---
title: "Functions"
description: "Write functions to define your server behavior."
hide_table_of_contents: true
pagination_prev: tutorial/index
---

Functions run on the backend and are written in JavaScript (or TypeScript). They
are automatically available as APIs accessed through
[client libraries](/client/react.mdx). Everything you do in the Convex backend
starts from functions.

There are three types of functions:

- [Queries](/functions/query-functions.mdx) read data from your Convex database
  and are automatically cached and subscribable (realtime, reactive).
- [Mutations](/functions/mutation-functions.mdx) write data to the database and
  run as a transaction.
- [Actions](/functions/actions.mdx) can call OpenAI, Stripe, Twilio, or any
  other service or API you need to make your app work.

You can also build [HTTP actions](/functions/http-actions.mdx) when you want to
call your functions from a webhook or a custom client.

Here's an overview of the three different types of Convex functions and what
they can do:

|                            | Queries | Mutations | Actions |
| -------------------------- | ------- | --------- | ------- |
| Database access            | Yes     | Yes       | No      |
| Transactional              | Yes     | Yes       | No      |
| Cached                     | Yes     | No        | No      |
| Real-time Updates          | Yes     | No        | No      |
| External API Calls (fetch) | No      | No        | Yes     |


---

# api.md

<!-- Source: generated-api/api.md -->

---
title: "api.js"
sidebar_position: 2
---

<Admonition type="caution" title="This code is generated">

These exports are not directly available in the `convex` package!

Instead you need to run `npx convex dev` to create `convex/_generated/api.js`
and `convex/_generated/api.d.ts`.

</Admonition>

These types require running code generation because they are specific to the
Convex functions you define for your app.

If you aren't using code generation, you can use
[`makeFunctionReference`](/api/modules/server#makefunctionreference) instead.

### api

An object of type `API` describing your app's public Convex API.

Its `API` type includes information about the arguments and return types of your
app's Convex functions.

The api object is used by client-side React hooks and Convex functions that run
or schedule other functions.

```javascript title="src/App.jsx"
import { api } from "../convex/_generated/api";
import { useQuery } from "convex/react";

const data = useQuery(api.messages.list);
```

### internal

Another object of type `API` describing your app's internal Convex API.

```js title="convex/upgrade.js"
import { action } from "../_generated/server";
import { internal } from "../_generated/api";

export default action({
  handler: async ({ runMutation }, { planId, ... }) => {
    // Call out to payment provider (e.g. Stripe) to charge customer
    const response = await fetch(...);
    if (response.ok) {
      // Mark the plan as "professional" in the Convex DB
      await runMutation(internal.plans.markPlanAsProfessional, { planId });
    }
  },
});
```


---

# data-model.md

<!-- Source: generated-api/data-model.md -->

---
title: "dataModel.d.ts"
sidebar_position: 1
---

<Admonition type="caution" title="This code is generated">

These exports are not directly available in the `convex` package!

Instead you must run `npx convex dev` to create
`convex/_generated/dataModel.d.ts`.

</Admonition>

Generated data model types.

## Types

### TableNames

Ƭ **TableNames**: `string`

The names of all of your Convex tables.

---

### Doc

Ƭ **Doc**`<TableName>`: `Object`

The type of a document stored in Convex.

#### Type parameters

| Name        | Type                                | Description                                             |
| :---------- | :---------------------------------- | :------------------------------------------------------ |
| `TableName` | extends [`TableNames`](#tablenames) | A string literal type of the table name (like "users"). |

---

### Id

An identifier for a document in Convex.

Convex documents are uniquely identified by their `Id`, which is accessible on
the `_id` field. To learn more, see [Document IDs](/database/document-ids.mdx).

Documents can be loaded using `db.get(id)` in query and mutation functions.

IDs are just strings at runtime, but this type can be used to distinguish them
from other strings when type checking.

This is an alias of [`GenericId`](/api/modules/values#genericid) that is typed
for your data model.

#### Type parameters

| Name        | Type                                | Description                                             |
| :---------- | :---------------------------------- | :------------------------------------------------------ |
| `TableName` | extends [`TableNames`](#tablenames) | A string literal type of the table name (like "users"). |

---

### DataModel

Ƭ **DataModel**: `Object`

A type describing your Convex data model.

This type includes information about what tables you have, the type of documents
stored in those tables, and the indexes defined on them.

This type is used to parameterize methods like
[`queryGeneric`](/api/modules/server#querygeneric) and
[`mutationGeneric`](/api/modules/server#mutationgeneric) to make them type-safe.


---

# index.md

<!-- Source: generated-api/index.md -->

---
title: Generated Code
---

Convex uses code generation to create code that is specific to your app's data
model and API. Convex generates JavaScript files (`.js`) with TypeScript type
definitions (`.d.ts`).

Code generation isn't required to use Convex, but using the generated code will
give you more better autocompletion in your editor and more type safety if
you're using TypeScript.

To generate the code, run:

```
npx convex dev
```

This creates a `convex/_generated` directory that contains:

- [`api.js` and `api.d.ts`](./api.md)
- [`dataModel.d.ts`](./data-model.md)
- [`server.js` and `server.d.ts`](./server.md)


---

# server.md

<!-- Source: generated-api/server.md -->

---
title: "server.js"
sidebar_position: 4
---

<Admonition type="caution" title="This code is generated">

These exports are not directly available in the `convex` package!

Instead you must run `npx convex dev` to create `convex/_generated/server.js`
and `convex/_generated/server.d.ts`.

</Admonition>

Generated utilities for implementing server-side Convex query and mutation
functions.

## Functions

### query

▸ **query**(`func`): [`RegisteredQuery`](/api/modules/server#registeredquery)

Define a query in this Convex app's public API.

This function will be allowed to read your Convex database and will be
accessible from the client.

This is an alias of [`queryGeneric`](/api/modules/server#querygeneric) that is
typed for your app's data model.

#### Parameters

| Name   | Description                                                                             |
| :----- | :-------------------------------------------------------------------------------------- |
| `func` | The query function. It receives a [QueryCtx](server.md#queryctx) as its first argument. |

#### Returns

[`RegisteredQuery`](/api/modules/server#registeredquery)

The wrapped query. Include this as an `export` to name it and make it
accessible.

---

### internalQuery

▸ **internalQuery**(`func`):
[`RegisteredQuery`](/api/modules/server#registeredquery)

Define a query that is only accessible from other Convex functions (but not from
the client).

This function will be allowed to read from your Convex database. It will not be
accessible from the client.

This is an alias of
[`internalQueryGeneric`](/api/modules/server#internalquerygeneric) that is typed
for your app's data model.

#### Parameters

| Name   | Description                                                                             |
| :----- | :-------------------------------------------------------------------------------------- |
| `func` | The query function. It receives a [QueryCtx](server.md#queryctx) as its first argument. |

#### Returns

[`RegisteredQuery`](/api/modules/server#registeredquery)

The wrapped query. Include this as an `export` to name it and make it
accessible.

---

### mutation

▸ **mutation**(`func`):
[`RegisteredMutation`](/api/modules/server#registeredmutation)

Define a mutation in this Convex app's public API.

This function will be allowed to modify your Convex database and will be
accessible from the client.

This is an alias of [`mutationGeneric`](/api/modules/server#mutationgeneric)
that is typed for your app's data model.

#### Parameters

| Name   | Description                                                                             |
| :----- | :-------------------------------------------------------------------------------------- |
| `func` | The mutation function. It receives a [MutationCtx](#mutationctx) as its first argument. |

#### Returns

[`RegisteredMutation`](/api/modules/server#registeredmutation)

The wrapped mutation. Include this as an `export` to name it and make it
accessible.

---

### internalMutation

▸ **internalMutation**(`func`):
[`RegisteredMutation`](/api/modules/server#registeredmutation)

Define a mutation that is only accessible from other Convex functions (but not
from the client).

This function will be allowed to read and write from your Convex database. It
will not be accessible from the client.

This is an alias of
[`internalMutationGeneric`](/api/modules/server#internalmutationgeneric) that is
typed for your app's data model.

#### Parameters

| Name   | Description                                                                                      |
| :----- | :----------------------------------------------------------------------------------------------- |
| `func` | The mutation function. It receives a [MutationCtx](server.md#mutationctx) as its first argument. |

#### Returns

[`RegisteredMutation`](/api/modules/server#registeredmutation)

The wrapped mutation. Include this as an `export` to name it and make it
accessible.

---

### action

▸ **action**(`func`): [`RegisteredAction`](/api/modules/server#registeredaction)

Define an action in this Convex app's public API.

An action is a function which can execute any JavaScript code, including
non-deterministic code and code with side-effects, like calling third-party
services. They can be run in Convex's JavaScript environment or in Node.js using
the `"use node"` directive. They can interact with the database indirectly by
calling queries and mutations using the [`ActionCtx`](#actionctx).

This is an alias of [`actionGeneric`](/api/modules/server#actiongeneric) that is
typed for your app's data model.

#### Parameters

| Name   | Description                                                                        |
| :----- | :--------------------------------------------------------------------------------- |
| `func` | The action function. It receives an [ActionCtx](#actionctx) as its first argument. |

#### Returns

[`RegisteredAction`](/api/modules/server#registeredaction)

The wrapped function. Include this as an `export` to name it and make it
accessible.

---

### internalAction

▸ **internalAction**(`func`):
[`RegisteredAction`](/api/modules/server#registeredaction)

Define an action that is only accessible from other Convex functions (but not
from the client).

This is an alias of
[`internalActionGeneric`](/api/modules/server#internalactiongeneric) that is
typed for your app's data model.

#### Parameters

| Name   | Description                                                                                 |
| :----- | :------------------------------------------------------------------------------------------ |
| `func` | The action function. It receives an [ActionCtx](server.md#actionctx) as its first argument. |

#### Returns

[`RegisteredAction`](/api/modules/server#registeredaction)

The wrapped action. Include this as an `export` to name it and make it
accessible.

---

### httpAction

▸
**httpAction**(`func: (ctx: ActionCtx, request: Request) => Promise<Response>`):
[`PublicHttpAction`](/api/modules/server#publichttpaction)

#### Parameters

| Name   | Type                                                      | Description                                                                                                                                                                                         |
| :----- | :-------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `func` | `(ctx: ActionCtx, request: Request) => Promise<Response>` | The function. It receives an [`ActionCtx`](/api/modules/server#actionctx) as its first argument and a [`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request) as its second argument. |

#### Returns

[`PublicHttpAction`](/api/modules/server#publichttpaction)

The wrapped function. Import this function from `convex/http.js` and route it to
hook it up.

## Types

### QueryCtx

Ƭ **QueryCtx**: `Object`

A set of services for use within Convex query functions.

The query context is passed as the first argument to any Convex query function
run on the server.

This differs from the [MutationCtx](#mutationctx) because all of the services
are read-only.

This is an alias of [`GenericQueryCtx`](/api/interfaces/server.GenericQueryCtx)
that is typed for your app's data model.

#### Type declaration

| Name      | Type                                                       |
| :-------- | :--------------------------------------------------------- |
| `db`      | [`DatabaseReader`](#databasereader)                        |
| `auth`    | [`Auth`](/api/interfaces/server.Auth.md)                   |
| `storage` | [`StorageReader`](/api/interfaces/server.StorageReader.md) |

---

### MutationCtx

Ƭ **MutationCtx**: `Object`

A set of services for use within Convex mutation functions.

The mutation context is passed as the first argument to any Convex mutation
function run on the server.

This is an alias of
[`GenericMutationCtx`](/api/interfaces/server.GenericMutationCtx) that is typed
for your app's data model.

#### Type declaration

| Name        | Type                                                       |
| :---------- | :--------------------------------------------------------- |
| `db`        | [`DatabaseWriter`](#databasewriter)                        |
| `auth`      | [`Auth`](/api/interfaces/server.Auth.md)                   |
| `storage`   | [`StorageWriter`](/api/interfaces/server.StorageWriter.md) |
| `scheduler` | [`Scheduler`](/api/interfaces/server.Scheduler.md)         |

---

### ActionCtx

Ƭ **ActionCtx**: `Object`

A set of services for use within Convex action functions.

The action context is passed as the first argument to any Convex action function
run on the server.

This is an alias of [`ActionCtx`](/api/modules/server#actionctx) that is typed
for your app's data model.

#### Type declaration

| Name           | Type                                                                                                                                                                         |
| :------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `runQuery`     | (`name`: `string`, `args`?: `Record<string, Value>`) => `Promise<Value>`                                                                                                     |
| `runMutation`  | (`name`: `string`, `args`?: `Record<string, Value>`) => `Promise<Value>`                                                                                                     |
| `runAction`    | (`name`: `string`, `args`?: `Record<string, Value>`) => `Promise<Value>`                                                                                                     |
| `auth`         | [`Auth`](/api/interfaces/server.Auth.md)                                                                                                                                     |
| `scheduler`    | [`Scheduler`](/api/interfaces/server.Scheduler.md)                                                                                                                           |
| `storage`      | [`StorageActionWriter`](/api/interfaces/server.StorageActionWriter.md)                                                                                                       |
| `vectorSearch` | (`tableName`: `string`, `indexName`: `string`, `query`: [`VectorSearchQuery`](/api/interfaces/server.VectorSearchQuery.md)) => `Promise<Array<{ _id: Id, _score: number }>>` |

---

### DatabaseReader

An interface to read from the database within Convex query functions.

This is an alias of
[`GenericDatabaseReader`](/api/interfaces/server.GenericDatabaseReader) that is
typed for your app's data model.

---

### DatabaseWriter

An interface to read from and write to the database within Convex mutation
functions.

This is an alias of
[`GenericDatabaseWriter`](/api/interfaces/server.GenericDatabaseWriter) that is
typed for your app's data model.


---

# index.md

<!-- Source: http-api/index.md -->

---
title: "Convex HTTP API"
sidebar_label: "HTTP API"
description: "Connecting to Convex directly with HTTP"
---

import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';

# HTTP APIs

HTTP APIs include:

- [Functions API](#functions-api)
- [Streaming export API](#streaming-export-api)
- [Streaming import API](#streaming-import-api)

## Convex value format

Each of the HTTP APIs take a `format` query param that describes how documents
are formatted. Currently the only supported value is `json`. See our
[types page](/database/types#convex-values) for details. Note that for
simplicity, the `json` format does not support all Convex data types as input,
and uses overlapping representation for several data types in output. We plan to
add a new format with support for all Convex data types in the future.

## API authentication

The Functions API can be optionally authenticated as a user via a bearer token
in a `Authorization` header. The value is `Bearer <access_key>` where the key is
a token from your auth provider. See the
[under the hood](/auth/clerk#under-the-hood) portion of the Clerk docs for
details on how this works with Clerk.

Streaming export and streaming import requests require deployment admin
authorization via the HTTP header `Authorization`. The value is
`Convex <access_key>` where the access key comes from "Deploy key" on the Convex
dashboard and gives full read and write access to your Convex data.

## Functions API

### POST `/api/query`, `/api/mutation`, `/api/action`

These HTTP endpoints allow you to call Convex functions and get the result as a
value.

You can find your backend deployment URL on the dashboard
[Settings](/dashboard/deployments/settings.md) page, then the API URL will be
`<CONVEX_URL>/api/query` etc., for example:

<Tabs>
<TabItem value="shell" label="Shell">

```
curl https://acoustic-panther-728.convex.cloud/api/query \
   -d '{"path": "messages:list", "args": {}, "format": "json"}' \
   -X POST -H "Content-Type: application/json"
```

</TabItem>
<TabItem value="js" label="NodeJS">

```js
const url = "https://acoustic-panther-728.convex.cloud/api/query";
const request = { path: "messages:list", args: {}, format: "json" };

const response = fetch(url, {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
  },
  body: JSON.stringify(request),
});
```

</TabItem>
<TabItem value="py" label="Python">

```py
import requests

url = "https://acoustic-panther-728.convex.cloud/api/query"
headers = {"accept": "application/json"}
body = {"path": "messages:list", "args": {}, "format": "json"}

response = requests.post(url, headers=headers, json=body)
```

</TabItem>
</Tabs>

**JSON Body parameters**

| Name   | Type   | Required | Description                                                                                                  |
| ------ | ------ | -------- | ------------------------------------------------------------------------------------------------------------ |
| path   | string | y        | Path to the Convex function formatted as a string as defined [here](/functions/query-functions#query-names). |
| args   | object | y        | Named argument object to pass to the Convex function.                                                        |
| format | string | n        | Output format for values. Valid values: [`json`]                                                             |

**Result JSON on success**

| Field Name | Type         | Description                                            |
| ---------- | ------------ | ------------------------------------------------------ |
| status     | string       | "success"                                              |
| value      | object       | Result of the Convex function in the requested format. |
| logLines   | list[string] | Log lines printed out during the function execution.   |

**Result JSON on error**

| Field Name   | Type         | Description                                                                                              |
| ------------ | ------------ | -------------------------------------------------------------------------------------------------------- |
| status       | string       | "error"                                                                                                  |
| errorMessage | string       | The error message.                                                                                       |
| errorData    | object       | Error data within an [application error](/functions/error-handling/application-errors) if it was thrown. |
| logLines     | list[string] | Log lines printed out during the function execution.                                                     |

### POST `/api/run/{functionIdentifier}`

This HTTP endpoint allows you to call arbitrary Convex function types with the
path in the request URL and get the result as a value. The function identifier
is formatted as a string as defined
[here](/functions/query-functions#query-names) with a `/` replacing the `:`.

You can find your backend deployment URL on the dashboard
[Settings](/dashboard/deployments/settings.md) page, then the API URL will be
`<CONVEX_URL>/api/run/{functionIdentifier}` etc., for example:

<Tabs>
<TabItem value="shell" label="Shell">

```
curl https://acoustic-panther-728.convex.cloud/api/run/messages/list \
   -d '{"args": {}, "format": "json"}' \
   -X POST -H "Content-Type: application/json"
```

</TabItem>
<TabItem value="js" label="NodeJS">

```js
const url = "https://acoustic-panther-728.convex.cloud/api/run/messages/list";
const request = { args: {}, format: "json" };

const response = fetch(url, {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
  },
  body: JSON.stringify(request),
});
```

</TabItem>
<TabItem value="py" label="Python">

```py
import requests

url = "https://acoustic-panther-728.convex.cloud/api/run/messages/list"
headers = {"accept": "application/json"}
body = {"args": {}, "format": "json"}

response = requests.get(url, headers=headers, body=json)
```

</TabItem>
</Tabs>

**JSON Body parameters**

| Name   | Type   | Required | Description                                                          |
| ------ | ------ | -------- | -------------------------------------------------------------------- |
| args   | object | y        | Named argument object to pass to the Convex function.                |
| format | string | n        | Output format for values. Defaults to `json`. Valid values: [`json`] |

**Result JSON on success**

| Field Name | Type         | Description                                            |
| ---------- | ------------ | ------------------------------------------------------ |
| status     | string       | "success"                                              |
| value      | object       | Result of the Convex function in the requested format. |
| logLines   | list[string] | Log lines printed out during the function execution.   |

**Result JSON on error**

| Field Name   | Type         | Description                                                                                              |
| ------------ | ------------ | -------------------------------------------------------------------------------------------------------- |
| status       | string       | "error"                                                                                                  |
| errorMessage | string       | The error message.                                                                                       |
| errorData    | object       | Error data within an [application error](/functions/error-handling/application-errors) if it was thrown. |
| logLines     | list[string] | Log lines printed out during the function execution.                                                     |

## Streaming export API

Convex supports streaming export. Convex provides connector implementations for
[Fivetran and Airbyte](/production/integrations/streaming-import-export.md).
Those connectors use the following APIs.

Sign up for a [Professional plan](https://www.convex.dev/pricing) for streaming
export support. You can also read the
[documentation on streaming export](/production/integrations/streaming-import-export.md).

<BetaAdmonition feature="Streaming Export HTTP APIs" verb="are" />

### GET `/api/json_schemas`

The JSON Schemas endpoint lists tables, and for each table describes how
documents will be encoded, given as [JSON Schema](https://json-schema.org/).
This endpoint returns `$description` tags throughout the schema to describe
unintuitive encodings and give extra information like the table referenced by
`Id` fields.

**Query parameters**

| Name        | Type    | Required | Description                                                                                                     |
| ----------- | ------- | -------- | --------------------------------------------------------------------------------------------------------------- |
| deltaSchema | boolean | n        | If set, include metadata fields returned by document_deltas and list_snapshot (`_ts`, `_deleted`, and `_table`) |
| format      | string  | n        | Output format for values. Valid values: [`json`]                                                                |

### GET `/api/list_snapshot`

The `list_snapshot` endpoint walks a consistent snapshot of documents. It may
take one or more calls to `list_snapshot` to walk a full snapshot.

**Query parameters**

| Name      | Type   | Required | Description                                                                                                                                  |
| --------- | ------ | -------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
| snapshot  | int    | n        | Database timestamp at which to continue the snapshot. The timestamp must not be older than 30 days. If omitted, select the latest timestamp. |
| cursor    | string | n        | An opaque cursor representing the progress in paginating through the snapshot. If omitted, start from the first page of the snapshot.        |
| tableName | string | n        | If provided, filters the snapshot to a table. If omitted, provide snapshot across all tables.                                                |
| format    | string | n        | Output format for values. Valid values: [`json`]                                                                                             |

**Result JSON**

| Field Name | Type              | Description                                                                                             |
| ---------- | ----------------- | ------------------------------------------------------------------------------------------------------- |
| values     | List[ConvexValue] | List of convex values in the requested format. Each value includes extra fields `_ts` and `_table`.     |
| hasMore    | boolean           | True if there are more pages to the snapshot.                                                           |
| snapshot   | int               | A value that represents the database timestamp at which the snapshot was taken.                         |
| cursor     | string            | An opaque cursor representing the end of the progress on the given page. Pass this to subsequent calls. |

Expected API usage (pseudocode):

```python
def list_full_snapshot()
    snapshot_values = []
    snapshot = None
    cursor = None
    while True:
        result = api.list_snapshot(cursor, snapshot)
        snapshot_values.extend(result.values)
        (cursor, snapshot) = (result.cursor, result.snapshot)
        if !result.hasMore:
            break
    return (snapshot_values, result.snapshot)
```

### GET `/api/document_deltas`

The `document_deltas` endpoint walks the change log of documents to find new,
updated, and deleted documents in the order of their mutations. This order is
given by a `_ts` field on the returned documents. Deletions are represented as
JSON objects with fields `_id`, `_ts`, and `_deleted: true`.

**Query parameters**

| Name      | Type   | Required | Description                                                                                                                              |
| --------- | ------ | -------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| cursor    | int    | y        | Database timestamp after which to continue streaming document deltas. Initial value is the `snapshot` field returned from list_snapshot. |
| tableName | string | n        | If provided, filters the document deltas to a table. If omitted, provide deltas across all tables.                                       |
| format    | string | n        | Output format for values. Valid values: [`json`]                                                                                         |

**Result JSON**

| Field Name | Type              | Description                                                                                                                                    |
| ---------- | ----------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| values     | List[ConvexValue] | List of convex values in the requested format. Each value includes extra fields for `_ts`, and `_table`. Deletions include a field `_deleted`. |
| hasMore    | boolean           | True if there are more pages to the snapshot.                                                                                                  |
| cursor     | int               | A value that represents the database timestamp at the end of the page. Pass to subsequent calls to document_deltas.                            |

Expected API usage (pseudocode):

```python
def delta_sync(delta_cursor):
    delta_values = []
    while True:
        result = api.document_deltas(cursor)
        delta_values.extend(result.values)
        cursor = result.cursor
        if !hasMore:
            break
    return (delta_values, delta_cursor)

(snapshot_values, delta_cursor) = list_full_snapshot()
(delta_values, delta_cursor) = delta_sync(delta_cursor)
# Save delta_cursor for the next sync
```

## Streaming import API

Convex supports streaming import. Convex provides a connector implementation for
[Airbyte](/production/integrations/streaming-import-export.md). Those connectors
use the following APIs.

Streaming import support is automatically enabled for all Convex projects.

### Headers

Streaming import endpoints accept a `Convex-Client: streaming-import-<version>`
header, where the version follows [Semver](https://semver.org/) guidelines. If
this header is not specified, Convex will default to the latest version. We
recommend using the header to ensure the consumer of this API does not break as
the API changes.

### GET `/api/streaming_import/primary_key_indexes_ready`

The `primary_key_indexes_ready` endpoint takes a list of table names and returns
true if the primary key indexes (created by `add_primary_key_indexes`) on all
those tables are ready. If the tables are newly created, the indexes should be
ready immediately; however if there are existing documents in the tables, it may
take some time to backfill the primary key indexes. The response looks like:

```json
{
  "indexesReady": true
}
```

### PUT `/api/streaming_import/add_primary_key_indexes`

The `add_primary_key_indexes` endpoint takes a JSON body containing the primary
keys for tables and creates indexes on the primary keys to be backfilled. Note
that they are not immediately ready to query - the `primary_key_indexes_ready`
endpoint needs to be polled until it returns True before calling
`import_airbyte_records` with records that require primary key indexes. Also
note that Convex queries will not have access to these added indexes. These are
solely for use in `import_airbyte_records`. The body takes the form of a map of
index names to list of field paths to index. Each field path is represented by a
list of fields that can represent nested field paths.

```json
{
  "indexes": {
    "<table_name>": [["<field1>"], ["<field2>", "<nested_field>"]]
  }
}
```

Expected API Usage:

1. Add indexes for primary keys by making a request to
   `add_primary_key_indexes`.
2. Poll `primary_key_indexes_ready` until the response is true.
3. Query using the added indexes.

### PUT `api/streaming_import/clear_tables`

The `clear_tables` endpoint deletes all documents from the specified tables.
Note that this may require multiple transactions. If there is an intermediate
error only some documents may be deleted. The JSON body to use this API request
contains a list of table names:

```json
{
  "tableNames": ["<table_1>", "<table_2>"]
}
```

### POST `api/streaming_import/replace_tables`

This endpoint is no longer supported. Use `api/streaming_import/clear_tables`
instead.

The `replace_tables` endpoint renames tables with temporary names to their final
names, deleting any existing tables with the final names.

The JSON body to use this API request contains a list of table names:

```json
{
  "tableNames": { "<table_1_temp>": "<table_1>", "<table_2_temp>": "<table_2>" }
}
```

### POST `api/streaming_import/import_airbyte_records`

The `import_airbyte_records` endpoint enables streaming ingress into a Convex
deployment and is designed to be called from an Airbyte destination connector.

It takes a map of streams and a list of messages in the JSON body. Each stream
has a name and JSON schema that will correspond to a Convex table. Streams where
records should be deduplicated include a primary key as well, which is
represented as a list of lists of strings that are field paths. Records for
streams without a primary key are appended to tables; records for streams with a
primary key replace an existing record where the primary key value matches or
are appended if there is no match. If you are using primary keys, you must call
the `add_primary_key_indexes` endpoint first and wait for them to backfill by
polling `primary_key_indexes_ready`.

Each message contains a stream name and a JSON document that will be inserted
(or replaced, in the case of deduplicated sync) into the table with the
corresponding stream name. Table names are same as the stream names. Airbyte
records become Convex documents.

```json
{
   "tables": {
      "<stream_name>": {
         "primaryKey": [["<field1>"], ["<field2>", "<nested_field>"]],
         "jsonSchema": // see https://json-schema.org/ for examples
      }
   },
   "messages": [{
      "tableName": "<table_name>",
      "data": {} // JSON object conforming to the `json_schema` for that stream
   }]
}
```

Similar to `clear_tables`, it is possible to execute a partial import using
`import_airbyte_records` if there is a failure after a transaction has
committed.

Expected API Usage:

1. [Optional] Add any indexes if using primary keys and
   [deduplicated sync](https://docs.airbyte.com/understanding-airbyte/connections/incremental-deduped-history/)
   (see `add_primary_key_indexes` above).
2. [Optional] Delete all documents in specified tables using `clear_tables` if
   using
   [overwrite sync](https://docs.airbyte.com/understanding-airbyte/connections/full-refresh-overwrite).
3. Make a request to `import_airbyte_records` with new records to sync and
   stream information.


---

# contact.md

<!-- Source: production/contact.md -->

---
title: "Contact Us"
sidebar_position: 500
---

Convex is a rapidly developing platform and we're always eager to hear your
feedback.

## Feedback and Support

Please share any general questions, feature requests, or product feedback in our
[Convex Discord Community](https://convex.dev/community). We're particularly
excited to see what you build on Convex!

Any specific support questions that aren't able to be adequately addressed on
our Discord channel can be directed to
[support@convex.dev](mailto:support@convex.dev).

## Following Convex

Release notes are shared on [Convex News](https://news.convex.dev/tag/releases)
and the [Convex Discord Community](https://convex.dev/community).

Product announcements, articles and demos are posted on
[Stack](https://stack.convex.dev/), [News](https://news.convex.dev/),
[our YouTube channel](https://www.youtube.com/channel/UCoC_9mdiPwIu1sDxDtGQggQ),
and [X (fka Twitter)](https://x.com/convex_dev).

## Vulnerability Disclosure

If you believe you've discovered a bug in Convex's security, please get in touch
at [security@convex.dev](mailto:security@convex.dev) and we'll get back to you
within 24 hours. We request that you not publicly disclose the issue until we
have had a chance to address it.


---

# environment-variables.mdx

<!-- Source: production/environment-variables.mdx -->

---
title: "Environment Variables"
sidebar_label: "Environment Variables"
sidebar_position: 2
description: "Store and access environment variables in Convex"
---

Environment variables are key-value pairs that are useful for storing values you
wouldn't want to put in code or in a table, such as an API key. You can set
environment variables in Convex through the dashboard, and you can access them
in [functions](/functions.mdx) using `process.env`.

## Setting environment variables

Under [Deployment Settings](/dashboard/deployments/settings.md) in the
Dashboard, you can see a list of environment variables in the current
deployment.
![Environment Variables Table](/screenshots/environment_variables_table.png)

You can add up to 100 environment variables. Environment variable names cannot
be more than 40 characters long, and they must start with a letter and only
contain letters numbers, and underscores. Environment variable values cannot be
larger than 8KB.

You can modify environment variables using the pencil icon button:

![Edit Environment Variable](/screenshots/edit_environment_variable.png)

Environment variables can also be viewed and modified with the
[command line](/cli.md#read-and-write-environment-variables).

```sh
npx convex env list
npx convex env set API_KEY secret-api-key
```

### Using environment variables in dev and prod deployments

Since environment variables are set per-deployment, you can use different values
for the same key in dev and prod deployments. This can be useful for when you
have different external accounts you'd like to use depending on the environment.
For example, you might have a dev and prod SendGrid account for sending emails,
and your function expects an environment variable called `SENDGRID_API_KEY` that
should work in both environments.

If you expect an environment variable to be always present in a function, you
must add it to **all** your deployments. In this example, you would add an
environment variable with the name `SENDGRID_API_KEY` to your dev and prod
deployments, with a different value for dev and prod.

## Accessing environment variables

You can access environment variables in Convex functions using
`process.env.KEY`. If the variable is set it is a `string`, otherwise it is
`undefined`. Here is an example of accessing an environment variable with the
key `GIPHY_KEY`:

```javascript
function giphyUrl(query) {
  return (
    "https://api.giphy.com/v1/gifs/translate?api_key=" +
    process.env.GIPHY_KEY +
    "&s=" +
    encodeURIComponent(query)
  );
}
```

Note that you should not condition your Convex function exports on environment
variables. The set of Convex functions that can be called is determined during
deployment and is not reevaluated when you change an environment variable. The
following code will throw an error at runtime, if the DEBUG environment variable
changes between deployment and calling the function.

```javascript
// THIS WILL NOT WORK!
export const myFunc = process.env.DEBUG ? mutation(...) : internalMutation(...);
```

Similarly, environment variables used in cron definitions will only be
reevaluated on deployment.

## System environment variables

The following environment variables are always available in Convex functions:

- `CONVEX_CLOUD_URL` - Your deployment URL (eg.
  `https://dusty-nightingale-847.convex.cloud`) for use with Convex clients.
- `CONVEX_SITE_URL` - Your deployment site URL (eg.
  `https://dusty-nightingale-847.convex.site`) for use with
  [HTTP Actions](/functions/http-actions.mdx)

## Project environment variable defaults

You can set up default environment variable values for a project for development
and preview deployments in Project Settings.

![Project Default Environment Variables](/screenshots/project_default_environment_variables.png)

These default values will be used when creating a new development or preview
deployment, and will have no effect on existing deployments (they are not kept
in sync).

The Deployment Settings will indicate when a deployment has environment
variables that do not match the project defaults.
![Environment Variable Default Mismatch](/screenshots/environment_variable_default_diff.png)


---

# custom.mdx

<!-- Source: production/hosting/custom.mdx -->

---
title: "Custom Domains & Hosting"
sidebar_label: "Custom Domains & Hosting"
description:
  "Serve requests from any domains and host your frontend on any static hosting
  provider, such as GitHub."
sidebar_position: 100
---

## Custom Domains

You can configure a custom domain, like `api.example.com`, to serve HTTP actions
or Convex functions from your production Convex deployments. The settings for
this feature are accessed through the Project Settings page on any of your
projects.

![Add Custom Domain](/screenshots/add_custom_domain.png)

After you enter a domain, you will be shown which records to set on your DNS
provider. Some popular DNS providers that you can use to buy a domain are
Cloudflare and GoDaddy. We will verify your domain in the background, and once
these records are set, you will see a green checkmark.

When you see that checkmark, your backend will now serve traffic from that
domain. The first request may take up to a minute because Convex will have to
mint a new SSL certificate.

Reach out to support@convex.dev if you have any questions about getting set up!

<ProFeatureUpsell feature="Custom domains" verb="require" />

### Hosting with a Custom Domain

To use a custom domain to serve your Convex functions, there's an additional
step: override the `CONVEX_CLOUD_URL` environment variable.

![Override system environment variables](/screenshots/override_system_env_vars.png)

Then re-deploy your project. This may entail clicking "Redeploy" in Vercel or
Netlify, or directly running `npx convex deploy --cmd 'npm run build'`. The
newly deployed code will access your Convex functions through your custom
domain.

The `CONVEX_CLOUD_URL` environment variable is used in several places:

- `npx convex deploy --cmd '...'` sets `CONVEX_URL` (or similarly named) for
  your frontend to connect websockets and HTTP clients
- In your Convex functions, it is available as `process.env.CONVEX_CLOUD_URL`
- File storage URLs: `ctx.storage.getUrl(id)` and
  `ctx.storage.generateUploadUrl()`
- Generate an OpenAPI spec with `npx convex function-spec --prod`

You may also override the `CONVEX_SITE_URL` environment variable to be a custom
HTTP Action domain.

- In your Convex functions, it is available as `process.env.CONVEX_SITE_URL`
- It may be used for webhooks
- It may be used in `auth.config.ts` as the `issuer` for Convex Auth

## Custom Hosting

If you're using only Convex for backend functionality you can host your web app
on any static hosting provider. This guide will use
[GitHub Pages](https://pages.github.com/) as an example.

If you're using Next.js or other framework with server functionality you'll need
to use a provider that supports it, such as
[Netlify](/production/hosting/netlify.mdx) or
[Vercel](/production/hosting/vercel.mdx). You can still host Next.js statically
via a
[static export](https://nextjs.org/docs/pages/building-your-application/deploying/static-exports).

### Configure your build

First make sure that you have a working build process.

In this guide we'll set up a local build, but your hosting provider might
support a remote build. For example see
[Vite's Deploying to GitHub Pages guide](https://vitejs.dev/guide/static-deploy.html#github-pages)
which uses GitHub actions.

We'll use Vite and GitHub Pages as an example.

1. Configure <JSDialectFileName name="vite.config.mts" />:

   ```ts title="vite.config.mts"
   import { defineConfig } from "vite";
   import react from "@vitejs/plugin-react";

   // https://vitejs.dev/config/
   export default defineConfig({
     plugins: [react()],
     // highlight-next-line
     build: {
       // highlight-next-line
       outDir: "docs",
       // highlight-next-line
     },
     // highlight-next-line
     base: "/some-repo-name/",
   });
   ```

   The `build.outDir` field specifies where Vite will place the production
   build, and we use `docs` because that's the directory GitHub Pages allow
   hosting from.

   The `base` field specifies the URL path under which you'll serve your app, in
   this case we will serve on
   `https://<some username>.github.io/<some repo name>`.

### Configure your hosting provider

With GitHub Pages, you can choose whether you want to include your build output
in your main working branch or publish from a separate branch.

Open your repository's GitHub page > _Settings_ > _Pages_. Under _Build and
deployment_ > _Source_ choose `Deploy from a branch`.

Under _branch_ choose a branch (if you want to use a separate branch, push at
least one commit to it first), and the `/docs` folder name. Hit _Save_.

### Build and deploy to Convex and GitHub Pages

To manually deploy to GitHub pages follow these steps:

1. Checkout the branch you chose to publish from
2. Run `npx convex deploy --cmd 'npm run build'` and confirm that you want to
   push your current backend code to your **production** deployment
3. Commit the build output changes and push to GitHub.

### How it works

First, `npx convex deploy` runs through these steps:

1. It sets the `VITE_CONVEX_URL` (or similarly named) environment variable to
   your **production** Convex deployment.
2. It invokes the frontend framework build process, via `npm run build`. The
   build process reads the environment variable and uses it to point the built
   site at your **production** deployment.
3. It deploys your backend code, from the `convex` directory, to your
   **production** deployment.

Afterwards you deploy the built frontend code to your hosting provider. In this
case you used Git, but for other providers you might use a different method,
such as an old-school FTP request.

You can use `--cmd-url-env-var-name` to customize the variable name used by your
frontend code if the `deploy` command cannot infer it, like

```sh
npx convex deploy --cmd-url-env-var-name CUSTOM_CONVEX_URL --cmd 'npm run build'
```

### Authentication

You will want to configure your [authentication](/auth.mdx) provider (Clerk,
Auth0 or other) to accept your production URL, where your frontend is served.


---

# hosting.mdx

<!-- Source: production/hosting/hosting.mdx -->

---
title: "Hosting and Deployment"
description: "Share your Convex backend and web app with the world."
sidebar_position: 1
---

The easiest way to publish your full-stack web app is to use a hosting provider
like [Vercel](https://vercel.com) or [Netlify](https://netlify.com).

Both Vercel and Netlify integrate with Git to deploy code whenever a new
revision is pushed. To host your app:

1. Commit all files and push to your favorite Git hosting provider such as
   [GitHub](https://github.com/), [GitLab](https://gitlab.com/) or
   [Bitbucket](https://bitbucket.org/).

2. Follow the appropriate guide below.

If you aren't using Netlify or Vercel, you can follow the Custom Hosting guide.

- [Vercel](/production/hosting/vercel.mdx)
- [Netlify](/production/hosting/netlify.mdx)
- [Custom Hosting](/production/hosting/custom.mdx)


---

# netlify.mdx

<!-- Source: production/hosting/netlify.mdx -->

---
title: "Using Convex with Netlify"
sidebar_label: "Netlify"
description: "Host your frontend on Netlify and your backend on Convex."
sidebar_position: 20
---

Hosting your Convex app on Netlify allows you to automatically re-deploy both
your backend and your frontend whenever you push your code.

## Deploying to Netlify

This guide assumes you already have a working React app with Convex. If not
follow the [Convex React Quickstart](/quickstart/react.mdx) first. Then:

<StepByStep>
  <Step title="Create a Netlify account">
    If you haven't done so, create a [Netlify](https://netlify.com) account.
    This is free for small projects and should take less than a minute to set
    up.

    <></>

  </Step>
  <Step title="Link your project on Netlify">
    Create a Netlify project at https://app.netlify.com/start and link it to the
    source code repository for your project on GitHub or other Git platform.

    <div className="screenshot-border">
      ![Netlify import project](/screenshots/netlify_import.png)
    </div>

  </Step>
  <Step title="Override the Build command">
    Override the _Build command_ to be
    `npx convex deploy --cmd 'npm run build'`.

    If your project lives in a subdirectory of your repository you'll
    also need to change _Base directory_ in Netlify accordingly.

    <div className="screenshot-border">
      ![Netlify build settings](/screenshots/netlify_build_settings.png)
    </div>

  </Step>
  <Step title="Set up the CONVEX_DEPLOY_KEY environment variable">
    On your [Convex Dashboard](https://dashboard.convex.dev/)
    go to your project's _Settings_ page. Click the _Generate_ button to generate a **Production** deploy key.
    Then click the copy button to copy the key.

    In Netlify, click _Add environment variables_ and _New variable_.

    Create an environment variable `CONVEX_DEPLOY_KEY` and paste
    in your deploy key.

    <div className="screenshot-border">
      ![Netlify environment variable CONVEX_DEPLOY_KEY](/screenshots/netlify_prod_deploy_key.png)
    </div>

  </Step>
  <Step title="Deploy your site">
    Now click the _Deploy_ button and your work here is done!

    <></>

  </Step>

</StepByStep>

Netlify will automatically publish your site to a URL
`https://<site-name>.netlify.app` listed at the top of the site overview page.
Every time you push to your git repository, Netlify will automatically deploy
your Convex functions and publish your site changes.

<Admonition type="info" title="Using a Custom Domain?">
  If you're using a custom domain to serve your Convex functions, you'll need
  additional configuration. See [Custom
  Domains](/production/hosting/custom.mdx#hosting-with-a-custom-domain) for more
  information.
</Admonition>
### How it works

In Netlify, we overrode the _Build Command_ to be
`npx convex deploy --cmd 'npm run build'`.

`npx convex deploy` will read `CONVEX_DEPLOY_KEY` from the environment and use
it to set the `CONVEX_URL` (or similarly named) environment variable to point to
your **production** deployment.

Your frontend framework of choice invoked by `npm run build` will read the
`CONVEX_URL` environment variable and point your deployed site (via
`ConvexReactClient`) at your **production** deployment.

Finally, `npx convex deploy` will push your Convex functions to your production
deployment.

Now, your production deployment has your newest functions and your app is
configured to connect to it.

You can use `--cmd-url-env-var-name` to customize the variable name used by your
frontend code if the `deploy` command cannot infer it, like

```sh
npx convex deploy --cmd-url-env-var-name CUSTOM_CONVEX_URL --cmd 'npm run build'
```

## Authentication

You will want to configure your [authentication](/auth.mdx) provider (Clerk,
Auth0 or other) to accept your production `<site-name>.netlify.app` URL.

## Deploy Previews

Netlify's Deploy Previews allow you to preview changes to your app before
they're merged in. In order to preview both changes to frontend code and Convex
functions, you can set up
[Convex preview deployments](/production/hosting/preview-deployments.mdx).

This will create a fresh Convex backend for each preview and leave your
production and development deployments unaffected.

This assumes you have already followed the steps in
[Deploying to Netlify](#deploying-to-netlify) above.

<StepByStep>
  <Step title="Set up the CONVEX_DEPLOY_KEY environment variable">
    On your [Convex Dashboard](https://dashboard.convex.dev/)
    go to your project's _Settings_ page. Click the _Generate Preview Deploy Key_ button to generate a **Preview** deploy key.
    Then click the copy button to copy the key.

    In Netlify, click _Site configuration_ > _Environment variables_. Edit your existing `CONVEX_DEPLOY_KEY` environment variable.
    Select _Different value for each deploy context_ and paste the key under _Deploy Previews_.


    <div className="screenshot-border">
      ![Netlify environment variable CONVEX_DEPLOY_KEY](/screenshots/netlify_preview_deploy_key.png)
    </div>

  </Step>
  <Step title="(optional) Set up default environment variables">
    If your app depends on certain Convex environment variables, you can set up [default
    environment variables](/production/environment-variables.mdx#project-environment-variable-defaults) for preview and development deployments in your project.
    <div className="screenshot-border">
      ![Project Default Environment Variables](/screenshots/project_default_environment_variables.png)
    </div>
  </Step>

<Step title="(optional) Run a function to set up initial data">
  Deploy Previews run against fresh Convex backends, which do not share data
  with development or production Convex deployments. You can call a Convex
  function to set up data by adding `--preview-run 'functionName'` to the `npx
  convex deploy` command. This function will only be run for preview deployments, and will be ignored
  when deploying to production.

```sh title="Netlify > Site configuration > Build & deploy > Build settings > Build command"
npx convex deploy --cmd 'npm run build' --preview-run 'functionName'
```

</Step>

  <Step title="Now test out creating a PR and generating a Deploy Preview!">

    You can find the Convex deployment for your branch in the Convex dashboard.
    <div className="screenshot-border">
      ![Preview Deployment in Deployment Picker](/screenshots/preview_deployment_deployment_picker.png)
    </div>

  </Step>

</StepByStep>

### How it works

For Deploy Previews, `npx convex deploy` will read `CONVEX_DEPLOY_KEY` from the
environment, and use it to create a Convex deployment associated with the Git
branch name for the Deploy Preview. It will set the `CONVEX_URL` (or similarly
named) environment variable to point to the new Convex deployment.

Your frontend framework of choice invoked by `npm run build` will read the
`CONVEX_URL` environment variable and point your deployed site (via
`ConvexReactClient`) at the Convex preview deployment.

Finally, `npx convex deploy` will push your Convex functions to the preview
deployment and run the `--preview-run` function (if provided). This deployment
has separate functions, data, crons and all other configuration from any other
deployments.

`npx convex deploy` will infer the Git branch name for Vercel, Netlify, GitHub,
and GitLab environments, but the `--preview-create` option can be used to
customize the name associated with the newly created deployment.

Production deployments will work exactly the same as before.


---

# preview-deployments.mdx

<!-- Source: production/hosting/preview-deployments.mdx -->

---
title: "Preview Deployments"
sidebar_label: "Preview Deployments"
description: "Use Convex with your hosting provider's preview deployments"
sidebar_position: 200
---

Convex preview deployments allow your team to test out backend changes before
pushing them to production.

In combination with Vercel Preview Deployments or Netlify Deploy Previews, you
can preview both frontend and backend changes together.

<ProFeatureUpsell feature="Convex preview deployments" verb="require" />

<BetaAdmonition feature="Convex preview deployments" verb="are" />

## Setup

Follow the [Vercel](/production/hosting/vercel.mdx#preview-deployments) or
[Netlify](/production/hosting/netlify.mdx#deploy-previews) hosting guide for
setting up frontend and backend previews together, as well as details on how
Convex preview deployments work.

See `npx convex deploy --help` for all available options for
`npx convex deploy`.

## Limits

Convex preview deployments are automatically cleaned up 14 days after creation,
or when a new preview deployment with the same name is created. They can also be
manually deleted from the Convex dashboard.

When a Convex preview deployment is deleted, the Vercel/Netlify preview link
will open and show UI, but will be unable to run any Convex functions since it
is pointing at a Convex deployment that no longer exists. In these cases,
re-deploying in Vercel/Netlify should produce a link pointing at a new Convex
deployment.

Convex allows a single deployment at a time for a given name (Git branch). When
pushing updates to an existing branch, the deployment will be deleted, resulting
in a preview link unable to run Convex functions, before it is replaced by a new
Convex deployment.

Initial data can be set up on a Convex preview deployment by running a function.
There are currently no other ways to set up data on a Convex preview deployment
-- viewing changes against a copy of production data or importing data from a
different Convex deployment is not supported.

Note that if the function call fails, the `deploy` command will fail, but the
new preview deployment will have already been provisioned. Best course of action
is to fix the issue in the function and redeploy.

Support for preview deployments is a beta feature, so
[let us know on Discord](https://convex.dev/community) if you have feedback!


---

# vercel.mdx

<!-- Source: production/hosting/vercel.mdx -->

---
title: "Using Convex with Vercel"
sidebar_label: "Vercel"
description: "Host your frontend on Vercel and your backend on Convex."
sidebar_position: 10
---

Hosting your Convex app on Vercel allows you to automatically re-deploy both
your backend and your frontend whenever you push your code.

## Deploying to Vercel

This guide assumes you already have a working React app with Convex. If not
follow the [Convex React Quickstart](/quickstart/react.mdx) first. Then:

<StepByStep>
  <Step title="Create a Vercel account">    
    If you haven't done so, create a [Vercel](https://vercel.com) account. This is
    free for small projects and should take less than a minute to set up.

    <></>

  </Step>
  <Step title="Link your project on Vercel">
    Create a Vercel project at https://vercel.com/new and link it to the
    source code repository for your project on GitHub or other Git platform.

    ![Vercel import project](/screenshots/vercel_import.png)

  </Step>
  <Step title="Override the Build command">
    Override the "Build command" to be
    `npx convex deploy --cmd 'npm run build'`.

    If your project lives in a subdirectory of your repository you'll
    also need to change _Root Directory_ above accordingly.

    ![Vercel build settings](/screenshots/vercel_build_command.png)

  </Step>

  <Step title="Set up the CONVEX_DEPLOY_KEY environment variable">
    On your [Convex Dashboard](https://dashboard.convex.dev/)
    go to your project's _Settings_ page. Click the _Generate Production Deploy Key_ button to generate a **Production** deploy key.
    Then click the copy button to copy the key.

    In Vercel, click _Environment Variables_.
    Create an environment variable named `CONVEX_DEPLOY_KEY` and paste
    in your deploy key. Under _Environment_, uncheck all except _Production_ and click _Save_.

    ![Vercel environment variable CONVEX_DEPLOY_KEY](/screenshots/vercel_prod_deploy_key.png)

  </Step>
  <Step title="Deploy your site">
    Now click the _Deploy_ button and your work here is done!

    <></>

  </Step>

</StepByStep>

Vercel will automatically publish your site to an URL like
`https://<site-name>.vercel.app`, shown on the page after deploying. Every time
you push to your Git repository, Vercel will automatically deploy your Convex
functions and publish your site changes.

<Admonition type="info" title="Using a Custom Domain?">
  If you're using a custom domain to serve your Convex functions, you'll need
  additional configuration. See [Custom
  Domains](/production/hosting/custom.mdx#hosting-with-a-custom-domain) for more
  information.
</Admonition>

### How it works

In Vercel, we overrode the _Build Command_ to be
`npx convex deploy --cmd 'npm run build'`.

`npx convex deploy` will read `CONVEX_DEPLOY_KEY` from the environment and use
it to set the `CONVEX_URL` (or similarly named) environment variable to point to
your **production** deployment.

Your frontend framework of choice invoked by `npm run build` will read the
`CONVEX_URL` (or similarly named) environment variable to point your deployed
site (via `ConvexReactClient`) at your **production** deployment.

Finally, `npx convex deploy` will push your Convex functions to your production
deployment.

Now, your production deployment has your newest functions and your app is
configured to connect to it.

You can use `--cmd-url-env-var-name` to customize the variable name used by your
frontend code if the `deploy` command cannot infer it, like

```sh
npx convex deploy --cmd-url-env-var-name CUSTOM_CONVEX_URL --cmd 'npm run build'
```

### Authentication

You will want to configure your [authentication](/auth.mdx) provider (Clerk,
Auth0 or other) to accept your production URL. Note that Clerk does not support
`https://<site-name>.vercel.app`, so you'll have to configure a custom domain.

## Preview Deployments

Vercel Preview Deployments allow you to preview changes to your app before
they're merged in. In order to preview both changes to frontend code and Convex
functions, you can set up
[Convex preview deployments](/production/hosting/preview-deployments.mdx).

This will create a fresh Convex backend for each preview and leave your
production and development deployments unaffected.

This assumes you have already followed the steps in
[Deploying to Vercel](#deploying-to-vercel) above.

<StepByStep>
  <Step title="Set up the CONVEX_DEPLOY_KEY environment variable">
    On your [Convex Dashboard](https://dashboard.convex.dev/)
    go to your project's _Settings_ page. Click the _Generate Preview Deploy Key_ button to generate a **Preview** deploy key.
    Then click the copy button to copy the key.

    In Vercel, click _Environment Variables_.
    Create an environment variable named `CONVEX_DEPLOY_KEY` and paste
    in your deploy key. Under _Environment_, uncheck all except _Preview_ and click _Save_.

    <div className="screenshot-border">
      ![Vercel environment variable CONVEX_DEPLOY_KEY](/screenshots/vercel_preview_deploy_key.png)
    </div>

  </Step>
  <Step title="(optional) Set up default environment variables">
    If your app depends on certain Convex environment variables, you can set up [default
    environment variables](/production/environment-variables.mdx#project-environment-variable-defaults) for preview and development deployments in your project.
    <div className="screenshot-border">
      ![Project Default Environment Variables](/screenshots/project_default_environment_variables.png)
    </div>
  </Step>

<Step title="(optional) Run a function to set up initial data">
  Vercel Preview Deployments run against fresh Convex backends, which do not share data
  with development or production Convex deployments. You can call a Convex
  function to set up data by adding `--preview-run 'functionName'` to the `npx
  convex deploy` command. This function will only be run for preview deployments, and will be ignored
  when deploying to production.

```sh title="Vercel > Settings > Build & Development settings > Build Command"
npx convex deploy --cmd 'npm run build' --preview-run 'functionName'
```

</Step>

  <Step title="Now test out creating a PR and generating a Preview Deployment!">

    You can find the Convex deployment for your branch in the Convex dashboard.
    <div className="screenshot-border">
      ![Preview Deployment in Deployment Picker](/screenshots/preview_deployment_deployment_picker.png)
    </div>

  </Step>

</StepByStep>

### How it works

For Preview Deployments, `npx convex deploy` will read `CONVEX_DEPLOY_KEY` from
the environment, and use it to create a Convex deployment associated with the
Git branch name for the Vercel Preview Deployment. It will set the `CONVEX_URL`
(or similarly named) environment variable to point to the new Convex deployment.

Your frontend framework of choice invoked by `npm run build` will read the
`CONVEX_URL` environment variable and point your deployed site (via
`ConvexReactClient`) at the Convex preview deployment.

Finally, `npx convex deploy` will push your Convex functions to the preview
deployment and run the `--preview-run` function (if provided). This deployment
has separate functions, data, crons and all other configuration from any other
deployments.

`npx convex deploy` will infer the Git branch name for Vercel, Netlify, GitHub,
and GitLab environments, but the `--preview-create` option can be used to
customize the name associated with the newly created deployment.

Production deployments will work exactly the same as before.


---

# exception-reporting.mdx

<!-- Source: production/integrations/exception-reporting.mdx -->

---
title: "Exception Reporting"
sidebar_label: "Exception Reporting"
sidebar_position: 3
description:
  "Configure exception reporting integrations for your Convex deployment"
---

Configure exception reporting to gain visibility into errors from your Convex
function executions. Convex supports integration with
[Sentry](https://sentry.io/) and with
[Datadog Error Tracking](https://www.datadoghq.com/product/error-tracking/).

Currently, exception reporting is only available to Pro users.

## Configuring Sentry

To configure sentry, navigate to the
[Deployment Settings](/dashboard/deployments/settings.md) in the Dashboard, and
the "Integrations" tab in the sidebar.

![Integrations Page](/screenshots/integrations_page.png)

Click on the Sentry card and follow the setup directions. You will need your
[Sentry DSN](https://docs.sentry.io/product/sentry-basics/concepts/dsn-explainer/).
You may optionally specify additional tags to be added to each exception event.

![Configure sentry](/screenshots/configure_sentry.png)

## Supported Tags

Convex automatically tags exception events on their way to sentry with the
following tags. These tags cannot be overridden.

- `func`: The name of the running function in
  [string format](/functions/query-functions#query-names)
- `func_type`: One of `["query", "mutation", "action", "http_action"]`
- `func_runtime`: One of the [function runtimes](/functions/runtimes.mdx) -
  `["default", "node"]`
- `request_id`: The
  [request id](/functions/debugging.mdx#finding-relevant-logs-by-request-id) of
  the function that errored.
- `server_name`: The name of the deployment. e.g. `happy-animal-123`
- `environment`: One of `["prod", "dev", "preview"]`
- `user`: If the function is [authenticated](/auth.mdx), then the
  [tokenIdentifier](/api/interfaces/server.UserIdentity#tokenidentifier) is used
  as the user id on Sentry. The `tokenIdentifier` is a stable and globally
  unique string representing the authenticated user.

## Sentry Notes

- Sentry Exceptions may take a minute or two to propagate to Sentry.
- Convex's built-in sentry support does not yet support the advanced
  customization provided by the sentry SDK.
- Please reach out with any questions, comments, or suggestions
  [on Discord](https://convex.dev/community).

## Configuring Datadog Error Tracking

Follow the instructions in the
[Datadog application](https://app.datadoghq.com/error-tracking/settings/setup/sentry)
to configure Datadog error tracking via the Sentry SDK. Then use the
Convex-Sentry integration to proceed.


---

# integrations.mdx

<!-- Source: production/integrations/integrations.mdx -->

---
title: "Integrations"
description: "Integrate Convex with third party services."
sidebar_position: 1
---

Convex integrates with a variety of supported third party tools for log
streaming and exception reporting.

- [Log Streams](/production/integrations/log-streams) enable streaming of log
  events from your Convex deployment to supported destinations, such as Axiom,
  Datadog, or a custom webhook.
- [Exception Reporting](/production/integrations/exception-reporting) gives
  visibility into errors in your Convex function executions.

## Configuring an Integration

To configure an integration, navigate to the
[Deployment Settings](https://dashboard.convex.dev/deployment/settings) in the
Dashboard, and the "Integrations" tab in the sidebar. This page provides a list
of your configured integrations, their current health status, and other
integrations available to be configured. To configure a integration, click on
the card and follow the setup directions.

![Integrations Page](/screenshots/integrations_page.png)

## Deleting an Integration

To remove an integration and stop further events from being piped out to the
configured destination, select the menu icon in the upper-right corner of a
configured panel and select "Delete integration". After confirming, the
integration will stop running within a few seconds.

## Feedback

Please reach out with any questions, comments, or suggestions
[on Discord](https://convex.dev/community).


---

# legacy-event-schema.mdx

<!-- Source: production/integrations/log-streams/legacy-event-schema.mdx -->

# (Legacy) Event schema

<Admonition type="info">
  Log streams configured before May 23, 2024 will use the legacy format
  documented here. We recommend updating your log stream to use the new format.
</Admonition>

## Updating to the new format

You can update existing log streams to the new format in the dashboard under
your [deployment's Settings](https://dashboard.convex.dev/deployment/settings) >
Integrations.

You can either create an entirely new dataset to hold events using the new
format, or can reuse your existing dataset to hold historical events in the
legacy format as well as events in the new format going forward.

We recommend reading the documentation on both the legacy format and the
[current format](/production/integrations/log-streams/log-streams.mdx#log-event-schema)
for the full set of differences, but here are a few key differences:

- Many fields have been renamed to drop leading underscores and use `snake_case`
- Fields have been added, e.g.
  - `function.request_id`
  - `usage.vector_storage_read_bytes`
  - `log_level`
- Fields have been renamed or nested for clarity, e.g.
  - `reason` -> `error_message`
  - `_functionPath` -> `function.path`

## (Legacy) Event schema

Log events have a well-defined JSON schema that allow building complex,
type-safe pipelines ingesting log events.

## System fields

System fields are reserved fields which are included on log events and prefixed
by an underscore.

All log events include the following system fields:

- `_topic`: string that categorizes a log event by its internal source
- `_timestamp`: Unix epoch timestamp in milliseconds. This is as an integer.

## Log sources

This section outlines the source and data model of all log events.

### `console` logs

Convex function logs via the `console` API.

Schema:

- `_topic = "_console"`
- `_timestamp` = Unix epoch timestamp in milliseconds
- `_functionType = "query" | "mutation" | "action" | "httpAction"`
- `_functionPath` =
  - If this is an HTTP action, this is a string of the HTTP method and URL
    pathname i.e. `POST /my_endpoint`
  - Otherwise, this is a path to function within `convex/` directory including
    an optional module export identifier i.e. `myDir/myFile:myFunction`.
- `_functionCached = true | false`. This field is only set if
  `_functionType = "query"` and says if this log event came from a cached
  function execution.
- `message` = payload string of arguments to `console` API

Example query log event:

```json
{
  "_topic": "_console",
  "_timestamp": 1695066350531,
  "_functionType": "query",
  "_functionPath": "myDir/myFile",
  "_functionCached": true,
  "message": "[LOG] 'My log message'"
}
```

### Function execution record logs

Function executions which log a record of their execution and their result.

Schema:

- `_topic = "_execution_record"`
- `_timestamp` = Unix epoch timestamp in milliseconds
- `_functionType = "query" | "mutation" | "action" | "httpAction"`
- `_functionPath` = path to function within `convex/` directory including module
  export identifier
- `_functionCached = true | false`. This field is only set if
  `_functionType = "query"` and says if this log event came from a cached
  function execution.
- `status = "success" | "failure"`
- `reason` = error message from function. Only set if `status = "failure"`
- `executionTimeMs` = length of execution of this function in milliseconds
- `databaseReadBytes` = the database read bandwidth used by this function in
  bytes
- `databaseWriteBytes` = the database write bandwidth used by this function in
  bytes
- `storageReadBytes` = the file storage read bandwidth this function used in
  bytes
- `storageWriteBytes` = the file storage write bandwidth this function used in
  bytes

Example execution record log from an HTTP action:

```json
{
  "_topic": "_execution_record",
  "_timestamp": 1695066350531,
  "_functionType": "httpAction",
  "_functionPath": "POST /sendImage",
  "status": "failure",
  "reason": "Unexpected Error: Some error message\n\n  at ....",
  "executionTimeMs": 73
}
```

### Audit trail logs

Audit logs of deployment events.

Schema:

- `_topic = "_audit_log"`
- `_timestamp` = Unix epoch timestamp in milliseconds
- `action = "create_environment_variable" | "update_environment_variable" | "delete_environment_variable" | "replace_environment_variable" | "push_config" | "build_indexes" | "change_deployment_state"`
- `actionMetadata` = object whose fields depends on the value of the `action`
  field.

Example `push_config` audit log:

```json
{
  "_topic": "_audit_log",
  "_timestamp": 1695066350531,
  "action": "push_config",
  "actionMetadata": {
    "modules": {
      "added": ["ffmpeg.js", "fetch.js", "test.js"],
      "removed": ["removed.js"]
    }
  }
}
```

### Verification logs

Internal logging events used to verify access to a log stream.

Schema

- `_topic = "_verification"`
- `_timestamp` = Unix epoch timestamp in milliseconds.
- `message = Convex connection test`


---

# log-streams.mdx

<!-- Source: production/integrations/log-streams/log-streams.mdx -->

---
title: "Log Streams"
sidebar_label: "Log Streams"
sidebar_position: 2
description: "Configure logging integrations for your Convex deployment"
---

Log streams enable streaming of events such as function executions and
`console.log`s from your Convex deployment to supported destinations, such as
Axiom, Datadog, or a custom webhook.

The most recent logs produced by your Convex deployment can be viewed in the
Dashboard [Logs page](/dashboard/deployments/logs.md), the
[Convex CLI](/cli.md), or in the browser console, providing a quick and easy way
to view recent logs.

Log streaming to a third-party destination like Axiom or Datadog enables storing
historical logs, more powerful querying and data visualization, and integrations
with other tools (e.g. PagerDuty, Slack).

<ProFeatureUpsell feature="Log streams" verb="require" />

## Configuring log streams

We currently support the following log streams, with plans to support many more:

- [Axiom](https://www.axiom.co)
- [Datadog](https://www.datadoghq.com/)
- Webhook to a custom URL

See the instructions for
[configuring an integration](/production/integrations/integrations.mdx#configuring-an-integration).
The specific information needed for each log stream is covered below.

### Axiom

Configuring an Axiom log stream requires specifying:

- The name of your
  [Axiom dataset](https://axiom.co/docs/reference/settings#dataset)
- An Axiom [API key](https://axiom.co/docs/reference/settings#api-token)
- An optional list of attributes and their values to be included in all log
  events send to Axiom. These will be sent via the `attributes` field in the
  [Ingest API](https://axiom.co/docs/send-data/ingest#ingest-api).

### Datadog

Configuring a Datadog log stream requires specifying:

- The [site location](https://docs.datadoghq.com/getting_started/site/) of your
  Datadog deployment
- A Datadog
  [API key](https://docs.datadoghq.com/account_management/api-app-keys/#add-an-api-key-or-client-token)
- A comma-separated list of tags that will be passed using the
  [`ddtags` field](https://docs.datadoghq.com/getting_started/tagging/) in all
  payloads sent to Datadog. This can be used to include any other metadata that
  can be useful for querying or categorizing your Convex logs ingested by your
  Datadog deployment.

### Webhook

A webhook log stream is the simplest and most generic stream, allowing piping
logs via POST requests to any URL you configure. The only parameter required to
set up this stream is the desired webhook URL.

A request to this webhook contains as its body a JSON array of events in the
schema defined below.

## Log event schema

<Admonition type="info">
  Log streams configured before May 23, 2024 will use the legacy format
  documented on [this
  page](/production/integrations/log-streams/legacy-event-schema.mdx). We
  recommend updating your log stream to use the new format.
</Admonition>

Log events have a well-defined JSON schema that allow building complex,
type-safe pipelines ingesting log events.

All events will have the following three fields:

- `topic`: string, categorizes a log event, one of
  `["verification", "console", "function_execution", "audit_log"]`
- `timestamp`: number, Unix epoch timestamp in milliseconds as an integer
- `convex`: An object containing metadata related to your Convex deployment,
  including `deployment_name`, `deployment_type`, `project_name`, and
  `project_slug`.

Note: In the Axiom integration, event-specific information will be available
under the `data` field.

### `verification` events

This is an event sent to confirm the log stream is working. Schema:

- `topic`: `"verification"`
- `timestamp`: Unix epoch timestamp in milliseconds
- `message`: string

### `console` events

Convex function logs via the [`console` API](/functions/debugging.mdx).

Schema:

- `topic`: `"console"`
- `timestamp`: Unix epoch timestamp in milliseconds
- `function`: object, see
  [function fields](/production/integrations/log-streams/log-streams.mdx#function-fields)
- `log_level`: string, one of `["DEBUG", "INFO", "LOG", "WARN", "ERROR"]`
- `message`: string, the
  [`object-inspect`](https://www.npmjs.com/package/object-inspect)
  representation of the `console.log` payload
- `is_truncated`: boolean, whether this message was truncated to fit within our
  logging limits
- `system_code`: optional string, present for automatically added warnings when
  functions are approaching [limits](/production/state/limits.mdx#functions)

Example event for `console.log("Sent message!")` from a mutation:

```json
{
    "topic": "console"
    "timestamp": 1715879172882,
    "function": {
      "path": "messages:send",
      "request_id": "d064ef901f7ec0b7",
      "type": "mutation"
    },
    "log_level": "LOG",
    "message": "'Sent message!'"
}
```

### `function_execution` events

These events occur whenever a function is run.

Schema:

- `topic`: `"function_execution"`
- `timestamp`: Unix epoch timestamp in milliseconds
- `function`: object, see
  [function fields](/production/integrations/log-streams/log-streams.mdx#function-fields)
- `execution_time_ms`: number, the time in milliseconds this function took to
- `status`: string, one of `["success", "failure"]`
- `error_message`: string, present for functions with status `failure`,
  containing the error and any stack trace.
- `mutation_queue_length`: optional number (for mutations only), the length of
  the per-session mutation queue at the time the mutation was executed. This is
  useful for monitoring and debugging mutation queue backlogs in individual
  sessions.
- `mutation_retry_count`: number, the number of previous failed executions (for
  mutations only) run before a successful one. Only applicable to mutations and
  actions.
- `occ_info`: object, if the function call resulted in an OCC (write conflict
  between two functions), this field will be present and contain information
  relating to the OCC.
  [Learn more about write conflicts](https://docs.convex.dev/error/#1).
  - `table_name`: table the conflict occurred in
  - `document_id`: Id of the document that received conflicting writes
  - `write_source`: name of the function that conflicted writes against
    `table_name`
  - `retry_count`: the number of previously failed attempts before the current
    function execution
- `usage`:
  - `database_read_bytes`: number
  - `database_write_bytes`: number, this and `database_read_bytes` make up the
    database bandwidth used by the function
  - `database_read_documents`: number, the number of documents read by the
    function
  - `file_storage_read_bytes`: number
  - `file_storage_write_bytes`: number, this and `file_storage_read_bytes` make
    up the file bandwidth used by the function
  - `vector_storage_read_bytes`: number
  - `vector_storage_write_bytes`: number, this and `vector_storage_read_bytes`
    make up the vector bandwidth used by the function
  - `action_memory_used_mb`: number, for actions, the memory used in MiB. This
    combined with `execution_time_ms` makes up the action compute.

Example event for a query:

```json
{
  "data": {
    "execution_time_ms": 294,
    "function": {
      "cached": false,
      "path": "message:list",
      "request_id": "892104e63bd39d9a",
      "type": "query"
    },
    "status": "success",
    "timestamp": 1715973841548,
    "topic": "function_execution",
    "usage": {
      "database_read_bytes": 1077,
      "database_write_bytes": 0,
      "database_read_documents": 3,
      "file_storage_read_bytes": 0,
      "file_storage_write_bytes": 0,
      "vector_storage_read_bytes": 0,
      "vector_storage_write_bytes": 0
    }
  }
}
```

### Function fields

The following fields are added under `function` for all `console` and
`function_execution` events:

- `type`: string, one of `["query", "mutation", "action", "http_action"]`
- `path`: string, e.g. `"myDir/myFile:myFunction"`, or `"POST /my_endpoint"`
- `cached`: optional boolean, for queries this denotes whether this event came
  from a cached function execution
- `request_id`: string, the
  [request ID](/functions/debugging.mdx#finding-relevant-logs-by-request-id) of
  the function.

### `scheduled_job_lag` events

These events are periodically sent by the scheduler reporting the delay in
executing your scheduled functions.

Schema:

- `topic`: `"scheduled_job_lag"`
- `timestamp`: Unix epoch timestamp in milliseconds
- `lag_seconds`: The difference between `timestamp` and the scheduled run time
  of the oldest overdue scheduled job, in seconds.

### `audit_log` events

These events represent changes to your deployment, which also show up in the
[History tab](https://dashboard.convex.dev/deployment/history) in the dashboard.

Schema:

- `topic`: `audit_log`
- `timestamp`: Unix epoch timestamp in milliseconds
- `audit_log_action`: string, e.g. `"create_environment_variable"`,
  `"push_config"`, `"change_deployment_state"`
- `audit_log_metadata`: string, stringified JSON holding metadata about the
  event. The exact format of this event may change.

Example `push_config` audit log:

```json
{
  "topic": "audit_log",
  "timestamp": 1714421999886,
  "audit_log_action": "push_config",
  "audit_log_metadata": "{\"auth\":{\"added\":[],\"removed\":[]},\"crons\":{\"added\":[],\"deleted\":[],\"updated\":[]},..."
}
```

## Guarantees

Log events provide a best-effort delivery guarantee. Log streams are buffered
in-memory and sent out in batches to your deployment's configured streams. This
means that logs can be dropped if ingestion throughput is too high. Similarly,
due to network retries, it is possible for a log event to be duplicated in a log
stream.

That's it! Your logs are now configured to stream out. If there is a log
streaming destination that you would like to see supported,
[please let us know](/production/contact.md)!

<StackPosts query="axiom" />


---

# streaming-import-export.md

<!-- Source: production/integrations/streaming-import-export.md -->

---
title: "Streaming Data in and out of Convex"
sidebar_label: "Streaming Import/Export"
description: "Streaming Data in and out of Convex"
sidebar_position: 4
---

[Fivetran](https://www.fivetran.com) and [Airbyte](https://airbyte.com) are data
integration platforms that allow you to sync your Convex data with other
databases.

Fivetran enables streaming export from Convex to any of their
[supported destinations](https://fivetran.com/docs/destinations). The Convex
team maintains a Convex source connector, for streaming export. Streaming import
into Convex via Fivetran is not supported at the moment.

Using Airbyte enables streaming import from any of their
[supported sources](https://airbyte.com/connectors?connector-type=Sources) into
Convex and streaming export from Convex into any of their
[supported destinations](https://airbyte.com/connectors?connector-type=Destinations).
The Convex team maintains a Convex source connector for streaming export and a
Convex destination connector for streaming import.

<BetaAdmonition feature="Fivetran & Airbyte integrations" verb="are" />

## Streaming Export

Exporting data can be useful for handling workloads that aren't supported by
Convex directly. Some use cases include:

1. Analytics
   - Convex isn't optimized for queries that load huge amounts of data. A data
     platform like [Databricks](https://www.databricks.com) or
     [Snowflake](https://www.snowflake.com/) is more appropriate.
2. Flexible querying
   - While Convex has powerful
     [database queries](/database/reading-data/reading-data.mdx#querying-documents)
     and built-in [full text search](/search.mdx) support, there are still some
     queries that are difficult to write within Convex. If you need very dynamic
     sorting and filtering for something like an "advanced search" view,
     databases like [ElasticSearch](https://www.elastic.co) can be helpful.
3. Machine learning training
   - Convex isn't optimized for queries running computationally intensive
     machine learning algorithms.

<ProFeatureUpsell feature="Streaming export" verb="requires" />

See the [Fivetran](https://fivetran.com/integrations/convex) or
[Airbyte](https://docs.airbyte.com/integrations/sources/convex) docs to learn
how to set up a streaming export. [Contact us](https://convex.dev/community) if
you need help or have questions.

## Streaming Import

Adopting new technologies can be a slow, daunting process, especially when the
technologies involve databases. Streaming import enables adopting Convex
alongside your existing stack without having to write your own migration or data
sync tooling. Some use cases include:

1. Prototyping how Convex could replace your project's existing backend using
   its own data.
2. Building new products faster by using Convex alongside existing databases.
3. Developing a reactive UI-layer on top of an existing dataset.
4. Migrating your data to Convex (if the [CLI](/cli.md) tool doesn't meet your
   needs).

<Admonition type="caution" title="Make imported tables read-only">
A common use case is to "mirror" a table in the source database to Convex to
build something new using Convex. We recommend leaving imported
tables as read-only in Convex because syncing the results back to the source
database could result in dangerous write conflicts. While Convex doesn't yet
have access controls that would ensure a table is read-only, you can make sure that
there are no mutations or actions writing to imported tables in your code and avoid editing
documents in imported tables in the dashboard.
</Admonition>

Streaming import is included with all Convex plans. See the Airbyte docs on how
to set up the Convex destination connector
[here](https://docs.airbyte.com/integrations/destinations/convex).


---

# multiple-repos.mdx

<!-- Source: production/multiple-repos.mdx -->

---
title: Multiple Repositories
sidebar_label: Multiple Repositories
description: "Use Convex in multiple repositories"
sidebar_position: 180
---

import Functions from "!!raw-loader!@site/../private-demos/snippets/convex/tsGeneration.ts";
import API from "!!raw-loader!@site/../private-demos/snippets/api.ts";
import Frontend from "!!raw-loader!@site/../private-demos/snippets/src/tsGeneration.tsx";

Your TypeScript clients can call Convex functions in a type-safe way outside of
the repository where your Convex functions are defined. By following the steps
below, you can generate a file similar to `convex/_generated/api.d.ts` that you
can check in and use in a separate repository.

<BetaAdmonition feature="TypeScript API generation" verb="is" />

<StepByStep>
  <Step title="Install the Convex Helpers npm package">
    Install the `convex-helpers` package, which contains a CLI command to generate an api file.

    ```sh
    npm install convex-helpers
    ```

  </Step>
  <Step title="Run a command to generate a TypeScript API file">
    Running this command will call into your configured Convex deployment and generate an `api.ts` file based
    on it. You can see additional flags by passing `--help` to the command.

    ```sh
    npx convex-helpers ts-api-spec
    ```

  </Step>
</StepByStep>

## Example

Below are code snippets of what this workflow looks like in action. These
snippets include three different files:

- `convex/messages.ts` - contains Convex function definitions
- `api.ts` - a generated file from running the command above
- `src/App.tsx` - frontend code in a separate repository where `api.ts` is
  checked in

<TSAndJSSnippet
  title="convex/messages.ts"
  snippets="send"
  sourceTS={Functions}
  sourceJS={Functions}
/>

<TSAndJSSnippet title="api.ts" sourceTS={API} sourceJS={API} />

<TSAndJSSnippet
  title="src/App.tsx"
  sourceTS={Frontend}
  sourceJS={Frontend}
  highlightPatterns={["import { api } from"]}
/>

## Limits

- Argument and return value validators are not required, but they will enrich
  the types of your TypeScript API. Where validators aren't defined, we default
  to `v.any()` as the validator.
- You cannot call internal functions from outside of your Convex deployment.


---

# pause-deployment.mdx

<!-- Source: production/pause-deployment.mdx -->

---
title: "Pausing a Deployment"
sidebar_label: "Pausing a Deployment"
sidebar_position: 4
---

Pausing a deployment is a way to "turn off" a deployment without deleting any
data. This can be useful if you have an action that is blowing through a
third-party API quota and you just need a big red stop button.

When a deployment is paused:

- New function calls will return an error.
- Scheduled jobs will queue and run when the deployment is resumed.
- Cron jobs will be skipped.
- Everything else (e.g. code push, dashboard edits) should work as usual.

**This is important!** All new function calls will return an error when a
deployment is paused, so if you are running an app in production you may want to
consider alternatives like pushing code that disables a feature you are trying
to "turn off". We recommend testing this feature in a dev deployment first
before pausing a production deployment.

![Pause Deployment Button](/screenshots/pause_deployment.png)

A deployment can be resumed with this button on the same page:

![Resume Deployment](/screenshots/resume_deployment.png)


---

# project-configuration.mdx

<!-- Source: production/project-configuration.mdx -->

---
title: "Project Configuration"
sidebar_label: "Project Configuration"
sidebar_position: 3
---

## Local development

When you're developing locally you need two pieces of information:

1. The name of your dev deployment. This is where your functions are pushed to
   and served from. It is stored in the `CONVEX_DEPLOYMENT` environment
   variable. `npx convex dev` writes it to the `.env.local` file.
2. The URL of your dev deployment, for your client to connect to. The name of
   the variable and which file it can be read from varies between client
   frameworks. `npx convex dev` writes the URL to the `.env.local` or `.env`
   file.

## Production deployment

You should only be deploying to your production deployment once you have tested
your changes on your local deployment. When you're ready, you can deploy either
via a hosting/CI provider or from your local machine.

For a CI environment you can follow the
[hosting](/production/hosting/hosting.mdx) docs. `npx convex deploy` run by the
CI pipeline will use the `CONVEX_DEPLOY_KEY`, and the frontend build command
will use the deployment URL variable, both configured in your CI environment.

You can also deploy your backend from your local machine. `npx convex deploy`
will ask for a confirmation and then deploy to the production deployment in the
same project as your configured development `CONVEX_DEPLOYMENT`.

## `convex.json`

Additional project configuration can be specified in the `convex.json` file in
the root of your project (in the same directory as your `package.json`).

You can use the JSON schema for editor validation by adding a `$schema`
property:

```json title="convex.json"
{
  "$schema": "https://raw.githubusercontent.com/get-convex/convex-backend/refs/heads/main/npm-packages/convex/schemas/convex.schema.json",
  "functions": "src/convex/"
}
```

The file supports the following configuration options:

### Changing the `convex/` folder name or location

You can choose a different name or location for the `convex/` folder via the
`functions` field. For example, Create React App doesn't allow importing from
outside the `src/` directory, so if you're using Create React App you should
have the following config:

```json title="convex.json"
{
  "functions": "src/convex/"
}
```

### Installing packages on the server

You can specify which packages used by Node actions should be installed on the
server, instead of being bundled, via the `node.externalPackages` field.
[Read more](/functions/bundling.mdx#external-packages).

### Importing the generated functions API via `require()` syntax

The Convex code generation can be configured to generate a CommonJS-version of
the `_generated/api.js` file via the `generateCommonJSApi` field.
[Read more](/client/javascript/node.mdx#javascript-with-commonjs-require-syntax).

### Using static code generation (beta)

Convex's code generation heavily relies on TypeScript's type inference. This
makes updates snappy and jump-to-definition work for the `api` and `internal`
objects, but it often slows down with large codebases.

If you're running into language server performance issues, you can instruct the
Convex CLI to generate static versions of the `_generated/api.d.ts` and
`_generated/dataModel.d.ts`:

```json title="convex.json"
{
  "codegen": {
    "staticApi": true,
    "staticDataModel": true
  }
}
```

This will greatly improve autocomplete and incremental typechecking performance,
but it does have some tradeoffs:

- These types only update when `convex dev` is running.
- Jump-to-definition no longer works. To find `api.example.f`, you'll need to
  manually open `convex/example.ts` and find `f`.
- Functions no longer have return type inference and will default to `v.any()`
  if they don't have a returns validator.
- [TypeScript enums](https://www.typescriptlang.org/docs/handbook/enums.html) no
  longer work in schema or API definitions. Use unions of string literal types
  instead.

This feature is currently in beta, and we'd love to improve these limitations.
Let us know if you run into any issues or have any feedback!


---

# limits.mdx

<!-- Source: production/state/limits.mdx -->

---
title: "Limits"
sidebar_position: 2
---

We’d love for you to have _unlimited_ joy building on Convex but engineering
practicalities dictate a few limits. This page outlines current limits in the
Convex ecosystem.

Many of these limits will become more permissive over time. Please get in touch
if any are prohibitive for your application.

Limits are applied per team unless stated otherwise.

## Team

|            | Starter | Professional                  |
| ---------- | ------- | ----------------------------- |
| Developers | 1-6     | 1-20<br/>$25/member per month |
| Projects   | 20      | 100                           |

## Database

|                   | Starter       | Professional                                       | Notes                                                                                     |
| ----------------- | ------------- | -------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| Storage           | 0.5 GiB       | 50 GiB included<br/>$0.20/month per additional GiB | Includes database rows and indexes but not files or backups.                              |
| Bandwidth         | 1 GiB/month   | 50 GiB/month included<br/>$0.20 per additional GiB | Document and index data transferred between Convex functions and the underlying database. |
| Tables            | 10,000        | 10,000                                             | Per deployment.                                                                           |
| Indexes per table | 32            | 32                                                 |                                                                                           |
| Fields per index  | 16            | 16                                                 |
| Index name length | 64 characters | 64 characters                                      |                                                                                           |

### Restrictions

- Table and index names must be valid identifiers and cannot start with an
  underscore.

## Documents

Applied per document and to any nested `Object` unless stated otherwise.

|                     |               | Notes                                                            |
| ------------------- | ------------- | ---------------------------------------------------------------- |
| Size                | 1 MiB         |                                                                  |
| Fields              | 1024          | The number of fields/keys                                        |
| Field name length   | 64 characters | Nested `Object` keys can have length up to 1024 characters.      |
| Field nesting depth | 16            | How many times objects and arrays can be nested, e.g. `[[[[]]]]` |
| Array elements      | 8192          |                                                                  |

### Restrictions

- Field names must only contain non-control alphanumeric ASCII characters and
  underscores and must start with an alphabetic character or underscore.
- Documents cannot contain top-level fields that start with an underscore, other
  than the system-provided `_id` and `_creationTime` fields.
- Strings must be valid Unicode sequences with no unpaired surrogates.

## Functions

|                                                                              | Starter                             | Professional                                              | Notes                                                                                                         |
| ---------------------------------------------------------------------------- | ----------------------------------- | --------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| Function calls                                                               | 1,000,000/month                     | 25,000,000/month included<br/>$2 per additional 1,000,000 | Explicit client calls, scheduled executions, subscription updates, and file accesses count as function calls. |
| Action execution                                                             | 20 GiB-hours                        | 250 GiB-hours included<br/>$0.30/GiB-hour additional      | Convex runtime: 64 MiB RAM.<br/>Node.js runtime: 512 MiB RAM.                                                 |
| Code size                                                                    | 32 MiB                              | 32 MiB                                                    | Per deployment.                                                                                               |
| Function argument size                                                       | 16 MiB                              | 16 MiB                                                    |                                                                                                               |
| Function return value size                                                   | 16 MiB                              | 16 MiB                                                    |                                                                                                               |
| HTTP action response size                                                    | 20 MiB                              | 20 MiB                                                    | There is no specific limit on request size                                                                    |
| Length of a console.log line                                                 | 4 KiB                               | 4 KiB                                                     |                                                                                                               |
| [Log streaming](/production/integrations/log-streams/log-streams.mdx) limits | 4096 logs, flushed every 10 seconds | 4096 logs, flushed every 10 seconds                       | How many logs can be buffered when streaming                                                                  |

## Concurrent Function Executions

Number of functions you can run at a time for each function type.

|                | Starter | Professional |
| -------------- | ------- | ------------ |
| Queries        | 16      | 256          |
| Mutations      | 16      | 256          |
| V8 actions     | 64      | 256          |
| Node actions   | 64      | 1000         |
| HTTP actions   | 16      | 128          |
| Scheduled jobs | 10      | 100          |

## Execution time and scheduling

|                                              |                 | Notes                                                                                                                   |
| -------------------------------------------- | --------------- | ----------------------------------------------------------------------------------------------------------------------- |
| Query/mutation execution time                | 1 second        | Limit applies only to user code and doesn’t include database operations.                                                |
| Action execution time                        | 10&nbsp;minutes |                                                                                                                         |
| Scheduled functions                          | 1000            | The number of other functions a single mutation can schedule.                                                           |
| Total size of scheduled functions' arguments | 16 MiB          | Applies only to mutations.                                                                                              |
| Concurrent IO operations per function        | 1000            | The number of IO operations a single function can perform, e.g., a database operation, or a fetch request in an action. |
| Outstanding scheduled functions              | 1,000,000       |                                                                                                                         |

## Transactions

These limits apply to each `query` or `mutation` function.

|                            |        | Notes                                                     |
| -------------------------- | ------ | --------------------------------------------------------- |
| Data read                  | 16 MiB | Data not returned due to a `filter` counts as scanned     |
| Data written               | 16 MiB |
| Documents scanned          | 32,000 | Documents not returned due to a `filter` count as scanned |
| Documents written          | 16,000 |
| Function return value size | 16 MiB |

## Environment Variables

Applied per-deployment.

|                     |               |
| ------------------- | ------------- |
| Number of variables | 100           |
| Maximum name length | 40 characters |
| Maximum value size  | 8 KiB         |

## File Storage

|           | Starter     | Professional                                        | Notes                                                                                                     |
| --------- | ----------- | --------------------------------------------------- | --------------------------------------------------------------------------------------------------------- |
| Storage   | 1 GiB       | 100 GiB included<br/>$0.03/month per additional GiB | Includes user files and backups.                                                                          |
| Bandwidth | 1 GiB/month | 50 GiB/month included<br/>$0.30 per additional GiB  | Includes serving user files, accessing user files inside functions, and generating and restoring backups. |

## Full text search

|                          | Value |
| ------------------------ | ----- |
| Search indexes per table | 4     |
| Filters per search index | 16    |
| Terms per search query   | 16    |
| Filters per search query | 8     |
| Maximum term length      | 32 B  |
| Maximum result set       | 1024  |

## Vector search

|                          | Value                    |
| ------------------------ | ------------------------ |
| Vector indexes per table | 4                        |
| Filters per vector index | 16                       |
| Terms per search query   | 16                       |
| Vectors to search by     | 1                        |
| Dimension fields         | 1 (value between 2-4096) |
| Filters per search query | 64                       |
| Maximum term length      | 32 B                     |
| Maximum result set       | 256 (defaults to 10)     |

If any of these limits don't work for you,
[let us know](https://convex.dev/community)!

Please see our [plans and pricing page](https://www.convex.dev/pricing) for
resource limits. After these limits are hit on a free plan, new mutations that
attempt to commit more insertions or updates may fail. Paid plans have no hard
resource limits - they can scale to billions of documents and TBs of storage.


---

# state.mdx

<!-- Source: production/state/state.mdx -->

---
title: "Status and Guarantees"
id: "state"
sidebar_position: 1
---

Please [contact us](mailto:support@convex.dev) with any specific requirements or
if you want to build a project on Convex that is not yet satisfied by our
guarantees.

## Guarantees

The official Convex Terms of Service, Privacy Policy and Customer Agreements are
[outlined in our official terms](https://www.convex.dev/legal/tos). We do not
yet have contractual agreements beyond what is listed in our official terms and
the discussions within this document don't constitute an amendment to these
terms.

Convex is always under continual development and future releases may require
code changes in order to upgrade to a new version. Code developed on Convex 1.0
or later will continue to operate as-is. If we are required to make a breaking
change in future we will contact teams directly to provide substantial advance
notice.

All user data in Convex is encrypted at rest. Database state is replicated
durably across multiple physical availability zones. Regular periodic and
incremental database backups are performed and stored with 99.999999999% (11
9's) durability.

We target an availability of 99.99% (4 9's) for Convex deployments although
these may experience downtime for maintenance without notice. A physical outage
may affect availability of a deployment but will not affect durability of the
data stored in Convex.

## Limits

For information on limits, see [here](/production/state/limits.mdx).

## Beta Features

Features tagged with **beta** in these docs are still in development. They can
be used in production but their APIs might change in the future, requiring
additional effort when upgrading to a new version of the Convex NPM package and
other Convex client libraries.

## Future Features

Convex is still under very active development and here we list some of the
missing functionality on our radar. We'd love to hear more about your
requirements in the [Convex Discord Community](https://convex.dev/community).

### Authorization

Convex currently has an [_authentication framework_](/auth.mdx) which verifies
user identities. In the future we plan to add an _authorization framework_ which
will allow developers to define what data a user can access.

For now, you can implement manual authorization checks within your queries and
mutations, but stay tuned for a more comprehensive, fool-proof solution in the
future.

### Telemetry

Currently, the dashboard provides only basic metrics. Serious sites at scale are
going to need to integrate our logs and metrics into more fully fledged
observability systems that categorize them and empower things like alerting.

Convex will eventually have methods to publish deployment data in formats that
can be ingested by third parties.

### Analytics / OLAP

Convex is designed to primarily service all your app's realtime implementation
(OLTP) needs. It is less suited to be a good solution for the kinds of complex
queries and huge table scans that are necessary to address the requirements of
analytics (OLAP) use cases.

Convex exposes
[Fivetran and Airbyte connectors](/production/integrations/streaming-import-export.md)
to export Convex data to external analytics systems.

### Browser support

Convex does not yet have an official browser support policy, but we strive to
support most modern browsers with significant
[usage](https://caniuse.com/usage-table).


---

# production.mdx

<!-- Source: production.mdx -->

---
title: "Deploying Your App to Production"
hide_table_of_contents: true
pagination_prev: search
---

Convex is built to serve live, production app traffic. Here we cover how to
deploy and maintain a production version of your app.

## Project management

When you sign up for Convex, a Convex team is created for you. You can
[create more teams from the dashboard](/dashboard/teams.md) and add other people
to them as members. You can upgrade your team to the
[Pro plan](https://www.convex.dev/pricing) for additional features, higher
limits and usage-based pricing.

Each team can have multiple projects. When you run `npx convex dev` for the
first time, a project is created for you automatically. You can also create a
project from the dashboard.

Every project has one shared production deployment and one development
deployment per team member. This allows each team member to make and test
changes independently before they are deployed to the production deployment.

Usually all deployments belonging to a single project run the same code base (or
a version of it), but Convex doesn't enforce this. You can also run the same
code base on multiple different prod deployments belonging to different
projects, see [staging](#staging-environment) below.

## Deploying to production

Your Convex deployments run your backend logic and in most cases you will also
develop a client that uses the backend. If your client is a web app, follow the
[Hosting and Deployment](/production/hosting/hosting.mdx) guide, to learn how to
deploy your client and your Convex backend together.

You can also deploy your backend on its own. Check out the
[Project Configuration](/production/project-configuration.mdx) page to learn
more.

## Staging environment

With Convex [preview deployments](/production/hosting/preview-deployments.mdx)
your team can test out changes before deploying them to production. If you need
a more permanent staging environment, you can use a separate Convex project, and
deploy to it by setting the `CONVEX_DEPLOY_KEY` environment variable when
running [`npx convex deploy`](/cli.md#deploy-convex-functions-to-production).

## Typical team development workflow

Teams developing on Convex usually follow this workflow:

1. If this is the team's first project, one team member creates a team on the
   dashboard.
2. One team member creates a project by running `npx convex dev`, perhaps
   starting with a [quickstart](/quickstarts.mdx) or a
   [template](https://www.convex.dev/templates).
3. The team member creates a Git repository from the initial code and shares it
   with their team (via GitHub, GitLab etc.).
4. Other team members pull the codebase, and get their own dev deployments by
   running `npx convex dev`.
5. All team members can make backend changes and test them out with their
   individual dev deployments. When a change is ready the team member opens a
   pull-request (or commits to a shared branch).
   - [Backup / Restore](/database/backup-restore) can be used to populate a dev
     deployment with data from a prod deployment.
   - [Data import](/database/import-export/import.mdx) can be used to populate a
     dev deployment with synthetic seed data.
   - Members of a team with the [Pro plan](https://www.convex.dev/pricing) can
     get separate
     [preview deployments](/production/hosting/preview-deployments.mdx) to test
     each other's pull-requests.
6. Deployment to production can happen
   [automatically](/production/hosting/hosting.mdx) when changes get merged to
   the designated branch (say `main`).
   - Alternatively one of the team members can deploy to production manually by
     running `npx convex deploy`.

### Making safe changes

Especially if your app is live you want to make sure that changes you make to
your Convex codebase do not break it.

Some unsafe changes are handled and caught by Convex, but others you need handle
yourself.

1. **Schema must always match existing data.** Convex enforces this constraint.
   You cannot push a schema to a deployment with existing data that doesn't
   match it, unless you turn off schema enforcement. In general it safe to:
   1. Add new tables to the schema.
   2. Add an `optional` field to an existing table's schema, set the field on
      all documents in the table, and then make the field required.
   3. Mark an existing field as `optional`, remove the field from all documents,
      and then remove the field.
   4. Mark an existing field as a `union` of the existing type and a new type,
      modify the field on all documents to match the new type, and then change
      the type to the new type.
2. **Functions should be backwards compatible.** Even if your only client is a
   website, and you deploy it together with your backend, your users might still
   be running the old version of your website when your backend changes.
   Therefore you should make your functions backwards compatible until you are
   OK to break old clients. In general it is safe to:
   1. Add new functions.
   2. Add an `optional` named argument to an existing function.
   3. Mark an existing named argument as `optional`.
   4. Mark an existing named argument as a `union` of the existing type and a
      new type.
   5. Change the behavior of the function in such a way that given the arguments
      from an old client its behavior will still be acceptable to the old
      client.
3. **Scheduled functions should be backwards compatible.** When you schedule a
   function to run in the future, you provide the argument values it will
   receive. Whenever a function runs, it always runs its currently deployed
   version. If you change the function between the time it was scheduled and the
   time it runs, you must ensure the new version will behave acceptably given
   the old arguments.

<StackPosts query="deploy" />


---

# android.mdx

<!-- Source: quickstart/android.mdx -->

---
title: Android Kotlin Quickstart
sidebar_label: Android Kotlin
description: "Add Convex to an Android Kotlin project"
hide_table_of_contents: true
sidebar_position: 600
---

Learn how to query data from Convex in a Android Kotlin project.

This quickstart assumes that you have Android Studio, node and npm installed. If
you don’t have those tools, take time to install them first.

<StepByStep>
  <Step title="Create a new Android app in Android Studio">
    Choose the following options in the wizard.

    ```
    1. Choose the "Empty Activity" template
    2. Name it "Convex Quickstart"
    3. Choose min SDK as 26
    4. Choose Kotlin as the Gradle DSL
    ```

  </Step>

  <Step title="Configure the AndroidManifest">
    Add the following to your `AndroidManifest.xml`.

    ```xml
    <?xml version="1.0" encoding="utf-8"?>
    <manifest xmlns:android="http://schemas.android.com/apk/res/android"
        xmlns:tools="http://schemas.android.com/tools">
        // highlight-next-line
        <uses-permission android:name="android.permission.INTERNET"/>
        <application>
            <!-- ... existing application contents -->
        </application>
    </manifest>
    ```

  </Step>

  <Step title="Configure your dependencies">
    Add the following entries to the `:app` `build.gradle.kts` file (ignore IDE
    suggestion to move them to version catalog for now, if present).
    
    Ensure that you sync Gradle when all of the above is complete (Android
    Studio should prompt you to do so).

    ```kotlin
    plugins {
        // ... existing plugins
        // highlight-next-line
        kotlin("plugin.serialization") version "1.9.0"
    }

    dependencies {
        // ... existing dependencies
        // highlight-next-line
        implementation("dev.convex:android-convexmobile:0.4.1@aar") {
            // highlight-next-line
            isTransitive = true
        // highlight-next-line
        }
        // highlight-next-line
        implementation("org.jetbrains.kotlinx:kotlinx-serialization-json:1.6.3")
    }
    ```

  </Step>

  <Step title="Install the Convex Backend">
    Open a terminal in your Android Studio instance and install the Convex 
    client and server library.

    ```bash
    npm init -y
    npm install convex
    ```

  </Step>

  <Step title="Start Convex">
    Start a Convex dev deployment. Follow the command line instructions.

    ```bash
    npx convex dev
    ```

  </Step>

  <Step title="Create a sample data for your database">
    Create a new `sampleData.jsonl` file with these contents.

    ```json
    {"text": "Buy groceries", "isCompleted": true}
    {"text": "Go for a swim", "isCompleted": true}
    {"text": "Integrate Convex", "isCompleted": false}
    ```

  </Step>

  <Step title="Add the sample data to your database">
    Open another terminal tab and run.

    ```bash
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Create a `tasks.ts` file in your `convex/` directory with the following 
    contents.

    ```tsx
    import { query } from "./_generated/server";

    export const get = query({
      args: {},
      handler: async (ctx) => {
        return await ctx.db.query("tasks").collect();
      },
    });
    ```

  </Step>

  <Step title="Create a data class">
    Add a new `data class` to your `MainActivity` to support the task data 
    defined above. Import whatever it asks you to.

    ```kotlin
    @Serializable
    data class Task(val text: String, val isCompleted: Boolean)
    ```

  </Step>

  <Step title="Create your UI">
    Delete the template `@Composable` functions that Android Studio created and
    add a new one to display data from your Convex deployment. Again, import
    whatever it asks you to.

    ```kotlin
    @Composable
    fun Tasks(client: ConvexClient, modifier: Modifier = Modifier) {
        var tasks: List<Task> by remember { mutableStateOf(listOf()) }
        LaunchedEffect(key1 = "launch") {
            client.subscribe<List<Task>>("tasks:get").collect { result ->
                result.onSuccess { remoteTasks ->
                    tasks = remoteTasks
                }
            }
        }
        LazyColumn(
            modifier = modifier
        ) {
            items(tasks) { task ->
                Text(text = "Text: ${task.text}, Completed?: ${task.isCompleted}")
            }
        }
    }
    ```

  </Step>

  <Step title="Connect the app to your backend">
    1. Get the deployment URL of your dev server with
        `cat .env.local | grep CONVEX_URL`
    2. Update the `onCreate` method in your `MainActivity.kt` to look like

    ```kotlin
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        enableEdgeToEdge()
        setContent {
            ConvexQuickstartTheme {
                Scaffold(modifier = Modifier.fillMaxSize()) { innerPadding ->
                    // highlight-next-line
                    Tasks(
                        // highlight-next-line
                        client = ConvexClient($YOUR_CONVEX_URL),
                        // highlight-next-line
                        modifier = Modifier.padding(innerPadding)
                    // highlight-next-line
                    )
                }
            }
        }
    }
    ```

  </Step>

  <Step title="Fix any missing imports">
    Fix up any missing imports (your import declarations should look something
    like this):

    ```kotlin
    import android.os.Bundle
    import androidx.activity.ComponentActivity
    import androidx.activity.compose.setContent
    import androidx.activity.enableEdgeToEdge
    import androidx.compose.foundation.layout.fillMaxSize
    import androidx.compose.foundation.layout.padding
    import androidx.compose.foundation.lazy.LazyColumn
    import androidx.compose.foundation.lazy.items
    import androidx.compose.material3.Scaffold
    import androidx.compose.material3.Text
    import androidx.compose.runtime.Composable
    import androidx.compose.runtime.LaunchedEffect
    import androidx.compose.runtime.getValue
    import androidx.compose.runtime.mutableStateOf
    import androidx.compose.runtime.remember
    import androidx.compose.runtime.setValue
    import androidx.compose.ui.Modifier
    import dev.convex.android.ConvexClient
    import kotlinx.serialization.Serializable
    ```

  </Step>
  <Step title="Run the app">
    You can also try adding, updating or deleting documents in your `tasks`
    table at `dashboard.convex.dev` - the app will update with the changes in
    real-time.

    ```
    From the IDE menu choose "Run" > "Run 'app'"
    ```

  </Step>

</StepByStep>

See the complete [Android Kotlin documentation](/client/android.md).


---

# bun.mdx

<!-- Source: quickstart/bun.mdx -->

---
title: Bun Quickstart
sidebar_label: Bun
description: "Add Convex to a Bun project"
hide_table_of_contents: true
sidebar_position: 450
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/bun/sampleData.jsonl";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/bun/convex/tasks.js";
import script from "!!raw-loader!@site/../private-demos/quickstarts/bun/index.ts";

Learn how to query data from Convex in a Bun project.

For instructions for subscriptions instead of point-in-time queries see
[Bun notes](/client/javascript/bun.mdx).

# Using Convex with Bun

<StepByStep>
  <Step title="Create a new Bun project">
    Create a new directory for your Bun project.

    ```sh
    mkdir my-project && cd my-project && bun init -y
    ```

  </Step>
  <Step title="Install the Convex client and server library">
    Install the `convex` package.

    ```sh
    bun add convex
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `bunx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    bunx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    bunx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.js` in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasks}
      title="convex/tasks.js"
    />

  </Step>

  <Step title="Connect the script to your backend">
    In a new file `index.ts`, create a `ConvexClient` using
    the URL of your development environment.

    <Snippet
      source={script}
      title="index.ts"
    />

  </Step>

  <Step title="Run the script">
    Run the script from the same directory and see the list of tasks logged to the terminal.

    ```sh
    bun index.ts
    ```

  </Step>

</StepByStep>

See the complete [Bun documentation](/client/javascript/bun.mdx).


---

# nextjs.mdx

<!-- Source: quickstart/nextjs.mdx -->

---
title: Next.js Quickstart
sidebar_label: Next.js
description: "Add Convex to a Next.js project"
hide_table_of_contents: true
sidebar_position: 200
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/nextjs/sampleData.jsonl";
import layout from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir/app/layout.tsx";
import ConvexClientProvider from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir/app/ConvexClientProvider.tsx";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir/convex/tasks.ts";
import page from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir/app/page.tsx";
import layoutJs from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir-js/app/layout.js";
import ConvexClientProviderJs from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir-js/app/ConvexClientProvider.jsx";
import tasksJs from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir-js/convex/tasks.js";
import pageJs from "!!raw-loader!@site/../private-demos/quickstarts/nextjs-app-dir-js/app/page.js";

<Admonition type="tip" title="Convex + Next.js">

Convex is an all-in-one backend and database that integrates quickly and easily
with Next.js.

Once you've gotten started, see how to set up
[hosting](/production/hosting/hosting.mdx),
[server rendering](/client/react/nextjs/nextjs-server-rendering.mdx), and
[auth](https://docs.convex.dev/client/react/nextjs/).

</Admonition>

To get setup quickly with Convex and Next.js run

<p>
  <b>
    <CodeWithCopyButton text="npm create convex@latest" />
  </b>
</p>

or follow the guide below.

---

Learn how to query data from Convex in a Next.js app using the App Router
and<LanguageSelector verbose />

Alternatively see the
[Pages Router](/client/react/nextjs-pages-router/quickstart-nextjs-pages-router.mdx)
version of this quickstart.

<StepByStep>
  <Step title="Create a Next.js app">
    Create a Next.js app using the `npx create-next-app` command.

    Choose the default option for every prompt (hit Enter).

    <JSDialectVariants>
      ```sh
      npx create-next-app@latest my-app
      ```

      ```sh
      npx create-next-app@latest my-app --js
      ```
    </JSDialectVariants>

  </Step>
  <Step title="Install the Convex client and server library">
    To get started, install the `convex` package.

    Navigate to your app and install `convex`.


    ```sh
    cd my-app && npm install convex
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Use the [`import`](/database/import-export/import) command to add a `tasks` table with the sample data into your Convex database.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    In the `convex/` folder, add a new file <JSDialectFileName name="tasks.ts" /> with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name: `api.tasks.get`.

    <TSAndJSSnippet
      sourceTS={tasks}
      sourceJS={tasksJs}
      title="convex/tasks.ts"
    />

  </Step>

  <Step title="Create a client component for the Convex provider">
    For `<ConvexProvider>` to work on the client, `ConvexReactClient` must be passed to it.

    In the `app/` folder, add a new file <JSDialectFileName name="ConvexClientProvider.tsx" /> with the following code. This creates a client component that wraps `<ConvexProvider>` and passes it the `<ConvexReactClient>`.

    <TSAndJSSnippet
      sourceTS={ConvexClientProvider}
      sourceJS={ConvexClientProviderJs}
      title="app/ConvexClientProvider.tsx"
    />

  </Step>

  <Step title="Wire up the ConvexClientProvider">
    In <JSDialectFileName name="app/layout.tsx" ext="js" />, wrap the children of the `body` element with the `<ConvexClientProvider>`.

    <TSAndJSSnippet
      sourceTS={layout}
      sourceJS={layoutJs}
      title="app/layout.tsx"
      jsExtension="js"
      highlightPatterns={[ "Convex", ]}
    />

  </Step>

  <Step title="Display the data in your app">
    In <JSDialectFileName name="app/page.tsx" ext="js" />, use the `useQuery()` hook to fetch from your `api.tasks.get`
    API function.

    <TSAndJSSnippet
      sourceTS={page}
      sourceJS={pageJs}
      title="app/page.tsx"
      jsExtension="js"
      highlightPatterns={[ "use client", "useQuery", "api", "tasks", "text", "\\)\\)\\}" ]}
    />

  </Step>

  <Step title="Start the app">
    Run your Next.js development server, open [http://localhost:3000](http://localhost:3000) in a browser,
    and see the list of tasks.

    ```sh
    npm run dev
    ```

  </Step>

</StepByStep>

See the complete [Next.js documentation](/client/react/nextjs/nextjs.mdx).


---

# nodejs.mdx

<!-- Source: quickstart/nodejs.mdx -->

---
title: Node.js Quickstart
sidebar_label: Node.js
description: "Add Convex to a Node.js project"
hide_table_of_contents: true
sidebar_position: 400
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/nodejs/sampleData.jsonl";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/nodejs/convex/tasks.js";
import script from "!!raw-loader!@site/../private-demos/quickstarts/nodejs/script.js";

Learn how to query data from Convex in a Node.js project.

For instructions for subscriptions instead of point-in-time queries and more
project configurations (TypeScript, bundlers, CJS vs ESM) see
[Node.js notes](/client/javascript/node.mdx).

<StepByStep>
  <Step title="Create a new npm project">
    Create a new directory for your Node.js project.

    ```sh
    mkdir my-project && cd my-project && npm init -y && npm pkg set type="module"
    ```

  </Step>
  <Step title="Install the Convex client and server library">
    Install the `convex`
    package which provides a convenient interface for working
    with Convex from JavaScript.

    Also install the `dotenv` library for loading `.env` files.

    ```sh
    npm install convex dotenv
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.js` in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasks}
      title="convex/tasks.js"
    />

  </Step>

  <Step title="Connect the script to your backend">
    In a new file `script.js`, create a `ConvexHttpClient` using
    the URL of your development environment.

    <Snippet
      source={script}
      title="script.js"
    />

  </Step>

  <Step title="Run the script">
    Run the script from the same directory and see the list of tasks logged to the terminal.

    ```sh
    node script.js
    ```

  </Step>

</StepByStep>

See the complete [Node.js documentation](/client/javascript/node.mdx).


---

# python.mdx

<!-- Source: quickstart/python.mdx -->

---
title: Python Quickstart
sidebar_label: Python
description: "Add Convex to a Python project"
hide_table_of_contents: true
sidebar_position: 500
---

import sampleData from "!!raw-loader!@site/../demos/python-quickstart/sampleData.jsonl";
import tasks from "!!raw-loader!@site/../demos/python-quickstart/convex/tasks.js";
import main from "!!raw-loader!@site/../demos/python-quickstart/main.py";

Learn how to query data from Convex in a Python app.

<StepByStep>
  <Step title="Create a Python script folder">
    Create a folder for your Python script
    with a virtual environment.

    ```sh
    python3 -m venv my-app/venv
    ```

  </Step>
  <Step title="Install the Convex client and server libraries">
    To get started, install the `convex` npm
    package which enables you to write your
    backend.

    And also install the `convex` Python client
    library and `python-dotenv` for working with `.env` files.

    ```sh
    cd my-app && npm init -y && npm install convex && venv/bin/pip install convex python-dotenv
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.js` in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `"tasks:get"`.

    <Snippet
      source={tasks}
      title="convex/tasks.js"
    />

  </Step>

  <Step title="Create a script to load data from Convex">
    In a new file `main.py`, create a `ConvexClient` and use it
    to fetch from your `"tasks:get"` API.
    
    <Snippet
      source={main}
      title="main.py"
    />

  </Step>

  <Step title="Run the script">
      Run the script 
      and see the serialized list of tasks.

      ```sh
      venv/bin/python -m main
      ```

  </Step>

</StepByStep>

See the [docs on PyPI](https://pypi.org/project/convex/) for more details.


---

# react-native.mdx

<!-- Source: quickstart/react-native.mdx -->

---
title: React Native Quickstart
sidebar_label: React Native
description: "Add Convex to a React Native Expo project"
hide_table_of_contents: true
sidebar_position: 300
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/expo/sampleData.jsonl";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/expo/convex/tasks.ts";
import layout from "!!raw-loader!@site/../private-demos/quickstarts/expo/app/_layout.tsx";
import index from "!!raw-loader!@site/../private-demos/quickstarts/expo/app/index.tsx";

Learn how to query data from Convex in a React Native app.

<StepByStep>
  <Step title="Create a React Native app">
    Create a React Native app using the `npx create-expo-app` command.

    ```sh
    npx create-expo-app my-app
    ```

  </Step>
  <Step title="Install the Convex client and server library">
    To get started, install the `convex`
    package which provides a convenient interface for working
    with Convex from a React app.

    Navigate to your app and install `convex`.

    ```sh
    cd my-app && npm install convex
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.

    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    Create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table with the sample data into
    your Convex database with the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.ts` in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasks}
      title="convex/tasks.ts"
    />

  </Step>

  <Step title="Reset the Expo project">
    If you haven't done so yet, reset the Expo project to get a fresh
    `app` directory.

    ```
    npm run reset-project
    ```

  </Step>

  <Step title="Connect the app to your backend">
    In `_layout.tsx`, create a `ConvexReactClient` and pass it to a `ConvexProvider`
    wrapping your component tree.

    <Snippet
      source={layout}
      title="app/_layout.tsx"
      highlightPatterns={[ "Convex", "get-random", "CONVEX", "unsaved", "}\\);", ]}
    />

  </Step>

  <Step title="Display the data in your app">
    In `index.tsx` use the `useQuery` hook to fetch
    from your `api.tasks.get` API.

    <Snippet
      source={index}
      title="app/index.tsx"
      highlightPatterns={[ "api", "useQuery", "tasks" ]}
    />

  </Step>

  <Step title="Start the app">
    Start the app, scan the provided QR code with your phone,
    and see the serialized list of tasks in the center of the screen.

    ```sh
    npm start
    ```

  </Step>
</StepByStep>

React native uses the same library as React web. See the complete
[React documentation](/client/react.mdx).


---

# react.mdx

<!-- Source: quickstart/react.mdx -->

---
title: React Quickstart
sidebar_label: React
description: "Add Convex to a React project"
hide_table_of_contents: true
sidebar_position: 100
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/react-vite/sampleData.jsonl";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/react-vite/convex/tasks.js";
import main from "!!raw-loader!@site/../private-demos/quickstarts/react-vite/src/main.jsx";
import App from "!!raw-loader!@site/../private-demos/quickstarts/react-vite/src/App.jsx";
import tasksTS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite-ts/convex/tasks.ts";
import mainTS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite-ts/src/main.tsx";
import AppTS from "!!raw-loader!@site/../private-demos/quickstarts/react-vite-ts/src/App.tsx";

To get setup quickly with Convex and React run

<p>
  <b>
    <CodeWithCopyButton text="npm create convex@latest" />
  </b>
</p>

or follow the guide below.

---

Learn how to query data from Convex in a React app using Vite
and<LanguageSelector verbose />

<StepByStep>
  <Step title="Create a React app">
    Create a React app using the `create vite` command.

    <JSDialectVariants>
      ```sh
      npm create vite@latest my-app -- --template react-ts
      ```

      ```sh
      npm create vite@latest my-app -- --template react
      ```
    </JSDialectVariants>

  </Step>
  <Step title="Install the Convex client and server library">
    To get started, install the `convex`
    package which provides a convenient interface for working
    with Convex from a React app.

    Navigate to your app directory and install `convex`.


    ```sh
    cd my-app && npm install convex
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="(optional) Define a schema">
    Add a new file `schema.ts` in the `convex/` folder
    with a description of your data.

    This will declare the types of your data for optional
    typechecking with TypeScript, and it will be also
    enforced at runtime.

    <JSDialectVariants>
    Alternatively remove the line `'plugin:@typescript-eslint/recommended-requiring-type-checking',`
    from the `.eslintrc.cjs` file to lower the type checking strictness.

    <></>
    </JSDialectVariants>

    ```ts noDialect title="convex/schema.ts"
    import { defineSchema, defineTable } from "convex/server";
    import { v } from "convex/values";

    export default defineSchema({
      tasks: defineTable({
        text: v.string(),
        isCompleted: v.boolean(),
      }),
    });
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file <JSDialectFileName name="tasks.ts" /> in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <TSAndJSSnippet
      sourceTS={tasksTS}
      sourceJS={tasks}
      title="convex/tasks.ts"
    />

  </Step>

  <Step title="Connect the app to your backend">
    In <JSDialectFileName name="src/main.jsx" />, create a `ConvexReactClient` and pass it to a `ConvexProvider`
    wrapping your app.

    <TSAndJSSnippet
      sourceTS={mainTS}
      sourceJS={main}
      title="src/main.tsx"
      highlightPatterns={[ "Convex", ]}
    />

  </Step>

  <Step title="Display the data in your app">
    In <JSDialectFileName name="src/App.jsx" />, use the `useQuery` hook to fetch from your `api.tasks.get`
    API function and display the data.

    <TSAndJSSnippet
      sourceTS={AppTS}
      sourceJS={App}
      title="src/App.tsx"
      highlightPatterns={[ "useQuery", "api", "tasks", "text", "\\)\\)\\}" ]}
    />

  </Step>

  <Step title="Start the app">
    Start the app, open [http://localhost:5173/](http://localhost:5173/) in a browser,
    and see the list of tasks.

    ```sh
    npm run dev
    ```

  </Step>

</StepByStep>

See the complete [React documentation](/client/react.mdx).


---

# remix.mdx

<!-- Source: quickstart/remix.mdx -->

---
title: Remix Quickstart
sidebar_label: Remix
description: "Add Convex to a Remix project"
hide_table_of_contents: true
sidebar_position: 200
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/remix/sampleData.jsonl";
import root from "!!raw-loader!@site/../private-demos/quickstarts/remix/app/root.tsx";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/remix/convex/tasks.ts";
import index from "!!raw-loader!@site/../private-demos/quickstarts/remix/app/routes/_index.tsx";

Learn how to query data from Convex in a Remix app.

<StepByStep>
  <Step title="Create a Remix site">
    Create a Remix site using the `npx create-remix@latest` command.

    <br></br>

    ```sh
    npx create-remix@latest my-remix-app
    ```

  </Step>

  <Step title="Install the Convex library">
    To get started, install the `convex` package.

    ```sh
    cd my-remix-app && npm install convex
    ```

  </Step>

  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file <JSDialectFileName name="tasks.ts" /> in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasks}
      title="convex/tasks.ts"
    />

  </Step>

  <Step title="Wire up the ConvexProvider">
    Modify `app/root.tsx` to set up the Convex client there to make it available on every page of your app.

    <Snippet
      source={root}
      title="app/root.tsx"
    />

  </Step>

  <Step title="Display the data in your app">
    In `app/routes/_index.tsx` use `useQuery` to subscribe your `api.tasks.get`
    API function.

    <Snippet
      source={index}
      title="app/routes/_index.tsx"
    />

  </Step>

  <Step title="Start the app">
    Start the app, open [http://localhost:5173](http://localhost:5173) in a browser,
    and see the list of tasks.

    ```sh
    npm run dev
    ```

  </Step>

</StepByStep>

Remix uses the React web library. See the complete
[React documentation](/client/react.mdx).


---

# rust.mdx

<!-- Source: quickstart/rust.mdx -->

---
title: Rust Quickstart
sidebar_label: Rust
description: "Add Convex to a Rust project"
hide_table_of_contents: true
sidebar_position: 700
---

import sampleData from "!!raw-loader!@site/../../crates/convex/examples/quickstart/sampleData.jsonl";
import tasks from "!!raw-loader!@site/../../crates/convex/examples/quickstart/convex/tasks.js";
import main from "!!raw-loader!@site/../../crates/convex/examples/quickstart/main.rs";

Learn how to query data from Convex in a Rust app with Tokio.

<StepByStep>
  <Step title="Create a Cargo project">
    Create a new Cargo project.

    ```sh
    cargo new my_app
    cd my_app
    ```

  </Step>
  <Step title="Install the Convex client and server libraries">
    To get started, install the `convex` npm
    package which enables you to write your
    backend.

    And also install the `convex` Rust client library,
    the `tokio` runtime, and `dotenvy` for working with `.env` files.

    ```sh
    npm init -y && npm install convex && cargo add convex tokio dotenvy
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.js` in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `"tasks:get"`.

    <Snippet
      source={tasks}
      title="convex/tasks.js"
    />

  </Step>

  <Step title="Connect the app to your backend">
    In the file `src/main.rs`, create a `ConvexClient` and use it
    to fetch from your `"tasks:get"` API.
    
    <Snippet
      source={main}
      title="src/main.rs"
    />

  </Step>

  <Step title="Run the app">
      Run the app and see the serialized list of tasks.

      ```sh
      cargo run
      ```

  </Step>

</StepByStep>

See the complete [Rust documentation](https://docs.rs/convex/latest/convex/).


---

# script-tag.mdx

<!-- Source: quickstart/script-tag.mdx -->

---
title: Script Tag Quickstart
sidebar_label: Script Tag
description: "Add Convex to any website"
hide_table_of_contents: true
sidebar_position: 450
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/nodejs/sampleData.jsonl";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/nodejs/convex/tasks.js";
import html from "!!raw-loader!@site/../demos/html/simple.html";

Learn how to query data from Convex from script tags in HTML.

<StepByStep>
  <Step title="Create a new npm project">
    Create a new directory for your Convex project.

    ```sh
    mkdir my-project && cd my-project && npm init -y
    ```

  </Step>
  <Step title="Install the Convex client and server library">
    Install the `convex`
    package which provides a convenient interface for working
    with Convex from JavaScript.

    ```sh
    npm install convex
    ```

  </Step>
  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.js` in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasks}
      title="convex/tasks.js"
    />

  </Step>

  <Step title="Copy the deployment URL">
    Open the `.env.local` file and copy the `CONVEX_URL` of your development
    environment for use in the HTML file.

    <></>

  </Step>

  <Step title="Add the script to your webpage">
    In a new file `index.html`, create a `ConvexClient` using
    the URL of your development environment.

    Open this file in a web browser and you'll see it run each time the `tasks`
    table is modified.

    <Snippet
      source={html}
      title="index.html"
      replacements={[
        [/https?:\/\/localhost:8000/g, 'CONVEX_URL_GOES_HERE'],
        [/messages:list/g, 'tasks:get'],
        [/\(messages\)/g, '(tasks)'],
        [/messages.map\(\(msg\) \=\> msg\.body\)/g, 'tasks.map((task) => task.text)'],
      ]}
    />

  </Step>

</StepByStep>

See the complete [Script Tag documentation](/client/javascript/script-tag.mdx).


---

# svelte.mdx

<!-- Source: quickstart/svelte.mdx -->

---
title: Svelte Quickstart
sidebar_label: Svelte
description: "Add Convex to a Svelte project"
hide_table_of_contents: true
sidebar_position: 350
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/sveltekit/sampleData.jsonl";
import layout from "!!raw-loader!@site/../private-demos/quickstarts/sveltekit/src/routes/+layout.svelte";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/sveltekit/src/convex/tasks.ts";
import page from "!!raw-loader!@site/../private-demos/quickstarts/sveltekit/src/routes/+page.svelte";

Learn how to query data from Convex in a Svelte app.

<StepByStep>
  <Step title="Create a SvelteKit app">
    Create a SvelteKit app using the `npx create svelte@latest` command.

    Other sets of options will work with the library as long as Svelte 5 is used but for this quickstart guide:

    - For "Which Svelte app template," choose **"Skeleton project."**
    - For "Add type checking with TypeScript," choose **"Yes, using TypeScript syntax."**
    - For "Select additional options," enable **"Try the Svelte 5 preview."**

    <br></br>

    ```sh
    npm create svelte@latest my-app
    ```

  </Step>

  <Step title="Install the Convex client and server library">
    To get started, install the `convex` and `convex-svelte` packages.

    ```sh
    cd my-app && npm install convex convex-svelte
    ```

  </Step>

  <Step title="Customize the convex path">
    SvelteKit doesn't like referencing code outside of source, so customize
    the convex functionsDir to be under `src/`.

    <Snippet
      source={'{\n\t\"functions\": "src/convex/\"\n}'}
      title="convex.json"
    />

  </Step>

  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file <JSDialectFileName name="tasks.ts" /> in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasks}
      title="convex/tasks.ts"
    />

  </Step>

  <Step title="Set up Convex">
    Create a new file `src/routes/+layout.svelte` and set up the Convex client there to make it available on every page of your app.

    <Snippet
      source={layout}
      title="src/routes/+layout.svelte"
    />

  </Step>

  <Step title="Display the data in your app">
    In `src/routes/+page.svelte` use `useQuery` to subscribe your `api.tasks.get`
    API function.

    <Snippet
      source={page}
      title="src/routes/page.tsx"
      jsExtension="js"
    />

  </Step>

  <Step title="Start the app">
    Start the app, open [http://localhost:5173](http://localhost:5173) in a browser,
    and see the list of tasks.

    ```sh
    npm run dev
    ```

  </Step>

</StepByStep>

See the
[Svelte npm package documentation](https://www.npmjs.com/package/convex-svelte).


---

# swift.mdx

<!-- Source: quickstart/swift.mdx -->

---
title: iOS Swift Quickstart
sidebar_label: iOS Swift
description: "Add Convex to an iOS Swift project"
hide_table_of_contents: true
sidebar_position: 600
---

Learn how to query data from Convex in an application targeting iOS and MacOS
devices built with Swift and SwiftUI.

This quickstart assumes that you have a Mac with Xcode, node and npm installed.
If you don’t have those tools, take time to install them first.

<StepByStep>
  <Step title="Create a new iOS app in Xcode">
    1. Click *Create New Project*
    2. Select iOS App and click *Next*
    3. Name your project something like “ConvexQuickstart”
    4. Ensure Language is set to Swift and User Interface is SwiftUI
    5. Click *Next*
    
    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/swift_qs_step_1.png" alt="Create new iOS project" width={600} />
    </p>
  </Step>

  <Step title="Configure dependencies">
    1. Click on the top-level ConvexQuickstart app container in the project
      navigator on the left
    2.  Click on ConvexQuickstart under the PROJECT heading
    3.  Click the Package Dependencies tab
    4.  Click the + button (See Screenshot)
    5.  Paste
        ```
        https://github.com/get-convex/convex-swift
        ```
        into the search box and press enter
    6.  When the `convex-swift` package loads, click the *Add Package* button
    7.  In the *Package Products* dialog, select ConvexQuickstart in the 
        *Add to Target* dropdown
    8.  Click the Add Package button

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/swift_qs_step_2.png" alt="Add Convex dependency to package" width={600} />
    </p>

  </Step>
  <br/>
  <Step title="Install the Convex backend">
    Open a terminal and `cd` to the directory for the Xcode project you
    created. Run the following commands to install the Convex client and
    server library.

    ```bash
    npm init -y
    npm install convex
    ```

  </Step>

  <Step title="Start Convex">
    Start a Convex dev deployment. Follow the command line instructions to
    create a new project.

    ```bash
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    Create a new `sampleData.jsonl` file in your Swift project directory with
    these contents

    ```json
    {"text": "Buy groceries", "isCompleted": true}
    {"text": "Go for a swim", "isCompleted": true}
    {"text": "Integrate Convex", "isCompleted": false}
    ```

  </Step>

  <Step title="Add the sample data to a table called `tasks` in your database">
    Open another terminal tab by pressing ⌘+T which should open in your Swift
    project directory and run

    ```bash
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Create a `tasks.ts` file in the `convex/` directory within your Swift
    project with the following contents

    ```tsx
    import { query } from "./_generated/server";

    export const get = query({
      args: {},
      handler: async (ctx) => {
        return await ctx.db.query("tasks").collect();
      },
    });
    ```

  </Step>

  <Step title="Create a Swift struct">
    Back in Xcode, create a `struct` at the bottom of the `ContentView` file to
    match the sample data

    ```swift
    // We're using the name Todo instead of Task to avoid clashing with
    // Swift's builtin Task type.
    struct Todo: Decodable {
      let _id: String
      let text: String
      let isCompleted: Bool
    }
    ```

  </Step>

  <Step title="Connect the app to your backend">
   1. Get the deployment URL of your dev server
      with `cat .env.local | grep CONVEX_URL`
   2. Create a `ConvexClient` instance near the top of the file, just above the
      `ContentView` struct

    ```swift
    import SwiftUI
    import ConvexMobile

    // highlight-next-line
    let convex = ConvexClient(deploymentUrl: "YOUR_CONVEX_URL")

    struct ContentView: View {
    ...
    ```

  </Step>

  <Step title="Create your UI">

    Replace the default `ContentView` with the following code that will
    refresh the list of todo items whenever the backend data changes.

    ```swift
    struct ContentView: View {
      @State private var todos: [Todo] = []

      var body: some View {
        List {
          ForEach(todos, id: \._id) { todo in
            Text(todo.text)
          }
        }.task {
          for await todos: [Todo] in convex.subscribe(to: "tasks:get")
            .replaceError(with: []).values
          {
            self.todos = todos
          }
        }.padding()
      }
    }
    ```

  </Step>

  <Step title="Run the app">
    1. Press ⌘+R or click *Product → Run*
    2. You can also try adding, updating or
    deleting documents in your `tasks` table at `dashboard.convex.dev` - the app
    will update with the changes in real-time.

    <p style={{textAlign: 'center'}}>
      <img src="/screenshots/swift_qs_final.png" alt="App preview" width={400} />
    </p>

  </Step>

</StepByStep>

See the complete [iOS Swift documentation](/client/swift.md).


---

# tanstack-start.mdx

<!-- Source: quickstart/tanstack-start.mdx -->

---
title: TanStack Start Quickstart
sidebar_label: TanStack Start
description: "Add Convex to a TanStack Start project"
hide_table_of_contents: true
sidebar_position: 200
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/tanstack-start/sampleData.jsonl";
import appRoutesRoot from "!!raw-loader!@site/../private-demos/quickstarts/tanstack-start/app/routes/__root.tsx";
import router from "!!raw-loader!@site/../private-demos/quickstarts/tanstack-start/app/router.tsx";
import index from "!!raw-loader!@site/../private-demos/quickstarts/tanstack-start/app/routes/index.tsx";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/tanstack-start/convex/tasks.ts";

<Admonition type="caution" title="TanStack Start is in Beta">

[TanStack Start](https://tanstack.com/start/latest) is a new React framework
currently in beta. You can try it today but there are likely to be breaking
changes before a stable release.

</Admonition>

To get setup quickly with Convex and TanStack Start run

<p>
  <b>
    <CodeWithCopyButton text="npm create convex@latest -- -t tanstack-start" />
  </b>
</p>

or follow the guide below.

To use Clerk with Convex and TanStack Start, see the
[TanStack Start + Clerk guide](/client/react/tanstack-start/clerk.mdx)

---

Learn how to query data from Convex in a TanStack Start site.

<StepByStep>
  <Step title="Create a TanStack Start site">

The TanStack team intends to release a CLI template starter soon, but until the
official way to create a new TanStack Start site is to follow the TanStack Start
[getting started](https://tanstack.com/router/latest/docs/framework/react/start/getting-started)
guide.

Once you've finished you'll have a directory called myApp with a minimal
TanStack Start app in it.

      ```sh
      .
      ├── app/
      │   ├── routes/
      │   │   ├── `index.tsx`
      │   │   └── `__root.tsx`
      │   ├── `client.tsx`
      │   ├── `router.tsx`
      │   ├── `routeTree.gen.ts`
      │   └── `ssr.tsx`
      ├── `.gitignore`
      ├── `app.config.ts`
      ├── `package.json`
      └── `tsconfig.json`
      ```

</Step>
  <Step title="Install the Convex client and server library">
    To get started with Convex install the `convex` package and a few React Query-related packages.

    ```sh
    npm install convex @convex-dev/react-query @tanstack/react-router-with-query @tanstack/react-query
    ```

  </Step>

  <Step title="Update app/routes/__root.tsx">
    Add a `QueryClient` to the router context to make React Query usable anywhere in the TanStack Start site.

    <Snippet
      source={appRoutesRoot}
      title="app/routes/__root.tsx"
      highlightPatterns={[ "createRootRouteWithContext", "QueryClient", "\\}\\>\\(\\)\\(\\{"]}
    />

  </Step>

  <Step title="Update app/router.tsx">
    Replace the file `app/router.tsx` with these contents.

    This creates a `ConvexClient` and a `ConvexQueryClient` and wires in a `ConvexProvider`.

    <Snippet
      source={router}
      title="app/router.tsx"
    />

  </Step>

  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file <JSDialectFileName name="tasks.ts" /> in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasks}
      title="convex/tasks.ts"
    />

  </Step>

  <Step title="Display the data in your app">
    Replace the file `app/routes/index.tsx` with these contents.

    The `useSuspenseQuery` hook renders the API function `api.tasks.get`
    query result on the server initially, then it updates live in the browser.

    <Snippet
      source={index}
      title="app/routes/index.tsx"
      highlightPatterns={[ "useSuspenseQuery" ]}
    />

  </Step>

  <Step title="Start the app">
    Start the app, open [http://localhost:3000](http://localhost:3000) in a browser,
    and see the list of tasks.

    ```sh
    npm run dev
    ```

  </Step>

</StepByStep>

For more see the
[TanStack Start with Convex](/client/react/tanstack-start/tanstack-start.mdx)
client documentation page.


---

# vue.mdx

<!-- Source: quickstart/vue.mdx -->

---
title: Vue Quickstart
sidebar_label: Vue
description: "Add Convex to a Vue project"
hide_table_of_contents: true
sidebar_position: 325
---

import sampleData from "!!raw-loader!@site/../private-demos/quickstarts/vue/sampleData.jsonl";
import main from "!!raw-loader!@site/../private-demos/quickstarts/vue/src/main.ts";
import tasks from "!!raw-loader!@site/../private-demos/quickstarts/vue/convex/tasks.ts";
import App from "!!raw-loader!@site/../private-demos/quickstarts/vue/src/App.vue";

Learn how to query data from Convex in a Vue app.

This quickstart guide uses a [community-maintained](/client/vue.md) Vue client
for Convex.

<StepByStep>
  <Step title="Create a Vue site">
    Create a Vue site using the `npm create vue@latest my-vue-app` command.

    Convex will work with any set of options but to follow this quickstart most closely choose:
    * Yes to "Add TypeScript?"
    * No to everything else

    <br></br>

    ```sh
    npm create vue@latest my-vue-app
    ```

  </Step>

  <Step title="Install the Convex library">
    To get started, install the `convex` package.

    ```sh
    cd my-vue-app && npm install @convex-vue/core @vueuse/core convex
    ```

  </Step>

  <Step title="Set up a Convex dev deployment">
    Next, run `npx convex dev`. This
    will prompt you to log in with GitHub,
    create a project, and save your production and deployment URLs.

    It will also create a `convex/` folder for you
    to write your backend API functions in. The `dev` command
    will then continue running to sync your functions
    with your dev deployment in the cloud.


    ```sh
    npx convex dev
    ```

  </Step>

  <Step title="Create sample data for your database">
    In a new terminal window, create a `sampleData.jsonl`
    file with some sample data.

    <Snippet
      source={sampleData}
      title="sampleData.jsonl"
    />

  </Step>

  <Step title="Add the sample data to your database">
    Now that your project is ready, add a `tasks` table
    with the sample data into your Convex database with
    the `import` command.

    ```
    npx convex import --table tasks sampleData.jsonl
    ```

  </Step>

  <Step title="Expose a database query">
    Add a new file `tasks.ts` in the `convex/` folder
    with a query function that loads the data.

    Exporting a query function from this file
    declares an API function named after the file
    and the export name, `api.tasks.get`.

    <Snippet
      source={tasks}
      title="convex/tasks.ts"
    />

  </Step>

  <Step title="Wire up the ConvexProvider">
    In `src/main.ts` set up the Convex client there to make it available on every page of your app.

    <Snippet
      source={main}
      title="src/main.ts"
    />

  </Step>

  <Step title="Display the data in your app">
    In `src/App.vue` use `useQuery` to subscribe your `api.tasks.get`
    API function.

    <Snippet
      source={App}
      title="src/App.vue"
    />

  </Step>

  <Step title="Start the app">
    Start the app, open [http://localhost:5173](http://localhost:5173) in a browser,
    and see the list of tasks.

    ```sh
    npm run dev
    ```

  </Step>

</StepByStep>

See the complete
[Vue npm package documentation](https://www.npmjs.com/package/@convex-vue/core).


---

# quickstarts.mdx

<!-- Source: quickstarts.mdx -->

---
title: Quickstarts
hide_table_of_contents: true
---

import {
  QuickLanguagesList,
  QuickFrameworksList,
} from "@site/src/QuickstartsList.tsx";

Quickly get up and running with your favorite frontend tooling:

<QuickFrameworksList />

Quickly get up and running with your favorite languages:

<QuickLanguagesList />


---

# realtime.mdx

<!-- Source: realtime.mdx -->

---
title: "Realtime"
sidebar_position: 100
description: "Building realtime apps with Convex"
---

Turns out Convex is automatically realtime! You don’t have to do anything
special if you are already using [query functions](./functions/query-functions),
[database](./database), and [client libraries](./client/react/) in your app.
Convex tracks the dependencies to your query functions, including database
changes, and triggers the subscription in the client libraries.

<div align="center">
  ![Convex is automatically reactive and realtime](/img/realtime.gif)
</div>

Aside from building a highly interactive app with ease, there are other benefits
to the realtime architecture of Convex:

## Automatic caching

Convex automatically caches the result of your query functions so that future
calls just read from the cache. The cache is updated if the data ever changes.
You don't get charged for database bandwidth for cached reads.

This requires no work or bookkeeping from you.

## Consistent data across your app

Every client subscription gets updated simultaneously to the same snapshot of
the database. Your app always displays the most consistent view of your data.

This avoids bugs like increasing the number of items in the shopping cart and
not showing that an item is sold out.

## Learn more

Learn how to work with realtime and reactive queries in Convex on
[Stack](https://stack.convex.dev/tag/Reactivity).

<StackPosts query="reactivity" />


---

# cron-jobs.mdx

<!-- Source: scheduling/cron-jobs.mdx -->

---
title: "Cron Jobs"
sidebar_position: 2
---

import Example from "!!raw-loader!@site/../private-demos/snippets/convex/crons.ts";

Convex allows you to schedule functions to run on a recurring basis. For
example, cron jobs can be used to clean up data at a regular interval, send a
reminder email at the same time every month, or schedule a backup every
Saturday.

**Example:**
[Cron Jobs](https://github.com/get-convex/convex-demos/tree/main/cron-jobs)

## Defining your cron jobs

Cron jobs are defined in a `crons.ts` file in your `convex/` directory and look
like:

<TSAndJSSnippet title="convex/crons.ts" sourceTS={Example} sourceJS={Example} />

The first argument is a unique identifier for the cron job.

The second argument is the schedule at which the function should run, see
[Supported schedules](/scheduling/cron-jobs.mdx#supported-schedules) below.

The third argument is the name of the public function or
[internal function](/functions/internal-functions.mdx), either a
[mutation](/functions/mutation-functions.mdx) or an
[action](/functions/actions.mdx).

## Supported schedules

- [`crons.interval()`](/api/classes/server.Crons#interval) runs a function every
  specified number of `seconds`, `minutes`, or `hours`. The first run occurs
  when the cron job is first deployed to Convex. Unlike traditional crons, this
  option allows you to have seconds-level granularity.
- [`crons.cron()`](/api/classes/server.Crons#cron) the traditional way of
  specifying cron jobs by a string with five fields separated by spaces
  <nobr>(e.g. `"* * * * *"`)</nobr>. Times in cron syntax are in the UTC
  timezone. [Crontab Guru](https://crontab.guru/) is a helpful resource for
  understanding and creating schedules in this format.
- [`crons.hourly()`](/api/classes/server.Crons#cron),
  [`crons.daily()`](/api/classes/server.Crons#daily),
  [`crons.weekly()`](/api/classes/server.Crons#weekly),
  [`crons.monthly()`](/api/classes/server.Crons#monthly) provide an alternative
  syntax for common cron schedules with explicitly named arguments.

## Viewing your cron jobs

You can view all your cron jobs in the
[Convex dashboard cron jobs view](/dashboard/deployments/schedules.md#cron-jobs-ui).
You can view added, updated, and deleted cron jobs in the logs and history view.
Results of previously executed runs of the cron jobs are also available in the
logs view.

## Error handling

Mutations and actions have the same guarantees that are described in
[Error handling](/scheduling/scheduled-functions.mdx#error-handling) for
scheduled functions.

At most one run of each cron job can be executing at any moment. If the function
scheduled by the cron job takes too long to run, following runs of the cron job
may be skipped to avoid execution from falling behind. Skipping a scheduled run
of a cron job due to the previous run still executing logs a message visible in
the logs view of the dashboard.


---

# scheduled-functions.mdx

<!-- Source: scheduling/scheduled-functions.mdx -->

---
title: Scheduled Functions
sidebar_position: 1
---

import Example from "!!raw-loader!@site/../private-demos/snippets/convex/messages.ts";

Convex allows you to schedule functions to run in the future. This allows you to
build powerful durable workflows without the need to set up and maintain queues
or other infrastructure.

Scheduled functions are stored in the database. This means you can schedule
functions minutes, days, and even months in the future. Scheduling is resilient
against unexpected downtime or system restarts.

**Example:**
[Scheduling](https://github.com/get-convex/convex-demos/tree/main/scheduling)

## Scheduling functions

You can schedule public functions and
[internal functions](/functions/internal-functions.mdx) from mutations and
actions via the [scheduler](/api/interfaces/server.Scheduler) provided in the
respective function context.

- [runAfter](/api/interfaces/server.Scheduler#runafter) schedules a function to
  run after a delay (measured in milliseconds).
- [runAt](/api/interfaces/server.Scheduler#runat) schedules a function run at a
  date or timestamp (measured in milliseconds elapsed since the epoch).

The rest of the arguments are the path to the function and its arguments,
similar to invoking a function from the client. For example, here is how to send
a message that self-destructs in five seconds.

<TSAndJSSnippet
  title="convex/messages.ts"
  sourceTS={Example}
  sourceJS={Example}
  snippet="scheduling-runAfter"
  highlightPatterns={["scheduler", "runAfter"]}
/>

A single function can schedule up to 1000 functions with total argument size of
8MB.

### Scheduling from mutations

Scheduling functions from
[mutations](/functions/mutation-functions.mdx#transactions) is atomic with the
rest of the mutation. This means that if the mutation succeeds, the scheduled
function is guaranteed to be scheduled. On the other hand, if the mutations
fails, no function will be scheduled, even if the function fails after the
scheduling call.

### Scheduling from actions

Unlike mutations, [actions](//docs/functions/actions.mdx) don't execute as a
single database transaction and can have side effects. Thus, scheduling from
actions does not depend on the outcome of the function. This means that an
action might succeed to schedule some functions and later fail due to transient
error or a timeout. The scheduled functions will still be executed.

### Scheduling immediately

Using `runAfter()` with delay set to 0 is used to immediately add a function to
the event queue. This usage may be familiar to you if you're used to calling
`setTimeout(fn, 0)`.

As noted above, actions are not atomic and are meant to cause side effects.
Scheduling immediately becomes useful when you specifically want to trigger an
action from a mutation that is conditional on the mutation succeeding.
[This post](https://stack.convex.dev/pinecone-and-embeddings#kick-off-a-background-action)
goes over a direct example of this in action, where the application depends on
an external service to fill in information to the database.

## Retrieving scheduled function status

Every scheduled function is reflected as a document in the
`"_scheduled_functions"` system table. `runAfter()` and `runAt()` return the id
of scheduled function. You can read data from system tables using the
`db.system.get` and `db.system.query` methods, which work the same as the
standard `db.get` and `db.query` methods.

<TSAndJSSnippet
  title="convex/messages.ts"
  sourceTS={Example}
  sourceJS={Example}
  snippet="scheduling-status"
  highlightPatterns={["system"]}
/>

This is an example of the returned document:

```json
{
  "_creationTime": 1699931054642.111,
  "_id": "3ep33196167235462543626ss0scq09aj4gqn9kdxrdr",
  "args": [{}],
  "completedTime": 1699931054690.366,
  "name": "messages.js:destruct",
  "scheduledTime": 1699931054657,
  "state": { "kind": "success" }
}
```

The returned document has the following fields:

- `name`: the path of the scheduled function
- `args`: the arguments passed to the scheduled function
- `scheduledTime`: the timestamp of when the function is scheduled to run
  (measured in milliseconds elapsed since the epoch)
- `completedTime`: the timestamp of when the function finished running, if it
  has completed (measured in milliseconds elapsed since the epoch)
- `state`: the status of the scheduled function. Here are the possible states a
  scheduled function can be in:
  - `Pending`: the function has not been started yet
  - `InProgress`: the function has started running is not completed yet (only
    applies to actions)
  - `Success`: the function finished running successfully with no errors
  - `Failed`: the function hit an error while running, which can either be a
    user error or an internal server error
  - `Canceled`: the function was canceled via the dashboard,
    `ctx.scheduler.cancel`, or recursively by a parent scheduled function that
    was canceled while in progress

Scheduled function results are available for 7 days after they have completed.

## Canceling scheduled functions

You can cancel a previously scheduled function with
[`cancel`](/api/interfaces/server.Scheduler#cancel) via the
[scheduler](/api/interfaces/server.Scheduler) provided in the respective
function context.

<TSAndJSSnippet
  title="convex/messages.ts"
  sourceTS={Example}
  sourceJS={Example}
  snippet="scheduling-cancel"
  highlightPatterns={["scheduler.cancel"]}
/>

What `cancel` does depends on the state of the scheduled function:

- If it hasn't started running, it won't run.
- If it already started, it will continue to run, but any functions it schedules
  will not run.

## Debugging

You can view logs from previously executed scheduled functions in the Convex
dashboard [Logs view](/dashboard/deployments/logs.md). You can view and cancel
yet to be executed functions in the
[Functions view](/dashboard/deployments/functions.md).

## Error handling

Once scheduled, mutations are guaranteed to be executed exactly once. Convex
will automatically retry any internal Convex errors, and only fail on developer
errors. See [Error Handling](/functions/error-handling/error-handling.mdx) for
more details on different error types.

Since actions may have side effects, they are not automatically retried by
Convex. Thus, actions will be executed at most once, and permanently fail if
there are transient errors while executing them. Developers can retry those
manually by scheduling a mutation that checks if the desired outcome has been
achieved and if not schedule the action again.

## Auth

The auth is not propagated from the scheduling to the scheduled function. If you
want to authenticate or check authorization, you'll have to pass the requisite
user information in as a parameter.


---

# scheduling.mdx

<!-- Source: scheduling.mdx -->

---
title: "Scheduling"
hide_table_of_contents: true
pagination_prev: auth
---

import { ComponentCardList } from "@site/src/components/ComponentCard";

Convex lets you easily schedule a function to run once or repeatedly in the
future. This allows you to build durable workflows like sending a welcome email
a day after someone joins or regularly reconciling your accounts with Stripe.
Convex provides two different features for scheduling:

- [Scheduled Functions](/scheduling/scheduled-functions.mdx) can be scheduled
  durably by any other function to run at a later point in time. You can
  schedule functions minutes, days, and even months in the future.
- [Cron Jobs](/scheduling/cron-jobs.mdx) schedule functions to run on a
  recurring basis, such as daily.

## Durable function components

Built-in scheduled functions and crons work well for simpler apps and workflows.
If you're operating at high scale or need more specific guarantees, use the
following higher-level [components](/components.mdx) for durable functions.

<ComponentCardList
  items={[
    {
      title: "Workpool",
      description:
        "Workpool give critical tasks priority by organizing async operations into separate, customizable queues.",
      href: "https://www.convex.dev/components/workpool",
    },
    {
      title: "Workflow",
      description:
        "Simplify programming long running code flows. Workflows execute durably with configurable retries and delays.",
      href: "https://www.convex.dev/components/workflow",
    },
    {
      title: "Action Retrier",
      description:
        "Add reliability to an unreliable external service. Retry idempotent calls a set number of times.",
      href: "https://www.convex.dev/components/retrier",
    },
    {
      title: "Crons",
      description:
        "Use cronspec to run functions on a repeated schedule at runtime.",
      href: "https://www.convex.dev/components/crons",
    },
  ]}
/>

<StackPosts query="scheduler" />


---

# search.mdx

<!-- Source: search/search.mdx -->

---
title: "Full Text Search"
sidebar_position: 110
description: "Run search queries over your Convex documents"
slug: "text-search"
---

Full text search allows you to find Convex documents that approximately match a
search query.

Unlike normal
[document queries](/database/reading-data/reading-data.mdx#querying-documents),
search queries look _within_ a string field to find the keywords. Search queries
are useful for building features like searching for messages that contain
certain words.

Search queries are automatically reactive, consistent, transactional, and work
seamlessly with pagination. They even include new documents created with a
mutation!

**Example:**
[Search App](https://github.com/get-convex/convex-demos/tree/main/search)

To use full text search you need to:

1. Define a search index.
2. Run a search query.

Search indexes are built and queried using Convex's multi-segment search
algorithm on top of [Tantivy](https://github.com/quickwit-oss/tantivy), a
powerful, open-source, full-text search library written in Rust.

## Defining search indexes

Like [database indexes](/database/reading-data/indexes/indexes.md), search
indexes are a data structure that is built in advance to enable efficient
querying. Search indexes are defined as part of your Convex
[schema](/database/schemas.mdx).

Every search index definition consists of:

1. A name.
   - Must be unique per table.
2. A `searchField`
   - This is the field which will be indexed for full text search.
   - It must be of type `string`.
3. [Optional] A list of `filterField`s
   - These are additional fields that are indexed for fast equality filtering
     within your search index.

To add a search index onto a table, use the
[`searchIndex`](/api/classes/server.TableDefinition#searchindex) method on your
table's schema. For example, if you want an index which can search for messages
matching a keyword in a channel, your schema could look like:

```ts noDialect title="convex/schema.ts"
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  messages: defineTable({
    body: v.string(),
    channel: v.string(),
  }).searchIndex("search_body", {
    searchField: "body",
    filterFields: ["channel"],
  }),
});
```

You can specify search and filter fields on nested documents by using a
dot-separated path like `properties.name`.

## Running search queries

A query for "10 messages in channel '#general' that best match the query 'hello
hi' in their body" would look like:

```js
const messages = await ctx.db
  .query("messages")
  .withSearchIndex("search_body", (q) =>
    q.search("body", "hello hi").eq("channel", "#general"),
  )
  .take(10);
```

This is just a normal [database read](/database/reading-data/reading-data.mdx)
that begins by querying the search index!

The
[`.withSearchIndex`](/api/interfaces/server.QueryInitializer#withsearchindex)
method defines which search index to query and how Convex will use that search
index to select documents. The first argument is the name of the index and the
second is a _search filter expression_. A search filter expression is a
description of which documents Convex should consider when running the query.

A search filter expression is always a chained list of:

1. 1 search expression against the index's search field defined with
   [`.search`](/api/interfaces/server.SearchFilterBuilder#search).
2. 0 or more equality expressions against the index's filter fields defined with
   [`.eq`](/api/interfaces/server.SearchFilterFinalizer#eq).

### Search expressions

Search expressions are issued against a search index, filtering and ranking
documents by their relevance to the search expression's query. Internally,
Convex will break up the query into separate words (called _terms_) and
approximately rank documents matching these terms.

In the example above, the expression `search("body", "hello hi")` would
internally be split into `"hi"` and `"hello"` and matched against words in your
document (ignoring case and punctuation).

The behavior of search incorporates [prefix matching rules](#search-behavior).

### Equality expressions

Unlike search expressions, equality expressions will filter to only documents
that have an exact match in the given field. In the example above,
`eq("channel", "#general")` will only match documents that have exactly
`"#general"` in their `channel` field.

Equality expressions support fields of any type (not just text).

To filter to documents that are missing a field, use
`q.eq("fieldName", undefined)`.

### Other filtering

Because search queries are normal database queries, you can also
[filter results](/database/reading-data/filters.mdx) using the
[`.filter` method](/api/interfaces/server.Query#filter)!

Here's a query for "messages containing 'hi' sent in the last 10 minutes":

```js
const messages = await ctx.db
  .query("messages")
  .withSearchIndex("search_body", (q) => q.search("body", "hi"))
  .filter((q) => q.gt(q.field("_creationTime", Date.now() - 10 * 60000)))
  .take(10);
```

**For performance, always put as many of your filters as possible into
`.withSearchIndex`.**

Every search query is executed by:

1. First, querying the search index using the search filter expression in
   `withSearchIndex`.
2. Then, filtering the results one-by-one using any additional `filter`
   expressions.

Having a very specific search filter expression will make your query faster and
less likely to hit Convex's limits because Convex will use the search index to
efficiently cut down on the number of results to consider.

### Retrieving results and paginating

Just like ordinary database queries, you can
[retrieve the results](/database/reading-data/reading-data.mdx#retrieving-results)
using [`.collect()`](/api/interfaces/server.Query#collect),
[`.take(n)`](/api/interfaces/server.Query#take),
[`.first()`](/api/interfaces/server.Query#first), and
[`.unique()`](/api/interfaces/server.Query#unique).

Additionally, search results can be [paginated](/database/pagination.mdx) using
[`.paginate(paginationOpts)`](/api/interfaces/server.OrderedQuery#paginate).

Note that `collect()` will throw an exception if it attempts to collect more
than the limit of 1024 documents. It is often better to pick a smaller limit and
use `take(n)` or paginate the results.

### Ordering

Search queries always return results in [relevance order](#relevance-order)
based on how well the document matches the search query. Different ordering of
results are not supported.

## Search Behavior

### Typeahead Search

Convex full-text search is designed to power as-you-type search experiences. In
your search queries, the final search term has _prefix search_ enabled, matching
any term that is a prefix of the original term. For example, the expression
`search("body", "r")` would match the documents:

- `"rabbit"`
- `"send request"`

Fuzzy search matches are deprecated. After January 15, 2025, search results will
not include `"snake"` for a typo like `"stake"`.

### Relevance order

**Relevance order is subject to change.** The relevance of search results and
the exact typo-tolerance rules Convex applies is subject to change to improve
the quality of search results.

Search queries return results in relevance order. Internally, Convex ranks the
relevance of a document based on a combination of its
[BM25 score](https://en.wikipedia.org/wiki/Okapi_BM25) and several other
criteria such as the number of typos of matched terms in the document, the
proximity of matches, the number of exact matches, and more. The BM25 score
takes into account:

- How many words in the search query appear in the field?
- How many times do they appear?
- How long is the text field?

If multiple documents have the same score, the newest documents are returned
first.

## Limits

Search indexes work best with English or other Latin-script languages. Text is
tokenized using Tantivy's
[`SimpleTokenizer`](https://docs.rs/tantivy/latest/tantivy/tokenizer/struct.SimpleTokenizer.html),
which splits on whitespace and punctuation. We also limit terms to 32 characters
in length and lowercase them.

Search indexes must have:

- Exactly 1 search field.
- Up to 16 filter fields.

Search indexes count against the
[limit of 32 indexes per table](/database/reading-data/indexes/indexes.md#limits).

Search queries can have:

- Up to 16 terms (words) in the search expression.
- Up to 8 filter expressions.

Additionally, search queries can scan up to 1024 results from the search index.

The source of truth for these limits is our
[source code](https://github.com/get-convex/convex-backend/blob/main/crates/search/src/constants.rs).

For information on other limits, see [here](/production/state/limits.mdx).


---

# vector-search.mdx

<!-- Source: search/vector-search.mdx -->

---
title: "Vector Search"
sidebar_position: 100
description: "Run vector search queries on embeddings"
slug: "vector-search"
---

import Schema from "!!raw-loader!@site/../demos/vector-search/convex/schema.ts";
import VectorSearchSnippets from "!!raw-loader!@site/../private-demos/snippets/convex/vectorSearch.ts";
import Foods from "!!raw-loader!@site/../private-demos/snippets/convex/foods.ts";
import VectorSearchSnippets2 from "!!raw-loader!@site/../private-demos/snippets/convex/vectorSearch2.ts";
import Movies from "!!raw-loader!@site/../demos/vector-search/convex/movies.ts";

Vector search allows you to find Convex documents similar to a provided vector.
Typically, vectors will be embeddings which are numerical representations of
text, images, or audio.

Embeddings and vector search enable you to provide useful context to LLMs for AI
powered applications, recommendations for similar content and more.

Vector search is consistent and fully up-to-date. You can write a vector and
immediately read it from a vector search. Unlike
[full text search](/search.mdx), however, vector search is only available in
[Convex actions](/functions/actions.mdx).

**Example:**
[Vector Search App](https://github.com/get-convex/convex-demos/tree/main/vector-search)

To use vector search you need to:

1. Define a vector index.
1. Run a vector search from within an [action](/functions/actions.mdx).

## Defining vector indexes

Like [database indexes](/database/reading-data/indexes/indexes.md), vector
indexes are a data structure that is built in advance to enable efficient
querying. Vector indexes are defined as part of your Convex
[schema](/database/schemas.mdx).

To add a vector index onto a table, use the
[`vectorIndex`](/api/classes/server.TableDefinition#vectorindex) method on your
table's schema. Every vector index has a unique name and a definition with:

1. `vectorField` string
   - The name of the field indexed for vector search.
1. `dimensions` number
   - The fixed size of the vectors index. If you're using embeddings, this
     dimension should match the size of your embeddings (e.g. `1536` for
     OpenAI).
1. [Optional] `filterFields` array
   - The names of additional fields that are indexed for fast filtering within
     your vector index.

For example, if you want an index that can search for similar foods within a
given cuisine, your table definition could look like:

<Snippet
  source={Schema}
  title="convex/schema.ts"
  snippet="schemaOneTable"
  highlightPatterns={["vectorIndex"]}
/>

You can specify vector and filter fields on nested documents by using a
dot-separated path like `properties.name`.

## Running vector searches

Unlike database queries or full text search, vector searches can only be
performed in a [Convex action](/functions/actions.mdx).

They generally involve three steps:

1. Generate a vector from provided input (e.g. using OpenAI)
1. Use
   [`ctx.vectorSearch`](/api/interfaces/server.GenericActionCtx#vectorsearch) to
   fetch the IDs of similar documents
1. Load the desired information for the documents

Here's an example of the first two steps for searching for similar French foods
based on a description:

<TSAndJSSnippet
  sourceTS={VectorSearchSnippets}
  sourceJS={VectorSearchSnippets}
  title="convex/foods.ts"
  snippet="vectorSearchQuery"
  highlightPatterns={["vectorSearch"]}
/>

An example of the first step can be found
[here](https://github.com/get-convex/convex-demos/blob/main/vector-search/convex/foods.ts#L18)
in the vector search demo app.

Focusing on the second step, the `vectorSearch` API takes in the table name, the
index name, and finally a
[`VectorSearchQuery`](/api/interfaces/server.VectorSearchQuery) object
describing the search. This object has the following fields:

1. `vector` array
   - An array of numbers (e.g. embedding) to use in the search.
   - The search will return the document IDs of the documents with the most
     similar stored vectors.
   - It must have the same length as the `dimensions` of the index.
2. [Optional] `limit` number
   - The number of results to get back. If specified, this value must be between
     1 and 256.
3. [Optional] `filter`
   - An expression that restricts the set of results based on the `filterFields`
     in the `vectorIndex` in your schema. See
     [Filter expressions](#filter-expressions) for details.

It returns an `Array` of objects containing exactly two fields:

1. `_id`
   - The [Document ID](https://docs.convex.dev/database/document-ids) for the
     matching document in the table
2. `_score`
   - An indicator of how similar the result is to the vector you were searching
     for, ranging from -1 (least similar) to 1 (most similar)

Neither the underlying document nor the vector are included in `results`, so
once you have the list of results, you will want to load the desired information
about the results.

There are a few strategies for loading this information documented in the
[Advanced Patterns](#advanced-patterns) section.

For now, let's load the documents and return them from the action. To do so,
we'll pass the list of results to a Convex query and run it inside of our
action, returning the result:

<TSAndJSSnippet
  sourceTS={Foods}
  sourceJS={Foods}
  title="convex/foods.ts"
  snippet="fetchResults"
/>

<TSAndJSSnippet
  sourceTS={VectorSearchSnippets2}
  sourceJS={VectorSearchSnippets2}
  title="convex/foods.ts"
  snippet="fetchResults"
/>

### Filter expressions

As mentioned above, vector searches support efficiently filtering results by
additional fields on your document using either exact equality on a single
field, or an `OR` of expressions.

For example, here's a filter for foods with cuisine exactly equal to "French":

<Snippet source={VectorSearchSnippets} snippet="filterSingleValue" />

You can also filter documents by a single field that contains several different
values using an `or` expression. Here's a filter for French or Indonesian
dishes:

<Snippet source={VectorSearchSnippets} snippet="filterMultipleValues" />

For indexes with multiple filter fields, you can also use `.or()` filters on
different fields. Here's a filter for dishes whose cuisine is French or whose
main ingredient is butter:

<Snippet source={VectorSearchSnippets} snippet="filterMultipleFields" />

**Both `cuisine` and `mainIngredient` would need to be included in the
`filterFields` in the `.vectorIndex` definition.**

### Other filtering

Results can be filtered based on how similar they are to the provided vector
using the `_score` field in your action:

```ts
const results = await ctx.vectorSearch("foods", "by_embedding", {
  vector: embedding,
});
const filteredResults = results.filter((result) => result._score >= 0.9);
```

Additional filtering can always be done by passing the vector search results to
a query or mutation function that loads the documents and performs filtering
using any of the fields on the document.

**For performance, always put as many of your filters as possible into
`.vectorSearch`.**

### Ordering

Vector queries always return results in relevance order.

Currently Convex searches vectors using an
[approximate nearest neighbor search](https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximate_nearest_neighbor)
based on [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity).
Support for more similarity metrics
[will come in the future](#future-development).

If multiple documents have the same score, ties are broken by the document ID.

## Advanced patterns

### Using a separate table to store vectors

There are two main options for setting up a vector index:

1. Storing vectors in the same table as other metadata
1. Storing vectors in a separate table, with a reference

The examples above show the first option, which is simpler and works well for
reading small amounts of documents. The second option is more complex, but
better supports reading or returning large amounts of documents.

Since vectors are typically large and not useful beyond performing vector
searches, it's nice to avoid loading them from the database when reading other
data (e.g. `db.get()`) or returning them from functions by storing them in a
separate table.

A table definition for movies, and a vector index supporting search for similar
movies filtering by genre would look like this:

<Snippet source={Schema} title="convex/schema.ts" snippet="schemaTwoTables" />

Generating an embedding and running a vector search are the same as using a
single table. Loading the relevant documents given the vector search result is
different since we have an ID for `movieEmbeddings` but want to load a `movies`
document. We can do this using the `by_embedding` database index on the `movies`
table:

<TSAndJSSnippet
  sourceTS={VectorSearchSnippets}
  sourceJS={VectorSearchSnippets}
  title="convex/movies.ts"
  snippet="fetchMovies"
  highlightPatterns={["withIndex"]}
/>

### Fetching results and adding new documents

Returning information from a vector search involves an action (since vector
search is only available in actions) and a query or mutation to load the data.

The example above used a query to load data and return it from an action. Since
this is an action, the data returned is not reactive. An alternative would be to
return the results of the vector search in the action, and have a separate query
that reactively loads the data. The search results will not update reactively,
but the data about each result would be reactive.

The
[Vector Search Demo App](https://github.com/get-convex/convex-demos/tree/main/vector-search)
uses this strategy to show similar movies with a reactive "Votes" count.

## Limits

Convex supports millions of vectors today. This is an ongoing project and we
will continue to scale this offering out with the rest of Convex.

Vector indexes must have:

- Exactly 1 vector index field.
  - The field must be of type `v.array(v.float64())` (or a union in which one of
    the possible types is `v.array(v.float64())`)
- Exactly 1 dimension field with a value between 2 and 4096.
- Up to 16 filter fields.

Vector indexes count towards the
[limit of 32 indexes per table](/database/reading-data/indexes/indexes.md#limits).
In addition you can have up to 4 vector indexes per table.

Vector searches can have:

- Exactly 1 vector to search by in the `vector` field
- Up to 64 filter expressions
- Up to 256 requested results (defaulting to 10).

If your action performs a vector search then passes the results to a query or
mutation function, you may find that one or more results from the vector search
have been deleted or mutated. Because vector search is only available in
actions, you cannot perform additional transactional queries or mutations based
on the results. If this is important for your use case, please
[let us know on Discord](https://convex.dev/community)!

Only documents that contain a vector of the size and in the field specified by a
vector index will be included in the index and returned by the vector search.

For information on limits, see [here](/production/state/limits.mdx).

## Future development

We're always open to customer feedback and requests. Some ideas we've considered
for improving vector search in Convex include:

- More sophisticated filters and filter syntax
- Filtering by score in the `vectorSearch` API
- Better support for generating embeddings

If any of these features is important for your app,
[let us know on Discord](https://convex.dev/community)!


---

# search.mdx

<!-- Source: search.mdx -->

---
title: "AI & Search"
sidebar_position: 105
description: "Run search queries over your Convex documents"
slug: "search"
pagination_prev: "scheduling"
---

Whether building RAG enabled chatbots or quick search in your applications,
Convex provides easy apis to create powerful AI and search enabled products.

[Vector Search](/search/vector-search.mdx) enables searching for documents based
on their semantic meaning. It uses vector embeddings to calculate similarity and
retrieve documents that are similar to a given query. Vector search is a key
part of common AI techniques like RAG.

[Full Text Search](/search/search.mdx) enables keyword and phrase search within
your documents. It supports both prefix and fuzzy matching. Convex full text
search is also reactive and always up to date like all Convex queries, making it
easy to build reliable quick search boxes.

[Convex Actions](functions/actions) easily enable you to call AI apis, save data
to your database, and drive your user interface. See examples of how you can use
this to [build sophisticated AI applications](https://stack.convex.dev/tag/AI).

<StackPosts query="AI" />


---

# self-hosting.mdx

<!-- Source: self-hosting.mdx -->

---
title: "Self Hosting"
sidebar_position: 100
description: "Self Hosting Convex Projects"
---

If you're excited about self-hosting, you can run the Convex backend on your own
servers. Self-hosted Convex runs the
[open-source backend](https://github.com/get-convex/convex-backend), and
contains the same fully up-to-date code the cloud service uses.

To get started with self hosting, follow the
[self hosting guide](https://github.com/get-convex/convex-backend/blob/main/self-hosted/README.md)
in the repository. Join the `#self-hosted` channel in the
[Discord community](https://convex.dev/community) for self-hosting support.

Self hosting is not for everyone. If you're looking for a more hands-off
solution, we recommend using the
[Convex-hosted product](https://convex.dev/pricing).

## Open Source Convex Backend

The majority of the backend is written in Rust, with a healthy dose of
TypeScript supporting the server-side function environment.

You can learn more about open-sourcing at Convex in our
[announcement](https://news.convex.dev/convex-goes-open-source/) and the
[software engineering daily podcast](https://softwareengineeringdaily.com/2024/03/20/going-open-source-at-convex-with-james-cowling/).
It is released under the [FSL Apache 2.0 License](https://fsl.software/).

## Other Convex Open Source Projects

The Convex backend, client libraries, dashboard, and CLI are all open-source.
You can explore everything on the
[Convex GitHub page](https://github.com/get-convex).

### Convex Clients

All Convex Clients are open-source.

- [Convex JavaScript/TypeScript clients & CLI](https://github.com/get-convex/convex-js)
- [Convex Python Client](https://github.com/get-convex/convex-py)
- [Convex Rust Client](https://github.com/get-convex/convex-rs)

### Much Much More

Convex also open-sources many other helpful projects including
[helpers](https://github.com/get-convex/convex-helpers),
[templates](https://github.com/orgs/get-convex/repositories?type=all&q=template),
[demos](https://github.com/get-convex/convex-demos), a
[testing harness](https://github.com/get-convex/convex-test) and much more. See
the complete list of all our public repositories
[at GitHub](https://github.com/orgs/get-convex/repositories?type=all).

<StackPosts query="open-source" />


---

# ci.mdx

<!-- Source: testing/ci.mdx -->

---
title: Continuous Integration
sidebar_label: CI
sidebar_position: 300
---

Continuous integration allows your team to move fast by combining changes from
all team members and automatically testing them on a remote machine.

## Testing in GitHub Actions

It's easy if you're using [GitHub](https://docs.github.com/en/actions) to set up
[CI](https://docs.github.com/en/actions/automating-builds-and-tests/about-continuous-integration)
workflow for running your test suite:

```yaml title=".github/workflows/test.yml"
name: Run Tests

on: [pull_request, push]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
      - run: npm ci
      - run: npm run test
```

After you commit and push this file to your repository, GitHub will run
`npm run test` every time you create a pull request or push a new commit.

{/* todo: testing against preview deployments */}


---

# convex-backend.mdx

<!-- Source: testing/convex-backend.mdx -->

---
title: Testing Local Backend
sidebar_label: Local Backend
sidebar_position: 200
---

Alternatively to [`convex-test`](/testing/convex-test.mdx) you can test your
functions using the
[open-source version of the Convex backend](https://github.com/get-convex/convex-backend).

## Getting Started

Follow [this guide](https://stack.convex.dev/testing-with-local-oss-backend) for
the instructions.

Compared to `convex-test`, which uses a JS mock of the backend, running your
tests against the real backend has these advantages:

- Your tests will run against the same code as your Convex production (as long
  you keep the local backend up-to-date).
- Limits on argument, data, query sizes are enforced.
- You can bootstrap a large test dataset from a data import.
- You can test your client code in combination with your backend logic.

## Limitations

Note that testing against the local backend also has some drawbacks:

- It requires setting up the local backend, which is more involved.
- No control over time and any scheduled functions will run as scheduled.
- Crons will also run unless disabled via
  [`IS_TEST`](https://stack.convex.dev/testing-with-local-oss-backend#setting-up-a-local-backend).
- No way to mock `fetch` calls.
- No way to mock dependencies or parts of the codebase.
- No way to control randomness (tests may not be deterministic).
- No way to set environment variable values from within tests.

To test your functions in JS with a mocked Convex backend, check out
[convex-test](/testing/convex-test.mdx).

## CI

See [Continuous Integration](/testing/ci.mdx) to run your tests on a shared
remote machine.


---

# convex-test.mdx

<!-- Source: testing/convex-test.mdx -->

---
title: convex-test
sidebar_label: convex-test
sidebar_position: 100
---

The `convex-test` library provides a mock implementation of the Convex backend
in JavaScript. It enables fast automated testing of the logic in your
[functions](/functions.mdx).

**Example:** The library includes a
[test suite](https://github.com/get-convex/convex-test/tree/main/convex) which
you can browse to see examples of using it.

## Get Started

<StepByStep>

  <Step title="Install test dependencies">
    Install [Vitest](https://vitest.dev/) and the [`convex-test`](https://www.npmjs.com/package/convex-test) library.

    ```sh
    npm install --save-dev convex-test vitest @edge-runtime/vm
    ```

  </Step>

  <Step title="Setup NPM scripts">
    
    Add these scripts to your `package.json`

    ```json title="package.json"
    "scripts": {
      "test": "vitest",
      "test:once": "vitest run",
      "test:debug": "vitest --inspect-brk --no-file-parallelism",
      "test:coverage": "vitest run --coverage --coverage.reporter=text",
    }
    ```

  </Step>

  <Step title="Configure Vitest">
    
    Add <JSDialectFileName name="vitest.config.mts" /> file to configure the test
    environment to better match the Convex runtime, and to inline the test library
    for better dependency tracking.

    ```ts title="vitest.config.mts"
    import { defineConfig } from "vitest/config";

    export default defineConfig({
      test: {
        environment: "edge-runtime",
        server: { deps: { inline: ["convex-test"] } },
      },
    });
    ```

  </Step>

  <Step title="Add a test file">
    
    In your `convex` folder add a file ending in <JSDialectFileName name=".test.ts" />

    The example test calls the `api.messages.send` mutation twice
    and then asserts that the `api.messages.list` query returns
    the expected results.

    ```ts title="convex/messages.test.ts"
    import { convexTest } from "convex-test";
    import { expect, test } from "vitest";
    import { api } from "./_generated/api";
    import schema from "./schema";

    test("sending messages", async () => {
      const t = convexTest(schema);
      await t.mutation(api.messages.send, { body: "Hi!", author: "Sarah" });
      await t.mutation(api.messages.send, { body: "Hey!", author: "Tom" });
      const messages = await t.query(api.messages.list);
      expect(messages).toMatchObject([
        { body: "Hi!", author: "Sarah" },
        { body: "Hey!", author: "Tom" }
      ]);
    });
    ```

  </Step>

  <Step title="Run tests">

    Start the tests with `npm run test`. When you change the test file or your
    functions the tests will rerun automatically.

    ```sh
    npm run test
    ```

  </Step>

</StepByStep>

If you're not familiar with Vitest or Jest read the
[Vitest Getting Started docs](https://vitest.dev/guide) first.

## `convexTest`

The library exports a `convexTest` function which should be called at the start
of each of your tests. The function returns an object which is by convention
stored in the `t` variable and which provides methods for exercising your Convex
functions.

If your project uses a [schema](/database/schemas.mdx) you should pass it to the
`convexTest` function:

```ts title="convex/myFunctions.test.ts"
import { convexTest } from "convex-test";
import { test } from "vitest";
import schema from "./schema";

test("some behavior", async () => {
  const t = convexTest(schema);
  // use `t`...
});
```

Passing in the schema is required for the tests to correctly implement schema
validation and for correct typing of
[`t.run`](#setting-up-and-inspecting-data-and-storage-with-trun).

If you don't have a schema, call `convexTest()` with no argument.

## Calling functions with `t.query`, `t.mutation` and `t.action`

Your test can call public and internal Convex [functions](/functions.mdx) in
your project:

```ts title="convex/myFunctions.test.ts"
import { convexTest } from "convex-test";
import { test } from "vitest";
import { api, internal } from "./_generated/api";

test("functions", async () => {
  const t = convexTest();
  const x = await t.query(api.myFunctions.myQuery, { a: 1, b: 2 });
  const y = await t.query(internal.myFunctions.internalQuery, { a: 1, b: 2 });
  const z = await t.mutation(api.myFunctions.mutateSomething, { a: 1, b: 2 });
  const w = await t.mutation(internal.myFunctions.mutateSomething, { a: 1 });
  const u = await t.action(api.myFunctions.doSomething, { a: 1, b: 2 });
  const v = await t.action(internal.myFunctions.internalAction, { a: 1, b: 2 });
});
```

## Setting up and inspecting data and storage with `t.run`

Sometimes you might want to directly [write](/database/writing-data.mdx) to the
mock database or [file storage](/file-storage.mdx) from your test, without
needing a declared function in your project. You can use the `t.run` method
which takes a handler that is given a `ctx` that allows reading from and writing
to the mock backend:

```ts title="convex/tasks.test.ts"
import { convexTest } from "convex-test";
import { expect, test } from "vitest";

test("functions", async () => {
  const t = convexTest();
  const firstTask = await t.run(async (ctx) => {
    await ctx.db.insert("tasks", { text: "Eat breakfast" });
    return await ctx.db.query("tasks").first();
  });
  expect(firstTask).toMatchObject({ text: "Eat breakfast" });
});
```

## Testing HTTP actions with `t.fetch`

Your test can call [HTTP actions](/functions/http-actions.mdx) registered by
your router:

```ts title="convex/http.test.ts"
import { convexTest } from "convex-test";
import { test } from "vitest";

test("functions", async () => {
  const t = convexTest();
  const response = await t.fetch("/some/path", { method: "POST" });
});
```

Mocking the global `fetch` function doesn't affect `t.fetch`, but you can use
`t.fetch` in a `fetch` mock to route to your HTTP actions.

## Testing scheduled functions

One advantage of using a mock implementation running purely in JavaScript is
that you can control time in the Vitest test environment. To test
implementations relying on
[scheduled functions](/scheduling/scheduled-functions.mdx) use
[Vitest's fake timers](https://vitest.dev/guide/mocking.html#timers) in
combination with `t.finishInProgressScheduledFunctions`:

```ts title="convex/scheduling.test.ts"
import { convexTest } from "convex-test";
import { expect, test, vi } from "vitest";
import { api } from "./_generated/api";
import schema from "./schema";

test("mutation scheduling action", async () => {
  // Enable fake timers
  vi.useFakeTimers();

  const t = convexTest(schema);

  // Call a function that schedules a mutation or action
  const scheduledFunctionId = await t.mutation(
    api.scheduler.mutationSchedulingAction,
    { delayMs: 10000 },
  );

  // Advance the mocked time
  vi.advanceTimersByTime(5000);

  // Advance the mocked time past the scheduled time of the function
  vi.advanceTimersByTime(6000);

  // Or run all currently pending timers
  vi.runAllTimers();

  // At this point the scheduled function will be `inProgress`,
  // now wait for it to finish
  await t.finishInProgressScheduledFunctions();

  // Assert that the scheduled function succeeded or failed
  const scheduledFunctionStatus = t.run(async (ctx) => {
    return await ctx.db.get(scheduledFunctionId);
  });
  expect(scheduledFunctionStatus).toMatchObject({ state: { kind: "success" } });

  // Reset to normal `setTimeout` etc. implementation
  vi.useRealTimers();
});
```

If you have a chain of several scheduled functions, for example a mutation that
schedules an action that schedules another action, you can use
`t.finishAllScheduledFunctions` to wait for all scheduled functions, including
recursively scheduled functions, to finish:

```ts title="convex/chainedScheduling.test.ts"
import { convexTest } from "convex-test";
import { expect, test, vi } from "vitest";
import { api } from "./_generated/api";
import schema from "./schema";

test("mutation scheduling action scheduling action", async () => {
  // Enable fake timers
  vi.useFakeTimers();

  const t = convexTest(schema);

  // Call a function that schedules a mutation or action
  await t.mutation(api.scheduler.mutationSchedulingActionSchedulingAction);

  // Wait for all scheduled functions, repeatedly
  // advancing time and waiting for currently in-progress
  // functions to finish
  await t.finishAllScheduledFunctions(vi.runAllTimers);

  // Assert the resulting state after all scheduled functions finished
  const createdTask = t.run(async (ctx) => {
    return await ctx.db.query("tasks").first();
  });
  expect(createdTask).toMatchObject({ author: "AI" });

  // Reset to normal `setTimeout` etc. implementation
  vi.useRealTimers();
});
```

Check out more examples in
[this file](https://github.com/get-convex/convex-test/blob/main/convex/scheduler.test.ts).

## Testing authentication with `t.withIdentity`

To test functions which depend on the current [authenticated](/auth.mdx) user
identity you can create a version of the `t` accessor with given
[user identity attributes](/api/interfaces/server.UserIdentity). If you don't
provide them, `issuer`, `subject` and `tokenIdentifier` will be generated
automatically:

```ts title="convex/tasks.test.ts"
import { convexTest } from "convex-test";
import { expect, test } from "vitest";
import { api } from "./_generated/api";
import schema from "./schema";

test("authenticated functions", async () => {
  const t = convexTest(schema);

  const asSarah = t.withIdentity({ name: "Sarah" });
  await asSarah.mutation(api.tasks.create, { text: "Add tests" });

  const sarahsTasks = await asSarah.query(api.tasks.list);
  expect(sarahsTasks).toMatchObject([{ text: "Add tests" }]);

  const asLee = t.withIdentity({ name: "Lee" });
  const leesTasks = await asLee.query(api.tasks.list);
  expect(leesTasks).toEqual([]);
});
```

## Mocking `fetch` calls

You can use Vitest's
[vi.stubGlobal](https://vitest.dev/guide/mocking.html#globals) method:

```ts title="convex/ai.test.ts"
import { expect, test, vi } from "vitest";
import { convexTest } from "../index";
import { api } from "./_generated/api";
import schema from "./schema";

test("ai", async () => {
  const t = convexTest(schema);

  vi.stubGlobal(
    "fetch",
    vi.fn(async () => ({ text: async () => "I am the overlord" }) as Response),
  );

  const reply = await t.action(api.messages.sendAIMessage, { prompt: "hello" });
  expect(reply).toEqual("I am the overlord");

  vi.unstubAllGlobals();
});
```

## Asserting results

See Vitest's [Expect](https://vitest.dev/api/expect.html) reference.

[`toMatchObject()`](https://vitest.dev/api/expect.html#tomatchobject) is
particularly helpful when asserting the shape of results without needing to list
every object field.

### Asserting errors

To assert that a function throws, use
[`.rejects.toThrowError()`](https://vitest.dev/api/expect.html#tothrowerror):

```ts title="convex/messages.test.ts"
import { convexTest } from "convex-test";
import { expect, test } from "vitest";
import { api } from "./_generated/api";
import schema from "./schema";

test("messages validation", async () => {
  const t = convexTest(schema);
  expect(async () => {
    await t.mutation(api.messages.send, { body: "", author: "James" });
  }).rejects.toThrowError("Empty message body is not allowed");
});
```

## Measuring test coverage

You can get a printout of the code coverage provided by your tests. Besides
answering the question "how much of my code is covered by tests" it is also
helpful to check that your test is actually exercising the code that you want it
to exercise.

Run <CodeWithCopyButton text="npm run test:coverage" />. It will ask you to
install a required dependency the first time you run it.

<p style={{ textAlign: "center" }}>
  <img
    src="/screenshots/testing_coverage.png"
    alt="example coverage printout"
    width={700}
  />
</p>

## Debugging tests

You can attach a debugger to the running tests. Read the Vitest
[Debugging docs](https://vitest.dev/guide/debugging.html) and then
use&#32;<CodeWithCopyButton text="npm run test:debug" />.

## Multiple environments

If you want to use Vitest to test both your Convex functions and your React
frontend, you might want to use multiple Vitest environments depending on the
test file location via
[environmentMatchGlobs](https://vitest.dev/config/#environmentmatchglobs):

```ts title="vitest.config.mts"
import { defineConfig } from "vitest/config";

export default defineConfig({
  test: {
    environmentMatchGlobs: [
      // all tests in convex/ will run in edge-runtime
      ["convex/**", "edge-runtime"],
      // all other tests use jsdom
      ["**", "jsdom"],
    ],
    server: { deps: { inline: ["convex-test"] } },
  },
});
```

## Custom `convex/` folder name or location

If your project has a
[different name or location configured](/production/project-configuration.mdx#changing-the-convex-folder-name-or-location)
for the `convex/` folder in `convex.json`, you need to call
[`import.meta.glob`](https://vitejs.dev/guide/features#glob-import) and pass the
result as the second argument to `convexTest`.

The argument to `import.meta.glob` must be a glob pattern matching all the files
containing your Convex functions. The paths are relative to the test file in
which `import.meta.glob` is called. It's best to do this in one place in your
custom functions folder:

```ts title="src/convex/test.setup.ts"
/// <reference types="vite/client" />
export const modules = import.meta.glob("./**/!(*.*.*)*.*s");
```

This example glob pattern includes all files with a single extension ending in
`s` (like `js` or `ts`) in the `src/convex` folder and any of its children.

Use the result in your tests:

```ts title="src/convex/messages.test.ts"
import { convexTest } from "convex-test";
import { test } from "vitest";
import schema from "./schema";
import { modules } from "./test.setup";

test("some behavior", async () => {
  const t = convexTest(schema, modules);
  // use `t`...
});
```

## Limitations

Since `convex-test` is only a mock implementation, it doesn't have many of the
behaviors of the real Convex backend. Still, it should be helpful for testing
the logic in your functions, and catching regressions caused by changes to your
code.

Some of the ways the mock differs:

- Error messages content. You should not write product logic that relies on the
  content of error messages thrown by the real backend, as they are always
  subject to change.
- Limits. The mock doesn't enforce size and time
  [limits](/production/state/limits.mdx).
- ID format. Your code should not depend on the document or storage ID format.
- Runtime built-ins. Most of your functions are written for the
  [Convex default runtime](/functions/runtimes.mdx), while Vitest uses a mock of
  Vercel's Edge Runtime, which is similar but might differ from the Convex
  runtime. You should always test new code manually to make sure it doesn't use
  built-ins not available in the Convex runtime.
- Some features have only simplified semantics, namely:
  - [Text search](/search.mdx) returns all documents that include a word for
    which at least one word in the searched string is a prefix. It does not
    implement fuzzy searching and doesn't sort the results by relevance.
  - [Vector search](/search/vector-search.mdx) returns results sorted by cosine
    similarity, but doesn't use an efficient vector index in its implementation.
  - There is no support for [cron jobs](/scheduling/cron-jobs.mdx), you should
    trigger your functions manually from the test.

To test your functions running on a real Convex backend, check out
[Testing Local Backend](/testing/convex-backend.mdx).

## CI

See [Continuous Integration](/testing/ci.mdx) to run your tests on a shared
remote machine.


---

# testing.mdx

<!-- Source: testing.mdx -->

---
title: "Testing"
sidebar_position: 105
description: "Testing your backend"
slug: "testing"
pagination_prev: "search"
---

Convex makes it easy to test your app via automated tests running in JS or
against a real backend, and manually in dev, preview and staging environments.

## Automated tests

### `convex-test` library

[Use the `convex-test` library](/testing/convex-test.mdx) to test your functions
in JS via the excellent Vitest testing framework.

### Testing against a real backend

Convex open source builds allow you to test all of your backend logic running on
a real [local Convex backend](/testing/convex-backend.mdx).

### Set up testing in CI

It's a good idea to test your app continuously in a controlled environment. No
matter which way automated method you use, it's easy to run them with
[GitHub Actions](/testing/ci.mdx).

{/* todo: automated testing against preview deployments */}
{/* todo: testing React+Convex - all the different ways */}

## Manual tests

### Running a function in dev

Manually run a function in dev to quickly see if things are working:

- [Run functions from the command line](/cli.md#run-convex-functions)
- [Run functions from the dashboard](/dashboard/deployments/functions.md#running-functions)

### Preview deployments

[Use preview deployments](/production/hosting/preview-deployments.mdx) to get
early feedback from your team for your in-progress features.

### Staging environment

You can set up a separate project as a staging environment to test against. See
[Deploying Your App to Production](/production.mdx#staging-environment).


---

# actions.mdx

<!-- Source: tutorial/actions.mdx -->

---
title: "Convex Tutorial: Calling External Services"
sidebar_label: "2. Calling external services"
slug: "actions"
sidebar_position: 200
hide_table_of_contents: true
---

# Convex Tutorial: Calling external services

In the [previous step](/tutorial/index.mdx), you built a fully self-contained
chat app. Data in, data out.

In order to power the automatic reactivity we just saw while providing strong
database transactions, query and mutation functions in Convex are not allowed to
make `fetch` calls to the outside world.

Real apps aren't this simple. They often need to talk to the rest of the
internet directly from the backend. Convex lets you do this too via **action**
functions.

Action functions let the sync engine access the external world by scheduling out
work that can then write data back via mutations.

Let's make our chat app a bit smarter by letting anyone in the chat get the
Wikipedia summary of a topic using the Wikipedia API.

## Your first `action`

**Add the following action to your `convex/chat.ts` file.**

```typescript
// highlight-next-line
// Update your server import like this:
// highlight-next-line
import { query, mutation, internalAction } from "./_generated/server";

//...

// highlight-next-line
export const getWikipediaSummary = internalAction({
  // highlight-next-line
  args: { topic: v.string() },
  // highlight-next-line
  handler: async (ctx, args) => {
    // highlight-next-line
    const response = await fetch(
      // highlight-next-line
      "https://en.wikipedia.org/w/api.php?format=json&action=query&prop=extracts&exintro&explaintext&redirects=1&titles=" +
        // highlight-next-line
        args.topic,
      // highlight-next-line
    );
    // highlight-next-line

    // highlight-next-line
    return getSummaryFromJSON(await response.json());
    // highlight-next-line
  },
  // highlight-next-line
});
// highlight-next-line

// highlight-next-line
function getSummaryFromJSON(data: any) {
  // highlight-next-line
  const firstPageId = Object.keys(data.query.pages)[0];
  // highlight-next-line
  return data.query.pages[firstPageId].extract;
  // highlight-next-line
}
```

Let's walk through it:

1. First, we created a new Convex action function called `getWikipediaSummary`.
   We used `internalAction` because we want this function to be private to the
   Convex backend and not exposed as a public API. This function does a simple
   fetch to the Wikipedia API with our topic.
1. Next, we have a helper TypeScript function called `getSummaryFromJSON` to
   pull out the summary text from the JSON response.
1. The `getWikipediaSummary` function calls our helper function like any other
   TypeScript function.

This is great and all, but how do I use it?

To quickly test this function in the Convex dashboard, go to
[https://dashboard.convex.dev](https://dashboard.convex.dev/deployment/functions)
and navigate to your project. Click on the Functions in the left nav, and then
click on the `getWikipediaSummary` function. Click "Run Function".

The function runner UI will pop up. Try making a few searches.

<video autoPlay playsInline muted loop width="100%">
  <source src="/img/tutorial/tut_dashboard_action.mp4" type="video/mp4" />
  Running a few Wikipedia queries
</video>

## Hooking it up to your app

It's awesome that we can call Wikipedia, but we still need to show up in our
chat. So, let's hook it all up.

**Update your existing `sendMessage` mutation like this:**

```typescript
// highlight-next-line
// Import the api reference
// highlight-next-line
import { api, internal } from "./_generated/api";

//...

export const sendMessage = mutation({
  args: {
    user: v.string(),
    body: v.string(),
  },
  handler: async (ctx, args) => {
    console.log("This TypeScript function is running on the server.");
    await ctx.db.insert("messages", {
      user: args.user,
      body: args.body,
    });

    // highlight-next-line
    // Add the following lines:
    // highlight-next-line
    if (args.body.startsWith("/wiki")) {
      // highlight-next-line
      // Get the string after the first space
      // highlight-next-line
      const topic = args.body.slice(args.body.indexOf(" ") + 1);
      // highlight-next-line
      await ctx.scheduler.runAfter(0, internal.chat.getWikipediaSummary, {
        // highlight-next-line
        topic,
        // highlight-next-line
      });
      // highlight-next-line
    }
  },
});
```

Wait a second! What's with this `ctx.scheduler` stuff? Convex comes with a
powerful durable function scheduler. It's a fundamental part of the sync engine,
and it's the way you coordinate asynchronous functions in Convex.

In the case of mutations, it's the only way to call an action to fetch from the
outside world. The really cool part is, if for some reason your mutation throws
an exception, then nothing is scheduled. This is because mutations are
transactions, and scheduling is just a write in the database to tell Convex to
run this function at a future time.

Ok so, we can schedule our action, but we still need to write the summary back
to the chat.

**Let's go back and update our `getWikipediaSummary` action:**

```typescript
export const getWikipediaSummary = internalAction({
  args: { topic: v.string() },
  handler: async (ctx, args) => {
    const response = await fetch(
      "https://en.wikipedia.org/w/api.php?format=json&action=query&prop=extracts&exintro&explaintext&redirects=1&titles=" +
        args.topic,
    );

    // highlight-next-line
    // Replace the `return ...` with the following.
    // highlight-next-line
    const summary = getSummaryFromJSON(await response.json());
    // highlight-next-line
    await ctx.scheduler.runAfter(0, api.chat.sendMessage, {
      // highlight-next-line
      user: "Wikipedia",
      // highlight-next-line
      body: summary,
      // highlight-next-line
    });
  },
});
```

Just like scheduling the action, we're now scheduling our `sendMessage` mutation
to send the result of our Wikipedia lookup to our chat.

Go ahead, now play with your app!

<video autoPlay playsInline muted loop width="100%">
  <source src="/img/tutorial/tut_wikipedia.mp4" type="video/mp4" />
  Chat with Wikipedia
</video>

## The scheduler, actions, and the sync engine

<div className="center-image" style={{ maxWidth: "900px" }}>
  ![Sync engine with actions](/img/tutorial/ConvexSyncAction.png)
</div>

Queries and mutations are the only ways to interact with the database and the
scheduler enables building sophisticated workflows with actions in between.

[Actions](/functions/actions.mdx) are normal serverless functions like AWS
Lambda and Google Cloud Run. They help model flows like calling AI APIs and
using the Vector Store. They serve as an escape hatch. They deal with the
reality of the messy outside world with few guarantees.

Actions are not part of the sync engine. To talk to the database they have to
talk through query and mutation functions. This restriction lets Convex enforce
transactional guarantees in the database and keep the sync engine fast and
nimble.

The best way to structure your application for scale is to minimize the work
that happens in an action. Only the part that needs the
[non-determinism](https://en.wikipedia.org/wiki/Deterministic_algorithm), like
making the external `fetch` call should use them. Keeping them as small as
possible is the most scalable way to build Convex apps, enabling the highest
throughput.

The scheduler allows your app to keep most of its important logic in queries and
mutations and structure your code as workflows in and out of actions.

## What you built

In this section of the tutorial, you built an action to talk to the outside
world and used the scheduler to trigger this work.

You learned that keeping our actions small and keeping most of our work in
queries and mutations are fundamental to building scalable Convex backends.

## Next up

You've now learned the most important concepts in Convex. As a full-featured
backend, Convex is capable of many things such as [authentication](/auth.mdx),
[file storage](/file-storage.mdx) and [search](/search.mdx). You can add those
features as needed by following the documentation.

We touched a little bit on setting your app up for success. As your application
scales, you will run into new challenges. Let's learn how to deal with some of
these challenges in the [next section →](/tutorial/scale.mdx).

<CardLink
  className="convex-hero-card"
  item={{
    href: "/tutorial/scale",
    docId: "tutorial/scale",
    label: "Scaling your app",
  }}
/>


---

# index.mdx

<!-- Source: tutorial/index.mdx -->

---
title: "Convex Tutorial: A Chat App"
sidebar_label: "1. A chat app"
sidebar_position: 100
hide_table_of_contents: true
pagination_next: tutorial/actions
pagination_label: "Convex Tutorial: A chat app"
---

# Convex Tutorial: A chat app

Convex provides you with a fully featured backend with cloud functions,
database, scheduling, and a sync engine that keeps your frontend and backend up
to date in real-time.

Today, in about **10 lines of code,** we'll build a backend that reads and
writes to the database and automatically updates all users in a chat app.

After that we'll see how to connect to external services and setup your product
for success and scale.

## Start developing with Convex

<Details summary="Before you begin: You'll need Node.js 18+ and Git">

Ensure you have Node.js version 18 or greater installed on your computer. You
can check your version of Node.js by running `node --version` in your terminal.
If you don't have the appropriate version of Node.js installed,
[install it from the Node.js website.](https://nodejs.org/en)

In addition, this walkthrough requires Git, so verify you have it installed by
running `git -v` in your terminal. If not, head over to the
[Git website](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) for
installation instructions.

</Details>

First, clone the example project repo from GitHub and install the dependencies:

```shell
git clone https://github.com/get-convex/convex-tutorial.git
cd convex-tutorial
npm install
```

This app's `dev` npm command sets up Convex and then runs the web app:

```shell
npm run dev
```

During setup, you'll see that Convex uses your GitHub account for
authentication. Sign into Convex with GitHub and then accept the default project
setup prompts.

This will **automatically create your backend** and a folder called `convex/` in
your project, where you'll write your backend code.

**Make sure you keep this command (`npm run dev`) running in the background
throughout this tutorial.** It's running both the dev web server for the
frontend as well as the `convex` command in the background to keep your backend
in sync with your local codebase.

Once your server is up and running, open [localhost:5173](http://localhost:5173)
and check it out:

<div className="center-image" style={{ maxWidth: "676px" }}>
  ![Chat UI](/img/tutorial/tut_chat_ui.png)
</div>

If you try sending a message now, you'll see an alert telling you the mutation
is not yet implemented. We'll do that in a bit, but first here's a quick summary
of how Convex works.

## How Convex works

<div className="center-image" style={{ maxWidth: "700px" }}>
  ![Overview of the sync engine](/img/tutorial/ConvexSyncEngine.png)
</div>

**Database.** The Convex database is a document-relational database, which means
you have tables with JSON like documents in them. All documents have an
auto-generated `_id` that can be used to create relations between documents. You
interact with the database through mutation and query functions that are written
entirely in TypeScript.

**Mutation functions.** Mutations are TypeScript functions that update the
database. All mutation functions in Convex run as a database transaction. So
either all the changes are committed, or none are.

**Query functions.** Queries are TypeScript functions that can only read from
the database. As we'll see in a bit, you subscribe to them from your frontend to
keep your app automatically up to date.

Your frontend registers to listen to query updates through the **client
library**. The client libraries talk to Convex via WebSockets for fast realtime
updates.

The **sync engine** reruns query functions when any input to the function
changes, including any changes to the documents in the database that the query
reads. It then updates every app listening to the query. The sync engine is the
combination of queries, mutations and the database.

Now, let's dive into the code!

## Your first `mutation`

Create a new file in your `convex/` folder called `chat.ts`. This is where
you'll write your Convex backend functions for this application.

**Add the following to your `convex/chat.ts` file.**

```typescript
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export const sendMessage = mutation({
  args: {
    user: v.string(),
    body: v.string(),
  },
  handler: async (ctx, args) => {
    console.log("This TypeScript function is running on the server.");
    await ctx.db.insert("messages", {
      user: args.user,
      body: args.body,
    });
  },
});
```

Let's break this down:

1. You've added a new backend `mutation` function called `sendMessage` and
   exposed it as a public api.
1. The whole function automatically runs as a transaction that will roll back if
   an exception is thrown.
1. Since this is just a TypeScript function you can drop `console.log` lines to
   do simple debugging on the server.
1. `args:` ensures the function arguments are two strings named `user` and
   `body`, both as types and runtime values.
1. `ctx.db.insert` tells Convex to insert a new message document into the table.

Now, let's connect this mutation to your web app.

**Update your `src/App.tsx` file like so:**

```tsx
// highlight-next-line
// Import `useMutation` and `api` from Convex.
// highlight-next-line
import { useMutation } from "convex/react";
// highlight-next-line
import { api } from "../convex/_generated/api";

//...

export default function App() {
  // highlight-next-line
  // Replace the "TODO: Add mutation hook here." with:
  // highlight-next-line
  const sendMessage = useMutation(api.chat.sendMessage);

  //...

  return (
    <main className="chat">
      {/* ... */}
      <form
        onSubmit={async (e) => {
          e.preventDefault();
          // highlight-next-line
          // Replace "alert("Mutation not implemented yet");" with:
          // highlight-next-line
          await sendMessage({ user: NAME, body: newMessageText });

          setNewMessageText("");
        }}
      >
        {/* ... */}
      </form>
    </main>
  );
}
```

There are two steps to call a mutation in your frontend:

1. `const sendMessage = useMutation(api.chat.sendMessage);` gives your frontend
   app a handle to the mutation function
2. `await sendMessage({ user: NAME, body: newMessageText });` calls the mutation
   with the proper parameters.

This is a good time to **open up the Convex dashboard**. Open a new browser
window and go to [https://dashboard.convex.dev](https://dashboard.convex.dev)
and find new `convex-tutorial` project.

**Go to the "Data" screen**. So far, there is no data in your database.

**Keep your chat app and dashboard windows open side by side**. Now try to send
some messages from your chat app.

<video autoPlay playsInline muted loop width="100%">
  <source src="/img/tutorial/tut_first_mutation.mp4" type="video/mp4" />
  Mutations hooked up to the Convex backend and database.
</video>

You'll notice new chat messages showing up live in the `messages` table.

Convex automatically created a `messages` table when you sent the first message.
In Convex, [schemas](/database/schemas.mdx) are optional. Eventually, you'll
want to enforce the structure of your tables, but for the purposes of the
tutorial we'll skip this.

In the dashboard you can also go to the
[logs screen](https://dashboard.convex.dev/deployment/logs) and see every call
to the mutation as you ran with the log line we added earlier. The logs screen
is a critical part of debugging your backend in development.

You've successfully created a `mutation` function, which is also a database
transaction, and connected it to your UI.

Now, let's make sure your app can update live the same way the dashboard is
updating live.

## Your first `query`

**Update your `convex/chat.ts` file like this:**

```tsx
// highlight-next-line
// Update your server import like this:
// highlight-next-line
import { query, mutation } from "./_generated/server";

// ...

// highlight-next-line
// Add the following function to the file:
// highlight-next-line
export const getMessages = query({
  // highlight-next-line
  args: {},
  // highlight-next-line
  handler: async (ctx) => {
    // highlight-next-line
    // Get most recent messages first
    // highlight-next-line
    const messages = await ctx.db.query("messages").order("desc").take(50);
    // highlight-next-line
    // Reverse the list so that it's in a chronological order.
    // highlight-next-line
    return messages.reverse();
    // highlight-next-line
  },
  // highlight-next-line
});
```

Let's break this down:

1. You've added a new backend `query` function called `getMessages` and exposed
   it as a public api.
1. Since this is a query function, the `ctx.db` in this function only lets you
   read data.
1. In the first line of the `handler` you are querying the most recent 50
   messages from newest to oldest.
1. In the second line you're reversing the list using plain old TypeScript.

**Now update `src/App.tsx` to read from your query:**

```tsx
// highlight-next-line
// Update your convex/react import like this:
// highlight-next-line
import { useQuery, useMutation } from "convex/react";

//...

export default function App() {
  // highlight-next-line
  // Replace the `const messages = ...` line with the following
  // highlight-next-line
  const messages = useQuery(api.chat.getMessages);

  //...
}
```

That one `useQuery` line is doing a lot of work automatically for you. It's
telling the Convex client library to subscribe to your `getMessages` function.
Anytime there are new messages to show the query function is automatically
rerun. The result is put in `const messages` variable and React rerenders your
UI component to show the latest messages.

That's it. Now go back to your app and try sending messages.

Your app should be showing live updates as new messages arrive:

<video autoPlay playsInline muted loop width="100%">
  <source src="/img/tutorial/tut_first_query.mp4" type="video/mp4" />
  Queries hooked up and live updating to the app.
</video>

<br />
<br />
Don't believe it? Try opening two chat windows side by side and send some
messages:

<video autoPlay playsInline muted loop width="100%">
  <source src="/img/tutorial/tut_side_by_side.mp4" type="video/mp4" />
  Live syncing chat app.
</video>

## What you built

With just a few lines of code you've built a live updating chat app.

1. You created a `mutation` TypeScript function that, in a transaction, adds new
   chat messages to your database.
1. You created a `query` TypeScript function updates your app with the latest
   data.
1. You used the client library that keeps your frontend in live sync with the
   backend.

You've learned the fundamentals of Convex and the sync engine that powers
everything.

## Next up

In this tutorial we just touched on the very basics. It's ok to just stop here
and go explore the rest of the docs, including
[efficient queries via indexes](/database/reading-data/indexes/indexes.md) and
traversing
[relationships through joins](/database/reading-data/reading-data.mdx#join). If
you're deeply curious about how Convex works, you can read this
[excellent deep dive](https://stack.convex.dev/how-convex-works).

But if you want to see how to call external services and build sophisticated
backend workflows, jump into the [next section →](/tutorial/actions.mdx).

<CardLink
  className="convex-hero-card"
  item={{
    href: "/tutorial/actions",
    docId: "tutorial/actions",
    label: "Calling external services",
  }}
/>


---

# scale.mdx

<!-- Source: tutorial/scale.mdx -->

---
title: "Convex Tutorial: Scaling Your App"
sidebar_label: "3. Scaling your app"
slug: "scale"
sidebar_position: 300
hide_table_of_contents: true
---

import ComponentsIcon from "@site/static/img/sidebar-icons/components.svg";

# Convex Tutorial: Scaling your app

Convex was designed from the ground up for scale. In the previous section we
already talked about how keeping your actions small and most of your logic in
queries and mutations are crucial to building fast scalable backends.

Let's talk about a few other ways to keep your app fast and scalable.

## Indexed queries

Indexes tell the database to create a lookup structure to make it really fast to
filter data. If, in our chat app we wanted to build a way to look up `messages`
from just one user, we'd tell Convex to index the `user` field in the `messages`
table and write the query with the `withIndex` syntax.

[Learn how to use indexes](/database/reading-data/indexes/indexes.md).

## Too many writes on the same document

Let's say you decide to show a counter in your app. You may write a mutation
that reads a number field, adds 1, and updates the same field in the database.
At some point, this pattern may cause an
[optimistic concurrency control conflict](/error#1). That means that the
database isn't able to handle updating the document that fast. All databases
have trouble with this sort of pattern.

There are a [few ways to deal with this](/error#remediation), including building
something called a sharded counter...

But before you go learn advanced scaling techniques on your own, there is a
better way with Convex components.

## Scaling best practices with Convex Components

In the case of the counter above, the Convex team has already built a
[scalable counter](https://www.convex.dev/components/sharded-counter) Convex
component for you to use.

Convex components are installed in your Convex backend as an npm library. They
are sandboxed, so they can't read your app's tables or call your app's functions
unless explicitly provided.

As you build more complicated features like AI agent
[workflows](https://www.convex.dev/components/workflow),
[leaderboards](https://www.convex.dev/components/aggregate),
[feature flags](https://www.convex.dev/components/launchdarkly) or
[rate limiters](https://www.convex.dev/components/rate-limiter), you may find
that there is already a Convex component that solves this problem.

<CardLink
  className="convex-hero-card"
  item={{
    icon: <ComponentsIcon height={40} />,
    href: "https://www.convex.dev/components",
    label: "Components directory",
  }}
/>

## Wrap up

We've covered a lot of ground in this tutorial. We started by
[building a chat app](/tutorial/index.mdx) with queries, mutations and the
database that form the fundamental building blocks of the Convex sync engine. We
then called an [external API](/tutorial/actions.mdx) from our backend, using the
scheduler to coordinate the work. Finally, we learned that
[Convex components](https://www.convex.dev/components) give you scaling best
practices in neat packages.

If you are looking for more tips, read our
[best practices](/understanding/best-practices/best-practices.mdx) and join the
[community](https://www.convex.dev/community).

Convex enables you to build your MVP fast and then scale to new heights. Many
great products have already done so. You're in good company.


---

# best-practices.mdx

<!-- Source: understanding/best-practices/best-practices.mdx -->

---
title: "Best Practices"
sidebar_position: 400
toc_max_heading_level: 2
---

import BestPracticesTS from "!!raw-loader!@site/../private-demos/snippets/convex/bestPractices/index.ts";
import HelperFunctionsTS from "!!raw-loader!@site/../private-demos/snippets/convex/bestPractices/helperFunctions.ts";
import UserHelpersJS from "!!raw-loader!@site/../private-demos/snippets/convex/userHelpersJS.js";
import Teams from "!!raw-loader!@site/../private-demos/snippets/convex/bestPracticesHelpersTeams.ts";
import TeamsJS from "!!raw-loader!@site/../private-demos/snippets/convex/bestPracticesHelpersTeamsJS.js";

This is a list of best practices and common anti-patterns around using Convex.
We recommend going through this list before broadly releasing your app to
production. You may choose to try using all of these best practices from the
start, or you may wait until you've gotten major parts of your app working
before going through and adopting the best practices here.

## Await all Promises

### Why?

Convex functions use async / await. If you don't await all your promises (e.g.
`await ctx.scheduler.runAfter`, `await ctx.db.patch`), you may run into
unexpected behavior (e.g. failing to schedule a function) or miss handling
errors.

### How?

We recommend the
[no-floating-promises](https://typescript-eslint.io/rules/no-floating-promises/)
eslint rule with TypeScript.

## Avoid `.filter` on database queries

### Why?

Filtering in code instead of using the `.filter` syntax has the same
performance, and is generally easier code to write. Conditions in `.withIndex`
or `.withSearchIndex` are more efficient than `.filter` or filtering in code, so
almost all uses of `.filter` should either be replaced with a `.withIndex` or
`.withSearchIndex` condition, or written as TypeScript code.

Read through the
[indexes documentation](/database/reading-data/indexes/indexes-and-query-perf.md)
for an overview of how to define indexes and how they work.

### Examples

<TSAndJSSnippet
  title="convex/messages.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="filter"
/>

### How?

Search for `.filter` in your Convex codebase — a regex like `\.filter\(\(?q`
will probably find all the ones on database queries.

Decide whether they should be replaced with a `.withIndex` condition — per
[this section](/understanding/best-practices/best-practices.mdx#only-use-collect-with-a-small-number-of-results),
if you are filtering over a large (1000+) or potentially unbounded number of
documents, you should use an index. If not using a `.withIndex` /
`.withSearchIndex` condition, consider replacing them with a filter in code for
more readability and flexibility.

See [this article](https://stack.convex.dev/complex-filters-in-convex) for more
strategies for filtering.

### Exceptions

Using `.filter` on a paginated query (`.paginate`) has advantages over filtering
in code. The paginated query will return the number of documents requested,
including the `.filter` condition, so filtering in code afterwards can result in
a smaller page or even an empty page. Using `.withIndex` on a paginated query
will still be more efficient than a `.filter`.

## Only use `.collect` with a small number of results

### Why?

All results returned from `.collect` count towards database bandwidth (even ones
filtered out by `.filter`). It also means that if any document in the result
changes, the query will re-run or the mutation will hit a conflict.

If there's a chance the number of results is large (say 1000+ documents), you
should use an index to filter the results further before calling `.collect`, or
find some other way to avoid loading all the documents such as using pagination,
denormalizing data, or changing the product feature.

### Example

**Using an index:**

<TSAndJSSnippet
  title="convex/movies.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="collectIndex"
/>

**Using pagination:**

<TSAndJSSnippet
  title="convex/movies.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="collectPaginate"
/>

**Using a limit or denormalizing:**

<TSAndJSSnippet
  title="convex/movies.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="collectCount"
/>

### How?

Search for `.collect` in your Convex codebase (a regex like `\.collect\(` will
probably find these). And think through whether the number of results is small.
This function health page in the dashboard can also help surface these.

The [aggregate component](https://www.npmjs.com/package/@convex-dev/aggregate)
or [database triggers](https://stack.convex.dev/triggers) can be helpful
patterns for denormalizing data.

### Exceptions

If you're doing something that requires loading a large number of documents
(e.g. performing a migration, making a summary), you may want to use an action
to load them in batches via separate queries / mutations.

## Check for redundant indexes

### Why?

Indexes like `by_foo` and `by_foo_and_bar` are usually redundant (you only need
`by_foo_and_bar`). Reducing the number of indexes saves on database storage and
reduces the overhead of writing to the table.

<TSAndJSSnippet
  title="convex/teams.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="redundantIndexes"
  replacements={[[/\sOMIT_ME.*/g, ""]]}
/>

### How?

Look through your indexes, either in your `schema.ts` file or in the dashboard,
and look for any indexes where one is a prefix of another.

### Exceptions

`.index("by_foo", ["foo"])` is really an index on the properties `foo` and
`_creationTime`, while `.index("by_foo_and_bar", ["foo", "bar"])` is an index on
the properties `foo`, `bar`, and `_creationTime`. If you have queries that need
to be sorted by `foo` and then `_creationTime`, then you need both indexes.

For example, `.index("by_channel", ["channel"])` on a table of messages can be
used to query for the most recent messages in a channel, but
`.index("by_channel_and_author", ["channel", "author"])` could not be used for
this since it would first sort the messages by `author`.

## Use argument validators for all public functions

### Why?

Public functions can be called by anyone, including potentially malicious
attackers trying to break your app.
[Argument validators](/functions/validation.mdx) (as well as return value
validators) help ensure you're getting the traffic you expect.

### Example

<TSAndJSSnippet
  title="convex/messages.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="validation"
  replacements={[[/_OMIT_[0-9]+/g, ""]]}
/>

### How?

Search for `query`, `mutation`, and `action` in your Convex codebase, and ensure
that all of them have argument validators (and optionally return value
validators). If you have `httpAction`s, you may want to use something like `zod`
to validate that the HTTP request is the shape you expect.

## Use some form of access control for all public functions

### Why?

Public functions can be called by anyone, including potentially malicious
attackers trying to break your app. If portions of your app should only be
accessible when the user is signed in, make sure all these Convex functions
check that `ctx.auth.getUserIdentity()` is set.

You may also have specific checks, like only loading messages that were sent to
or from the current user, which you'll want to apply in every relevant public
function.

Favoring more granular functions like `setTeamOwner` over `updateTeam` allows
more granular checks for which users can do what.

Access control checks should either use `ctx.auth.getUserIdentity()` or a
function argument that is unguessable (e.g. a UUID, or a Convex ID, provided
that this ID is never exposed to any client but the one user). In particular,
don't use a function argument which could be spoofed (e.g. email) for access
control checks.

### Example

<TSAndJSSnippet
  title="convex/teams.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="accessControl"
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
/>

### How?

Search for `query`, `mutation`, `action`, and `httpAction` in your Convex
codebase, and ensure that all of them have some form of access control.
[Custom functions](https://github.com/get-convex/convex-helpers/blob/main/packages/convex-helpers/README.md#custom-functions)
like
[`authenticatedQuery`](https://stack.convex.dev/custom-functions#modifying-the-ctx-argument-to-a-server-function-for-user-auth)
can be helpful.

Some apps use Row Level Security (RLS) to check access to each document
automatically whenever it's loaded, as described in
[this article](https://stack.convex.dev/row-level-security). Alternatively, you
can check access in each Convex function instead of checking access for each
document.

Helper functions for common checks and common operations can also be useful --
e.g. `isTeamMember`, `isTeamAdmin`, `loadTeam` (which throws if the current user
does not have access to the team).

## Only schedule and `ctx.run*` internal functions

### Why?

Public functions can be called by anyone, including potentially malicious
attackers trying to break your app, and should be carefully audited to ensure
they can't be used maliciously. Functions that are only called within Convex can
be marked as internal, and relax these checks since Convex will ensure that
internal functions can only be called within Convex.

### How?

Search for `ctx.runQuery`, `ctx.runMutation`, and `ctx.runAction` in your Convex
codebase. Also search for `ctx.scheduler` and check the `crons.ts` file. Ensure
all of these use `internal.foo.bar` functions instead of `api.foo.bar`
functions.

If you have code you want to share between a public Convex function and an
internal Convex function, create a helper function that can be called from both.
The public function will likely have additional access control checks.

Alternatively, make sure that `api` from `_generated/api.ts` is never used in
your Convex functions directory.

### Examples

<TSAndJSSnippet
  title="convex/teams.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="internal"
  replacements={[
    [/_OMIT_[0-9]+/g, ""],
    [
      "// REPLACE_WITH_MUTATION_CTX_IMPORT",
      "import { MutationCtx } from './_generated/server';",
    ],
  ]}
/>

## Use helper functions to write shared code

### Why?

Most logic should be written as plain TypeScript functions, with the `query`,
`mutation`, and `action` wrapper functions being a thin wrapper around one or
more helper function.

Concretely, most of your code should live in a directory like `convex/model`,
and your public API, which is defined with `query`, `mutation`, and `action`,
should have very short functions that mostly just call into `convex/model`.

Organizing your code this way makes several of the refactors mentioned in this
list easier to do.

See the [TypeScript page](/understanding/best-practices/typescript.mdx) for
useful types.

### Example

**❌** This example overuses `ctx.runQuery` and `ctx.runMutation`, which is
discussed more in the
[Avoid sequential `ctx.runMutation` / `ctx.runQuery` from actions](/understanding/best-practices/best-practices.mdx#avoid-sequential-ctxrunmutation--ctxrunquery-calls-from-actions)
section.

<TSAndJSSnippet
  title="convex/users.ts"
  sourceTS={HelperFunctionsTS}
  sourceJS={HelperFunctionsTS}
  snippet="usersWrong"
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
/>

<TSAndJSSnippet
  title="convex/conversations.ts"
  sourceTS={HelperFunctionsTS}
  sourceJS={HelperFunctionsTS}
  snippet="conversationsWrong"
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
/>

**✅** Most of the code here is now in the `convex/model` directory. The API for
this application is in `convex/conversations.ts`, which contains very little
code itself.

<TSAndJSSnippet
  title="convex/model/users.ts"
  sourceTS={HelperFunctionsTS}
  sourceJS={HelperFunctionsTS}
  snippet="usersCorrect"
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
  prefix={`import { QueryCtx } from '../_generated/server';\n`}
/>

<TSAndJSSnippet
  title="convex/model/conversations.ts"
  sourceTS={HelperFunctionsTS}
  sourceJS={HelperFunctionsTS}
  snippet="conversationsModelCorrect"
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
  prefix={`import { QueryCtx, MutationCtx } from '../_generated/server';\nimport * as Users from './users';\n`}
/>

<TSAndJSSnippet
  title="convex/conversations.ts"
  sourceTS={HelperFunctionsTS}
  sourceJS={HelperFunctionsTS}
  snippet="conversationsApiCorrect"
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
  prefix={`import * as Conversations from './model/conversations';\n`}
/>

## Use `runAction` only when using a different runtime

### Why?

Calling `runAction` has more overhead than calling a plain TypeScript function.
It counts as an extra function call with its own memory and CPU usage, while the
parent action is doing nothing except waiting for the result. Therefore,
`runAction` should almost always be replaced with calling a plain TypeScript
function. However, if you want to call code that requires Node.js from a
function in the Convex runtime (e.g. using a library that requires Node.js),
then you can use `runAction` to call the Node.js code.

### Example

<TSAndJSSnippet
  title="convex/scrape.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="runAction"
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
/>

<TSAndJSSnippet
  title="convex/model/scrape.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="scrapeModel"
  prefix={`import { ActionCtx } from '../_generated/server';\n`}
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
/>

<TSAndJSSnippet
  title="convex/scrape.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="scrapeAction"
  prefix={`import * as Scrape from './model/scrape';\n`}
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
/>

### How?

Search for `runAction` in your Convex codebase, and see if the function it calls
uses the same runtime as the parent function. If so, replace the `runAction`
with a plain TypeScript function. You may want to structure your functions so
the Node.js functions are in a separate directory so it's easier to spot these.

## Avoid sequential `ctx.runMutation` / `ctx.runQuery` calls from actions

### Why?

Each `ctx.runMutation` or `ctx.runQuery` runs in its own transaction, which
means if they're called separately, they may not be consistent with each other.
If instead we call a single `ctx.runQuery` or `ctx.runMutation`, we're
guaranteed that the results we get are consistent.

### How?

Audit your calls to `ctx.runQuery` and `ctx.runMutation` in actions. If you see
multiple in a row with no other code between them, replace them with a single
`ctx.runQuery` or `ctx.runMutation` that handles both things. Refactoring your
code to use helper functions will make this easier.

### Example: Queries

<TSAndJSSnippet
  title="convex/teams.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="runQueryWrong"
/>

<TSAndJSSnippet
  title="convex/teams.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="runQueryCorrect"
  prefix={`import * as Teams from './model/teams';\nimport * as Users from './model/users';\n`}
/>

### Example: Loops

<TSAndJSSnippet
  title="convex/teams.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="runMutationWrong"
  prefix={`import * as Users from './model/users';\n`}
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
/>

<TSAndJSSnippet
  title="convex/teams.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="runMutationCorrect"
  prefix={`import * as Users from './model/users';\n`}
  replacements={[
    [/\sOMIT_ME.*/g, ""],
    [/_OMIT_[0-9]+/g, ""],
  ]}
/>

### Exceptions

If you're intentionally trying to process more data than fits in a single
transaction, like running a migration or aggregating data, then it makes sense
to have multiple sequential `ctx.runMutation` / `ctx.runQuery` calls.

Multiple `ctx.runQuery` / `ctx.runMutation` calls are often necessary because
the action does a side effect in between them. For example, reading some data,
feeding it to an external service, and then writing the result back to the
database.

## Use `ctx.runQuery` and `ctx.runMutation` sparingly in queries and mutations

### Why?

While these queries and mutations run in the same transaction, and will give
consistent results, they have extra overhead compared to plain TypeScript
functions. Wanting a TypeScript helper function is much more common than needing
`ctx.runQuery` or `ctx.runMutation`.

### How?

Audit your calls to `ctx.runQuery` and `ctx.runMutation` in queries and
mutations. Unless one of the exceptions below applies, replace them with a plain
TypeScript function.

### Exceptions

- If you're using components, these require `ctx.runQuery` or `ctx.runMutation`.
- If you want partial rollback on an error, you will want `ctx.runMutation`
  instead of a plain TypeScript function.

<TSAndJSSnippet
  title="convex/messages.ts"
  sourceTS={BestPracticesTS}
  sourceJS={BestPracticesTS}
  snippet="partialRollback"
/>


---

# other-recommendations.mdx

<!-- Source: understanding/best-practices/other-recommendations.mdx -->

---
title: "Other Recommendations"
sidebar_position: 170
sidebar_class_name: "hidden"
pagination_next: null
---

import UserHelpers from "!!raw-loader!@site/../private-demos/snippets/convex/userHelpers.ts";
import UserHelpersJS from "!!raw-loader!@site/../private-demos/snippets/convex/userHelpersJS.js";
import Teams from "!!raw-loader!@site/../private-demos/snippets/convex/bestPracticesHelpersTeams.ts";
import TeamsJS from "!!raw-loader!@site/../private-demos/snippets/convex/bestPracticesHelpersTeamsJS.js";

{/* This page was previously the Best Practices page which has been rewritten */}
{/* with some of this content dropped. We are keeping this as a hidden page that is */}
{/* still scrape-able */}

Here's a collection of our recommendations on how best to use Convex to build
your application. If you want guidance specific to your app's needs or have
discovered other ways of using Convex,
[message us on Discord](https://convex.dev/community)!

## Use [TypeScript](/understanding/best-practices/typescript.mdx)

All Convex libraries have complete type annotations and using theses types is a
great way to learn the framework.

Even better, Convex supports [code generation](/generated-api/) to create types
that are specific to your app's [schema](/database/schemas.mdx) and
[Convex functions](/functions.mdx).

Code generation is run automatically by
[`npx convex dev`](/cli.md#run-the-convex-dev-server).

## Check generated code into version control

Inside the convex folder is a `_generated/` directory containing code customized
to your convex functions. Check this folder in to your git repo. That way your
code will typecheck without needing to run `npx convex codegen` or
`npx convex dev` (which includes codegen) first.

This also allows developers to make changes to a project that uses convex by
running it against the production deployment by setting an environment variable,
without ever needing to run the Convex CLI tool. To run against a production
deployment set an environment variable like VITE_CONVEX_URL (the exact variable
name depends on the framework you use) to a production deployment URL like
`https://happy-otter-123.convex.cloud` found in project's production deployment
settings in the dashboard. Most frameworks search for variables like this in a
file called `.env` or `.env.production`.

## Functions

### Use [argument validation](/functions/validation.mdx) in all public functions.

Argument validation prevents malicious users from calling your functions with
the wrong types of arguments. It's okay to skip argument validation for
[internal functions](/functions/internal-functions.mdx) because they are not
publicly accessible.

### Use `console.log` to debug your Convex functions.

All server-side logs from Convex functions are shown on the
[dashboard Logs page](/dashboard/deployments/logs.md). If a server-side
exception occurs, it will also be logged as an error event.

On a **dev deployment** the logs will also be forwarded to the client and will
show up in the browser developer tools Console for the user who invoked the
function call, including full server error messages and server-side stack
traces.

### Use helper functions to write shared code.

Write helper functions in your `convex/` directory and use them within your
Convex functions. Helpers can be a powerful way to share business logic,
authorization code, and more.

Helper functions allow sharing code while still executing the entire query or
mutation in a single transaction. For actions, sharing code via helper functions
instead of using `ctx.runAction` reduces function calls and resource usage.

See the [TypeScript page](/understanding/best-practices/typescript.mdx) for
useful types.

<TSAndJSSnippet sourceTS={Teams} sourceJS={TeamsJS} title="convex/teams.js" />

<TSAndJSSnippet
  sourceTS={UserHelpers}
  sourceJS={UserHelpersJS}
  title="convex/userHelpers.js"
  snippet="userHelpers"
  suffix={`}`}
/>

### Prefer queries and mutations over actions

You should generally avoid using actions when the same goal can be achieved
using queries or mutations. Since actions can have side effects, they can't be
automatically retried nor their results cached. Actions should be used in more
limited scenarios, such as calling third-party services.

## Database

### Use indexes or paginate all large database queries.

[Database indexes](/database/reading-data/indexes/indexes.md) with
[range expressions](/database/reading-data/indexes/indexes.md#querying-documents-using-indexes)
allow you to write efficient database queries that only scan a small number of
documents in the table. [Pagination](/database/pagination.mdx) allows you to
quickly display incremental lists of results. If your table could contain more
than a few thousand documents, you should consider pagination or an index with a
range expression to ensure that your queries stay fast.

For more details, check out our
[Introduction to Indexes and Query Performance](/database/reading-data/indexes/indexes-and-query-perf.md)
article.

### Use tables to separate logical object types.

Even though Convex does support nested documents, it is often better to put
separate objects into separate tables and use `Id`s to create references between
them. This will give you more flexibility when loading and
[querying documents](/database/reading-data/reading-data.mdx).

You can read more about this at [Document IDs](/database/document-ids.mdx).

## UI patterns

### Check for `undefined` to determine if a query is loading.

The [`useQuery` React hook](/api/modules/react#usequery) will return `undefined`
when it is first mounted, before the query has been loaded from Convex. Once a
query is loaded it will never be `undefined` again (even as the data reactively
updates). `undefined` is not a valid return type for queries (you can see the
types that Convex supports at [Data Types](/database/types.md))

You can use this as a signal for when to render loading indicators and
placeholder UI.

### Add optimistic updates for the interactions you want to feel snappy.

By default all relevant `useQuery` hooks will update automatically after a
mutation is synced from Convex. If you would like some interactions to happen
even faster, you can add
[optimistic updates](/client/react/optimistic-updates.mdx) to your `useMutation`
calls so that the UI updates instantaneously.

### Use an exception handling service and error boundaries to manage errors.

Inevitably, your Convex functions will have bugs and hit exceptions. If you have
an exception handling service and error boundaries configured, you can ensure
that you hear about these errors and your users see appropriate UI.

See [Error Handling](/functions/error-handling/error-handling.mdx) for more
information.


---

# typescript.mdx

<!-- Source: understanding/best-practices/typescript.mdx -->

---
title: "TypeScript"
sidebar_position: 80
description: "Move faster with end-to-end type safety."
pagination_next: null
---

import ArgValidation from "!!raw-loader!@site/../private-demos/snippets/convex/typescriptWithValidation.ts";
import WithSchema from "!!raw-loader!@site/../private-demos/snippets/convex/typescriptWithSchema.ts";
import WithoutArgValidation from "!!raw-loader!@site/../private-demos/snippets/convex/typescriptWithoutValidation.ts";
import ClientDatabaseTypes from "!!raw-loader!@site/../private-demos/snippets/src/typescriptClientDatabaseTypes.tsx";
import ContextTypes from "!!raw-loader!@site/../private-demos/snippets/convex/typescriptContextTypes.ts";
import FunctionReturnTypes from "!!raw-loader!@site/../private-demos/snippets/src/typescriptFunctionReturnTypes.ts";
import ValidatorTypes from "!!raw-loader!@site/../private-demos/snippets/convex/typescriptValidatorTypes.ts";
import SystemFieldsTypes from "!!raw-loader!@site/../private-demos/snippets/convex/typescriptSystemFieldsTypes.ts";

Convex provides end-to-end type support when Convex functions are written in
[TypeScript](https://www.typescriptlang.org/).

You can gradually add TypeScript to a Convex project: the following steps
provide progressively better type support. For the best support you'll want to
complete them all.

**Example:**
[TypeScript and Schema](https://github.com/get-convex/convex-demos/tree/main/typescript)

## Writing Convex functions in TypeScript

The first step to improving type support in a Convex project is to writing your
Convex functions in TypeScript by using the `.ts` extension.

If you are using [argument validation](/functions/validation.mdx), Convex will
infer the types of your functions arguments automatically:

<Snippet title="convex/sendMessage.ts" source={ArgValidation} />

Otherwise you can annotate the arguments type manually:

<Snippet
  title="convex/sendMessage.ts"
  source={WithoutArgValidation}
  highlightPatterns={["body: string"]}
/>

This can be useful for [internal functions](/functions/internal-functions.mdx)
accepting complicated types.

If TypeScript is installed in your project `npx convex dev` and
`npx convex deploy` will typecheck Convex functions before sending code to the
Convex backend.

Convex functions are typechecked with the `tsconfig.json` in the Convex folder:
you can modify some parts of this file to change typechecking settings, or
delete this file to disable this typecheck.

You'll find most database methods have a return type of `Promise<any>` until you
add a schema.

## Adding a schema

Once you [define a schema](/database/schemas.mdx) the type signature of database
methods will be known. You'll also be able to use types imported from
`convex/_generated/dataModel` in both Convex functions and clients written in
TypeScript (React, React Native, Node.js etc.).

The types of documents in tables can be described using the
[`Doc`](/generated-api/data-model#doc) type from the generated data model and
references to documents can be described with parametrized
[Document IDs](/database/document-ids.mdx).

<Snippet title="convex/messages.ts" source={WithSchema} />

## Type annotating server-side helpers

When you want to reuse logic across Convex functions you'll want to define
helper TypeScript functions, and these might need some of the provided context,
to access the database, authentication and any other Convex feature.

Convex generates types corresponding to documents and IDs in your database,
`Doc` and `Id`, as well as `QueryCtx`, `MutationCtx` and `ActionCtx` types based
on your schema and declared Convex functions:

<Snippet title="convex/helpers.ts" source={ContextTypes} />

### Inferring types from validators

Validators can be reused between
[argument validation](/functions/validation.mdx) and
[schema validation](/database/schemas.mdx). You can use the provided
[`Infer`](/api/modules/values#infer) type to get a TypeScript type corresponding
to a validator:

<Snippet title="convex/helpers.ts" source={ValidatorTypes} />

### Document types without system fields

All documents in Convex include the built-in `_id` and `_creationTime` fields,
and so does the generated `Doc` type. When creating or updating a document you
might want use the type without the system fields. Convex provides
[`WithoutSystemFields`](/api/modules/server#withoutsystemfields) for this
purpose:

<Snippet title="convex/helpers.ts" source={SystemFieldsTypes} />

## Writing frontend code in TypeScript

All Convex JavaScript clients, including React hooks like
[`useQuery`](/api/modules/react#usequery) and
[`useMutation`](/api/modules/react#usemutation) provide end to end type safety
by ensuring that arguments and return values match the corresponding Convex
functions declarations. For React, install and configure TypeScript so you can
write your React components in `.tsx` files instead of `.jsx` files.

Follow our [React](/quickstart/react.mdx) or [Next.js](/quickstart/nextjs.mdx)
quickstart to get started with Convex and TypeScript.

### Type annotating client-side code

When you want to pass the result of calling a function around your client
codebase, you can use the generated types `Doc` and `Id`, just like on the
backend:

<Snippet title="src/App.tsx" source={ClientDatabaseTypes} />

You can also declare custom types inside your backend codebase which include
`Doc`s and `Id`s, and import them in your client-side code.

You can also use `WithoutSystemFields` and any types inferred from validators
via `Infer`.

#### Using inferred function return types

Sometimes you might want to annotate a type on the client based on whatever your
backend function returns. Beside manually declaring the type (on the backend or
on the frontend), you can use the generic `FunctionReturnType` and
`UsePaginatedQueryReturnType` types with a function reference:

<Snippet title="src/Components.tsx" source={FunctionReturnTypes} />

## Turning `string`s into valid document IDs

See [Serializing IDs](/database/document-ids.mdx#serializing-ids).

## Required TypeScript version

Convex requires TypeScript version
[5.0.3](https://www.npmjs.com/package/typescript/v/5.0.3) or newer.

<StackPosts query="types" />


---

# index.mdx

<!-- Source: understanding/index.mdx -->

---
title: "Convex Overview"
hidden: false
sidebar_position: 100
pagination_next: understanding/workflow
---

Convex is the open source, reactive database where queries are TypeScript code
running right in the database. Just like React components react to state
changes, Convex queries react to database changes.

Convex provides a database, a place to write your server functions, and client
libraries. It makes it easy to build and scale dynamic live-updating apps.

The following diagram shows the standard three-tier app architecture that Convex
enables. We'll start at the bottom and work our way up to the top of this
diagram.

<div
  className="center-image"
  style={{ maxWidth: "600px", background: "white", borderRadius: "10px" }}
>
  ![Convex in your app](/img/basic-diagram.png)
</div>

## Database

The [database](/database.mdx) is at the core of Convex. The Convex database is
automatically provisioned when you create your project. There is no connection
setup or cluster management.

<Admonition type="info">
  In Convex, your database queries are just [TypeScript
  code](/database/reading-data/reading-data.mdx) written in your [server
  functions](/functions.mdx). There is no SQL to write. There are no ORMs
  needed.
</Admonition>

The Convex database is reactive. Whenever any data on which a query depends
changes, the query is rerun, and client subscriptions are updated.

Convex is a "document-relational" database. "Document" means you put JSON-like
nested objects into your database. "Relational" means you have tables with
relations, like `tasks` assigned to a `user` using IDs to reference documents in
other tables.

The Convex cloud offering runs on top of Amazon RDS using MySQL as its
persistence layer. The Open Source version uses SQLite, Postgres and MySQL. The
database is ACID-compliant and uses
[serializable isolation and optimistic concurrency control](/database/advanced/occ.md).
All that to say, Convex provides the strictest possible transactional
guarantees, and you never see inconsistent data.

## Server functions

When you create a new Convex project, you automatically get a `convex/` folder
where you write your [server functions](/functions.mdx). This is where all your
backend application logic and database query code live.

Example TypeScript server functions that read (query) and write (mutation) to
the database.

```typescript title="convex/tasks.ts"
// A Convex query function
export const getAllOpenTasks = query({
  args: {},
  handler: async (ctx, args) => {
    // Query the database to get all items that are not completed
    const tasks = await ctx.db
      .query("tasks")
      .withIndex("by_completed", (q) => q.eq("completed", false))
      .collect();
    return tasks;
  },
});

// A Convex mutation function
export const setTaskCompleted = mutation({
  args: { taskId: v.id("tasks"), completed: v.boolean() },
  handler: async (ctx, { taskId, completed }) => {
    // Update the database using TypeScript
    await ctx.db.patch(taskId, { completed });
  },
});
```

You read and write to your database through query or mutation functions.
[Query functions](/functions/query-functions.mdx) are pure functions that can
only read from the database.
[Mutation functions](/functions/mutation-functions.mdx) are transactions that
can read or write from the database. These two database functions are
[not allowed to take any non-deterministic](/functions/runtimes.mdx#restrictions-on-queries-and-mutations)
actions like network requests to ensure transactional guarantees.

<Admonition type="info">
  The entire Convex mutation function is a transaction. There are no `begin` or
  `end` transaction statements to write. Convex automatically retries the
  function on conflicts, and you don't have to manage anything.
</Admonition>

Convex also provides standard general-purpose serverless functions called
actions. [Action functions](/functions/actions.mdx) can make network requests.
They have to call query or mutation functions to read and write to the database.
You use actions to call LLMs or send emails.

You can also durably schedule Convex functions via the
[scheduler](scheduling/scheduled-functions.mdx) or
[cron jobs](scheduling/cron-jobs.mdx). Scheduling lets you build workflows like
emailing a new user a day later if they haven't performed an onboarding task.

You call your Convex functions via [client libraries](/client/react.mdx) or
directly via [HTTP](/http-api/index.md#functions-api).

## Client libraries

Convex client libraries keep your frontend synced with the results of your
server functions.

```tsx
// In your React component
import { useQuery } from "convex/react";
import { api } from "../convex/_generated/api";

export function TaskList() {
  const data = useQuery(api.tasks.getAllOpenTasks);
  return data ?? "Loading...";
}
```

Like the `useState` hook that updates your React component when local state
changes, the Convex `useQuery` hook automatically updates your component
whenever the result of your query changes. There's no manual subscription
management or state synchronization needed.

When calling query functions, the client library subscribes to the results of
the function. Convex tracks the dependencies of your query functions, including
what data was read from the database. Whenever relevant data in the database
changes, the Convex automatically reruns the query and sends the result to the
client.

The client library also queues up mutations in memory to send to the server. As
mutations execute and cause query results to update, the client library keeps
your app state consistent. It updates all subscriptions to the same logical
moment in time in the database.

Convex provides client libraries for nearly all popular web and native app
frameworks. Client libraries connect to your Convex deployment via WebSockets.
You can then call your public Convex functions
[through the library](/client/react.mdx#fetching-data). Convex also use Convex
with [HTTP directly](/http-api/index.md#functions-api), you just won't get the
automatic subscriptions.

## Putting it all together

Let's return to the `getAllOpenTasks` Convex query function from earlier that
gets all tasks that are not marked as `completed`:

```typescript title="convex/tasks.ts"
export const getAllOpenTasks = query({
  args: {},
  handler: async (ctx, args) => {
    // Query the database to get all items that are not completed
    const tasks = await ctx.db
      .query("tasks")
      .withIndex("by_completed", (q) => q.eq("completed", false))
      .collect();
    return tasks;
  },
});
```

Let's follow along what happens when you subscribe to this query:

<div
  className="center-image"
  style={{ maxWidth: "1800px", background: "white", borderRadius: "10px" }}
>
  ![Convex data flow](/img/convex-query-subscription.png)
</div>

The web app uses the `useQuery` hook to subscribe to this query, and the
following happens to get an initial value:

- The Convex client sends a message to the Convex server to subscribe to the
  query
- The Convex server runs the function, which reads data from the database
- The Convex server sends a message to the client with the function's result

In this case the initial result looks like this (1):

```json
[
  { _id: "e4g", title: "Grocery shopping", complete: false },
  { _id: "u9v", title: "Plant new flowers", complete: false },
];
```

Then you use a mutation to mark an item as completed (2). Convex then reruns the
query (3) to get an updated result. And pushes the result to the web app via the
WebSocket connection (4):

```json
[
  { _id: "e4g", title: "Grocery shopping", complete: false },
];
```

## Beyond reactivity

Beyond reactivity, Convex's architecture is crucial for a deeper reason. Convex
does not let your app have inconsistent state at any layer of the stack.

To illustrate this, let's imagine you're building a shopping cart for an
e-commerce store.

<div className="center-image" style={{ maxWidth: "600px" }}>
  ![Convex in your app](/img/convex-swaghaus.png)
</div>

On the product listing page, you have two numbers, one showing the number of
items remaining in stock and another showing the number of items in your
shopping cart. Each number is a result of a different query function.

Every time you press the "Add to Cart" button, a mutation is called to remove
one item from the stock and add it to the shopping cart.

The mutation to change the cart runs in a transaction, so your database is
always in a consistent state. The reactive database knows that the queries
showing the number of items in stock and the number of items in the shopping
cart both need to be updated. The queries are invalidated and rerun. The results
are pushed to the web app via the WebSocket connection.

The client library makes sure that both queries update at the same time in the
web app since they reflect a singular moment in time in your database. You never
have a moment where those numbers don't add up. Your app always shows consistent
data.

You can see this example in action in the
[Swaghaus sample app](https://swaghaus.biz/).

## For human and AI generated code

Convex is designed around a small set of composable abstractions with strong
guarantees that result in code that is not only faster to write, it’s easier to
read and maintain, whether written by a team member or an LLM. Key features make
sure you get bug-free AI generated code:

1. **Queries are Just TypeScript** Your database queries are pure TypeScript
   functions with end-to-end type safety and IDE support. This means AI can
   generate database code using the large training set of TypeScript code
   without switching to SQL.
1. **Less Code for the Same Work** Since so much infrastructure and boiler plate
   is automatically manged by Convex there is less code to write, and thus less
   code to get wrong.
1. **Automatic Reactivity** The reactive system automatically tracks data
   dependencies and updates your UI. AI doesn't need to manually manage
   subscriptions, WebSocket connections, or complex state synchronization—Convex
   handles all of this automatically.
1. **Transactional Guarantees** Queries are read-only and mutations run in
   transactions. These constraints make it nearly impossible for AI to write
   code that could corrupt your data or leave your app in an inconsistent state.

Together, these features mean AI can focus on your business logic while Convex's
guarantees prevent common failure modes.

## Learn more

If you are intrigued about the details of how Convex pulls this all off, you can
read Convex co-founder Sujay's excellent
[How Convex Works](https://stack.convex.dev/how-convex-works) blog post.

Now that you have a good sense of how Convex fits in your app. Let's walk
through the overall workflow of setting up and launching a Convex app.


---

# workflow.mdx

<!-- Source: understanding/workflow.mdx -->

---
title: "Dev workflow"
hidden: false
sidebar_position: 200
---

Let's walk through everything that needs to happen from creating a new project
to launching your app in production.

This doc assumes you are building an app with Convex and React and you already
have a basic React app already up and running. You can follow one of our
[quickstarts](/quickstarts.mdx) to set this up.

## Installing and running Convex

You install Convex adding the npm dependency to your app:

```sh
npm i convex
```

Then you create your Convex project and start the backend dev loop:

```sh
npx convex dev
```

The first time you run the `npx convex dev` command you'll be asked whether you
want start developing locally without an account or create an account.

### Developing without an account

`npx convex dev` will prompt you for the name of your project, and then start
running the open-source Convex backend locally on your machine (this is also
called a "deployment").

The data for your project will be saved in the `~/.convex` directory.

1. The name of your project will get saved to your `.env.local` file so future
   runs of `npx convex dev` will know to use this project.
1. A `convex/` folder will be created (if it doesn't exist), where you'll write
   your Convex backend functions.

You can run `npx convex login` in the future to create an account and link any
existing projects.

### Developing with an account

`npx convex dev` will prompt you through creating an account if one doesn't
exist, and will add your credentials to `~/.convex/config.json` on your machine.
You can run `npx convex logout` to log you machine out of the account in the
future.

Next, `npx convex dev` will create a new project and provision a new personal
development deployment for this project:

1.  Deployment details will automatically be added to your `.env.local` file so
    future runs of `npx convex dev` will know which dev deployment to connect
    to.
1.  A `convex/` folder will be created (if it doesn't exist), where you'll write
    your Convex backend functions.

<div className="center-image" style={{ maxWidth: "149px" }}>
  ![Convex directory in your app](/img/convex-directory.png)
</div>

## Running the dev loop

Keep the `npx convex dev` command running while you're working on your Convex
app. This continuously pushes backend code you write in the `convex/` folder to
your deployment. It also keeps the necessary TypeScript types up-to-date as you
write your backend code.

When you're developing with a locally running deployment, `npx convex dev` is
also responsible for running your deployment.

You can then add new server functions to your Convex backend:

```typescript title="convex/tasks.ts"
import { query } from "./_generated/server";
import { v } from "convex/values";

// Return the last 100 tasks in a given task list.
export const getTaskList = query({
  args: { taskListId: v.id("taskLists") },
  handler: async (ctx, args) => {
    const tasks = await ctx.db
      .query("tasks")
      .withIndex("taskListId", (q) => q.eq("taskListId", args.taskListId))
      .order("desc")
      .take(100);
    return tasks;
  },
});
```

When you write and save this code in your editor, several things happen:

1. The `npx convex dev` command typechecks your code and updates the
   `convex/_generated` directory.
1. The contents of your `convex/` directory get uploaded to your dev deployment.
1. Your Convex dev deployment analyzes your code and finds all Convex functions.
   In this example, it determines that `tasks.getTaskList` is a new public query
   function.
1. If there are any changes to the [schema](/database/schemas.mdx), the
   deployment will automatically enforce them.
1. The `npx convex dev` command updates generated TypeScript code in the
   `convex/_generated` directory to provide end to end type safety for your
   functions.

<Admonition type="tip">
  Check in everything in your `convex/_generated/` directory. This it ensures
  that your code immediately type checks and runs without having to first run
  `npx convex dev`. It's particularly useful when non-backend developers are
  writing frontend code and want to ensure their code type checks against
  currently deployed backend code.
</Admonition>

Once this is done you can use your new server function in your frontend:

```typescript title="src/App.tsx"
import { useQuery } from "convex/react";
import { api } from "../convex/_generated/api";

export function App() {
  const data = useQuery(api.tasks.getTaskList);
  return data ?? "Loading...";
}
```

If you have other configuration like [crons](/scheduling/cron-jobs.mdx) or
[auth](/auth.mdx) in your `convex/` folder, Convex ensures that they are applied
and enforced on your backend.

## Convex dashboard

The [Convex dashboard](/dashboard/deployments/deployments.md) will be a trusty
helper throughout your dev, debug and deploy workflow in Convex.

`npx convex dashboard` will open a link to the dashboard for your deployment.

### Logs

Since Convex functions are TypeScript functions you can always use the standard
`console.log` and `console.time` functions to debug your apps.

Logs from your functions show up
[in your dashboard](/dashboard/deployments/logs.md).

![Logs Dashboard Page](/screenshots/logs.png)

### Health, Data, Functions and more

- [Health](/dashboard/deployments/health.md) - provides invaluable information
  on how your app is performing in production, with deep insights on how your
  Convex queries are doing.
- [Data](/dashboard/deployments/data.md) - gives you a complete data browser to
  spot check your data.
- [Functions](/dashboard/deployments/functions.md) - gives you stats and run
  functions to debug them.

There is a lot more to to the dashboard. Be sure to click around or
[check out the docs](/dashboard.md).

## Deploying your app

So far you've been working on your app against your personal dev deployment.

All Convex projects have one production deployment running in the cloud. It has
separate data and has a separate push process from personal dev deployments,
which allows you and your teammates to work on new features using personal dev
deployments without disrupting your app running in production.

If you have not created a Convex account yet, you will need to do so with
`npx convex login`. This will automatically link any projects you've started
with your new account, and enable using your production deployment.

To push your code to your production deployment for your project you run the
deploy command:

```sh
npx convex deploy
```

<Admonition type="info">
  If you're running this command for the first time, it will automatically
  provision the prod deployment for your project.
</Admonition>

### Setting up your deployment pipeline

It's rare to run `npx convex deploy` directly. Most production applications run
an automated workflow that runs tests and deploys your backend and frontend
together.

You can see detailed deployment and frontend configuration instructions in the
[Hosting and Deployment](/production/hosting/hosting.mdx) doc. For most React
meta-frameworks Convex
[automatically sets the correct environment variable](/production/hosting/vercel.mdx#how-it-works)
to connect to the production deployment.

## Up next

You now know the basics of how Convex works and fits in your app. Go head and
explore the docs further to learn more about the specific features you want to
use.

Whenever you're ready be sure the read the
[Best Practices](/understanding/best-practices/best-practices.mdx), and then the
[Zen of Convex](/understanding/zen.mdx) once you are ready to "think in Convex."


---

# zen.mdx

<!-- Source: understanding/zen.mdx -->

---
title: "The Zen of Convex"
slug: "zen"
hidden: false
sidebar_position: 500
hide_table_of_contents: true
---

export function CategoryIcon(props) {
  switch (props.title) {
    case "Performance":
      return (
        <svg
          fill="currentColor"
          viewBox="0 0 24 24"
          xmlns="http://www.w3.org/2000/svg"
          aria-hidden="true"
          {...props}
        >
          <path
            clipRule="evenodd"
            fillRule="evenodd"
            d="M14.615 1.595a.75.75 0 01.359.852L12.982 9.75h7.268a.75.75 0 01.548 1.262l-10.5 11.25a.75.75 0 01-1.272-.71l1.992-7.302H3.75a.75.75 0 01-.548-1.262l10.5-11.25a.75.75 0 01.913-.143z"
          />
        </svg>
      );
    case "Architecture":
      return (
        <svg
          fill="currentColor"
          viewBox="0 0 24 24"
          xmlns="http://www.w3.org/2000/svg"
          aria-hidden="true"
        >
          <path d="M11.584 2.376a.75.75 0 01.832 0l9 6a.75.75 0 11-.832 1.248L12 3.901 3.416 9.624a.75.75 0 01-.832-1.248l9-6z" />
          <path
            clipRule="evenodd"
            fillRule="evenodd"
            d="M20.25 10.332v9.918H21a.75.75 0 010 1.5H3a.75.75 0 010-1.5h.75v-9.918a.75.75 0 01.634-.74A49.109 49.109 0 0112 9c2.59 0 5.134.202 7.616.592a.75.75 0 01.634.74zm-7.5 2.418a.75.75 0 00-1.5 0v6.75a.75.75 0 001.5 0v-6.75zm3-.75a.75.75 0 01.75.75v6.75a.75.75 0 01-1.5 0v-6.75a.75.75 0 01.75-.75zM9 12.75a.75.75 0 00-1.5 0v6.75a.75.75 0 001.5 0v-6.75z"
          />
          <path d="M12 7.875a1.125 1.125 0 100-2.25 1.125 1.125 0 000 2.25z" />
          //{" "}
        </svg>
      );
    case "Development workflow":
      return (
        <svg
          fill="currentColor"
          viewBox="0 0 24 24"
          xmlns="http://www.w3.org/2000/svg"
          aria-hidden="true"
          {...props}
        >
          <path
            clipRule="evenodd"
            fillRule="evenodd"
            d="M2.25 6a3 3 0 013-3h13.5a3 3 0 013 3v12a3 3 0 01-3 3H5.25a3 3 0 01-3-3V6zm3.97.97a.75.75 0 011.06 0l2.25 2.25a.75.75 0 010 1.06l-2.25 2.25a.75.75 0 01-1.06-1.06l1.72-1.72-1.72-1.72a.75.75 0 010-1.06zm4.28 4.28a.75.75 0 000 1.5h3a.75.75 0 000-1.5h-3z"
          />
        </svg>
      );
    default:
      return null;
  }
}

export function ZenHeader({ title }) {
  return (
    <h2 className="zen-header">
      {title} <CategoryIcon title={title} />
    </h2>
  );
}

export function TipIcon({ type }) {
  switch (type) {
    case "do":
      return (
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          className="w-6 h-6"
        >
          <path
            fillRule="evenodd"
            d="M2.25 12c0-5.385 4.365-9.75 9.75-9.75s9.75 4.365 9.75 9.75-4.365 9.75-9.75 9.75S2.25 17.385 2.25 12zm13.36-1.814a.75.75 0 10-1.22-.872l-3.236 4.53L9.53 12.22a.75.75 0 00-1.06 1.06l2.25 2.25a.75.75 0 001.14-.094l3.75-5.25z"
            clipRule="evenodd"
          />
        </svg>
      );
    case "do-not":
      return (
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          className="w-6 h-6"
        >
          <path
            fillRule="evenodd"
            d="M9.401 3.003c1.155-2 4.043-2 5.197 0l7.355 12.748c1.154 2-.29 4.5-2.599 4.5H4.645c-2.309 0-3.752-2.5-2.598-4.5L9.4 3.003zM12 8.25a.75.75 0 01.75.75v3.75a.75.75 0 01-1.5 0V9a.75.75 0 01.75-.75zm0 8.25a.75.75 0 100-1.5.75.75 0 000 1.5z"
            clipRule="evenodd"
          />
        </svg>
      );
    default:
      return null;
  }
}

export function ZenTip({ type, title, children }) {
  return (
    <div className={`zen-tip zen-${type}`}>
      <h3>
        <TipIcon type={type} /> {title}
      </h3>
      {children}
    </div>
  );
}

<span className="convex-hero">
Convex is an opinionated framework, with every element designed to pull developers into
[the pit of success](https://blog.codinghorror.com/falling-into-the-pit-of-success/).

The Zen of Convex is a set of guidelines & best practices developers have
discovered that keep their projects falling into this wonderful pit.

</span>

<ZenHeader title="Performance" />

<ZenTip type="do" title={<span>Double down on the <a href="/tutorial#how-convex-works">sync engine</a></span>} >

    There's a reason why a deterministic, reactive database is the beating heart
    of Convex: the more you center your apps around its properties, the better
    your projects will fare over time. Your projects will be easier to
    understand and refactor. Your app's performance will stay screaming fast.
    You won't have any consistency or state management problems.

<Details summary="Use a query for nearly every app read">
  Queries are the reactive, automatically cacheable, consistent and resilient
  way to propagate data to your application and its jobs. With very few
  exceptions, every read operation in your app should happen via a query
  function.
</Details>

<Details summary="Keep sync engine functions light & fast">
  In general, your mutations and queries should be working with less than a few
  hundred records and should aim to finish in less than 100ms. It's nearly
  impossible to maintain a snappy, responsive app if your synchronous
  transactions involve a lot more work than this.
</Details>

<Details summary="Use actions sparingly and incrementally">
  Actions are wonderful for batch jobs and/or integrating with outside services.
  They're very powerful, but they're slower, more expensive, and Convex provides
  a lot fewer guarantees about their behavior. So never use an action if a query
  or mutation will get the job done.
</Details>

</ZenTip>

<ZenTip type="do-not" title="Don't over-complicate client-side state management">

Convex builds in a ton of its own caching and consistency controls into the
app's client library. Rather than reinvent the wheel, let your client-side code
take advantage of these built-in performance boosts.

<Details summary="Let Convex handle caching & consistency">

You might be tempted to quickly build your own local cache or state aggregation
layer in Convex to sit between your components and your Convex functions. With
Convex, most of the time, you won't end up needing this. More often than not,
you can bind your components to Convex functions in pretty simple ways and
things will Just Work and be plenty fast.

</Details>

<Details summary="Be thoughtful about the return values of mutations">
  Mutation return values can be useful to trigger state changes in your app, but
  it's rarely a good idea to use them to set in-app state to update the UI. Let
  queries and the sync engine do that.
</Details>

</ZenTip>

<ZenHeader title="Architecture" />

<ZenTip type="do" title='Create server-side frameworks using "just code"'>
  <p>
    Convex's built-in primitives are pretty low level! They're just functions.
    What about authentication frameworks? What about object-relational mappings?
    Do you need to wait until Convex ships some in-built feature to get those?
    Nope. In general, you should solve composition and encapsulation problems in
    your server-side Convex code using the same methods you use for the rest of
    your TypeScript code bases. After all, this is why Convex is "just code!"
    [Stack](https://stack.convex.dev) always has
    [great](https://stack.convex.dev/functional-relationships-helpers)
    [examples](https://stack.convex.dev/wrappers-as-middleware-authentication)
    of ways to tackle [these
    needs](https://stack.convex.dev/row-level-security).
  </p>
</ZenTip>

<ZenTip type="do-not" title="Don't misuse actions" >

Actions are powerful, but it's important to be intentional in how they fit into
your app's data flow.

<Details summary="Don't invoke actions directly from your app">
  In general, it's an anti-pattern to call actions from the browser. Usually,
  actions are running on some dependent record that should be living in a Convex
  table. So it's best trigger actions by invoking a mutation that both _writes_
  that dependent record and _schedules_ the subsequent action to run in the
  background.
</Details>

<Details summary="Don't think 'background jobs', think 'workflow'">
   When actions are involved, it's useful to write chains of effects and
   mutations, such as:

action code &rarr; mutation &rarr; more action code &rarr; mutation.

Then apps or other jobs can follow along with queries.

</Details>

<Details summary="Record progress one step at a time">
  While actions _could_ work with thousands of records and call dozens of APIs,
  it's normally best to do smaller batches of work and/or to perform individual
  transformations with outside services. Then record your progress with a
  mutation, of course. Using this pattern makes it easy to debug issues, resume
  partial jobs, and report incremental progress in your app's UI.
</Details>

</ZenTip>

<ZenHeader title="Development workflow" />

<ZenTip type="do" title="Keep the dashboard by your side">
  <p>
    Working on your Convex project without using the dashboard is like driving a
    car with your eyes closed. The dashboard lets you view logs, give
    mutations/queries/actions a test run, make sure your configuration and
    codebase are as you expect, inspect your tables, generate schemas, etc. It's
    an invaluable part of your rapid development cycle.
  </p>
</ZenTip>

<ZenTip type="do-not" title="Don't go it alone" >

  <p>
    Between these [docs](https://docs.convex.dev),
    [Stack](https://stack.convex.dev), and [our
    community](https://convex.dev/community), someone has _probably_ encountered
    the design or architectural issue you're facing. So why try to figure things out the hard way, when you can take advantage of a whole community's experience?
   </p>
  
  <Details summary="Leverage Convex developer search">
  With so many great resources from the Convex team & community, it can be hard to know where to look first. If you want a quick way to
    search across all of these, [we have a portal for
    that](https://search.convex.dev)!
  </Details>
   
  <Details summary="Join the Convex community">
  Whether you're stuck on a tricky use case, you have a question or feature request for the Convex team, or you're excited to share the amazing app(s) you've built and help others learn, the Convex community is there for you! Join the party on [Discord](https://convex.dev/community).
  </Details>
</ZenTip>


---

